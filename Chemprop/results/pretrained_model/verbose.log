Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9872, lr_0 = 3.0475e-04
Loss = 1.4487e+00, PNorm = 34.0770, GNorm = 2.0191, lr_0 = 3.2725e-04
Loss = 1.1913e+00, PNorm = 34.0841, GNorm = 1.2119, lr_0 = 3.4975e-04
Loss = 1.4935e+00, PNorm = 34.0956, GNorm = 6.5507, lr_0 = 3.7225e-04
Loss = 1.3780e+00, PNorm = 34.1090, GNorm = 0.8872, lr_0 = 3.9475e-04
Loss = 1.2917e+00, PNorm = 34.1167, GNorm = 4.5210, lr_0 = 4.1725e-04
Loss = 1.2137e+00, PNorm = 34.1218, GNorm = 2.5117, lr_0 = 4.3975e-04
Loss = 1.4005e+00, PNorm = 34.1337, GNorm = 1.0219, lr_0 = 4.6225e-04
Loss = 1.4215e+00, PNorm = 34.1523, GNorm = 3.1036, lr_0 = 4.8475e-04
Loss = 1.2907e+00, PNorm = 34.1736, GNorm = 7.7724, lr_0 = 5.0725e-04
Loss = 1.3125e+00, PNorm = 34.1881, GNorm = 1.1320, lr_0 = 5.2975e-04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9871, lr_0 = 3.0475e-04
Loss = 1.4488e+00, PNorm = 34.0770, GNorm = 2.0192, lr_0 = 3.2725e-04
Loss = 1.1913e+00, PNorm = 34.0841, GNorm = 1.2117, lr_0 = 3.4975e-04
Loss = 1.4935e+00, PNorm = 34.0956, GNorm = 6.5480, lr_0 = 3.7225e-04
Loss = 1.3781e+00, PNorm = 34.1090, GNorm = 0.8827, lr_0 = 3.9475e-04
Loss = 1.2924e+00, PNorm = 34.1167, GNorm = 4.5561, lr_0 = 4.1725e-04
Loss = 1.2141e+00, PNorm = 34.1218, GNorm = 2.5106, lr_0 = 4.3975e-04
Loss = 1.3994e+00, PNorm = 34.1336, GNorm = 1.0422, lr_0 = 4.6225e-04
Loss = 1.4202e+00, PNorm = 34.1526, GNorm = 3.1622, lr_0 = 4.8475e-04
Loss = 1.2899e+00, PNorm = 34.1747, GNorm = 6.9020, lr_0 = 5.0725e-04
Loss = 1.3126e+00, PNorm = 34.1897, GNorm = 1.2044, lr_0 = 5.2975e-04
Loss = 1.0931e+00, PNorm = 34.2106, GNorm = 2.9813, lr_0 = 5.5225e-04
Loss = 6.5340e-01, PNorm = 34.2123, GNorm = 2.8982, lr_0 = 5.5450e-04
Validation rmse = 1.205578
Epoch 1
Loss = 1.1234e+00, PNorm = 34.2219, GNorm = 0.7689, lr_0 = 5.7700e-04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9871, lr_0 = 3.0475e-04
Loss = 1.4488e+00, PNorm = 34.0770, GNorm = 2.0192, lr_0 = 3.2725e-04
Loss = 1.1913e+00, PNorm = 34.0841, GNorm = 1.2117, lr_0 = 3.4975e-04
Loss = 1.4935e+00, PNorm = 34.0956, GNorm = 6.5480, lr_0 = 3.7225e-04
Loss = 1.3781e+00, PNorm = 34.1090, GNorm = 0.8827, lr_0 = 3.9475e-04
Loss = 1.2924e+00, PNorm = 34.1167, GNorm = 4.5561, lr_0 = 4.1725e-04
Loss = 1.2141e+00, PNorm = 34.1218, GNorm = 2.5106, lr_0 = 4.3975e-04
Loss = 1.3994e+00, PNorm = 34.1336, GNorm = 1.0422, lr_0 = 4.6225e-04
Loss = 1.4202e+00, PNorm = 34.1526, GNorm = 3.1622, lr_0 = 4.8475e-04
Loss = 1.2899e+00, PNorm = 34.1747, GNorm = 6.9018, lr_0 = 5.0725e-04
Loss = 1.3126e+00, PNorm = 34.1897, GNorm = 1.2000, lr_0 = 5.2975e-04
Loss = 1.0930e+00, PNorm = 34.2107, GNorm = 2.9709, lr_0 = 5.5225e-04
Loss = 6.5299e-01, PNorm = 34.2123, GNorm = 2.8557, lr_0 = 5.5450e-04
Validation rmse = 1.205432
Epoch 1
Loss = 1.1240e+00, PNorm = 34.2221, GNorm = 0.7680, lr_0 = 5.7700e-04
Loss = 1.3899e+00, PNorm = 34.2383, GNorm = 3.0294, lr_0 = 5.9950e-04
Loss = 1.1687e+00, PNorm = 34.2568, GNorm = 4.9596, lr_0 = 6.2200e-04
Loss = 1.1754e+00, PNorm = 34.2715, GNorm = 1.1486, lr_0 = 6.4450e-04
Loss = 1.2759e+00, PNorm = 34.2819, GNorm = 3.1983, lr_0 = 6.6700e-04
Loss = 1.2107e+00, PNorm = 34.2975, GNorm = 2.7554, lr_0 = 6.8950e-04
Loss = 1.1797e+00, PNorm = 34.3182, GNorm = 2.1497, lr_0 = 7.1200e-04
Loss = 1.2630e+00, PNorm = 34.3370, GNorm = 3.6643, lr_0 = 7.3450e-04
Loss = 1.1942e+00, PNorm = 34.3631, GNorm = 1.3334, lr_0 = 7.5700e-04
Loss = 1.2763e+00, PNorm = 34.4031, GNorm = 1.2526, lr_0 = 7.7950e-04
Loss = 1.1636e+00, PNorm = 34.4345, GNorm = 1.4960, lr_0 = 8.0200e-04
Loss = 1.2095e+00, PNorm = 34.4600, GNorm = 1.9382, lr_0 = 8.2450e-04
Loss = 1.3340e+00, PNorm = 34.5042, GNorm = 1.8290, lr_0 = 8.4700e-04
Loss = 1.4304e+00, PNorm = 34.5422, GNorm = 2.4605, lr_0 = 8.6950e-04
Loss = 1.2067e+00, PNorm = 34.5950, GNorm = 1.0352, lr_0 = 8.9200e-04
Loss = 1.2681e+00, PNorm = 34.6336, GNorm = 1.1536, lr_0 = 9.1450e-04
Loss = 1.2547e+00, PNorm = 34.6637, GNorm = 1.0104, lr_0 = 9.3700e-04
Loss = 1.1682e+00, PNorm = 34.6896, GNorm = 1.0699, lr_0 = 9.5950e-04
Loss = 1.1565e+00, PNorm = 34.7130, GNorm = 1.6275, lr_0 = 9.8200e-04
Loss = 1.1903e+00, PNorm = 34.7445, GNorm = 0.9597, lr_0 = 9.9918e-04
Loss = 4.6107e+00, PNorm = 34.7468, GNorm = 17.9484, lr_0 = 9.9877e-04
Validation rmse = 1.124442
Epoch 2
Loss = 1.3721e+00, PNorm = 34.7956, GNorm = 0.4678, lr_0 = 9.9467e-04
Loss = 1.2739e+00, PNorm = 34.8535, GNorm = 0.9879, lr_0 = 9.9059e-04
Loss = 1.1104e+00, PNorm = 34.9046, GNorm = 1.7285, lr_0 = 9.8652e-04
Loss = 1.3002e+00, PNorm = 34.9373, GNorm = 0.6354, lr_0 = 9.8247e-04
Loss = 1.2032e+00, PNorm = 34.9726, GNorm = 0.9419, lr_0 = 9.7844e-04
Loss = 1.1538e+00, PNorm = 35.0093, GNorm = 1.3736, lr_0 = 9.7443e-04
Loss = 1.0364e+00, PNorm = 35.0358, GNorm = 1.1120, lr_0 = 9.7043e-04
Loss = 1.2870e+00, PNorm = 35.0526, GNorm = 0.7166, lr_0 = 9.6645e-04
Loss = 1.1424e+00, PNorm = 35.0683, GNorm = 0.7976, lr_0 = 9.6248e-04
Loss = 1.1343e+00, PNorm = 35.0957, GNorm = 1.2417, lr_0 = 9.5853e-04
Loss = 1.2395e+00, PNorm = 35.1232, GNorm = 3.9323, lr_0 = 9.5460e-04
Loss = 1.1575e+00, PNorm = 35.1381, GNorm = 0.6612, lr_0 = 9.5068e-04
Loss = 1.2343e+00, PNorm = 35.1614, GNorm = 0.5493, lr_0 = 9.4678e-04
Loss = 1.1496e+00, PNorm = 35.1923, GNorm = 0.5128, lr_0 = 9.4290e-04
Loss = 1.1830e+00, PNorm = 35.2164, GNorm = 1.2079, lr_0 = 9.3903e-04
Loss = 1.3031e+00, PNorm = 35.2407, GNorm = 0.7813, lr_0 = 9.3517e-04
Loss = 1.0858e+00, PNorm = 35.2635, GNorm = 0.6147, lr_0 = 9.3134e-04
Loss = 1.1868e+00, PNorm = 35.2908, GNorm = 0.6035, lr_0 = 9.2752e-04
Loss = 1.0822e+00, PNorm = 35.3168, GNorm = 1.3128, lr_0 = 9.2371e-04
Loss = 1.0989e+00, PNorm = 35.3551, GNorm = 2.9021, lr_0 = 9.1992e-04
Loss = 5.4881e-01, PNorm = 35.3590, GNorm = 1.3753, lr_0 = 9.1954e-04
Validation rmse = 1.075992
Epoch 3
Loss = 1.1651e+00, PNorm = 35.3876, GNorm = 0.8200, lr_0 = 9.1577e-04
Loss = 1.0935e+00, PNorm = 35.4291, GNorm = 1.5164, lr_0 = 9.1201e-04
Loss = 1.2451e+00, PNorm = 35.4558, GNorm = 0.9772, lr_0 = 9.0827e-04
Loss = 1.0775e+00, PNorm = 35.4858, GNorm = 1.5370, lr_0 = 9.0454e-04
Loss = 1.0732e+00, PNorm = 35.5098, GNorm = 0.4513, lr_0 = 9.0083e-04
Loss = 1.0970e+00, PNorm = 35.5515, GNorm = 1.2639, lr_0 = 8.9713e-04
Loss = 1.1262e+00, PNorm = 35.5922, GNorm = 0.6643, lr_0 = 8.9345e-04
Loss = 1.1262e+00, PNorm = 35.6333, GNorm = 4.0875, lr_0 = 8.8979e-04
Loss = 1.2332e+00, PNorm = 35.6608, GNorm = 1.0796, lr_0 = 8.8614e-04
Loss = 1.0913e+00, PNorm = 35.7106, GNorm = 2.1820, lr_0 = 8.8250e-04
Loss = 1.1295e+00, PNorm = 35.7533, GNorm = 1.0019, lr_0 = 8.7888e-04
Loss = 1.1628e+00, PNorm = 35.7946, GNorm = 1.4105, lr_0 = 8.7527e-04
Loss = 1.2086e+00, PNorm = 35.8264, GNorm = 1.0876, lr_0 = 8.7168e-04
Loss = 1.1679e+00, PNorm = 35.8548, GNorm = 0.7984, lr_0 = 8.6810e-04
Loss = 1.2269e+00, PNorm = 35.8794, GNorm = 1.2802, lr_0 = 8.6454e-04
Loss = 1.2327e+00, PNorm = 35.9063, GNorm = 1.5978, lr_0 = 8.6099e-04
Loss = 1.0617e+00, PNorm = 35.9279, GNorm = 1.4467, lr_0 = 8.5746e-04
Loss = 9.3895e-01, PNorm = 35.9633, GNorm = 1.7805, lr_0 = 8.5394e-04
Loss = 1.0484e+00, PNorm = 35.9929, GNorm = 0.9595, lr_0 = 8.5044e-04
Loss = 1.0924e+00, PNorm = 36.0158, GNorm = 2.0601, lr_0 = 8.4695e-04
Loss = 5.9208e-01, PNorm = 36.0185, GNorm = 1.8386, lr_0 = 8.4660e-04
Validation rmse = 1.054344
Epoch 4
Loss = 9.9987e-01, PNorm = 36.0416, GNorm = 0.8462, lr_0 = 8.4313e-04
Loss = 1.1496e+00, PNorm = 36.0733, GNorm = 0.9571, lr_0 = 8.3967e-04
Loss = 1.1407e+00, PNorm = 36.1195, GNorm = 2.1989, lr_0 = 8.3622e-04
Loss = 1.2128e+00, PNorm = 36.1662, GNorm = 1.3006, lr_0 = 8.3279e-04
Loss = 1.1744e+00, PNorm = 36.2178, GNorm = 0.6454, lr_0 = 8.2937e-04
Loss = 1.0922e+00, PNorm = 36.2601, GNorm = 3.0756, lr_0 = 8.2597e-04
Loss = 1.0835e+00, PNorm = 36.3058, GNorm = 2.3190, lr_0 = 8.2258e-04
Loss = 1.0940e+00, PNorm = 36.3438, GNorm = 1.0190, lr_0 = 8.1921e-04
Loss = 1.0918e+00, PNorm = 36.3940, GNorm = 1.9278, lr_0 = 8.1584e-04
Loss = 1.0618e+00, PNorm = 36.4151, GNorm = 1.6698, lr_0 = 8.1250e-04
Loss = 1.0637e+00, PNorm = 36.4422, GNorm = 1.0601, lr_0 = 8.0916e-04
Loss = 1.0158e+00, PNorm = 36.4753, GNorm = 1.2900, lr_0 = 8.0584e-04
Loss = 1.2832e+00, PNorm = 36.5156, GNorm = 3.1934, lr_0 = 8.0254e-04
Loss = 1.0725e+00, PNorm = 36.5524, GNorm = 1.2638, lr_0 = 7.9924e-04
Loss = 9.9005e-01, PNorm = 36.6072, GNorm = 1.7268, lr_0 = 7.9596e-04
Loss = 1.1348e+00, PNorm = 36.6364, GNorm = 3.4536, lr_0 = 7.9270e-04
Loss = 1.0581e+00, PNorm = 36.6690, GNorm = 1.2355, lr_0 = 7.8944e-04
Loss = 1.0263e+00, PNorm = 36.6940, GNorm = 1.7169, lr_0 = 7.8620e-04
Loss = 1.0124e+00, PNorm = 36.7219, GNorm = 2.1184, lr_0 = 7.8298e-04
Loss = 1.0565e+00, PNorm = 36.7590, GNorm = 2.6532, lr_0 = 7.7977e-04
Loss = 5.2330e-01, PNorm = 36.7626, GNorm = 3.9402, lr_0 = 7.7945e-04
Validation rmse = 0.988893
Epoch 5
Loss = 1.0265e+00, PNorm = 36.8223, GNorm = 1.5218, lr_0 = 7.7625e-04
Loss = 1.0614e+00, PNorm = 36.8417, GNorm = 1.1657, lr_0 = 7.7306e-04
Loss = 1.0620e+00, PNorm = 36.8826, GNorm = 1.3889, lr_0 = 7.6989e-04
Loss = 1.1298e+00, PNorm = 36.9229, GNorm = 0.9107, lr_0 = 7.6673e-04
Loss = 1.1091e+00, PNorm = 36.9633, GNorm = 3.3360, lr_0 = 7.6358e-04
Loss = 9.9162e-01, PNorm = 37.0009, GNorm = 1.3048, lr_0 = 7.6045e-04
Loss = 1.0952e+00, PNorm = 37.0381, GNorm = 1.7219, lr_0 = 7.5733e-04
Loss = 1.0433e+00, PNorm = 37.0755, GNorm = 1.7917, lr_0 = 7.5422e-04
Loss = 1.0858e+00, PNorm = 37.1115, GNorm = 3.4988, lr_0 = 7.5113e-04
Loss = 9.4120e-01, PNorm = 37.1407, GNorm = 1.1063, lr_0 = 7.4805e-04
Loss = 1.1666e+00, PNorm = 37.1740, GNorm = 2.4911, lr_0 = 7.4498e-04
Loss = 9.6637e-01, PNorm = 37.2095, GNorm = 2.0225, lr_0 = 7.4192e-04
Loss = 1.0277e+00, PNorm = 37.2382, GNorm = 1.1513, lr_0 = 7.3888e-04
Loss = 1.1950e+00, PNorm = 37.2636, GNorm = 3.8311, lr_0 = 7.3584e-04
Loss = 1.0823e+00, PNorm = 37.2882, GNorm = 1.8783, lr_0 = 7.3282e-04
Loss = 1.0289e+00, PNorm = 37.3171, GNorm = 1.3289, lr_0 = 7.2982e-04
Loss = 9.7458e-01, PNorm = 37.3241, GNorm = 0.9672, lr_0 = 7.2682e-04
Loss = 1.0536e+00, PNorm = 37.3452, GNorm = 1.7096, lr_0 = 7.2384e-04
Loss = 1.0117e+00, PNorm = 37.3850, GNorm = 2.9065, lr_0 = 7.2087e-04
Loss = 1.1612e+00, PNorm = 37.4276, GNorm = 0.6809, lr_0 = 7.1791e-04
Loss = 7.2669e-01, PNorm = 37.4312, GNorm = 4.9914, lr_0 = 7.1762e-04
Validation rmse = 0.990147
Epoch 6
Loss = 9.8550e-01, PNorm = 37.4653, GNorm = 2.4843, lr_0 = 7.1467e-04
Loss = 1.0461e+00, PNorm = 37.4858, GNorm = 1.9496, lr_0 = 7.1174e-04
Loss = 9.8932e-01, PNorm = 37.5078, GNorm = 1.3924, lr_0 = 7.0882e-04
Loss = 1.1006e+00, PNorm = 37.5487, GNorm = 1.6144, lr_0 = 7.0591e-04
Loss = 1.0355e+00, PNorm = 37.5845, GNorm = 2.6420, lr_0 = 7.0301e-04
Loss = 9.8202e-01, PNorm = 37.6295, GNorm = 1.1769, lr_0 = 7.0013e-04
Loss = 9.4442e-01, PNorm = 37.6617, GNorm = 1.0212, lr_0 = 6.9726e-04
Loss = 1.0194e+00, PNorm = 37.6942, GNorm = 2.3002, lr_0 = 6.9440e-04
Loss = 9.5713e-01, PNorm = 37.7275, GNorm = 2.6035, lr_0 = 6.9155e-04
Loss = 9.9270e-01, PNorm = 37.7439, GNorm = 0.9388, lr_0 = 6.8871e-04
Loss = 1.0227e+00, PNorm = 37.7711, GNorm = 2.6344, lr_0 = 6.8588e-04
Loss = 1.0425e+00, PNorm = 37.7964, GNorm = 1.9701, lr_0 = 6.8307e-04
Loss = 1.0331e+00, PNorm = 37.8235, GNorm = 1.4191, lr_0 = 6.8027e-04
Loss = 9.7602e-01, PNorm = 37.8603, GNorm = 1.5615, lr_0 = 6.7747e-04
Loss = 9.0506e-01, PNorm = 37.8930, GNorm = 1.7111, lr_0 = 6.7469e-04
Loss = 9.0282e-01, PNorm = 37.9333, GNorm = 1.7745, lr_0 = 6.7193e-04
Loss = 1.0815e+00, PNorm = 37.9546, GNorm = 3.3238, lr_0 = 6.6917e-04
Loss = 1.0416e+00, PNorm = 37.9755, GNorm = 0.9830, lr_0 = 6.6642e-04
Loss = 8.8374e-01, PNorm = 38.0205, GNorm = 1.3378, lr_0 = 6.6369e-04
Loss = 9.8886e-01, PNorm = 38.0548, GNorm = 1.6151, lr_0 = 6.6097e-04
Loss = 5.0991e-01, PNorm = 38.0575, GNorm = 1.5272, lr_0 = 6.6069e-04
Validation rmse = 0.898907
Epoch 7
Loss = 1.0592e+00, PNorm = 38.0887, GNorm = 1.4429, lr_0 = 6.5798e-04
Loss = 9.9836e-01, PNorm = 38.1302, GNorm = 1.2308, lr_0 = 6.5528e-04
Loss = 9.0178e-01, PNorm = 38.1695, GNorm = 1.4064, lr_0 = 6.5259e-04
Loss = 1.0131e+00, PNorm = 38.1989, GNorm = 4.5840, lr_0 = 6.4992e-04
Loss = 1.0038e+00, PNorm = 38.2218, GNorm = 1.7950, lr_0 = 6.4725e-04
Loss = 9.2439e-01, PNorm = 38.2432, GNorm = 1.9619, lr_0 = 6.4459e-04
Loss = 9.6661e-01, PNorm = 38.2926, GNorm = 3.9877, lr_0 = 6.4195e-04
Loss = 9.5473e-01, PNorm = 38.3362, GNorm = 3.8609, lr_0 = 6.3931e-04
Loss = 8.5950e-01, PNorm = 38.3763, GNorm = 2.2665, lr_0 = 6.3669e-04
Loss = 8.9095e-01, PNorm = 38.4099, GNorm = 1.1561, lr_0 = 6.3408e-04
Loss = 8.9530e-01, PNorm = 38.4542, GNorm = 3.0165, lr_0 = 6.3148e-04
Loss = 9.2047e-01, PNorm = 38.4926, GNorm = 2.7866, lr_0 = 6.2889e-04
Loss = 1.0154e+00, PNorm = 38.5231, GNorm = 2.8030, lr_0 = 6.2630e-04
Loss = 1.0163e+00, PNorm = 38.5553, GNorm = 1.6847, lr_0 = 6.2373e-04
Loss = 9.7826e-01, PNorm = 38.5747, GNorm = 2.8707, lr_0 = 6.2118e-04
Loss = 9.8801e-01, PNorm = 38.5989, GNorm = 1.2590, lr_0 = 6.1863e-04
Loss = 9.4240e-01, PNorm = 38.6223, GNorm = 3.3093, lr_0 = 6.1609e-04
Loss = 9.2249e-01, PNorm = 38.6494, GNorm = 2.4652, lr_0 = 6.1356e-04
Loss = 1.0614e+00, PNorm = 38.6889, GNorm = 1.6193, lr_0 = 6.1104e-04
Loss = 9.3052e-01, PNorm = 38.7257, GNorm = 2.1064, lr_0 = 6.0854e-04
Loss = 9.4913e-01, PNorm = 38.7285, GNorm = 5.9696, lr_0 = 6.0829e-04
Validation rmse = 0.899934
Epoch 8
Loss = 1.0007e+00, PNorm = 38.7577, GNorm = 1.4284, lr_0 = 6.0579e-04
Loss = 9.6519e-01, PNorm = 38.7849, GNorm = 3.6397, lr_0 = 6.0330e-04
Loss = 9.7702e-01, PNorm = 38.8179, GNorm = 2.8433, lr_0 = 6.0083e-04
Loss = 9.0895e-01, PNorm = 38.8536, GNorm = 1.3993, lr_0 = 5.9836e-04
Loss = 8.7715e-01, PNorm = 38.8863, GNorm = 2.2024, lr_0 = 5.9591e-04
Loss = 9.4723e-01, PNorm = 38.9131, GNorm = 4.5690, lr_0 = 5.9346e-04
Loss = 6.9960e-01, PNorm = 38.9272, GNorm = 1.4775, lr_0 = 5.9103e-04
Loss = 9.3296e-01, PNorm = 38.9677, GNorm = 6.3310, lr_0 = 5.8860e-04
Loss = 1.0240e+00, PNorm = 39.0004, GNorm = 1.8411, lr_0 = 5.8619e-04
Loss = 8.8697e-01, PNorm = 39.0273, GNorm = 1.7670, lr_0 = 5.8378e-04
Loss = 1.0803e+00, PNorm = 39.0410, GNorm = 2.3032, lr_0 = 5.8139e-04
Loss = 9.8587e-01, PNorm = 39.0536, GNorm = 1.3736, lr_0 = 5.7900e-04
Loss = 1.0058e+00, PNorm = 39.0774, GNorm = 0.9818, lr_0 = 5.7662e-04
Loss = 9.9070e-01, PNorm = 39.1102, GNorm = 2.4608, lr_0 = 5.7426e-04
Loss = 8.5971e-01, PNorm = 39.1203, GNorm = 2.9915, lr_0 = 5.7190e-04
Loss = 8.7967e-01, PNorm = 39.1413, GNorm = 4.1103, lr_0 = 5.6956e-04
Loss = 7.6684e-01, PNorm = 39.1705, GNorm = 1.8757, lr_0 = 5.6722e-04
Loss = 7.9399e-01, PNorm = 39.2021, GNorm = 3.2788, lr_0 = 5.6489e-04
Loss = 9.6677e-01, PNorm = 39.2261, GNorm = 3.9591, lr_0 = 5.6257e-04
Loss = 9.5850e-01, PNorm = 39.2488, GNorm = 2.1211, lr_0 = 5.6026e-04
Loss = 1.9439e+00, PNorm = 39.2523, GNorm = 2.7358, lr_0 = 5.6003e-04
Validation rmse = 0.851189
Epoch 9
Loss = 8.9011e-01, PNorm = 39.2830, GNorm = 2.5468, lr_0 = 5.5774e-04
Loss = 7.6638e-01, PNorm = 39.3165, GNorm = 3.5814, lr_0 = 5.5545e-04
Loss = 9.2144e-01, PNorm = 39.3475, GNorm = 6.6069, lr_0 = 5.5317e-04
Loss = 7.9416e-01, PNorm = 39.3704, GNorm = 2.1988, lr_0 = 5.5090e-04
Loss = 9.8255e-01, PNorm = 39.3923, GNorm = 2.0260, lr_0 = 5.4864e-04
Loss = 8.2851e-01, PNorm = 39.4165, GNorm = 2.2153, lr_0 = 5.4639e-04
Loss = 8.6316e-01, PNorm = 39.4495, GNorm = 1.7229, lr_0 = 5.4414e-04
Loss = 8.4632e-01, PNorm = 39.4765, GNorm = 4.6861, lr_0 = 5.4191e-04
Loss = 9.4789e-01, PNorm = 39.4951, GNorm = 1.7513, lr_0 = 5.3969e-04
Loss = 8.1099e-01, PNorm = 39.5225, GNorm = 2.0123, lr_0 = 5.3747e-04
Loss = 8.3642e-01, PNorm = 39.5511, GNorm = 2.7681, lr_0 = 5.3527e-04
Loss = 8.1034e-01, PNorm = 39.5744, GNorm = 2.2670, lr_0 = 5.3307e-04
Loss = 8.1487e-01, PNorm = 39.6095, GNorm = 2.0076, lr_0 = 5.3088e-04
Loss = 9.0986e-01, PNorm = 39.6182, GNorm = 2.5724, lr_0 = 5.2871e-04
Loss = 8.6463e-01, PNorm = 39.6394, GNorm = 1.5145, lr_0 = 5.2654e-04
Loss = 1.0169e+00, PNorm = 39.6711, GNorm = 3.4248, lr_0 = 5.2438e-04
Loss = 1.0312e+00, PNorm = 39.6995, GNorm = 2.1816, lr_0 = 5.2222e-04
Loss = 8.4849e-01, PNorm = 39.7286, GNorm = 3.2227, lr_0 = 5.2008e-04
Loss = 7.8875e-01, PNorm = 39.7444, GNorm = 1.3890, lr_0 = 5.1795e-04
Loss = 8.8717e-01, PNorm = 39.7680, GNorm = 3.2223, lr_0 = 5.1582e-04
Validation rmse = 0.848184
Epoch 10
Loss = 7.9525e-01, PNorm = 39.8007, GNorm = 4.5986, lr_0 = 5.1371e-04
Loss = 9.0712e-01, PNorm = 39.8214, GNorm = 6.6718, lr_0 = 5.1160e-04
Loss = 9.3556e-01, PNorm = 39.8423, GNorm = 1.3970, lr_0 = 5.0950e-04
Loss = 8.5727e-01, PNorm = 39.8673, GNorm = 1.5274, lr_0 = 5.0741e-04
Loss = 8.5462e-01, PNorm = 39.8890, GNorm = 1.5745, lr_0 = 5.0533e-04
Loss = 8.9665e-01, PNorm = 39.9072, GNorm = 1.7169, lr_0 = 5.0325e-04
Loss = 9.6383e-01, PNorm = 39.9292, GNorm = 3.7819, lr_0 = 5.0119e-04
Loss = 7.5648e-01, PNorm = 39.9532, GNorm = 2.0931, lr_0 = 4.9913e-04
Loss = 9.9998e-01, PNorm = 39.9810, GNorm = 1.5810, lr_0 = 4.9708e-04
Loss = 8.0860e-01, PNorm = 40.0040, GNorm = 2.5113, lr_0 = 4.9504e-04
Loss = 8.3475e-01, PNorm = 40.0178, GNorm = 2.0537, lr_0 = 4.9301e-04
Loss = 7.7579e-01, PNorm = 40.0467, GNorm = 1.8733, lr_0 = 4.9099e-04
Loss = 7.5269e-01, PNorm = 40.0686, GNorm = 3.0649, lr_0 = 4.8897e-04
Loss = 7.9810e-01, PNorm = 40.0913, GNorm = 5.3096, lr_0 = 4.8697e-04
Loss = 8.3886e-01, PNorm = 40.1106, GNorm = 1.1801, lr_0 = 4.8497e-04
Loss = 8.8660e-01, PNorm = 40.1306, GNorm = 1.6377, lr_0 = 4.8298e-04
Loss = 9.0404e-01, PNorm = 40.1474, GNorm = 1.2898, lr_0 = 4.8100e-04
Loss = 7.8103e-01, PNorm = 40.1658, GNorm = 2.3954, lr_0 = 4.7902e-04
Loss = 8.3137e-01, PNorm = 40.1855, GNorm = 2.5314, lr_0 = 4.7706e-04
Loss = 7.8687e-01, PNorm = 40.2020, GNorm = 4.5286, lr_0 = 4.7510e-04
Validation rmse = 0.783365
Epoch 11
Loss = 7.0933e-01, PNorm = 40.2206, GNorm = 3.2236, lr_0 = 4.7296e-04
Loss = 8.5203e-01, PNorm = 40.2445, GNorm = 2.8035, lr_0 = 4.7102e-04
Loss = 7.2015e-01, PNorm = 40.2796, GNorm = 1.9245, lr_0 = 4.6908e-04
Loss = 6.8944e-01, PNorm = 40.3111, GNorm = 7.2006, lr_0 = 4.6716e-04
Loss = 8.1168e-01, PNorm = 40.3346, GNorm = 2.7075, lr_0 = 4.6524e-04
Loss = 9.3874e-01, PNorm = 40.3610, GNorm = 2.9417, lr_0 = 4.6333e-04
Loss = 6.6564e-01, PNorm = 40.3864, GNorm = 1.5413, lr_0 = 4.6143e-04
Loss = 8.5872e-01, PNorm = 40.4095, GNorm = 1.8045, lr_0 = 4.5954e-04
Loss = 7.2761e-01, PNorm = 40.4292, GNorm = 2.9315, lr_0 = 4.5765e-04
Loss = 7.3285e-01, PNorm = 40.4482, GNorm = 1.9249, lr_0 = 4.5577e-04
Loss = 7.1585e-01, PNorm = 40.4689, GNorm = 2.7771, lr_0 = 4.5390e-04
Loss = 7.6231e-01, PNorm = 40.4950, GNorm = 4.7507, lr_0 = 4.5204e-04
Loss = 8.0930e-01, PNorm = 40.5156, GNorm = 2.3738, lr_0 = 4.5019e-04
Loss = 9.4795e-01, PNorm = 40.5359, GNorm = 2.1786, lr_0 = 4.4834e-04
Loss = 8.1528e-01, PNorm = 40.5533, GNorm = 2.3699, lr_0 = 4.4650e-04
Loss = 8.6424e-01, PNorm = 40.5686, GNorm = 3.5743, lr_0 = 4.4467e-04
Loss = 7.2147e-01, PNorm = 40.5821, GNorm = 5.6300, lr_0 = 4.4284e-04
Loss = 9.6444e-01, PNorm = 40.6029, GNorm = 1.7902, lr_0 = 4.4103e-04
Loss = 7.7982e-01, PNorm = 40.6208, GNorm = 2.6238, lr_0 = 4.3922e-04
Loss = 8.7962e-01, PNorm = 40.6369, GNorm = 2.7684, lr_0 = 4.3741e-04
Validation rmse = 0.771863
Epoch 12
Loss = 7.6222e-01, PNorm = 40.6582, GNorm = 4.3066, lr_0 = 4.3544e-04
Loss = 6.6610e-01, PNorm = 40.6766, GNorm = 2.4670, lr_0 = 4.3365e-04
Loss = 7.8823e-01, PNorm = 40.6893, GNorm = 15.3589, lr_0 = 4.3187e-04
Loss = 8.9407e-01, PNorm = 40.6974, GNorm = 1.6112, lr_0 = 4.3010e-04
Loss = 8.7847e-01, PNorm = 40.7088, GNorm = 1.7052, lr_0 = 4.2834e-04
Loss = 7.2403e-01, PNorm = 40.7233, GNorm = 4.0733, lr_0 = 4.2658e-04
Loss = 8.4741e-01, PNorm = 40.7430, GNorm = 3.8469, lr_0 = 4.2483e-04
Loss = 7.7016e-01, PNorm = 40.7689, GNorm = 4.2418, lr_0 = 4.2309e-04
Loss = 8.3243e-01, PNorm = 40.7938, GNorm = 4.9480, lr_0 = 4.2135e-04
Loss = 6.9268e-01, PNorm = 40.8128, GNorm = 2.0914, lr_0 = 4.1962e-04
Loss = 5.5385e-01, PNorm = 40.8275, GNorm = 2.5049, lr_0 = 4.1790e-04
Loss = 7.5675e-01, PNorm = 40.8557, GNorm = 3.2689, lr_0 = 4.1618e-04
Loss = 7.1417e-01, PNorm = 40.8656, GNorm = 3.0514, lr_0 = 4.1448e-04
Loss = 7.0644e-01, PNorm = 40.8757, GNorm = 1.9004, lr_0 = 4.1278e-04
Loss = 6.5253e-01, PNorm = 40.9016, GNorm = 3.6544, lr_0 = 4.1108e-04
Loss = 6.9222e-01, PNorm = 40.9210, GNorm = 2.5385, lr_0 = 4.0940e-04
Loss = 7.2092e-01, PNorm = 40.9411, GNorm = 2.2169, lr_0 = 4.0772e-04
Loss = 8.0446e-01, PNorm = 40.9641, GNorm = 2.1319, lr_0 = 4.0604e-04
Loss = 7.4205e-01, PNorm = 40.9794, GNorm = 2.5603, lr_0 = 4.0438e-04
Loss = 8.8925e-01, PNorm = 40.9901, GNorm = 5.2882, lr_0 = 4.0272e-04
Validation rmse = 0.770848
Epoch 13
Loss = 6.8452e-01, PNorm = 41.0131, GNorm = 3.4377, lr_0 = 4.0090e-04
Loss = 7.6716e-01, PNorm = 41.0369, GNorm = 2.0259, lr_0 = 3.9925e-04
Loss = 9.0661e-01, PNorm = 41.0554, GNorm = 1.9070, lr_0 = 3.9762e-04
Loss = 8.7599e-01, PNorm = 41.0733, GNorm = 2.8546, lr_0 = 3.9598e-04
Loss = 6.4596e-01, PNorm = 41.0861, GNorm = 4.1675, lr_0 = 3.9436e-04
Loss = 7.5084e-01, PNorm = 41.1033, GNorm = 4.4987, lr_0 = 3.9274e-04
Loss = 7.0680e-01, PNorm = 41.1205, GNorm = 3.0168, lr_0 = 3.9113e-04
Loss = 6.9468e-01, PNorm = 41.1367, GNorm = 3.7362, lr_0 = 3.8953e-04
Loss = 6.1474e-01, PNorm = 41.1525, GNorm = 3.3037, lr_0 = 3.8793e-04
Loss = 7.4179e-01, PNorm = 41.1678, GNorm = 8.1766, lr_0 = 3.8634e-04
Loss = 6.9595e-01, PNorm = 41.1891, GNorm = 3.6806, lr_0 = 3.8475e-04
Loss = 7.1792e-01, PNorm = 41.2100, GNorm = 2.7957, lr_0 = 3.8317e-04
Loss = 7.8068e-01, PNorm = 41.2264, GNorm = 4.4329, lr_0 = 3.8160e-04
Loss = 7.0978e-01, PNorm = 41.2411, GNorm = 3.0320, lr_0 = 3.8003e-04
Loss = 6.8336e-01, PNorm = 41.2520, GNorm = 2.0168, lr_0 = 3.7847e-04
Loss = 7.1553e-01, PNorm = 41.2643, GNorm = 8.3674, lr_0 = 3.7692e-04
Loss = 7.7797e-01, PNorm = 41.2737, GNorm = 5.1434, lr_0 = 3.7537e-04
Loss = 7.0274e-01, PNorm = 41.2885, GNorm = 4.7650, lr_0 = 3.7383e-04
Loss = 8.1081e-01, PNorm = 41.3021, GNorm = 1.8078, lr_0 = 3.7230e-04
Loss = 7.7686e-01, PNorm = 41.3163, GNorm = 2.0481, lr_0 = 3.7077e-04
Validation rmse = 0.724560
Epoch 14
Loss = 7.2446e-01, PNorm = 41.3316, GNorm = 2.7089, lr_0 = 3.6910e-04
Loss = 6.6333e-01, PNorm = 41.3498, GNorm = 3.4383, lr_0 = 3.6758e-04
Loss = 6.1262e-01, PNorm = 41.3706, GNorm = 4.2117, lr_0 = 3.6608e-04
Loss = 7.5858e-01, PNorm = 41.3843, GNorm = 3.3447, lr_0 = 3.6457e-04
Loss = 7.1604e-01, PNorm = 41.3935, GNorm = 2.5304, lr_0 = 3.6308e-04
Loss = 7.0474e-01, PNorm = 41.4080, GNorm = 1.8781, lr_0 = 3.6159e-04
Loss = 6.0151e-01, PNorm = 41.4283, GNorm = 5.1049, lr_0 = 3.6010e-04
Loss = 6.7040e-01, PNorm = 41.4459, GNorm = 4.4264, lr_0 = 3.5863e-04
Loss = 5.8111e-01, PNorm = 41.4551, GNorm = 7.6383, lr_0 = 3.5716e-04
Loss = 6.3787e-01, PNorm = 41.4633, GNorm = 2.1885, lr_0 = 3.5569e-04
Loss = 6.7534e-01, PNorm = 41.4678, GNorm = 3.2628, lr_0 = 3.5423e-04
Loss = 6.9728e-01, PNorm = 41.4752, GNorm = 5.5165, lr_0 = 3.5278e-04
Loss = 6.6009e-01, PNorm = 41.4976, GNorm = 4.0221, lr_0 = 3.5133e-04
Loss = 7.1480e-01, PNorm = 41.5174, GNorm = 2.9445, lr_0 = 3.4989e-04
Loss = 7.7292e-01, PNorm = 41.5328, GNorm = 2.1518, lr_0 = 3.4845e-04
Loss = 7.0541e-01, PNorm = 41.5476, GNorm = 2.3572, lr_0 = 3.4702e-04
Loss = 6.7721e-01, PNorm = 41.5615, GNorm = 8.1294, lr_0 = 3.4560e-04
Loss = 6.8968e-01, PNorm = 41.5771, GNorm = 11.0770, lr_0 = 3.4418e-04
Loss = 7.1843e-01, PNorm = 41.5892, GNorm = 2.2845, lr_0 = 3.4277e-04
Loss = 7.1983e-01, PNorm = 41.6015, GNorm = 2.4072, lr_0 = 3.4136e-04
Validation rmse = 0.792615
Epoch 15
Loss = 7.6541e-01, PNorm = 41.6231, GNorm = 5.4411, lr_0 = 3.3982e-04
Loss = 8.0551e-01, PNorm = 41.6417, GNorm = 2.2669, lr_0 = 3.3843e-04
Loss = 7.1952e-01, PNorm = 41.6583, GNorm = 3.3589, lr_0 = 3.3704e-04
Loss = 5.6170e-01, PNorm = 41.6735, GNorm = 2.9564, lr_0 = 3.3565e-04
Loss = 6.5367e-01, PNorm = 41.6871, GNorm = 3.9276, lr_0 = 3.3428e-04
Loss = 7.4999e-01, PNorm = 41.6998, GNorm = 3.1277, lr_0 = 3.3291e-04
Loss = 5.9644e-01, PNorm = 41.7107, GNorm = 2.8800, lr_0 = 3.3154e-04
Loss = 5.5787e-01, PNorm = 41.7211, GNorm = 3.7313, lr_0 = 3.3018e-04
Loss = 5.9826e-01, PNorm = 41.7344, GNorm = 3.3333, lr_0 = 3.2882e-04
Loss = 6.8169e-01, PNorm = 41.7401, GNorm = 3.3459, lr_0 = 3.2748e-04
Loss = 5.4187e-01, PNorm = 41.7550, GNorm = 4.3349, lr_0 = 3.2613e-04
Loss = 6.5266e-01, PNorm = 41.7678, GNorm = 1.8982, lr_0 = 3.2479e-04
Loss = 7.2834e-01, PNorm = 41.7754, GNorm = 1.8841, lr_0 = 3.2346e-04
Loss = 5.5013e-01, PNorm = 41.7879, GNorm = 2.7441, lr_0 = 3.2213e-04
Loss = 5.9755e-01, PNorm = 41.7995, GNorm = 7.0082, lr_0 = 3.2081e-04
Loss = 7.4618e-01, PNorm = 41.8093, GNorm = 3.4995, lr_0 = 3.1950e-04
Loss = 7.6679e-01, PNorm = 41.8181, GNorm = 2.4958, lr_0 = 3.1818e-04
Loss = 6.8927e-01, PNorm = 41.8303, GNorm = 3.3358, lr_0 = 3.1688e-04
Loss = 6.7263e-01, PNorm = 41.8480, GNorm = 4.1793, lr_0 = 3.1558e-04
Loss = 6.2586e-01, PNorm = 41.8627, GNorm = 3.4045, lr_0 = 3.1428e-04
Validation rmse = 0.730029
Epoch 16
Loss = 7.3626e-01, PNorm = 41.8796, GNorm = 4.6099, lr_0 = 3.1287e-04
Loss = 6.6841e-01, PNorm = 41.8936, GNorm = 4.2150, lr_0 = 3.1158e-04
Loss = 6.8572e-01, PNorm = 41.9036, GNorm = 3.7932, lr_0 = 3.1030e-04
Loss = 6.0424e-01, PNorm = 41.9186, GNorm = 2.8099, lr_0 = 3.0903e-04
Loss = 5.7511e-01, PNorm = 41.9354, GNorm = 4.8823, lr_0 = 3.0776e-04
Loss = 6.9113e-01, PNorm = 41.9515, GNorm = 3.0603, lr_0 = 3.0650e-04
Loss = 6.2158e-01, PNorm = 41.9636, GNorm = 2.5526, lr_0 = 3.0524e-04
Loss = 5.1024e-01, PNorm = 41.9762, GNorm = 4.3370, lr_0 = 3.0399e-04
Loss = 4.8037e-01, PNorm = 41.9882, GNorm = 10.0683, lr_0 = 3.0274e-04
Loss = 5.4336e-01, PNorm = 41.9972, GNorm = 7.2731, lr_0 = 3.0150e-04
Loss = 6.9397e-01, PNorm = 42.0054, GNorm = 2.2424, lr_0 = 3.0026e-04
Loss = 6.9212e-01, PNorm = 42.0068, GNorm = 2.0278, lr_0 = 2.9903e-04
Loss = 6.0716e-01, PNorm = 42.0124, GNorm = 2.7869, lr_0 = 2.9780e-04
Loss = 6.1324e-01, PNorm = 42.0221, GNorm = 6.0839, lr_0 = 2.9658e-04
Loss = 6.1227e-01, PNorm = 42.0352, GNorm = 3.7817, lr_0 = 2.9536e-04
Loss = 7.3557e-01, PNorm = 42.0393, GNorm = 3.0611, lr_0 = 2.9415e-04
Loss = 5.7279e-01, PNorm = 42.0488, GNorm = 3.3930, lr_0 = 2.9294e-04
Loss = 7.0171e-01, PNorm = 42.0656, GNorm = 2.5158, lr_0 = 2.9174e-04
Loss = 5.0342e-01, PNorm = 42.0798, GNorm = 3.3987, lr_0 = 2.9055e-04
Loss = 6.6790e-01, PNorm = 42.0922, GNorm = 4.6822, lr_0 = 2.8935e-04
Validation rmse = 0.726770
Epoch 17
Loss = 5.6694e-01, PNorm = 42.1059, GNorm = 4.8981, lr_0 = 2.8805e-04
Loss = 5.8404e-01, PNorm = 42.1113, GNorm = 4.8544, lr_0 = 2.8687e-04
Loss = 5.5373e-01, PNorm = 42.1224, GNorm = 2.3840, lr_0 = 2.8569e-04
Loss = 6.4630e-01, PNorm = 42.1375, GNorm = 3.7211, lr_0 = 2.8452e-04
Loss = 5.4426e-01, PNorm = 42.1485, GNorm = 2.8777, lr_0 = 2.8335e-04
Loss = 5.2061e-01, PNorm = 42.1571, GNorm = 9.1583, lr_0 = 2.8219e-04
Loss = 6.8194e-01, PNorm = 42.1666, GNorm = 7.6715, lr_0 = 2.8103e-04
Loss = 6.6967e-01, PNorm = 42.1715, GNorm = 3.9077, lr_0 = 2.7988e-04
Loss = 5.9762e-01, PNorm = 42.1766, GNorm = 3.6120, lr_0 = 2.7873e-04
Loss = 5.3162e-01, PNorm = 42.1846, GNorm = 3.1734, lr_0 = 2.7758e-04
Loss = 5.7663e-01, PNorm = 42.1981, GNorm = 5.1225, lr_0 = 2.7644e-04
Loss = 5.5121e-01, PNorm = 42.2069, GNorm = 4.8306, lr_0 = 2.7531e-04
Loss = 7.4166e-01, PNorm = 42.2180, GNorm = 4.8350, lr_0 = 2.7418e-04
Loss = 5.5716e-01, PNorm = 42.2268, GNorm = 2.9734, lr_0 = 2.7305e-04
Loss = 5.8485e-01, PNorm = 42.2368, GNorm = 6.8864, lr_0 = 2.7193e-04
Loss = 6.0007e-01, PNorm = 42.2457, GNorm = 5.4398, lr_0 = 2.7082e-04
Loss = 5.3027e-01, PNorm = 42.2504, GNorm = 9.4771, lr_0 = 2.6971e-04
Loss = 6.2295e-01, PNorm = 42.2569, GNorm = 2.4636, lr_0 = 2.6860e-04
Loss = 6.4756e-01, PNorm = 42.2713, GNorm = 3.3832, lr_0 = 2.6750e-04
Loss = 4.9447e-01, PNorm = 42.2878, GNorm = 4.5659, lr_0 = 2.6640e-04
Validation rmse = 0.708909
Epoch 18
Loss = 5.5253e-01, PNorm = 42.3027, GNorm = 4.3151, lr_0 = 2.6520e-04
Loss = 5.6042e-01, PNorm = 42.3116, GNorm = 4.3603, lr_0 = 2.6411e-04
Loss = 5.2146e-01, PNorm = 42.3164, GNorm = 5.2667, lr_0 = 2.6303e-04
Loss = 4.9748e-01, PNorm = 42.3263, GNorm = 7.2743, lr_0 = 2.6195e-04
Loss = 3.8781e-01, PNorm = 42.3374, GNorm = 5.3255, lr_0 = 2.6087e-04
Loss = 4.5480e-01, PNorm = 42.3484, GNorm = 16.2338, lr_0 = 2.5980e-04
Loss = 5.0590e-01, PNorm = 42.3627, GNorm = 11.8189, lr_0 = 2.5874e-04
Loss = 6.8488e-01, PNorm = 42.3723, GNorm = 3.3392, lr_0 = 2.5767e-04
Loss = 5.5635e-01, PNorm = 42.3809, GNorm = 6.7533, lr_0 = 2.5662e-04
Loss = 5.6643e-01, PNorm = 42.3860, GNorm = 2.5619, lr_0 = 2.5556e-04
Loss = 5.2121e-01, PNorm = 42.3949, GNorm = 2.9737, lr_0 = 2.5452e-04
Loss = 5.6884e-01, PNorm = 42.4052, GNorm = 2.4488, lr_0 = 2.5347e-04
Loss = 6.2712e-01, PNorm = 42.4118, GNorm = 5.3452, lr_0 = 2.5243e-04
Loss = 4.7067e-01, PNorm = 42.4210, GNorm = 6.9532, lr_0 = 2.5140e-04
Loss = 3.2192e-01, PNorm = 42.4315, GNorm = 3.8279, lr_0 = 2.5036e-04
Loss = 5.2294e-01, PNorm = 42.4368, GNorm = 7.3678, lr_0 = 2.4934e-04
Loss = 5.7501e-01, PNorm = 42.4498, GNorm = 3.3852, lr_0 = 2.4831e-04
Loss = 6.4495e-01, PNorm = 42.4579, GNorm = 5.6916, lr_0 = 2.4729e-04
Loss = 6.4346e-01, PNorm = 42.4649, GNorm = 3.2245, lr_0 = 2.4628e-04
Loss = 7.0788e-01, PNorm = 42.4723, GNorm = 2.1021, lr_0 = 2.4527e-04
Validation rmse = 0.706798
Epoch 19
Loss = 4.0005e-01, PNorm = 42.4862, GNorm = 10.4274, lr_0 = 2.4416e-04
Loss = 5.9412e-01, PNorm = 42.4946, GNorm = 3.9812, lr_0 = 2.4316e-04
Loss = 5.3925e-01, PNorm = 42.5028, GNorm = 5.8019, lr_0 = 2.4216e-04
Loss = 5.9367e-01, PNorm = 42.5115, GNorm = 3.2562, lr_0 = 2.4117e-04
Loss = 4.8335e-01, PNorm = 42.5204, GNorm = 5.6299, lr_0 = 2.4018e-04
Loss = 4.7920e-01, PNorm = 42.5254, GNorm = 7.8234, lr_0 = 2.3919e-04
Loss = 5.1649e-01, PNorm = 42.5336, GNorm = 7.3733, lr_0 = 2.3821e-04
Loss = 4.9775e-01, PNorm = 42.5432, GNorm = 4.9912, lr_0 = 2.3723e-04
Loss = 6.1891e-01, PNorm = 42.5511, GNorm = 8.4937, lr_0 = 2.3626e-04
Loss = 5.7258e-01, PNorm = 42.5582, GNorm = 4.6452, lr_0 = 2.3529e-04
Loss = 4.6849e-01, PNorm = 42.5641, GNorm = 3.1905, lr_0 = 2.3433e-04
Loss = 5.1955e-01, PNorm = 42.5719, GNorm = 4.1471, lr_0 = 2.3336e-04
Loss = 5.9668e-01, PNorm = 42.5828, GNorm = 3.7569, lr_0 = 2.3241e-04
Loss = 5.9436e-01, PNorm = 42.5908, GNorm = 4.7002, lr_0 = 2.3145e-04
Loss = 5.2193e-01, PNorm = 42.5953, GNorm = 2.6710, lr_0 = 2.3050e-04
Loss = 4.7590e-01, PNorm = 42.5999, GNorm = 3.3090, lr_0 = 2.2956e-04
Loss = 4.3558e-01, PNorm = 42.6028, GNorm = 5.7616, lr_0 = 2.2862e-04
Loss = 4.9685e-01, PNorm = 42.6098, GNorm = 8.4012, lr_0 = 2.2768e-04
Loss = 5.1408e-01, PNorm = 42.6216, GNorm = 5.1062, lr_0 = 2.2674e-04
Loss = 4.5111e-01, PNorm = 42.6376, GNorm = 2.7520, lr_0 = 2.2581e-04
Validation rmse = 0.706491
Epoch 20
Loss = 3.6060e-01, PNorm = 42.6502, GNorm = 5.2401, lr_0 = 2.2489e-04
Loss = 3.8465e-01, PNorm = 42.6623, GNorm = 11.8414, lr_0 = 2.2396e-04
Loss = 4.1322e-01, PNorm = 42.6722, GNorm = 5.8214, lr_0 = 2.2305e-04
Loss = 4.2857e-01, PNorm = 42.6802, GNorm = 6.4652, lr_0 = 2.2213e-04
Loss = 5.1125e-01, PNorm = 42.6881, GNorm = 4.3972, lr_0 = 2.2122e-04
Loss = 5.1858e-01, PNorm = 42.6969, GNorm = 3.3432, lr_0 = 2.2031e-04
Loss = 5.4060e-01, PNorm = 42.7014, GNorm = 5.6069, lr_0 = 2.1941e-04
Loss = 4.1515e-01, PNorm = 42.7034, GNorm = 3.1651, lr_0 = 2.1851e-04
Loss = 4.8812e-01, PNorm = 42.7111, GNorm = 4.7105, lr_0 = 2.1761e-04
Loss = 5.5230e-01, PNorm = 42.7145, GNorm = 3.5751, lr_0 = 2.1672e-04
Loss = 3.9131e-01, PNorm = 42.7226, GNorm = 5.4859, lr_0 = 2.1583e-04
Loss = 4.6674e-01, PNorm = 42.7296, GNorm = 4.0475, lr_0 = 2.1494e-04
Loss = 5.7757e-01, PNorm = 42.7345, GNorm = 4.9304, lr_0 = 2.1406e-04
Loss = 4.5494e-01, PNorm = 42.7412, GNorm = 2.4958, lr_0 = 2.1318e-04
Loss = 5.1081e-01, PNorm = 42.7460, GNorm = 3.3220, lr_0 = 2.1231e-04
Loss = 5.5520e-01, PNorm = 42.7508, GNorm = 11.3810, lr_0 = 2.1144e-04
Loss = 5.9123e-01, PNorm = 42.7568, GNorm = 4.8282, lr_0 = 2.1057e-04
Loss = 5.0753e-01, PNorm = 42.7626, GNorm = 6.3468, lr_0 = 2.0970e-04
Loss = 5.0885e-01, PNorm = 42.7706, GNorm = 4.3144, lr_0 = 2.0884e-04
Loss = 4.4025e-01, PNorm = 42.7783, GNorm = 5.2292, lr_0 = 2.0799e-04
Validation rmse = 0.716310
Epoch 21
Loss = 5.6007e-01, PNorm = 42.7885, GNorm = 6.8250, lr_0 = 2.0705e-04
Loss = 3.6617e-01, PNorm = 42.7965, GNorm = 3.3703, lr_0 = 2.0620e-04
Loss = 4.4268e-01, PNorm = 42.8025, GNorm = 4.8742, lr_0 = 2.0535e-04
Loss = 4.8879e-01, PNorm = 42.8093, GNorm = 3.6539, lr_0 = 2.0451e-04
Loss = 6.1809e-01, PNorm = 42.8120, GNorm = 3.2335, lr_0 = 2.0367e-04
Loss = 3.6201e-01, PNorm = 42.8204, GNorm = 6.2846, lr_0 = 2.0283e-04
Loss = 3.9498e-01, PNorm = 42.8305, GNorm = 5.2628, lr_0 = 2.0200e-04
Loss = 3.4520e-01, PNorm = 42.8439, GNorm = 5.8702, lr_0 = 2.0117e-04
Loss = 5.5418e-01, PNorm = 42.8524, GNorm = 8.2350, lr_0 = 2.0035e-04
Loss = 3.3678e-01, PNorm = 42.8583, GNorm = 6.2705, lr_0 = 1.9953e-04
Loss = 6.6105e-01, PNorm = 42.8640, GNorm = 5.4797, lr_0 = 1.9871e-04
Loss = 5.6364e-01, PNorm = 42.8676, GNorm = 7.0832, lr_0 = 1.9789e-04
Loss = 5.6463e-01, PNorm = 42.8672, GNorm = 5.1149, lr_0 = 1.9708e-04
Loss = 4.3197e-01, PNorm = 42.8730, GNorm = 3.9066, lr_0 = 1.9627e-04
Loss = 4.3966e-01, PNorm = 42.8802, GNorm = 9.5062, lr_0 = 1.9547e-04
Loss = 5.8907e-01, PNorm = 42.8885, GNorm = 4.1023, lr_0 = 1.9466e-04
Loss = 3.9704e-01, PNorm = 42.8971, GNorm = 7.3439, lr_0 = 1.9387e-04
Loss = 3.8274e-01, PNorm = 42.9045, GNorm = 3.2696, lr_0 = 1.9307e-04
Loss = 4.7814e-01, PNorm = 42.9090, GNorm = 5.0570, lr_0 = 1.9228e-04
Loss = 4.9969e-01, PNorm = 42.9162, GNorm = 2.3180, lr_0 = 1.9149e-04
Validation rmse = 0.705149
Epoch 22
Loss = 4.4892e-01, PNorm = 42.9215, GNorm = 4.4354, lr_0 = 1.9062e-04
Loss = 3.8654e-01, PNorm = 42.9283, GNorm = 5.5771, lr_0 = 1.8984e-04
Loss = 3.6470e-01, PNorm = 42.9369, GNorm = 3.2081, lr_0 = 1.8906e-04
Loss = 5.3416e-01, PNorm = 42.9437, GNorm = 8.0489, lr_0 = 1.8829e-04
Loss = 4.4438e-01, PNorm = 42.9516, GNorm = 5.3805, lr_0 = 1.8751e-04
Loss = 3.9284e-01, PNorm = 42.9582, GNorm = 6.9566, lr_0 = 1.8675e-04
Loss = 4.7707e-01, PNorm = 42.9652, GNorm = 10.5115, lr_0 = 1.8598e-04
Loss = 5.6914e-01, PNorm = 42.9715, GNorm = 5.7857, lr_0 = 1.8522e-04
Loss = 2.3338e-01, PNorm = 42.9777, GNorm = 3.0963, lr_0 = 1.8446e-04
Loss = 4.5514e-01, PNorm = 42.9809, GNorm = 4.6941, lr_0 = 1.8370e-04
Loss = 3.3181e-01, PNorm = 42.9858, GNorm = 7.7420, lr_0 = 1.8295e-04
Loss = 4.4923e-01, PNorm = 42.9890, GNorm = 5.8097, lr_0 = 1.8219e-04
Loss = 2.9173e-01, PNorm = 42.9962, GNorm = 4.9378, lr_0 = 1.8145e-04
Loss = 3.6123e-01, PNorm = 43.0023, GNorm = 6.5102, lr_0 = 1.8070e-04
Loss = 4.5416e-01, PNorm = 43.0103, GNorm = 6.6577, lr_0 = 1.7996e-04
Loss = 4.4493e-01, PNorm = 43.0131, GNorm = 5.2337, lr_0 = 1.7922e-04
Loss = 4.7748e-01, PNorm = 43.0170, GNorm = 3.6833, lr_0 = 1.7849e-04
Loss = 5.3171e-01, PNorm = 43.0208, GNorm = 4.4404, lr_0 = 1.7775e-04
Loss = 5.7204e-01, PNorm = 43.0245, GNorm = 4.5013, lr_0 = 1.7703e-04
Loss = 4.7378e-01, PNorm = 43.0299, GNorm = 2.7048, lr_0 = 1.7630e-04
Validation rmse = 0.703222
Epoch 23
Loss = 2.8860e-01, PNorm = 43.0368, GNorm = 8.3962, lr_0 = 1.7550e-04
Loss = 4.4755e-01, PNorm = 43.0451, GNorm = 4.9383, lr_0 = 1.7478e-04
Loss = 5.2637e-01, PNorm = 43.0530, GNorm = 6.0009, lr_0 = 1.7407e-04
Loss = 4.6451e-01, PNorm = 43.0582, GNorm = 9.7689, lr_0 = 1.7335e-04
Loss = 4.5680e-01, PNorm = 43.0627, GNorm = 5.1206, lr_0 = 1.7264e-04
Loss = 4.1274e-01, PNorm = 43.0697, GNorm = 6.5583, lr_0 = 1.7193e-04
Loss = 3.1747e-01, PNorm = 43.0761, GNorm = 3.7753, lr_0 = 1.7123e-04
Loss = 4.5168e-01, PNorm = 43.0802, GNorm = 12.9950, lr_0 = 1.7052e-04
Loss = 3.3428e-01, PNorm = 43.0852, GNorm = 5.2276, lr_0 = 1.6982e-04
Loss = 3.1230e-01, PNorm = 43.0901, GNorm = 14.7813, lr_0 = 1.6913e-04
Loss = 3.8308e-01, PNorm = 43.0939, GNorm = 4.2625, lr_0 = 1.6843e-04
Loss = 2.7061e-01, PNorm = 43.0981, GNorm = 6.0985, lr_0 = 1.6774e-04
Loss = 6.0019e-01, PNorm = 43.1009, GNorm = 6.6098, lr_0 = 1.6705e-04
Loss = 4.1717e-01, PNorm = 43.1060, GNorm = 5.8680, lr_0 = 1.6637e-04
Loss = 4.2066e-01, PNorm = 43.1099, GNorm = 15.1189, lr_0 = 1.6569e-04
Loss = 4.4675e-01, PNorm = 43.1145, GNorm = 2.5605, lr_0 = 1.6501e-04
Loss = 4.3145e-01, PNorm = 43.1186, GNorm = 5.5768, lr_0 = 1.6433e-04
Loss = 4.6037e-01, PNorm = 43.1233, GNorm = 8.1088, lr_0 = 1.6365e-04
Loss = 5.1788e-01, PNorm = 43.1236, GNorm = 7.3931, lr_0 = 1.6298e-04
Loss = 3.0148e-01, PNorm = 43.1264, GNorm = 6.9001, lr_0 = 1.6231e-04
Validation rmse = 0.701719
Epoch 24
Loss = 4.2243e-01, PNorm = 43.1349, GNorm = 8.9848, lr_0 = 1.6158e-04
Loss = 3.5717e-01, PNorm = 43.1406, GNorm = 6.2222, lr_0 = 1.6092e-04
Loss = 4.7473e-01, PNorm = 43.1453, GNorm = 7.0471, lr_0 = 1.6026e-04
Loss = 3.6841e-01, PNorm = 43.1520, GNorm = 5.5716, lr_0 = 1.5960e-04
Loss = 5.0080e-01, PNorm = 43.1562, GNorm = 17.0602, lr_0 = 1.5895e-04
Loss = 5.4143e-01, PNorm = 43.1583, GNorm = 3.9631, lr_0 = 1.5829e-04
Loss = 4.5829e-01, PNorm = 43.1627, GNorm = 2.5722, lr_0 = 1.5764e-04
Loss = 4.2037e-01, PNorm = 43.1677, GNorm = 3.4738, lr_0 = 1.5700e-04
Loss = 2.9970e-01, PNorm = 43.1724, GNorm = 5.8384, lr_0 = 1.5635e-04
Loss = 3.7641e-01, PNorm = 43.1775, GNorm = 3.5039, lr_0 = 1.5571e-04
Loss = 4.1728e-01, PNorm = 43.1815, GNorm = 6.3274, lr_0 = 1.5507e-04
Loss = 2.8577e-01, PNorm = 43.1857, GNorm = 5.0667, lr_0 = 1.5444e-04
Loss = 3.9455e-01, PNorm = 43.1901, GNorm = 4.4558, lr_0 = 1.5380e-04
Loss = 4.1038e-01, PNorm = 43.2007, GNorm = 3.9822, lr_0 = 1.5317e-04
Loss = 3.4053e-01, PNorm = 43.2076, GNorm = 18.7567, lr_0 = 1.5254e-04
Loss = 2.4148e-01, PNorm = 43.2150, GNorm = 13.1659, lr_0 = 1.5192e-04
Loss = 1.1977e-01, PNorm = 43.2229, GNorm = 3.9998, lr_0 = 1.5129e-04
Loss = 3.9541e-01, PNorm = 43.2297, GNorm = 7.1555, lr_0 = 1.5067e-04
Loss = 3.0070e-01, PNorm = 43.2337, GNorm = 10.4566, lr_0 = 1.5005e-04
Loss = 4.7870e-01, PNorm = 43.2379, GNorm = 10.7401, lr_0 = 1.4944e-04
Validation rmse = 0.698809
Epoch 25
Loss = 3.2354e-01, PNorm = 43.2439, GNorm = 9.2219, lr_0 = 1.4876e-04
Loss = 2.4486e-01, PNorm = 43.2502, GNorm = 8.2419, lr_0 = 1.4815e-04
Loss = 3.8251e-01, PNorm = 43.2562, GNorm = 5.6074, lr_0 = 1.4755e-04
Loss = 3.1602e-01, PNorm = 43.2604, GNorm = 5.4137, lr_0 = 1.4694e-04
Loss = 1.3241e-01, PNorm = 43.2648, GNorm = 8.5512, lr_0 = 1.4634e-04
Loss = 4.7976e-01, PNorm = 43.2617, GNorm = 20.5328, lr_0 = 1.4574e-04
Loss = 2.3429e-01, PNorm = 43.2569, GNorm = 2.8408, lr_0 = 1.4514e-04
Loss = 3.5455e-01, PNorm = 43.2586, GNorm = 5.5943, lr_0 = 1.4454e-04
Loss = 4.4413e-01, PNorm = 43.2633, GNorm = 14.9857, lr_0 = 1.4395e-04
Loss = 3.0597e-01, PNorm = 43.2697, GNorm = 4.1036, lr_0 = 1.4336e-04
Loss = 2.4835e-01, PNorm = 43.2764, GNorm = 7.7967, lr_0 = 1.4277e-04
Loss = 4.4926e-01, PNorm = 43.2834, GNorm = 11.2455, lr_0 = 1.4219e-04
Loss = 4.3366e-01, PNorm = 43.2879, GNorm = 4.8256, lr_0 = 1.4160e-04
Loss = 4.3495e-01, PNorm = 43.2913, GNorm = 3.7031, lr_0 = 1.4102e-04
Loss = 5.3181e-01, PNorm = 43.2942, GNorm = 10.4484, lr_0 = 1.4044e-04
Loss = 3.5337e-01, PNorm = 43.2963, GNorm = 6.3746, lr_0 = 1.3987e-04
Loss = 4.2373e-01, PNorm = 43.3010, GNorm = 7.1075, lr_0 = 1.3929e-04
Loss = 4.5144e-01, PNorm = 43.3054, GNorm = 6.8607, lr_0 = 1.3872e-04
Loss = 3.4076e-01, PNorm = 43.3094, GNorm = 7.8078, lr_0 = 1.3815e-04
Loss = 3.9291e-01, PNorm = 43.3134, GNorm = 3.4937, lr_0 = 1.3759e-04
Validation rmse = 0.696080
Epoch 26
Loss = 4.0825e-01, PNorm = 43.3193, GNorm = 7.6401, lr_0 = 1.3696e-04
Loss = 3.2959e-01, PNorm = 43.3254, GNorm = 5.0085, lr_0 = 1.3640e-04
Loss = 2.9357e-01, PNorm = 43.3280, GNorm = 6.3022, lr_0 = 1.3584e-04
Loss = 2.7076e-01, PNorm = 43.3324, GNorm = 8.0821, lr_0 = 1.3529e-04
Loss = 2.2489e-01, PNorm = 43.3361, GNorm = 4.7735, lr_0 = 1.3473e-04
Loss = 3.7740e-01, PNorm = 43.3414, GNorm = 6.9815, lr_0 = 1.3418e-04
Loss = 5.1897e-01, PNorm = 43.3447, GNorm = 9.7724, lr_0 = 1.3363e-04
Loss = 3.2295e-01, PNorm = 43.3499, GNorm = 3.7946, lr_0 = 1.3308e-04
Loss = 3.1787e-01, PNorm = 43.3559, GNorm = 5.6464, lr_0 = 1.3253e-04
Loss = 3.3258e-01, PNorm = 43.3605, GNorm = 6.8396, lr_0 = 1.3199e-04
Loss = 3.2568e-01, PNorm = 43.3635, GNorm = 3.6953, lr_0 = 1.3145e-04
Loss = 3.3938e-01, PNorm = 43.3683, GNorm = 11.1172, lr_0 = 1.3091e-04
Loss = 4.6244e-01, PNorm = 43.3719, GNorm = 4.7486, lr_0 = 1.3037e-04
Loss = 3.1894e-01, PNorm = 43.3749, GNorm = 9.7563, lr_0 = 1.2984e-04
Loss = 4.7165e-01, PNorm = 43.3777, GNorm = 5.3709, lr_0 = 1.2930e-04
Loss = 3.0649e-01, PNorm = 43.3806, GNorm = 5.4815, lr_0 = 1.2877e-04
Loss = 2.4198e-01, PNorm = 43.3840, GNorm = 5.1539, lr_0 = 1.2824e-04
Loss = 2.9448e-01, PNorm = 43.3893, GNorm = 11.9150, lr_0 = 1.2772e-04
Loss = 2.7658e-01, PNorm = 43.3918, GNorm = 6.0372, lr_0 = 1.2719e-04
Loss = 3.9999e-01, PNorm = 43.3949, GNorm = 4.1957, lr_0 = 1.2667e-04
Validation rmse = 0.696600
Epoch 27
Loss = 4.5631e-01, PNorm = 43.3984, GNorm = 4.3401, lr_0 = 1.2610e-04
Loss = 3.3542e-01, PNorm = 43.4024, GNorm = 4.7845, lr_0 = 1.2558e-04
Loss = 2.6857e-01, PNorm = 43.4073, GNorm = 7.9232, lr_0 = 1.2507e-04
Loss = 2.4381e-01, PNorm = 43.4121, GNorm = 5.1743, lr_0 = 1.2455e-04
Loss = 3.9317e-01, PNorm = 43.4180, GNorm = 7.7101, lr_0 = 1.2404e-04
Loss = 3.5292e-01, PNorm = 43.4232, GNorm = 6.3326, lr_0 = 1.2353e-04
Loss = 2.0154e-01, PNorm = 43.4283, GNorm = 4.8239, lr_0 = 1.2303e-04
Loss = 2.8636e-01, PNorm = 43.4338, GNorm = 3.9959, lr_0 = 1.2252e-04
Loss = 3.4280e-01, PNorm = 43.4378, GNorm = 7.0517, lr_0 = 1.2202e-04
Loss = 2.8231e-01, PNorm = 43.4408, GNorm = 5.5097, lr_0 = 1.2152e-04
Loss = 2.5732e-01, PNorm = 43.4438, GNorm = 9.8463, lr_0 = 1.2102e-04
Loss = 1.5249e-01, PNorm = 43.4483, GNorm = 7.6357, lr_0 = 1.2052e-04
Loss = 3.9216e-01, PNorm = 43.4505, GNorm = 12.1828, lr_0 = 1.2003e-04
Loss = 3.6309e-01, PNorm = 43.4544, GNorm = 5.1817, lr_0 = 1.1954e-04
Loss = 3.6188e-01, PNorm = 43.4600, GNorm = 9.6296, lr_0 = 1.1905e-04
Loss = 3.8151e-01, PNorm = 43.4641, GNorm = 7.5379, lr_0 = 1.1856e-04
Loss = 3.2176e-01, PNorm = 43.4659, GNorm = 11.3958, lr_0 = 1.1807e-04
Loss = 3.4282e-01, PNorm = 43.4648, GNorm = 7.6677, lr_0 = 1.1759e-04
Loss = 2.3928e-01, PNorm = 43.4660, GNorm = 9.9930, lr_0 = 1.1710e-04
Loss = 3.2638e-01, PNorm = 43.4655, GNorm = 3.9372, lr_0 = 1.1662e-04
Validation rmse = 0.705707
Epoch 28
Loss = 2.3490e-01, PNorm = 43.4692, GNorm = 12.0883, lr_0 = 1.1610e-04
Loss = 1.8027e-01, PNorm = 43.4737, GNorm = 13.8480, lr_0 = 1.1562e-04
Loss = 2.9837e-01, PNorm = 43.4808, GNorm = 5.3931, lr_0 = 1.1515e-04
Loss = 2.4333e-01, PNorm = 43.4866, GNorm = 4.3520, lr_0 = 1.1467e-04
Loss = 2.5351e-01, PNorm = 43.4914, GNorm = 5.4668, lr_0 = 1.1420e-04
Loss = 3.3056e-01, PNorm = 43.4951, GNorm = 5.9491, lr_0 = 1.1373e-04
Loss = 2.9270e-01, PNorm = 43.4984, GNorm = 9.4681, lr_0 = 1.1327e-04
Loss = 3.0425e-01, PNorm = 43.5012, GNorm = 10.5557, lr_0 = 1.1280e-04
Loss = 2.2897e-01, PNorm = 43.5034, GNorm = 10.2398, lr_0 = 1.1234e-04
Loss = 4.6240e-01, PNorm = 43.5062, GNorm = 9.6886, lr_0 = 1.1188e-04
Loss = 4.2040e-01, PNorm = 43.5108, GNorm = 6.9136, lr_0 = 1.1142e-04
Loss = 3.0804e-01, PNorm = 43.5136, GNorm = 7.2455, lr_0 = 1.1096e-04
Loss = 2.9653e-01, PNorm = 43.5165, GNorm = 9.1329, lr_0 = 1.1051e-04
Loss = 2.8741e-01, PNorm = 43.5204, GNorm = 8.0768, lr_0 = 1.1005e-04
Loss = 3.2386e-01, PNorm = 43.5216, GNorm = 5.3865, lr_0 = 1.0960e-04
Loss = 2.9342e-01, PNorm = 43.5247, GNorm = 11.6516, lr_0 = 1.0915e-04
Loss = 3.2436e-01, PNorm = 43.5275, GNorm = 7.0618, lr_0 = 1.0871e-04
Loss = 2.2521e-01, PNorm = 43.5302, GNorm = 4.5997, lr_0 = 1.0826e-04
Loss = 2.9014e-01, PNorm = 43.5336, GNorm = 5.9646, lr_0 = 1.0781e-04
Loss = 1.7323e-01, PNorm = 43.5364, GNorm = 6.9616, lr_0 = 1.0737e-04
Validation rmse = 0.699791
Epoch 29
Loss = 3.0610e-01, PNorm = 43.5403, GNorm = 5.8202, lr_0 = 1.0689e-04
Loss = 2.5765e-01, PNorm = 43.5440, GNorm = 18.6921, lr_0 = 1.0645e-04
Loss = 1.7138e-01, PNorm = 43.5473, GNorm = 10.3953, lr_0 = 1.0601e-04
Loss = 1.4718e-01, PNorm = 43.5504, GNorm = 5.5974, lr_0 = 1.0558e-04
Loss = 4.0144e-01, PNorm = 43.5530, GNorm = 5.8257, lr_0 = 1.0514e-04
Loss = 1.5378e-01, PNorm = 43.5563, GNorm = 9.6000, lr_0 = 1.0471e-04
Loss = 3.0162e-01, PNorm = 43.5607, GNorm = 10.4900, lr_0 = 1.0428e-04
Loss = 3.3297e-01, PNorm = 43.5654, GNorm = 7.0311, lr_0 = 1.0386e-04
Loss = 3.9757e-01, PNorm = 43.5675, GNorm = 4.6237, lr_0 = 1.0343e-04
Loss = 2.9825e-01, PNorm = 43.5704, GNorm = 4.5189, lr_0 = 1.0300e-04
Loss = 2.7562e-01, PNorm = 43.5731, GNorm = 13.1254, lr_0 = 1.0258e-04
Loss = 3.3342e-01, PNorm = 43.5765, GNorm = 10.1442, lr_0 = 1.0216e-04
Loss = 2.2695e-01, PNorm = 43.5798, GNorm = 7.1304, lr_0 = 1.0174e-04
Loss = 2.9593e-01, PNorm = 43.5825, GNorm = 7.0945, lr_0 = 1.0132e-04
Loss = 3.1882e-01, PNorm = 43.5838, GNorm = 9.1566, lr_0 = 1.0091e-04
Loss = 2.5457e-01, PNorm = 43.5869, GNorm = 5.8789, lr_0 = 1.0049e-04
Loss = 3.0571e-01, PNorm = 43.5902, GNorm = 6.1746, lr_0 = 1.0008e-04
Loss = 2.3176e-01, PNorm = 43.5946, GNorm = 5.7115, lr_0 = 1.0000e-04
Loss = 2.6982e-01, PNorm = 43.5990, GNorm = 10.3866, lr_0 = 1.0000e-04
Loss = 3.4467e-01, PNorm = 43.5986, GNorm = 4.1650, lr_0 = 1.0000e-04
Validation rmse = 0.700469
Model 0 best validation rmse = 0.696080 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.783093
Ensemble test rmse = 0.783093
1-fold cross validation
	Seed 0 ==> test rmse = 0.783093
Overall test rmse = 0.783093 +/- 0.000000
Elapsed time = 0:04:19
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7351e+00, PNorm = 43.3114, GNorm = 1.7244, lr_0 = 4.0937e-04
Validation rmse = 1.358621
Epoch 1
Loss = 1.4556e+00, PNorm = 43.3196, GNorm = 1.2309, lr_0 = 6.9063e-04
Loss = 1.4051e+00, PNorm = 43.3433, GNorm = 0.5078, lr_0 = 9.7187e-04
Validation rmse = 1.261051
Epoch 2
Loss = 1.2797e+00, PNorm = 43.3806, GNorm = 0.9769, lr_0 = 9.5480e-04
Validation rmse = 1.203115
Epoch 3
Loss = 1.2933e+00, PNorm = 43.4290, GNorm = 1.2640, lr_0 = 9.0696e-04
Loss = 1.1046e+00, PNorm = 43.4983, GNorm = 3.5014, lr_0 = 8.6152e-04
Validation rmse = 1.016250
Epoch 4
Loss = 9.4411e-01, PNorm = 43.5722, GNorm = 4.7541, lr_0 = 8.1836e-04
Loss = 1.0741e+00, PNorm = 43.6314, GNorm = 8.0426, lr_0 = 7.7737e-04
Validation rmse = 1.169234
Epoch 5
Loss = 1.0507e+00, PNorm = 43.6691, GNorm = 3.1761, lr_0 = 7.3842e-04
Validation rmse = 0.988596
Epoch 6
Loss = 8.4512e-01, PNorm = 43.7173, GNorm = 1.1533, lr_0 = 7.0143e-04
Loss = 8.3727e-01, PNorm = 43.7677, GNorm = 1.3341, lr_0 = 6.6629e-04
Validation rmse = 0.910219
Epoch 7
Loss = 7.9852e-01, PNorm = 43.8028, GNorm = 7.8246, lr_0 = 6.3291e-04
Validation rmse = 0.959984
Epoch 8
Loss = 9.0639e-01, PNorm = 43.8341, GNorm = 5.1451, lr_0 = 6.0120e-04
Loss = 7.2297e-01, PNorm = 43.8727, GNorm = 7.6824, lr_0 = 5.7108e-04
Validation rmse = 0.850045
Epoch 9
Loss = 7.1434e-01, PNorm = 43.9038, GNorm = 5.6013, lr_0 = 5.4247e-04
Loss = 7.7927e-01, PNorm = 43.9325, GNorm = 2.1264, lr_0 = 5.1529e-04
Validation rmse = 0.870422
Epoch 10
Loss = 6.6285e-01, PNorm = 43.9618, GNorm = 3.3106, lr_0 = 4.8948e-04
Validation rmse = 0.858329
Epoch 11
Loss = 5.9702e-01, PNorm = 43.9861, GNorm = 2.3355, lr_0 = 4.6495e-04
Loss = 6.6478e-01, PNorm = 44.0114, GNorm = 4.7218, lr_0 = 4.4166e-04
Validation rmse = 0.836916
Epoch 12
Loss = 5.9836e-01, PNorm = 44.0359, GNorm = 4.5392, lr_0 = 4.1953e-04
Validation rmse = 0.828532
Epoch 13
Loss = 5.9678e-01, PNorm = 44.0626, GNorm = 3.1759, lr_0 = 3.9852e-04
Loss = 5.4540e-01, PNorm = 44.0905, GNorm = 3.0622, lr_0 = 3.7855e-04
Validation rmse = 0.843289
Epoch 14
Loss = 5.6340e-01, PNorm = 44.1095, GNorm = 2.9237, lr_0 = 3.5959e-04
Loss = 5.6388e-01, PNorm = 44.1318, GNorm = 3.3759, lr_0 = 3.4157e-04
Validation rmse = 0.836895
Epoch 15
Loss = 4.9007e-01, PNorm = 44.1534, GNorm = 3.9319, lr_0 = 3.2446e-04
Validation rmse = 0.836135
Epoch 16
Loss = 5.6895e-01, PNorm = 44.1691, GNorm = 3.1482, lr_0 = 3.0820e-04
Loss = 5.4919e-01, PNorm = 44.1872, GNorm = 5.7172, lr_0 = 2.9276e-04
Validation rmse = 0.827988
Epoch 17
Loss = 5.4431e-01, PNorm = 44.2040, GNorm = 10.5690, lr_0 = 2.7810e-04
Validation rmse = 0.817774
Epoch 18
Loss = 5.0769e-01, PNorm = 44.2205, GNorm = 4.8302, lr_0 = 2.6416e-04
Loss = 4.8789e-01, PNorm = 44.2368, GNorm = 12.7664, lr_0 = 2.5093e-04
Validation rmse = 0.848820
Epoch 19
Loss = 4.4168e-01, PNorm = 44.2499, GNorm = 4.0556, lr_0 = 2.3836e-04
Loss = 5.0509e-01, PNorm = 44.2631, GNorm = 4.9814, lr_0 = 2.2642e-04
Validation rmse = 0.813408
Epoch 20
Loss = 4.5404e-01, PNorm = 44.2778, GNorm = 6.3583, lr_0 = 2.1507e-04
Validation rmse = 0.815358
Epoch 21
Loss = 5.4918e-01, PNorm = 44.2896, GNorm = 7.4633, lr_0 = 2.0430e-04
Loss = 4.5083e-01, PNorm = 44.3025, GNorm = 17.7973, lr_0 = 1.9406e-04
Validation rmse = 0.822856
Epoch 22
Loss = 5.1233e-01, PNorm = 44.3112, GNorm = 6.6262, lr_0 = 1.8434e-04
Validation rmse = 0.828564
Epoch 23
Loss = 4.3857e-01, PNorm = 44.3241, GNorm = 4.4612, lr_0 = 1.7511e-04
Loss = 4.2581e-01, PNorm = 44.3361, GNorm = 12.6887, lr_0 = 1.6633e-04
Validation rmse = 0.814591
Epoch 24
Loss = 4.0237e-01, PNorm = 44.3473, GNorm = 7.6444, lr_0 = 1.5800e-04
Loss = 4.3782e-01, PNorm = 44.3571, GNorm = 4.2150, lr_0 = 1.5009e-04
Validation rmse = 0.807722
Epoch 25
Loss = 4.2540e-01, PNorm = 44.3637, GNorm = 2.9058, lr_0 = 1.4257e-04
Validation rmse = 0.820581
Epoch 26
Loss = 4.3267e-01, PNorm = 44.3728, GNorm = 2.7049, lr_0 = 1.3542e-04
Loss = 3.6277e-01, PNorm = 44.3821, GNorm = 6.7250, lr_0 = 1.2864e-04
Validation rmse = 0.817015
Epoch 27
Loss = 4.4910e-01, PNorm = 44.3908, GNorm = 3.8227, lr_0 = 1.2220e-04
Validation rmse = 0.809136
Epoch 28
Loss = 5.2209e-01, PNorm = 44.3977, GNorm = 10.2444, lr_0 = 1.1607e-04
Loss = 4.4075e-01, PNorm = 44.4034, GNorm = 12.4134, lr_0 = 1.1026e-04
Validation rmse = 0.817949
Epoch 29
Loss = 3.9778e-01, PNorm = 44.4101, GNorm = 5.0407, lr_0 = 1.0473e-04
Loss = 3.7881e-01, PNorm = 44.4175, GNorm = 8.6199, lr_0 = 1.0000e-04
Validation rmse = 0.809265
Model 0 best validation rmse = 0.807722 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.677784
Ensemble test rmse = 0.677784
1-fold cross validation
	Seed 0 ==> test rmse = 0.677784
Overall test rmse = 0.677784 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7351e+00, PNorm = 43.3114, GNorm = 1.7244, lr_0 = 4.0937e-04
Validation rmse = 1.358621
Epoch 1
Loss = 1.4556e+00, PNorm = 43.3196, GNorm = 1.2309, lr_0 = 6.9063e-04
Loss = 1.4051e+00, PNorm = 43.3433, GNorm = 0.5078, lr_0 = 9.7187e-04
Validation rmse = 1.261051
Epoch 2
Loss = 1.2797e+00, PNorm = 43.3806, GNorm = 0.9769, lr_0 = 9.5480e-04
Validation rmse = 1.203115
Epoch 3
Loss = 1.2933e+00, PNorm = 43.4290, GNorm = 1.2640, lr_0 = 9.0696e-04
Loss = 1.1046e+00, PNorm = 43.4983, GNorm = 3.5014, lr_0 = 8.6152e-04
Validation rmse = 1.016250
Epoch 4
Loss = 9.4411e-01, PNorm = 43.5722, GNorm = 4.7541, lr_0 = 8.1836e-04
Loss = 1.0741e+00, PNorm = 43.6314, GNorm = 8.0426, lr_0 = 7.7737e-04
Validation rmse = 1.169234
Epoch 5
Loss = 1.0507e+00, PNorm = 43.6691, GNorm = 3.1761, lr_0 = 7.3842e-04
Validation rmse = 0.988596
Epoch 6
Loss = 8.4512e-01, PNorm = 43.7173, GNorm = 1.1533, lr_0 = 7.0143e-04
Loss = 8.3727e-01, PNorm = 43.7677, GNorm = 1.3341, lr_0 = 6.6629e-04
Validation rmse = 0.910219
Epoch 7
Loss = 7.9852e-01, PNorm = 43.8028, GNorm = 7.8246, lr_0 = 6.3291e-04
Validation rmse = 0.959943
Epoch 8
Loss = 9.0645e-01, PNorm = 43.8341, GNorm = 5.1466, lr_0 = 6.0120e-04
Loss = 7.2310e-01, PNorm = 43.8727, GNorm = 7.7464, lr_0 = 5.7108e-04
Validation rmse = 0.850556
Epoch 9
Loss = 7.1402e-01, PNorm = 43.9037, GNorm = 5.5789, lr_0 = 5.4247e-04
Loss = 7.7954e-01, PNorm = 43.9323, GNorm = 2.1052, lr_0 = 5.1529e-04
Validation rmse = 0.870971
Epoch 10
Loss = 6.6184e-01, PNorm = 43.9615, GNorm = 3.4267, lr_0 = 4.8948e-04
Validation rmse = 0.857874
Epoch 11
Loss = 5.9811e-01, PNorm = 43.9856, GNorm = 2.2011, lr_0 = 4.6495e-04
Loss = 6.6447e-01, PNorm = 44.0110, GNorm = 4.6600, lr_0 = 4.4166e-04
Validation rmse = 0.838886
Epoch 12
Loss = 5.9997e-01, PNorm = 44.0350, GNorm = 4.7284, lr_0 = 4.1953e-04
Validation rmse = 0.830200
Epoch 13
Loss = 6.0026e-01, PNorm = 44.0606, GNorm = 2.8771, lr_0 = 3.9852e-04
Loss = 5.4893e-01, PNorm = 44.0881, GNorm = 3.4542, lr_0 = 3.7855e-04
Validation rmse = 0.841382
Epoch 14
Loss = 5.6149e-01, PNorm = 44.1074, GNorm = 2.8445, lr_0 = 3.5959e-04
Loss = 5.6666e-01, PNorm = 44.1288, GNorm = 3.0214, lr_0 = 3.4157e-04
Validation rmse = 0.837674
Epoch 15
Loss = 4.9241e-01, PNorm = 44.1505, GNorm = 4.3339, lr_0 = 3.2446e-04
Validation rmse = 0.834820
Epoch 16
Loss = 5.7363e-01, PNorm = 44.1651, GNorm = 3.1351, lr_0 = 3.0820e-04
Loss = 5.5246e-01, PNorm = 44.1829, GNorm = 5.7619, lr_0 = 2.9276e-04
Validation rmse = 0.829446
Epoch 17
Loss = 5.4698e-01, PNorm = 44.2004, GNorm = 10.7212, lr_0 = 2.7810e-04
Validation rmse = 0.820218
Epoch 18
Loss = 5.1359e-01, PNorm = 44.2174, GNorm = 4.7042, lr_0 = 2.6416e-04
Loss = 4.9370e-01, PNorm = 44.2335, GNorm = 12.9708, lr_0 = 2.5093e-04
Validation rmse = 0.850247
Epoch 19
Loss = 4.4365e-01, PNorm = 44.2464, GNorm = 3.6955, lr_0 = 2.3836e-04
Loss = 5.0758e-01, PNorm = 44.2598, GNorm = 4.7545, lr_0 = 2.2642e-04
Validation rmse = 0.812387
Epoch 20
Loss = 4.5858e-01, PNorm = 44.2749, GNorm = 6.9119, lr_0 = 2.1507e-04
Validation rmse = 0.815344
Epoch 21
Loss = 5.5217e-01, PNorm = 44.2869, GNorm = 7.1785, lr_0 = 2.0430e-04
Loss = 4.4657e-01, PNorm = 44.2995, GNorm = 17.4081, lr_0 = 1.9406e-04
Validation rmse = 0.823437
Epoch 22
Loss = 5.0909e-01, PNorm = 44.3081, GNorm = 6.0063, lr_0 = 1.8434e-04
Validation rmse = 0.830543
Epoch 23
Loss = 4.3611e-01, PNorm = 44.3208, GNorm = 4.0978, lr_0 = 1.7511e-04
Loss = 4.2357e-01, PNorm = 44.3329, GNorm = 11.6675, lr_0 = 1.6633e-04
Validation rmse = 0.814779
Epoch 24
Loss = 4.0223e-01, PNorm = 44.3441, GNorm = 7.0121, lr_0 = 1.5800e-04
Loss = 4.3695e-01, PNorm = 44.3537, GNorm = 4.8786, lr_0 = 1.5009e-04
Validation rmse = 0.806781
Epoch 25
Loss = 4.2549e-01, PNorm = 44.3603, GNorm = 3.3503, lr_0 = 1.4257e-04
Validation rmse = 0.819440
Epoch 26
Loss = 4.3215e-01, PNorm = 44.3693, GNorm = 2.8402, lr_0 = 1.3542e-04
Loss = 3.6516e-01, PNorm = 44.3786, GNorm = 6.7327, lr_0 = 1.2864e-04
Validation rmse = 0.816903
Epoch 27
Loss = 4.5153e-01, PNorm = 44.3872, GNorm = 3.8088, lr_0 = 1.2220e-04
Validation rmse = 0.809500
Epoch 28
Loss = 5.2086e-01, PNorm = 44.3940, GNorm = 10.3883, lr_0 = 1.1607e-04
Loss = 4.4278e-01, PNorm = 44.3996, GNorm = 12.8088, lr_0 = 1.1026e-04
Validation rmse = 0.818205
Epoch 29
Loss = 3.9764e-01, PNorm = 44.4064, GNorm = 5.3859, lr_0 = 1.0473e-04
Loss = 3.8117e-01, PNorm = 44.4137, GNorm = 8.2942, lr_0 = 1.0000e-04
Validation rmse = 0.809413
Model 0 best validation rmse = 0.806781 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.677906
Ensemble test rmse = 0.677906
1-fold cross validation
	Seed 0 ==> test rmse = 0.677906
Overall test rmse = 0.677906 +/- 0.000000
Elapsed time = 0:01:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7351e+00, PNorm = 43.3114, GNorm = 1.7244, lr_0 = 4.0937e-04
Validation rmse = 1.358621
Epoch 1
Loss = 1.4556e+00, PNorm = 43.3196, GNorm = 1.2309, lr_0 = 6.9063e-04
Loss = 1.4051e+00, PNorm = 43.3433, GNorm = 0.5078, lr_0 = 9.7187e-04
Validation rmse = 1.261051
Epoch 2
Loss = 1.2797e+00, PNorm = 43.3806, GNorm = 0.9769, lr_0 = 9.5480e-04
Validation rmse = 1.203115
Epoch 3
Loss = 1.2933e+00, PNorm = 43.4290, GNorm = 1.2640, lr_0 = 9.0696e-04
Loss = 1.1046e+00, PNorm = 43.4983, GNorm = 3.5014, lr_0 = 8.6152e-04
Validation rmse = 1.016250
Epoch 4
Loss = 9.4411e-01, PNorm = 43.5722, GNorm = 4.7541, lr_0 = 8.1836e-04
Loss = 1.0741e+00, PNorm = 43.6314, GNorm = 8.0426, lr_0 = 7.7737e-04
Validation rmse = 1.169234
Epoch 5
Loss = 1.0507e+00, PNorm = 43.6691, GNorm = 3.1761, lr_0 = 7.3842e-04
Validation rmse = 0.988596
Epoch 6
Loss = 8.4512e-01, PNorm = 43.7173, GNorm = 1.1533, lr_0 = 7.0143e-04
Loss = 8.3727e-01, PNorm = 43.7677, GNorm = 1.3341, lr_0 = 6.6629e-04
Validation rmse = 0.910219
Epoch 7
Loss = 7.9852e-01, PNorm = 43.8028, GNorm = 7.8247, lr_0 = 6.3291e-04
Validation rmse = 0.959963
Epoch 8
Loss = 9.0645e-01, PNorm = 43.8341, GNorm = 5.1491, lr_0 = 6.0120e-04
Loss = 7.2293e-01, PNorm = 43.8726, GNorm = 7.6590, lr_0 = 5.7108e-04
Validation rmse = 0.849704
Epoch 9
Loss = 7.1504e-01, PNorm = 43.9035, GNorm = 5.4051, lr_0 = 5.4247e-04
Loss = 7.7859e-01, PNorm = 43.9320, GNorm = 2.1528, lr_0 = 5.1529e-04
Validation rmse = 0.872148
Epoch 10
Loss = 6.6131e-01, PNorm = 43.9610, GNorm = 3.4867, lr_0 = 4.8948e-04
Validation rmse = 0.857216
Epoch 11
Loss = 6.0009e-01, PNorm = 43.9856, GNorm = 2.3043, lr_0 = 4.6495e-04
Loss = 6.6613e-01, PNorm = 44.0111, GNorm = 4.7584, lr_0 = 4.4166e-04
Validation rmse = 0.837564
Epoch 12
Loss = 5.9723e-01, PNorm = 44.0354, GNorm = 4.7752, lr_0 = 4.1953e-04
Validation rmse = 0.829992
Epoch 13
Loss = 5.9525e-01, PNorm = 44.0616, GNorm = 3.0403, lr_0 = 3.9852e-04
Loss = 5.4660e-01, PNorm = 44.0894, GNorm = 3.4025, lr_0 = 3.7855e-04
Validation rmse = 0.842718
Epoch 14
Loss = 5.6103e-01, PNorm = 44.1084, GNorm = 2.7160, lr_0 = 3.5959e-04
Loss = 5.6723e-01, PNorm = 44.1303, GNorm = 3.2000, lr_0 = 3.4157e-04
Validation rmse = 0.834146
Epoch 15
Loss = 4.8951e-01, PNorm = 44.1522, GNorm = 4.1476, lr_0 = 3.2446e-04
Validation rmse = 0.835704
Epoch 16
Loss = 5.6912e-01, PNorm = 44.1671, GNorm = 3.0283, lr_0 = 3.0820e-04
Loss = 5.5246e-01, PNorm = 44.1844, GNorm = 5.5425, lr_0 = 2.9276e-04
Validation rmse = 0.832779
Epoch 17
Loss = 5.5088e-01, PNorm = 44.2011, GNorm = 11.4074, lr_0 = 2.7810e-04
Validation rmse = 0.823559
Epoch 18
Loss = 5.1078e-01, PNorm = 44.2175, GNorm = 4.0612, lr_0 = 2.6416e-04
Loss = 4.9721e-01, PNorm = 44.2335, GNorm = 13.8364, lr_0 = 2.5093e-04
Validation rmse = 0.855579
Epoch 19
Loss = 4.4807e-01, PNorm = 44.2465, GNorm = 3.3457, lr_0 = 2.3836e-04
Loss = 5.1018e-01, PNorm = 44.2598, GNorm = 4.8748, lr_0 = 2.2642e-04
Validation rmse = 0.813650
Epoch 20
Loss = 4.6017e-01, PNorm = 44.2743, GNorm = 6.6210, lr_0 = 2.1507e-04
Validation rmse = 0.814002
Epoch 21
Loss = 5.5308e-01, PNorm = 44.2863, GNorm = 7.1891, lr_0 = 2.0430e-04
Loss = 4.5017e-01, PNorm = 44.2990, GNorm = 17.8550, lr_0 = 1.9406e-04
Validation rmse = 0.823340
Epoch 22
Loss = 5.1572e-01, PNorm = 44.3074, GNorm = 6.4975, lr_0 = 1.8434e-04
Validation rmse = 0.828267
Epoch 23
Loss = 4.3847e-01, PNorm = 44.3198, GNorm = 4.2742, lr_0 = 1.7511e-04
Loss = 4.2593e-01, PNorm = 44.3318, GNorm = 12.4824, lr_0 = 1.6633e-04
Validation rmse = 0.812761
Epoch 24
Loss = 4.0344e-01, PNorm = 44.3431, GNorm = 7.7825, lr_0 = 1.5800e-04
Loss = 4.3824e-01, PNorm = 44.3530, GNorm = 4.2366, lr_0 = 1.5009e-04
Validation rmse = 0.809263
Epoch 25
Loss = 4.2594e-01, PNorm = 44.3596, GNorm = 2.8930, lr_0 = 1.4257e-04
Validation rmse = 0.820164
Epoch 26
Loss = 4.3439e-01, PNorm = 44.3685, GNorm = 2.8643, lr_0 = 1.3542e-04
Loss = 3.6487e-01, PNorm = 44.3776, GNorm = 6.9655, lr_0 = 1.2864e-04
Validation rmse = 0.815573
Epoch 27
Loss = 4.5005e-01, PNorm = 44.3865, GNorm = 3.6776, lr_0 = 1.2220e-04
Validation rmse = 0.810616
Epoch 28
Loss = 5.2406e-01, PNorm = 44.3935, GNorm = 10.5155, lr_0 = 1.1607e-04
Loss = 4.4121e-01, PNorm = 44.3989, GNorm = 12.7522, lr_0 = 1.1026e-04
Validation rmse = 0.819186
Epoch 29
Loss = 3.9920e-01, PNorm = 44.4055, GNorm = 5.3914, lr_0 = 1.0473e-04
Loss = 3.8018e-01, PNorm = 44.4127, GNorm = 8.4774, lr_0 = 1.0000e-04
Validation rmse = 0.810569
Model 0 best validation rmse = 0.809263 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.674868
Ensemble test rmse = 0.674868
1-fold cross validation
	Seed 0 ==> test rmse = 0.674868
Overall test rmse = 0.674868 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7839e+00, PNorm = 43.3162, GNorm = 2.1368, lr_0 = 4.0937e-04
Validation rmse = 1.440581
Epoch 1
Loss = 1.4184e+00, PNorm = 43.3301, GNorm = 1.1245, lr_0 = 7.1875e-04
Loss = 1.3343e+00, PNorm = 43.3668, GNorm = 1.5231, lr_0 = 1.0000e-03
Validation rmse = 1.377410
Epoch 2
Loss = 1.2117e+00, PNorm = 43.4135, GNorm = 1.7198, lr_0 = 9.4990e-04
Loss = 1.1041e+00, PNorm = 43.4786, GNorm = 1.6816, lr_0 = 9.0231e-04
Validation rmse = 1.201355
Epoch 3
Loss = 9.7554e-01, PNorm = 43.5467, GNorm = 2.0962, lr_0 = 8.5711e-04
Validation rmse = 0.992108
Epoch 4
Loss = 7.8856e-01, PNorm = 43.6022, GNorm = 2.9247, lr_0 = 8.1417e-04
Loss = 8.9225e-01, PNorm = 43.6565, GNorm = 9.0152, lr_0 = 7.7338e-04
Validation rmse = 1.059401
Epoch 5
Loss = 8.8565e-01, PNorm = 43.7033, GNorm = 2.4256, lr_0 = 7.3463e-04
Loss = 7.7038e-01, PNorm = 43.7524, GNorm = 1.5115, lr_0 = 6.9783e-04
Loss = 7.7480e-01, PNorm = 43.7576, GNorm = 9.5103, lr_0 = 6.9425e-04
Validation rmse = 1.076947
Epoch 6
Loss = 7.2250e-01, PNorm = 43.8008, GNorm = 1.7879, lr_0 = 6.5947e-04
Validation rmse = 0.861733
Epoch 7
Loss = 5.7287e-01, PNorm = 43.8417, GNorm = 3.1445, lr_0 = 6.2643e-04
Loss = 6.4312e-01, PNorm = 43.8732, GNorm = 5.6859, lr_0 = 5.9505e-04
Validation rmse = 0.831184
Epoch 8
Loss = 6.6495e-01, PNorm = 43.9056, GNorm = 5.3012, lr_0 = 5.6524e-04
Loss = 5.6445e-01, PNorm = 43.9372, GNorm = 2.2326, lr_0 = 5.3692e-04
Validation rmse = 0.900201
Epoch 9
Loss = 5.7789e-01, PNorm = 43.9636, GNorm = 2.6441, lr_0 = 5.1002e-04
Validation rmse = 0.867218
Epoch 10
Loss = 4.4171e-01, PNorm = 43.9936, GNorm = 3.3192, lr_0 = 4.8447e-04
Loss = 6.1463e-01, PNorm = 44.0178, GNorm = 5.4171, lr_0 = 4.6020e-04
Validation rmse = 0.820205
Epoch 11
Loss = 5.3137e-01, PNorm = 44.0447, GNorm = 4.0982, lr_0 = 4.3490e-04
Loss = 5.1424e-01, PNorm = 44.0696, GNorm = 6.9531, lr_0 = 4.1312e-04
Validation rmse = 0.815714
Epoch 12
Loss = 4.6652e-01, PNorm = 44.0864, GNorm = 10.7984, lr_0 = 3.9242e-04
Validation rmse = 0.794552
Epoch 13
Loss = 4.5348e-01, PNorm = 44.1112, GNorm = 5.0112, lr_0 = 3.7276e-04
Loss = 4.4422e-01, PNorm = 44.1307, GNorm = 5.4372, lr_0 = 3.5408e-04
Validation rmse = 0.824398
Epoch 14
Loss = 4.5981e-01, PNorm = 44.1503, GNorm = 2.7774, lr_0 = 3.3635e-04
Loss = 4.8685e-01, PNorm = 44.1656, GNorm = 8.3528, lr_0 = 3.1950e-04
Validation rmse = 0.846549
Epoch 15
Loss = 4.1960e-01, PNorm = 44.1817, GNorm = 3.8932, lr_0 = 3.0349e-04
Validation rmse = 0.782356
Epoch 16
Loss = 4.1768e-01, PNorm = 44.2002, GNorm = 4.5183, lr_0 = 2.8681e-04
Loss = 3.8833e-01, PNorm = 44.2179, GNorm = 11.4276, lr_0 = 2.7244e-04
Validation rmse = 0.779011
Epoch 17
Loss = 4.3240e-01, PNorm = 44.2300, GNorm = 6.7596, lr_0 = 2.5879e-04
Loss = 3.7045e-01, PNorm = 44.2438, GNorm = 4.5465, lr_0 = 2.4582e-04
Validation rmse = 0.764766
Epoch 18
Loss = 3.9593e-01, PNorm = 44.2577, GNorm = 3.5810, lr_0 = 2.3351e-04
Validation rmse = 0.790873
Epoch 19
Loss = 2.9802e-01, PNorm = 44.2693, GNorm = 7.5258, lr_0 = 2.2181e-04
Loss = 3.8332e-01, PNorm = 44.2808, GNorm = 5.3477, lr_0 = 2.1070e-04
Validation rmse = 0.791455
Epoch 20
Loss = 3.0920e-01, PNorm = 44.2921, GNorm = 4.3049, lr_0 = 2.0014e-04
Loss = 3.4095e-01, PNorm = 44.3028, GNorm = 10.0664, lr_0 = 1.9012e-04
Validation rmse = 0.763931
Epoch 21
Loss = 3.2259e-01, PNorm = 44.3140, GNorm = 5.5792, lr_0 = 1.7967e-04
Validation rmse = 0.777337
Epoch 22
Loss = 3.1916e-01, PNorm = 44.3248, GNorm = 4.8846, lr_0 = 1.7066e-04
Loss = 3.3449e-01, PNorm = 44.3331, GNorm = 9.9493, lr_0 = 1.6211e-04
Validation rmse = 0.753887
Epoch 23
Loss = 3.2928e-01, PNorm = 44.3413, GNorm = 10.3692, lr_0 = 1.5399e-04
Loss = 3.6138e-01, PNorm = 44.3480, GNorm = 8.7201, lr_0 = 1.4628e-04
Validation rmse = 0.743952
Epoch 24
Loss = 3.4221e-01, PNorm = 44.3557, GNorm = 6.7136, lr_0 = 1.3895e-04
Loss = 2.9975e-01, PNorm = 44.3637, GNorm = 7.6127, lr_0 = 1.3199e-04
Validation rmse = 0.751601
Epoch 25
Loss = 2.6393e-01, PNorm = 44.3708, GNorm = 10.9081, lr_0 = 1.2538e-04
Validation rmse = 0.751666
Epoch 26
Loss = 2.6072e-01, PNorm = 44.3774, GNorm = 4.9433, lr_0 = 1.1848e-04
Loss = 3.5010e-01, PNorm = 44.3824, GNorm = 10.6259, lr_0 = 1.1255e-04
Validation rmse = 0.749681
Epoch 27
Loss = 2.9946e-01, PNorm = 44.3892, GNorm = 8.0065, lr_0 = 1.0691e-04
Loss = 2.7147e-01, PNorm = 44.3949, GNorm = 7.8793, lr_0 = 1.0155e-04
Validation rmse = 0.756832
Epoch 28
Loss = 2.7819e-01, PNorm = 44.4006, GNorm = 4.5514, lr_0 = 1.0000e-04
Validation rmse = 0.747478
Epoch 29
Loss = 2.3280e-01, PNorm = 44.4059, GNorm = 3.4797, lr_0 = 1.0000e-04
Loss = 2.5187e-01, PNorm = 44.4110, GNorm = 3.8063, lr_0 = 1.0000e-04
Validation rmse = 0.749841
Model 0 best validation rmse = 0.743952 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.687807
Ensemble test rmse = 0.687807
1-fold cross validation
	Seed 0 ==> test rmse = 0.687807
Overall test rmse = 0.687807 +/- 0.000000
Elapsed time = 0:01:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8792e+00, PNorm = 43.3135, GNorm = 1.9417, lr_0 = 3.9118e-04
Validation rmse = 1.481603
Epoch 1
Loss = 1.4596e+00, PNorm = 43.3251, GNorm = 1.3557, lr_0 = 6.8235e-04
Loss = 1.3545e+00, PNorm = 43.3549, GNorm = 1.4344, lr_0 = 9.4706e-04
Validation rmse = 1.375118
Epoch 2
Loss = 1.2940e+00, PNorm = 43.3971, GNorm = 0.9087, lr_0 = 9.6204e-04
Loss = 1.1291e+00, PNorm = 43.4552, GNorm = 1.6890, lr_0 = 9.1661e-04
Validation rmse = 1.114516
Epoch 3
Loss = 1.0794e+00, PNorm = 43.5199, GNorm = 2.8027, lr_0 = 8.6911e-04
Loss = 8.8757e-01, PNorm = 43.5897, GNorm = 2.6570, lr_0 = 8.2807e-04
Validation rmse = 0.941014
Epoch 4
Loss = 8.0697e-01, PNorm = 43.6533, GNorm = 2.7403, lr_0 = 7.8897e-04
Validation rmse = 0.882754
Epoch 5
Loss = 7.1370e-01, PNorm = 43.7004, GNorm = 4.2377, lr_0 = 7.5171e-04
Loss = 7.7038e-01, PNorm = 43.7506, GNorm = 8.4639, lr_0 = 7.1621e-04
Validation rmse = 0.987243
Epoch 6
Loss = 7.9792e-01, PNorm = 43.7948, GNorm = 6.2044, lr_0 = 6.7910e-04
Loss = 6.5509e-01, PNorm = 43.8379, GNorm = 7.5646, lr_0 = 6.4703e-04
Validation rmse = 0.948116
Epoch 7
Loss = 6.8976e-01, PNorm = 43.8691, GNorm = 5.2341, lr_0 = 6.1648e-04
Loss = 7.1850e-01, PNorm = 43.9013, GNorm = 6.2890, lr_0 = 5.8736e-04
Loss = 7.1648e-01, PNorm = 43.9039, GNorm = 5.6978, lr_0 = 5.8453e-04
Validation rmse = 0.878810
Epoch 8
Loss = 6.2578e-01, PNorm = 43.9341, GNorm = 11.3348, lr_0 = 5.5693e-04
Validation rmse = 0.822627
Epoch 9
Loss = 5.2235e-01, PNorm = 43.9589, GNorm = 2.0587, lr_0 = 5.3063e-04
Loss = 6.1485e-01, PNorm = 43.9876, GNorm = 9.7780, lr_0 = 5.0557e-04
Validation rmse = 0.799077
Epoch 10
Loss = 5.1428e-01, PNorm = 44.0113, GNorm = 2.9973, lr_0 = 4.8170e-04
Loss = 4.6917e-01, PNorm = 44.0358, GNorm = 5.2679, lr_0 = 4.5895e-04
Validation rmse = 0.775359
Epoch 11
Loss = 4.6612e-01, PNorm = 44.0612, GNorm = 2.7084, lr_0 = 4.3517e-04
Loss = 4.4298e-01, PNorm = 44.0816, GNorm = 10.0624, lr_0 = 4.1462e-04
Validation rmse = 0.734435
Epoch 12
Loss = 4.7044e-01, PNorm = 44.1048, GNorm = 6.0276, lr_0 = 3.9504e-04
Validation rmse = 0.708919
Epoch 13
Loss = 5.7417e-01, PNorm = 44.1271, GNorm = 8.4316, lr_0 = 3.7457e-04
Loss = 3.8515e-01, PNorm = 44.1478, GNorm = 7.7470, lr_0 = 3.5688e-04
Validation rmse = 0.712640
Epoch 14
Loss = 4.1293e-01, PNorm = 44.1701, GNorm = 8.4975, lr_0 = 3.4003e-04
Loss = 4.1427e-01, PNorm = 44.1890, GNorm = 3.9661, lr_0 = 3.2397e-04
Validation rmse = 0.723596
Epoch 15
Loss = 2.6734e-01, PNorm = 44.2123, GNorm = 3.4469, lr_0 = 3.0867e-04
Loss = 3.9137e-01, PNorm = 44.2291, GNorm = 4.3624, lr_0 = 2.9409e-04
Validation rmse = 0.695014
Epoch 16
Loss = 3.3686e-01, PNorm = 44.2445, GNorm = 5.3507, lr_0 = 2.7885e-04
Validation rmse = 0.689213
Epoch 17
Loss = 4.4279e-01, PNorm = 44.2608, GNorm = 11.6594, lr_0 = 2.6569e-04
Loss = 3.4095e-01, PNorm = 44.2735, GNorm = 5.2598, lr_0 = 2.5314e-04
Validation rmse = 0.692993
Epoch 18
Loss = 2.9724e-01, PNorm = 44.2907, GNorm = 3.9614, lr_0 = 2.4002e-04
Loss = 3.1480e-01, PNorm = 44.3046, GNorm = 4.7837, lr_0 = 2.2869e-04
Validation rmse = 0.690114
Epoch 19
Loss = 3.3428e-01, PNorm = 44.3149, GNorm = 3.1630, lr_0 = 2.1789e-04
Loss = 2.9605e-01, PNorm = 44.3295, GNorm = 7.9803, lr_0 = 2.0760e-04
Validation rmse = 0.699454
Epoch 20
Loss = 2.9067e-01, PNorm = 44.3379, GNorm = 4.7560, lr_0 = 1.9780e-04
Validation rmse = 0.775741
Epoch 21
Loss = 2.5805e-01, PNorm = 44.3517, GNorm = 5.5580, lr_0 = 1.8755e-04
Loss = 2.8355e-01, PNorm = 44.3616, GNorm = 4.4894, lr_0 = 1.7869e-04
Validation rmse = 0.685520
Epoch 22
Loss = 2.7161e-01, PNorm = 44.3738, GNorm = 2.1596, lr_0 = 1.7025e-04
Loss = 2.7364e-01, PNorm = 44.3805, GNorm = 5.2816, lr_0 = 1.6221e-04
Validation rmse = 0.727373
Epoch 23
Loss = 2.7151e-01, PNorm = 44.3923, GNorm = 6.5349, lr_0 = 1.5381e-04
Loss = 2.4707e-01, PNorm = 44.4011, GNorm = 3.5566, lr_0 = 1.4654e-04
Validation rmse = 0.713374
Epoch 24
Loss = 2.6087e-01, PNorm = 44.4083, GNorm = 18.6277, lr_0 = 1.3962e-04
Loss = 2.6570e-01, PNorm = 44.4156, GNorm = 7.4156, lr_0 = 1.3303e-04
Validation rmse = 0.690254
Epoch 25
Loss = 2.4968e-01, PNorm = 44.4226, GNorm = 5.1401, lr_0 = 1.2675e-04
Validation rmse = 0.686382
Epoch 26
Loss = 2.5113e-01, PNorm = 44.4303, GNorm = 12.5639, lr_0 = 1.2018e-04
Loss = 2.0796e-01, PNorm = 44.4376, GNorm = 3.3851, lr_0 = 1.1450e-04
Validation rmse = 0.690969
Epoch 27
Loss = 2.1285e-01, PNorm = 44.4414, GNorm = 9.6299, lr_0 = 1.0910e-04
Loss = 2.2000e-01, PNorm = 44.4481, GNorm = 3.5213, lr_0 = 1.0395e-04
Validation rmse = 0.679623
Epoch 28
Loss = 2.1921e-01, PNorm = 44.4552, GNorm = 11.1710, lr_0 = 1.0000e-04
Loss = 2.0940e-01, PNorm = 44.4609, GNorm = 6.6541, lr_0 = 1.0000e-04
Validation rmse = 0.718855
Epoch 29
Loss = 1.4783e-01, PNorm = 44.4665, GNorm = 12.6074, lr_0 = 1.0000e-04
Validation rmse = 0.689289
Model 0 best validation rmse = 0.679623 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.668189
Ensemble test rmse = 0.668189
1-fold cross validation
	Seed 0 ==> test rmse = 0.668189
Overall test rmse = 0.668189 +/- 0.000000
Elapsed time = 0:01:29
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8580e+00, PNorm = 43.3135, GNorm = 1.8669, lr_0 = 3.7500e-04
Validation rmse = 1.460216
Epoch 1
Loss = 1.4601e+00, PNorm = 43.3252, GNorm = 1.2684, lr_0 = 6.5000e-04
Loss = 1.3697e+00, PNorm = 43.3513, GNorm = 0.7721, lr_0 = 9.0000e-04
Validation rmse = 1.242801
Epoch 2
Loss = 1.1885e+00, PNorm = 43.4003, GNorm = 0.8640, lr_0 = 9.6853e-04
Loss = 1.1610e+00, PNorm = 43.4606, GNorm = 1.9097, lr_0 = 9.2527e-04
Validation rmse = 0.972268
Epoch 3
Loss = 9.7879e-01, PNorm = 43.5372, GNorm = 8.7057, lr_0 = 8.8395e-04
Loss = 8.9550e-01, PNorm = 43.6024, GNorm = 1.6851, lr_0 = 8.4448e-04
Validation rmse = 0.867944
Epoch 4
Loss = 8.2449e-01, PNorm = 43.6680, GNorm = 22.1005, lr_0 = 8.0309e-04
Loss = 8.3716e-01, PNorm = 43.7015, GNorm = 1.4276, lr_0 = 7.6722e-04
Validation rmse = 0.869923
Epoch 5
Loss = 7.6849e-01, PNorm = 43.7482, GNorm = 4.0901, lr_0 = 7.3296e-04
Loss = 6.3357e-01, PNorm = 43.7943, GNorm = 5.0820, lr_0 = 7.0023e-04
Loss = 6.7565e-01, PNorm = 43.7978, GNorm = 4.6174, lr_0 = 6.9703e-04
Validation rmse = 0.751289
Epoch 6
Loss = 6.2873e-01, PNorm = 43.8324, GNorm = 2.9643, lr_0 = 6.6591e-04
Validation rmse = 0.709475
Epoch 7
Loss = 5.1669e-01, PNorm = 43.8673, GNorm = 2.2651, lr_0 = 6.3327e-04
Loss = 5.7236e-01, PNorm = 43.8980, GNorm = 10.1864, lr_0 = 6.0499e-04
Validation rmse = 0.748873
Epoch 8
Loss = 5.0583e-01, PNorm = 43.9249, GNorm = 2.2114, lr_0 = 5.7797e-04
Loss = 5.2366e-01, PNorm = 43.9571, GNorm = 2.1819, lr_0 = 5.5216e-04
Validation rmse = 0.720070
Epoch 9
Loss = 4.8089e-01, PNorm = 43.9821, GNorm = 9.8513, lr_0 = 5.2510e-04
Loss = 5.2637e-01, PNorm = 44.0087, GNorm = 12.3949, lr_0 = 5.0165e-04
Validation rmse = 0.740673
Epoch 10
Loss = 4.9388e-01, PNorm = 44.0337, GNorm = 1.8304, lr_0 = 4.7924e-04
Loss = 4.3326e-01, PNorm = 44.0611, GNorm = 4.8375, lr_0 = 4.5784e-04
Validation rmse = 0.737881
Epoch 11
Loss = 4.8558e-01, PNorm = 44.0774, GNorm = 3.5552, lr_0 = 4.3540e-04
Loss = 4.2384e-01, PNorm = 44.1016, GNorm = 2.8261, lr_0 = 4.1596e-04
Loss = 5.1457e-01, PNorm = 44.1039, GNorm = 9.4875, lr_0 = 4.1406e-04
Validation rmse = 0.712810
Epoch 12
Loss = 4.1943e-01, PNorm = 44.1239, GNorm = 12.0204, lr_0 = 3.9557e-04
Validation rmse = 0.693980
Epoch 13
Loss = 4.5856e-01, PNorm = 44.1387, GNorm = 1.9903, lr_0 = 3.7790e-04
Loss = 5.0931e-01, PNorm = 44.1510, GNorm = 3.2865, lr_0 = 3.6103e-04
Validation rmse = 0.687215
Epoch 14
Loss = 4.1155e-01, PNorm = 44.1722, GNorm = 10.0030, lr_0 = 3.4333e-04
Loss = 3.9535e-01, PNorm = 44.1910, GNorm = 9.5318, lr_0 = 3.2800e-04
Validation rmse = 0.682507
Epoch 15
Loss = 2.9764e-01, PNorm = 44.2078, GNorm = 3.5165, lr_0 = 3.1335e-04
Loss = 3.2512e-01, PNorm = 44.2207, GNorm = 10.1139, lr_0 = 2.9936e-04
Validation rmse = 0.686226
Epoch 16
Loss = 4.0265e-01, PNorm = 44.2306, GNorm = 3.1787, lr_0 = 2.8469e-04
Loss = 3.1110e-01, PNorm = 44.2459, GNorm = 4.5168, lr_0 = 2.7197e-04
Validation rmse = 0.675106
Epoch 17
Loss = 3.0379e-01, PNorm = 44.2634, GNorm = 8.3715, lr_0 = 2.5864e-04
Loss = 3.4971e-01, PNorm = 44.2713, GNorm = 2.5329, lr_0 = 2.4709e-04
Validation rmse = 0.680688
Epoch 18
Loss = 2.8587e-01, PNorm = 44.2830, GNorm = 2.9383, lr_0 = 2.3606e-04
Validation rmse = 0.688907
Epoch 19
Loss = 2.9575e-01, PNorm = 44.2951, GNorm = 6.1009, lr_0 = 2.2449e-04
Loss = 3.3290e-01, PNorm = 44.3042, GNorm = 7.7212, lr_0 = 2.1446e-04
Validation rmse = 0.689352
Epoch 20
Loss = 1.9252e-01, PNorm = 44.3151, GNorm = 5.5671, lr_0 = 2.0488e-04
Loss = 2.8291e-01, PNorm = 44.3244, GNorm = 6.7280, lr_0 = 1.9573e-04
Validation rmse = 0.688294
Epoch 21
Loss = 1.9569e-01, PNorm = 44.3322, GNorm = 3.2995, lr_0 = 1.8614e-04
Loss = 2.8994e-01, PNorm = 44.3418, GNorm = 4.3694, lr_0 = 1.7783e-04
Validation rmse = 0.679991
Epoch 22
Loss = 3.0188e-01, PNorm = 44.3526, GNorm = 5.5125, lr_0 = 1.6911e-04
Loss = 2.8195e-01, PNorm = 44.3599, GNorm = 2.6705, lr_0 = 1.6156e-04
Validation rmse = 0.683247
Epoch 23
Loss = 2.2917e-01, PNorm = 44.3665, GNorm = 3.7757, lr_0 = 1.5434e-04
Loss = 2.8208e-01, PNorm = 44.3741, GNorm = 5.0324, lr_0 = 1.4745e-04
Validation rmse = 0.688012
Epoch 24
Loss = 1.8030e-01, PNorm = 44.3846, GNorm = 5.3104, lr_0 = 1.4022e-04
Loss = 3.2649e-01, PNorm = 44.3898, GNorm = 5.2947, lr_0 = 1.3396e-04
Validation rmse = 0.680608
Epoch 25
Loss = 2.1462e-01, PNorm = 44.3948, GNorm = 3.8031, lr_0 = 1.2798e-04
Validation rmse = 0.677459
Epoch 26
Loss = 2.5350e-01, PNorm = 44.4002, GNorm = 4.6529, lr_0 = 1.2171e-04
Loss = 2.1380e-01, PNorm = 44.4053, GNorm = 7.2703, lr_0 = 1.1627e-04
Validation rmse = 0.678937
Epoch 27
Loss = 2.3255e-01, PNorm = 44.4128, GNorm = 8.1470, lr_0 = 1.1057e-04
Loss = 2.3533e-01, PNorm = 44.4179, GNorm = 7.4788, lr_0 = 1.0564e-04
Validation rmse = 0.673307
Epoch 28
Loss = 2.3569e-01, PNorm = 44.4229, GNorm = 14.9576, lr_0 = 1.0092e-04
Loss = 2.0579e-01, PNorm = 44.4271, GNorm = 7.2591, lr_0 = 1.0000e-04
Validation rmse = 0.671803
Epoch 29
Loss = 1.5759e-01, PNorm = 44.4334, GNorm = 4.4166, lr_0 = 1.0000e-04
Loss = 2.5532e-01, PNorm = 44.4383, GNorm = 3.9977, lr_0 = 1.0000e-04
Validation rmse = 0.669075
Model 0 best validation rmse = 0.669075 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.610755
Ensemble test rmse = 0.610755
1-fold cross validation
	Seed 0 ==> test rmse = 0.610755
Overall test rmse = 0.610755 +/- 0.000000
Elapsed time = 0:01:33
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8078e+00, PNorm = 43.3151, GNorm = 1.4472, lr_0 = 3.6053e-04
Validation rmse = 1.626003
Epoch 1
Loss = 1.4784e+00, PNorm = 43.3260, GNorm = 1.4433, lr_0 = 6.2105e-04
Loss = 1.3357e+00, PNorm = 43.3539, GNorm = 0.8963, lr_0 = 8.5789e-04
Validation rmse = 1.401075
Epoch 2
Loss = 1.1426e+00, PNorm = 43.4061, GNorm = 1.4213, lr_0 = 9.7859e-04
Loss = 1.0903e+00, PNorm = 43.4781, GNorm = 4.0885, lr_0 = 9.3714e-04
Validation rmse = 1.202169
Epoch 3
Loss = 8.3803e-01, PNorm = 43.5530, GNorm = 2.4295, lr_0 = 8.9357e-04
Loss = 7.7487e-01, PNorm = 43.6153, GNorm = 2.4537, lr_0 = 8.5572e-04
Validation rmse = 0.856655
Epoch 4
Loss = 7.3959e-01, PNorm = 43.6609, GNorm = 13.7979, lr_0 = 8.1593e-04
Loss = 7.1593e-01, PNorm = 43.7020, GNorm = 10.1052, lr_0 = 7.8137e-04
Validation rmse = 0.820558
Epoch 5
Loss = 5.3283e-01, PNorm = 43.7500, GNorm = 3.4800, lr_0 = 7.4827e-04
Loss = 6.0366e-01, PNorm = 43.7846, GNorm = 5.1226, lr_0 = 7.1658e-04
Validation rmse = 0.812185
Epoch 6
Loss = 5.7705e-01, PNorm = 43.8211, GNorm = 6.7762, lr_0 = 6.8326e-04
Loss = 5.1435e-01, PNorm = 43.8582, GNorm = 4.6890, lr_0 = 6.5432e-04
Validation rmse = 0.754170
Epoch 7
Loss = 5.0576e-01, PNorm = 43.8919, GNorm = 2.1788, lr_0 = 6.2390e-04
Loss = 5.2947e-01, PNorm = 43.9200, GNorm = 5.5135, lr_0 = 5.9747e-04
Validation rmse = 0.733634
Epoch 8
Loss = 4.3843e-01, PNorm = 43.9429, GNorm = 3.4895, lr_0 = 5.6969e-04
Loss = 4.8112e-01, PNorm = 43.9710, GNorm = 2.3894, lr_0 = 5.4556e-04
Validation rmse = 0.769728
Epoch 9
Loss = 3.9857e-01, PNorm = 43.9950, GNorm = 6.9966, lr_0 = 5.2019e-04
Loss = 4.8368e-01, PNorm = 44.0146, GNorm = 2.7642, lr_0 = 4.9816e-04
Validation rmse = 0.741039
Epoch 10
Loss = 4.5588e-01, PNorm = 44.0245, GNorm = 4.5253, lr_0 = 4.7706e-04
Loss = 4.8607e-01, PNorm = 44.0461, GNorm = 3.4042, lr_0 = 4.5685e-04
Validation rmse = 0.733560
Epoch 11
Loss = 3.7521e-01, PNorm = 44.0736, GNorm = 7.7036, lr_0 = 4.3561e-04
Loss = 4.0357e-01, PNorm = 44.0860, GNorm = 6.5721, lr_0 = 4.1716e-04
Loss = 7.3840e-01, PNorm = 44.0861, GNorm = 9.4505, lr_0 = 4.1536e-04
Validation rmse = 0.746421
Epoch 12
Loss = 3.9591e-01, PNorm = 44.0975, GNorm = 4.1686, lr_0 = 3.9776e-04
Validation rmse = 0.715667
Epoch 13
Loss = 2.5149e-01, PNorm = 44.1161, GNorm = 2.9695, lr_0 = 3.7927e-04
Loss = 3.8832e-01, PNorm = 44.1317, GNorm = 11.7908, lr_0 = 3.6320e-04
Validation rmse = 0.711789
Epoch 14
Loss = 2.3227e-01, PNorm = 44.1497, GNorm = 4.6090, lr_0 = 3.4632e-04
Loss = 3.3297e-01, PNorm = 44.1636, GNorm = 7.6034, lr_0 = 3.3165e-04
Validation rmse = 0.748385
Epoch 15
Loss = 3.9365e-01, PNorm = 44.1746, GNorm = 9.2405, lr_0 = 3.1760e-04
Loss = 4.3333e-01, PNorm = 44.1825, GNorm = 4.5244, lr_0 = 3.0415e-04
Validation rmse = 0.727372
Epoch 16
Loss = 3.3102e-01, PNorm = 44.1996, GNorm = 10.1013, lr_0 = 2.9001e-04
Loss = 3.7478e-01, PNorm = 44.2140, GNorm = 3.6556, lr_0 = 2.7772e-04
Validation rmse = 0.703361
Epoch 17
Loss = 2.5053e-01, PNorm = 44.2253, GNorm = 3.7533, lr_0 = 2.6481e-04
Loss = 2.7461e-01, PNorm = 44.2343, GNorm = 6.9499, lr_0 = 2.5359e-04
Validation rmse = 0.712084
Epoch 18
Loss = 3.1230e-01, PNorm = 44.2432, GNorm = 5.3078, lr_0 = 2.4180e-04
Loss = 3.5170e-01, PNorm = 44.2543, GNorm = 2.5372, lr_0 = 2.3156e-04
Validation rmse = 0.690262
Epoch 19
Loss = 3.2713e-01, PNorm = 44.2629, GNorm = 5.8106, lr_0 = 2.2079e-04
Loss = 3.1396e-01, PNorm = 44.2720, GNorm = 4.4679, lr_0 = 2.1144e-04
Validation rmse = 0.697921
Epoch 20
Loss = 2.3163e-01, PNorm = 44.2784, GNorm = 3.7371, lr_0 = 2.0248e-04
Loss = 2.5189e-01, PNorm = 44.2880, GNorm = 8.4473, lr_0 = 1.9391e-04
Validation rmse = 0.690851
Epoch 21
Loss = 2.2140e-01, PNorm = 44.2975, GNorm = 9.8158, lr_0 = 1.8489e-04
Loss = 2.5901e-01, PNorm = 44.3051, GNorm = 8.0557, lr_0 = 1.7706e-04
Validation rmse = 0.701185
Epoch 22
Loss = 3.1998e-01, PNorm = 44.3131, GNorm = 6.8512, lr_0 = 1.6883e-04
Loss = 2.1119e-01, PNorm = 44.3207, GNorm = 3.3013, lr_0 = 1.6168e-04
Validation rmse = 0.710296
Epoch 23
Loss = 2.9960e-01, PNorm = 44.3265, GNorm = 10.0183, lr_0 = 1.5416e-04
Loss = 2.4321e-01, PNorm = 44.3333, GNorm = 11.4919, lr_0 = 1.4763e-04
Loss = 1.1187e-01, PNorm = 44.3340, GNorm = 18.0171, lr_0 = 1.4699e-04
Validation rmse = 0.689025
Epoch 24
Loss = 2.4892e-01, PNorm = 44.3410, GNorm = 13.4791, lr_0 = 1.4077e-04
Loss = 2.6328e-01, PNorm = 44.3465, GNorm = 7.6187, lr_0 = 1.3480e-04
Validation rmse = 0.697817
Epoch 25
Loss = 2.3175e-01, PNorm = 44.3516, GNorm = 7.5998, lr_0 = 1.2909e-04
Validation rmse = 0.682797
Epoch 26
Loss = 2.8834e-01, PNorm = 44.3569, GNorm = 2.7410, lr_0 = 1.2309e-04
Loss = 2.3796e-01, PNorm = 44.3623, GNorm = 5.9999, lr_0 = 1.1788e-04
Validation rmse = 0.692022
Epoch 27
Loss = 2.1742e-01, PNorm = 44.3676, GNorm = 5.3338, lr_0 = 1.1240e-04
Loss = 2.1715e-01, PNorm = 44.3715, GNorm = 4.3991, lr_0 = 1.0764e-04
Validation rmse = 0.692756
Epoch 28
Loss = 2.5082e-01, PNorm = 44.3752, GNorm = 8.1982, lr_0 = 1.0263e-04
Loss = 1.8999e-01, PNorm = 44.3790, GNorm = 3.2683, lr_0 = 1.0000e-04
Validation rmse = 0.700233
Epoch 29
Loss = 1.5435e-01, PNorm = 44.3835, GNorm = 2.5507, lr_0 = 1.0000e-04
Loss = 2.1327e-01, PNorm = 44.3884, GNorm = 8.0227, lr_0 = 1.0000e-04
Validation rmse = 0.689504
Model 0 best validation rmse = 0.682797 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.647800
Ensemble test rmse = 0.647800
1-fold cross validation
	Seed 0 ==> test rmse = 0.647800
Overall test rmse = 0.647800 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9148e+00, PNorm = 43.3133, GNorm = 1.0777, lr_0 = 3.4750e-04
Loss = 1.4944e+00, PNorm = 43.3209, GNorm = 1.2474, lr_0 = 5.7250e-04
Validation rmse = 1.535133
Epoch 1
Loss = 1.3706e+00, PNorm = 43.3442, GNorm = 1.2115, lr_0 = 7.9750e-04
Loss = 1.2466e+00, PNorm = 43.3891, GNorm = 1.0569, lr_0 = 9.9590e-04
Validation rmse = 1.497159
Epoch 2
Loss = 1.1191e+00, PNorm = 43.4497, GNorm = 1.5143, lr_0 = 9.5578e-04
Loss = 1.0004e+00, PNorm = 43.5208, GNorm = 3.2683, lr_0 = 9.1728e-04
Validation rmse = 1.026213
Epoch 3
Loss = 9.0545e-01, PNorm = 43.5897, GNorm = 3.9671, lr_0 = 8.8032e-04
Loss = 7.9221e-01, PNorm = 43.6536, GNorm = 9.5061, lr_0 = 8.4486e-04
Validation rmse = 1.016199
Epoch 4
Loss = 7.0478e-01, PNorm = 43.7084, GNorm = 2.1612, lr_0 = 8.1083e-04
Loss = 6.6476e-01, PNorm = 43.7566, GNorm = 14.2856, lr_0 = 7.7816e-04
Validation rmse = 0.918819
Epoch 5
Loss = 6.7611e-01, PNorm = 43.7963, GNorm = 5.6590, lr_0 = 7.4682e-04
Loss = 5.3942e-01, PNorm = 43.8377, GNorm = 6.3570, lr_0 = 7.1673e-04
Validation rmse = 0.868353
Epoch 6
Loss = 5.2899e-01, PNorm = 43.8741, GNorm = 5.7495, lr_0 = 6.8786e-04
Loss = 5.2242e-01, PNorm = 43.9018, GNorm = 1.9219, lr_0 = 6.6015e-04
Validation rmse = 0.994252
Epoch 7
Loss = 5.3512e-01, PNorm = 43.9287, GNorm = 1.9323, lr_0 = 6.3356e-04
Loss = 4.5279e-01, PNorm = 43.9577, GNorm = 2.0408, lr_0 = 6.0803e-04
Validation rmse = 0.821893
Epoch 8
Loss = 4.3418e-01, PNorm = 43.9926, GNorm = 7.0532, lr_0 = 5.8354e-04
Loss = 4.6110e-01, PNorm = 44.0130, GNorm = 2.4718, lr_0 = 5.6003e-04
Validation rmse = 0.816019
Epoch 9
Loss = 4.2184e-01, PNorm = 44.0351, GNorm = 3.4347, lr_0 = 5.3747e-04
Loss = 4.1011e-01, PNorm = 44.0598, GNorm = 7.2113, lr_0 = 5.1582e-04
Validation rmse = 0.812565
Epoch 10
Loss = 3.4595e-01, PNorm = 44.0845, GNorm = 5.5773, lr_0 = 4.9504e-04
Loss = 4.6155e-01, PNorm = 44.1003, GNorm = 2.9802, lr_0 = 4.7510e-04
Validation rmse = 0.861371
Epoch 11
Loss = 3.4934e-01, PNorm = 44.1207, GNorm = 7.6937, lr_0 = 4.5596e-04
Loss = 3.9169e-01, PNorm = 44.1433, GNorm = 3.9610, lr_0 = 4.3759e-04
Validation rmse = 0.921984
Epoch 12
Loss = 3.5789e-01, PNorm = 44.1602, GNorm = 3.6380, lr_0 = 4.1997e-04
Loss = 3.4112e-01, PNorm = 44.1801, GNorm = 8.2885, lr_0 = 4.0305e-04
Validation rmse = 0.822866
Epoch 13
Loss = 2.5496e-01, PNorm = 44.1977, GNorm = 5.5015, lr_0 = 3.8681e-04
Loss = 4.0429e-01, PNorm = 44.2130, GNorm = 7.5391, lr_0 = 3.7123e-04
Validation rmse = 0.800165
Epoch 14
Loss = 3.2376e-01, PNorm = 44.2279, GNorm = 6.3419, lr_0 = 3.5628e-04
Loss = 2.9492e-01, PNorm = 44.2434, GNorm = 6.0302, lr_0 = 3.4192e-04
Validation rmse = 0.885774
Epoch 15
Loss = 2.8686e-01, PNorm = 44.2575, GNorm = 10.3521, lr_0 = 3.2815e-04
Loss = 3.4323e-01, PNorm = 44.2706, GNorm = 4.1660, lr_0 = 3.1493e-04
Validation rmse = 0.807359
Epoch 16
Loss = 3.0048e-01, PNorm = 44.2828, GNorm = 3.2763, lr_0 = 3.0224e-04
Loss = 2.7027e-01, PNorm = 44.2947, GNorm = 10.7620, lr_0 = 2.9007e-04
Validation rmse = 0.806985
Epoch 17
Loss = 3.2488e-01, PNorm = 44.3098, GNorm = 8.4176, lr_0 = 2.7838e-04
Loss = 2.5967e-01, PNorm = 44.3169, GNorm = 5.8772, lr_0 = 2.6717e-04
Validation rmse = 0.790699
Epoch 18
Loss = 2.8501e-01, PNorm = 44.3292, GNorm = 7.5710, lr_0 = 2.5641e-04
Loss = 2.5569e-01, PNorm = 44.3393, GNorm = 3.6460, lr_0 = 2.4608e-04
Validation rmse = 0.808418
Epoch 19
Loss = 2.3047e-01, PNorm = 44.3497, GNorm = 6.5592, lr_0 = 2.3616e-04
Loss = 2.2528e-01, PNorm = 44.3613, GNorm = 4.8080, lr_0 = 2.2665e-04
Validation rmse = 0.807452
Epoch 20
Loss = 2.6452e-01, PNorm = 44.3707, GNorm = 15.9662, lr_0 = 2.1752e-04
Loss = 2.4152e-01, PNorm = 44.3796, GNorm = 14.1307, lr_0 = 2.0876e-04
Validation rmse = 0.797494
Epoch 21
Loss = 2.4425e-01, PNorm = 44.3891, GNorm = 4.4842, lr_0 = 2.0035e-04
Loss = 2.5048e-01, PNorm = 44.3975, GNorm = 4.4129, lr_0 = 1.9228e-04
Validation rmse = 0.794997
Epoch 22
Loss = 2.0540e-01, PNorm = 44.4047, GNorm = 3.5307, lr_0 = 1.8453e-04
Loss = 2.4363e-01, PNorm = 44.4114, GNorm = 7.2600, lr_0 = 1.7710e-04
Validation rmse = 0.795487
Epoch 23
Loss = 2.0618e-01, PNorm = 44.4193, GNorm = 5.0148, lr_0 = 1.6996e-04
Loss = 2.1367e-01, PNorm = 44.4276, GNorm = 3.5139, lr_0 = 1.6312e-04
Validation rmse = 0.808189
Epoch 24
Loss = 2.1078e-01, PNorm = 44.4338, GNorm = 5.2578, lr_0 = 1.5655e-04
Loss = 2.0427e-01, PNorm = 44.4401, GNorm = 4.9472, lr_0 = 1.5024e-04
Validation rmse = 0.781083
Epoch 25
Loss = 2.1593e-01, PNorm = 44.4474, GNorm = 3.3406, lr_0 = 1.4419e-04
Loss = 1.4837e-01, PNorm = 44.4542, GNorm = 6.7049, lr_0 = 1.3838e-04
Validation rmse = 0.786201
Epoch 26
Loss = 2.0278e-01, PNorm = 44.4604, GNorm = 4.8174, lr_0 = 1.3280e-04
Loss = 1.6747e-01, PNorm = 44.4657, GNorm = 10.8987, lr_0 = 1.2746e-04
Validation rmse = 0.799862
Epoch 27
Loss = 1.7676e-01, PNorm = 44.4728, GNorm = 14.7571, lr_0 = 1.2232e-04
Loss = 2.1104e-01, PNorm = 44.4767, GNorm = 11.3379, lr_0 = 1.1739e-04
Validation rmse = 0.833132
Epoch 28
Loss = 1.6608e-01, PNorm = 44.4819, GNorm = 3.8021, lr_0 = 1.1266e-04
Loss = 1.9183e-01, PNorm = 44.4871, GNorm = 6.2494, lr_0 = 1.0813e-04
Validation rmse = 0.784210
Epoch 29
Loss = 1.7075e-01, PNorm = 44.4923, GNorm = 6.9586, lr_0 = 1.0377e-04
Loss = 1.3815e-01, PNorm = 44.4966, GNorm = 5.6858, lr_0 = 1.0000e-04
Validation rmse = 0.794981
Model 0 best validation rmse = 0.781083 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.623251
Ensemble test rmse = 0.623251
1-fold cross validation
	Seed 0 ==> test rmse = 0.623251
Overall test rmse = 0.623251 +/- 0.000000
Elapsed time = 0:01:41
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9936e+00, PNorm = 43.3133, GNorm = 1.2801, lr_0 = 3.4750e-04
Loss = 1.4674e+00, PNorm = 43.3205, GNorm = 1.1259, lr_0 = 5.7250e-04
Loss = 1.4103e+00, PNorm = 43.3219, GNorm = 1.3833, lr_0 = 5.9500e-04
Validation rmse = 1.582990
Epoch 1
Loss = 1.3474e+00, PNorm = 43.3443, GNorm = 1.2908, lr_0 = 8.2000e-04
Loss = 1.2475e+00, PNorm = 43.3871, GNorm = 1.5632, lr_0 = 9.9181e-04
Validation rmse = 1.398938
Epoch 2
Loss = 1.0586e+00, PNorm = 43.4491, GNorm = 5.9675, lr_0 = 9.5186e-04
Loss = 1.0245e+00, PNorm = 43.5082, GNorm = 1.2755, lr_0 = 9.1351e-04
Validation rmse = 1.205176
Epoch 3
Loss = 9.0406e-01, PNorm = 43.5807, GNorm = 5.3406, lr_0 = 8.7671e-04
Loss = 7.5461e-01, PNorm = 43.6414, GNorm = 1.9540, lr_0 = 8.4140e-04
Validation rmse = 1.002232
Epoch 4
Loss = 6.4629e-01, PNorm = 43.7014, GNorm = 5.8807, lr_0 = 8.0750e-04
Loss = 6.5465e-01, PNorm = 43.7465, GNorm = 2.5898, lr_0 = 7.7497e-04
Validation rmse = 0.943916
Epoch 5
Loss = 4.9894e-01, PNorm = 43.7930, GNorm = 3.9882, lr_0 = 7.4375e-04
Loss = 6.0944e-01, PNorm = 43.8281, GNorm = 2.2673, lr_0 = 7.1379e-04
Validation rmse = 0.994140
Epoch 6
Loss = 4.7564e-01, PNorm = 43.8629, GNorm = 5.2546, lr_0 = 6.8223e-04
Loss = 5.3681e-01, PNorm = 43.9065, GNorm = 10.4010, lr_0 = 6.5474e-04
Validation rmse = 0.941739
Epoch 7
Loss = 5.7868e-01, PNorm = 43.9301, GNorm = 5.0286, lr_0 = 6.2837e-04
Loss = 4.3161e-01, PNorm = 43.9558, GNorm = 6.8038, lr_0 = 6.0306e-04
Validation rmse = 0.858341
Epoch 8
Loss = 4.0901e-01, PNorm = 43.9821, GNorm = 6.4730, lr_0 = 5.7876e-04
Loss = 3.8639e-01, PNorm = 44.0094, GNorm = 4.4139, lr_0 = 5.5545e-04
Validation rmse = 0.840598
Epoch 9
Loss = 4.0424e-01, PNorm = 44.0228, GNorm = 5.3406, lr_0 = 5.3307e-04
Loss = 3.8265e-01, PNorm = 44.0470, GNorm = 2.1404, lr_0 = 5.1160e-04
Validation rmse = 0.849488
Epoch 10
Loss = 5.0338e-01, PNorm = 44.0735, GNorm = 6.4301, lr_0 = 4.9099e-04
Loss = 4.2148e-01, PNorm = 44.0925, GNorm = 2.7452, lr_0 = 4.7121e-04
Validation rmse = 0.860293
Epoch 11
Loss = 3.0237e-01, PNorm = 44.1176, GNorm = 3.1439, lr_0 = 4.5037e-04
Loss = 3.3648e-01, PNorm = 44.1378, GNorm = 13.6449, lr_0 = 4.3223e-04
Validation rmse = 0.849975
Epoch 12
Loss = 4.7923e-01, PNorm = 44.1526, GNorm = 4.6233, lr_0 = 4.1482e-04
Loss = 3.7701e-01, PNorm = 44.1723, GNorm = 5.2155, lr_0 = 3.9811e-04
Loss = 3.4736e-01, PNorm = 44.1867, GNorm = 4.2424, lr_0 = 3.8207e-04
Validation rmse = 0.854446
Epoch 13
Loss = 3.2422e-01, PNorm = 44.2070, GNorm = 3.9675, lr_0 = 3.6668e-04
Loss = 3.2492e-01, PNorm = 44.2172, GNorm = 9.7640, lr_0 = 3.5191e-04
Validation rmse = 0.820590
Epoch 14
Loss = 2.5084e-01, PNorm = 44.2320, GNorm = 8.4348, lr_0 = 3.3773e-04
Loss = 3.5768e-01, PNorm = 44.2417, GNorm = 9.8098, lr_0 = 3.2413e-04
Validation rmse = 0.820276
Epoch 15
Loss = 2.9554e-01, PNorm = 44.2535, GNorm = 9.1958, lr_0 = 3.1107e-04
Loss = 2.8507e-01, PNorm = 44.2690, GNorm = 11.1880, lr_0 = 2.9854e-04
Validation rmse = 0.837589
Epoch 16
Loss = 2.9007e-01, PNorm = 44.2806, GNorm = 5.6312, lr_0 = 2.8534e-04
Loss = 3.1509e-01, PNorm = 44.2920, GNorm = 7.4478, lr_0 = 2.7384e-04
Validation rmse = 0.813051
Epoch 17
Loss = 2.5387e-01, PNorm = 44.3006, GNorm = 6.6148, lr_0 = 2.6281e-04
Loss = 2.5688e-01, PNorm = 44.3109, GNorm = 3.4895, lr_0 = 2.5222e-04
Validation rmse = 0.809908
Epoch 18
Loss = 2.6142e-01, PNorm = 44.3218, GNorm = 3.7492, lr_0 = 2.4206e-04
Loss = 2.9661e-01, PNorm = 44.3314, GNorm = 5.7477, lr_0 = 2.3231e-04
Validation rmse = 0.811794
Epoch 19
Loss = 2.6607e-01, PNorm = 44.3414, GNorm = 5.3824, lr_0 = 2.2295e-04
Loss = 2.2897e-01, PNorm = 44.3493, GNorm = 8.7361, lr_0 = 2.1397e-04
Validation rmse = 0.808962
Epoch 20
Loss = 1.6707e-01, PNorm = 44.3599, GNorm = 4.7279, lr_0 = 2.0535e-04
Loss = 2.2376e-01, PNorm = 44.3671, GNorm = 3.7939, lr_0 = 1.9708e-04
Validation rmse = 0.810888
Epoch 21
Loss = 2.0667e-01, PNorm = 44.3754, GNorm = 8.8165, lr_0 = 1.8836e-04
Loss = 2.5646e-01, PNorm = 44.3834, GNorm = 7.0726, lr_0 = 1.8078e-04
Validation rmse = 0.809690
Epoch 22
Loss = 1.6511e-01, PNorm = 44.3890, GNorm = 4.6057, lr_0 = 1.7349e-04
Loss = 2.1656e-01, PNorm = 44.3975, GNorm = 2.3985, lr_0 = 1.6651e-04
Validation rmse = 0.837334
Epoch 23
Loss = 4.1882e-02, PNorm = 44.4052, GNorm = 6.5481, lr_0 = 1.5980e-04
Loss = 2.6275e-01, PNorm = 44.4109, GNorm = 2.9130, lr_0 = 1.5336e-04
Validation rmse = 0.810189
Epoch 24
Loss = 5.1574e-01, PNorm = 44.4160, GNorm = 3.2774, lr_0 = 1.4718e-04
Loss = 1.9728e-01, PNorm = 44.4201, GNorm = 7.2093, lr_0 = 1.4125e-04
Loss = 1.5599e-01, PNorm = 44.4284, GNorm = 4.7569, lr_0 = 1.3556e-04
Validation rmse = 0.801541
Epoch 25
Loss = 1.8517e-01, PNorm = 44.4358, GNorm = 2.5378, lr_0 = 1.3010e-04
Loss = 1.8470e-01, PNorm = 44.4410, GNorm = 2.6639, lr_0 = 1.2486e-04
Loss = 3.4516e-02, PNorm = 44.4414, GNorm = 3.4513, lr_0 = 1.2435e-04
Validation rmse = 0.796829
Epoch 26
Loss = 1.7320e-01, PNorm = 44.4453, GNorm = 2.7397, lr_0 = 1.1934e-04
Loss = 1.7249e-01, PNorm = 44.4491, GNorm = 4.0122, lr_0 = 1.1453e-04
Validation rmse = 0.801185
Epoch 27
Loss = 1.4261e-01, PNorm = 44.4546, GNorm = 5.3756, lr_0 = 1.0992e-04
Loss = 1.8005e-01, PNorm = 44.4596, GNorm = 9.7705, lr_0 = 1.0549e-04
Validation rmse = 0.806119
Epoch 28
Loss = 1.0277e-01, PNorm = 44.4647, GNorm = 9.8318, lr_0 = 1.0124e-04
Loss = 2.1986e-01, PNorm = 44.4682, GNorm = 11.6328, lr_0 = 1.0000e-04
Validation rmse = 0.829304
Epoch 29
Loss = 2.0959e-01, PNorm = 44.4718, GNorm = 3.0846, lr_0 = 1.0000e-04
Loss = 1.4422e-01, PNorm = 44.4764, GNorm = 11.0149, lr_0 = 1.0000e-04
Validation rmse = 0.792057
Model 0 best validation rmse = 0.792057 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.651313
Ensemble test rmse = 0.651313
1-fold cross validation
	Seed 0 ==> test rmse = 0.651313
Overall test rmse = 0.651313 +/- 0.000000
Elapsed time = 0:01:45
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7578e+00, PNorm = 43.3132, GNorm = 2.4871, lr_0 = 3.3571e-04
Loss = 1.4925e+00, PNorm = 43.3207, GNorm = 1.3624, lr_0 = 5.5000e-04
Validation rmse = 1.579650
Epoch 1
Loss = 1.2868e+00, PNorm = 43.3492, GNorm = 1.6132, lr_0 = 7.8571e-04
Loss = 1.2166e+00, PNorm = 43.3926, GNorm = 1.5056, lr_0 = 1.0000e-03
Validation rmse = 1.322688
Epoch 2
Loss = 1.0482e+00, PNorm = 43.4615, GNorm = 2.7362, lr_0 = 9.6160e-04
Loss = 9.3492e-01, PNorm = 43.5351, GNorm = 6.8174, lr_0 = 9.2467e-04
Validation rmse = 1.068650
Epoch 3
Loss = 7.8051e-01, PNorm = 43.6070, GNorm = 4.7786, lr_0 = 8.8568e-04
Loss = 7.4225e-01, PNorm = 43.6749, GNorm = 6.3383, lr_0 = 8.5167e-04
Validation rmse = 0.893236
Epoch 4
Loss = 6.4808e-01, PNorm = 43.7380, GNorm = 9.4920, lr_0 = 8.1896e-04
Loss = 6.4018e-01, PNorm = 43.7777, GNorm = 2.9679, lr_0 = 7.8751e-04
Validation rmse = 0.892159
Epoch 5
Loss = 4.6932e-01, PNorm = 43.8152, GNorm = 5.1689, lr_0 = 7.5727e-04
Loss = 5.0862e-01, PNorm = 43.8560, GNorm = 8.7090, lr_0 = 7.2819e-04
Validation rmse = 0.956572
Epoch 6
Loss = 6.1996e-01, PNorm = 43.8832, GNorm = 3.9194, lr_0 = 6.9749e-04
Loss = 5.3935e-01, PNorm = 43.9231, GNorm = 5.5373, lr_0 = 6.7070e-04
Loss = 4.9797e-01, PNorm = 43.9592, GNorm = 7.4778, lr_0 = 6.4495e-04
Validation rmse = 0.846601
Epoch 7
Loss = 4.1369e-01, PNorm = 43.9881, GNorm = 4.2513, lr_0 = 6.2018e-04
Loss = 4.7202e-01, PNorm = 44.0162, GNorm = 5.6308, lr_0 = 5.9636e-04
Validation rmse = 0.859659
Epoch 8
Loss = 3.7395e-01, PNorm = 44.0475, GNorm = 4.1794, lr_0 = 5.7122e-04
Loss = 3.8824e-01, PNorm = 44.0755, GNorm = 2.4404, lr_0 = 5.4928e-04
Validation rmse = 0.838139
Epoch 9
Loss = 3.7821e-01, PNorm = 44.0955, GNorm = 2.1073, lr_0 = 5.2819e-04
Loss = 4.0098e-01, PNorm = 44.1218, GNorm = 5.2481, lr_0 = 5.0790e-04
Validation rmse = 0.826363
Epoch 10
Loss = 3.2415e-01, PNorm = 44.1459, GNorm = 5.2971, lr_0 = 4.8840e-04
Loss = 3.7645e-01, PNorm = 44.1625, GNorm = 2.7086, lr_0 = 4.6964e-04
Validation rmse = 0.831946
Epoch 11
Loss = 3.7599e-01, PNorm = 44.1831, GNorm = 8.5591, lr_0 = 4.4984e-04
Loss = 3.0686e-01, PNorm = 44.2081, GNorm = 6.1909, lr_0 = 4.3257e-04
Validation rmse = 0.879418
Epoch 12
Loss = 4.5335e-01, PNorm = 44.2282, GNorm = 8.2862, lr_0 = 4.1596e-04
Loss = 3.8609e-01, PNorm = 44.2408, GNorm = 7.5359, lr_0 = 3.9998e-04
Loss = 3.7918e-01, PNorm = 44.2597, GNorm = 8.9410, lr_0 = 3.8462e-04
Loss = 3.4028e-01, PNorm = 44.2617, GNorm = 4.8648, lr_0 = 3.8312e-04
Validation rmse = 0.809761
Epoch 13
Loss = 2.8341e-01, PNorm = 44.2837, GNorm = 7.4460, lr_0 = 3.6841e-04
Loss = 3.0912e-01, PNorm = 44.2960, GNorm = 2.4492, lr_0 = 3.5426e-04
Validation rmse = 0.808270
Epoch 14
Loss = 2.1462e-01, PNorm = 44.3099, GNorm = 2.6225, lr_0 = 3.4065e-04
Loss = 3.3174e-01, PNorm = 44.3251, GNorm = 4.0133, lr_0 = 3.2757e-04
Validation rmse = 0.795406
Epoch 15
Loss = 3.3966e-01, PNorm = 44.3397, GNorm = 3.1130, lr_0 = 3.1499e-04
Loss = 2.9141e-01, PNorm = 44.3545, GNorm = 7.9439, lr_0 = 3.0290e-04
Validation rmse = 0.799384
Epoch 16
Loss = 2.0170e-01, PNorm = 44.3662, GNorm = 4.5687, lr_0 = 2.9012e-04
Loss = 3.0295e-01, PNorm = 44.3796, GNorm = 2.0528, lr_0 = 2.7898e-04
Validation rmse = 0.797711
Epoch 17
Loss = 2.0926e-01, PNorm = 44.3936, GNorm = 3.6882, lr_0 = 2.6827e-04
Loss = 1.9619e-01, PNorm = 44.4056, GNorm = 5.2123, lr_0 = 2.5797e-04
Validation rmse = 0.787127
Epoch 18
Loss = 1.1431e-01, PNorm = 44.4155, GNorm = 3.3092, lr_0 = 2.4709e-04
Loss = 2.6174e-01, PNorm = 44.4252, GNorm = 2.7307, lr_0 = 2.3760e-04
Loss = 2.0029e-01, PNorm = 44.4364, GNorm = 3.7065, lr_0 = 2.2848e-04
Validation rmse = 0.780331
Epoch 19
Loss = 2.2357e-01, PNorm = 44.4497, GNorm = 8.8907, lr_0 = 2.1970e-04
Loss = 2.4466e-01, PNorm = 44.4575, GNorm = 16.7732, lr_0 = 2.1127e-04
Validation rmse = 0.784767
Epoch 20
Loss = 1.5131e-01, PNorm = 44.4659, GNorm = 3.0984, lr_0 = 2.0315e-04
Loss = 2.6154e-01, PNorm = 44.4752, GNorm = 2.1213, lr_0 = 1.9535e-04
Validation rmse = 0.787796
Epoch 21
Loss = 2.0297e-01, PNorm = 44.4810, GNorm = 4.2546, lr_0 = 1.8712e-04
Loss = 1.8979e-01, PNorm = 44.4891, GNorm = 2.7365, lr_0 = 1.7993e-04
Validation rmse = 0.787264
Epoch 22
Loss = 2.1335e-01, PNorm = 44.4983, GNorm = 4.0752, lr_0 = 1.7302e-04
Loss = 1.3935e-01, PNorm = 44.5064, GNorm = 3.9148, lr_0 = 1.6638e-04
Validation rmse = 0.786912
Epoch 23
Loss = 1.7588e-01, PNorm = 44.5156, GNorm = 4.7791, lr_0 = 1.5936e-04
Loss = 1.4904e-01, PNorm = 44.5225, GNorm = 3.4089, lr_0 = 1.5324e-04
Validation rmse = 0.779345
Epoch 24
Loss = 1.7395e-01, PNorm = 44.5269, GNorm = 2.9685, lr_0 = 1.4736e-04
Loss = 1.7814e-01, PNorm = 44.5342, GNorm = 2.9751, lr_0 = 1.4170e-04
Loss = 1.0934e-01, PNorm = 44.5414, GNorm = 7.8641, lr_0 = 1.3626e-04
Validation rmse = 0.796996
Epoch 25
Loss = 1.6945e-01, PNorm = 44.5459, GNorm = 12.8979, lr_0 = 1.3102e-04
Loss = 1.3234e-01, PNorm = 44.5501, GNorm = 8.1840, lr_0 = 1.2599e-04
Validation rmse = 0.782785
Epoch 26
Loss = 1.4874e-01, PNorm = 44.5581, GNorm = 3.9854, lr_0 = 1.2068e-04
Loss = 1.4614e-01, PNorm = 44.5645, GNorm = 5.2235, lr_0 = 1.1604e-04
Validation rmse = 0.776344
Epoch 27
Loss = 9.5270e-02, PNorm = 44.5687, GNorm = 5.3639, lr_0 = 1.1159e-04
Loss = 1.3721e-01, PNorm = 44.5732, GNorm = 3.3337, lr_0 = 1.0730e-04
Validation rmse = 0.775917
Epoch 28
Loss = 1.2099e-01, PNorm = 44.5789, GNorm = 3.5051, lr_0 = 1.0278e-04
Loss = 1.0864e-01, PNorm = 44.5838, GNorm = 2.5617, lr_0 = 1.0000e-04
Validation rmse = 0.779895
Epoch 29
Loss = 1.4471e-01, PNorm = 44.5873, GNorm = 4.8137, lr_0 = 1.0000e-04
Loss = 1.0913e-01, PNorm = 44.5918, GNorm = 7.9915, lr_0 = 1.0000e-04
Validation rmse = 0.776289
Model 0 best validation rmse = 0.775917 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.615082
Ensemble test rmse = 0.615082
1-fold cross validation
	Seed 0 ==> test rmse = 0.615082
Overall test rmse = 0.615082 +/- 0.000000
Elapsed time = 0:01:49
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8876e+00, PNorm = 43.3140, GNorm = 2.2781, lr_0 = 3.2500e-04
Loss = 1.4703e+00, PNorm = 43.3216, GNorm = 1.3139, lr_0 = 5.2955e-04
Validation rmse = 1.599929
Epoch 1
Loss = 1.3261e+00, PNorm = 43.3453, GNorm = 1.0209, lr_0 = 7.5455e-04
Loss = 1.2092e+00, PNorm = 43.3882, GNorm = 1.7901, lr_0 = 9.5909e-04
Validation rmse = 1.343001
Epoch 2
Loss = 1.0427e+00, PNorm = 43.4553, GNorm = 1.9678, lr_0 = 9.6692e-04
Loss = 9.5224e-01, PNorm = 43.5367, GNorm = 6.2413, lr_0 = 9.3144e-04
Validation rmse = 0.991779
Epoch 3
Loss = 8.5425e-01, PNorm = 43.6061, GNorm = 12.1510, lr_0 = 8.9727e-04
Loss = 7.2089e-01, PNorm = 43.6568, GNorm = 3.0606, lr_0 = 8.6435e-04
Validation rmse = 0.899593
Epoch 4
Loss = 8.1057e-01, PNorm = 43.7133, GNorm = 6.8208, lr_0 = 8.2953e-04
Loss = 6.1135e-01, PNorm = 43.7580, GNorm = 3.2918, lr_0 = 7.9909e-04
Loss = 6.6291e-01, PNorm = 43.7968, GNorm = 2.1061, lr_0 = 7.6977e-04
Validation rmse = 0.948381
Epoch 5
Loss = 4.9431e-01, PNorm = 43.8318, GNorm = 2.3754, lr_0 = 7.4153e-04
Loss = 5.5092e-01, PNorm = 43.8690, GNorm = 3.2274, lr_0 = 7.1433e-04
Validation rmse = 0.856645
Epoch 6
Loss = 4.5648e-01, PNorm = 43.9099, GNorm = 2.5825, lr_0 = 6.8555e-04
Loss = 5.0193e-01, PNorm = 43.9241, GNorm = 16.5645, lr_0 = 6.6040e-04
Validation rmse = 0.923831
Epoch 7
Loss = 6.1935e-01, PNorm = 43.9451, GNorm = 2.6601, lr_0 = 6.3379e-04
Loss = 5.3085e-01, PNorm = 43.9776, GNorm = 7.0034, lr_0 = 6.1054e-04
Validation rmse = 0.861944
Epoch 8
Loss = 2.3921e-01, PNorm = 44.0146, GNorm = 2.7939, lr_0 = 5.8814e-04
Loss = 4.7229e-01, PNorm = 44.0380, GNorm = 9.4069, lr_0 = 5.6656e-04
Loss = 4.5389e-01, PNorm = 44.0516, GNorm = 3.2699, lr_0 = 5.4577e-04
Validation rmse = 0.839020
Epoch 9
Loss = 3.2606e-01, PNorm = 44.0857, GNorm = 3.9101, lr_0 = 5.2379e-04
Loss = 4.2620e-01, PNorm = 44.0994, GNorm = 2.5042, lr_0 = 5.0457e-04
Validation rmse = 0.830316
Epoch 10
Loss = 3.2687e-01, PNorm = 44.1149, GNorm = 4.6855, lr_0 = 4.8606e-04
Loss = 3.7463e-01, PNorm = 44.1335, GNorm = 8.1884, lr_0 = 4.6822e-04
Validation rmse = 0.884086
Epoch 11
Loss = 3.3416e-01, PNorm = 44.1472, GNorm = 2.0315, lr_0 = 4.4936e-04
Loss = 3.5730e-01, PNorm = 44.1650, GNorm = 17.5005, lr_0 = 4.3288e-04
Validation rmse = 0.826817
Epoch 12
Loss = 4.0311e-01, PNorm = 44.1828, GNorm = 3.8487, lr_0 = 4.1544e-04
Loss = 3.2577e-01, PNorm = 44.1992, GNorm = 13.1018, lr_0 = 4.0020e-04
Loss = 2.6494e-01, PNorm = 44.2133, GNorm = 4.5172, lr_0 = 3.8551e-04
Validation rmse = 0.821363
Epoch 13
Loss = 3.1629e-01, PNorm = 44.2284, GNorm = 4.7870, lr_0 = 3.7137e-04
Loss = 2.3248e-01, PNorm = 44.2431, GNorm = 3.9490, lr_0 = 3.5774e-04
Validation rmse = 0.803282
Epoch 14
Loss = 2.8560e-01, PNorm = 44.2541, GNorm = 2.9175, lr_0 = 3.4333e-04
Loss = 3.1651e-01, PNorm = 44.2703, GNorm = 8.8973, lr_0 = 3.3074e-04
Validation rmse = 0.823552
Epoch 15
Loss = 2.4752e-01, PNorm = 44.2835, GNorm = 9.6495, lr_0 = 3.1860e-04
Loss = 2.6413e-01, PNorm = 44.2972, GNorm = 6.9766, lr_0 = 3.0691e-04
Validation rmse = 0.806261
Epoch 16
Loss = 2.0307e-01, PNorm = 44.3059, GNorm = 4.7342, lr_0 = 2.9455e-04
Loss = 2.7855e-01, PNorm = 44.3188, GNorm = 8.0461, lr_0 = 2.8374e-04
Loss = 2.3804e-01, PNorm = 44.3273, GNorm = 3.1052, lr_0 = 2.7333e-04
Loss = 2.6778e-01, PNorm = 44.3285, GNorm = 4.5124, lr_0 = 2.7231e-04
Validation rmse = 0.795808
Epoch 17
Loss = 1.7747e-01, PNorm = 44.3409, GNorm = 3.7434, lr_0 = 2.6232e-04
Loss = 2.4799e-01, PNorm = 44.3529, GNorm = 6.4554, lr_0 = 2.5270e-04
Validation rmse = 0.796476
Epoch 18
Loss = 1.7465e-01, PNorm = 44.3607, GNorm = 3.2004, lr_0 = 2.4342e-04
Loss = 2.0426e-01, PNorm = 44.3702, GNorm = 8.3527, lr_0 = 2.3449e-04
Validation rmse = 0.802364
Epoch 19
Loss = 2.1466e-01, PNorm = 44.3802, GNorm = 7.4064, lr_0 = 2.2505e-04
Loss = 2.1554e-01, PNorm = 44.3905, GNorm = 3.1267, lr_0 = 2.1679e-04
Validation rmse = 0.776651
Epoch 20
Loss = 1.3116e-01, PNorm = 44.3989, GNorm = 3.7299, lr_0 = 2.0884e-04
Loss = 2.4530e-01, PNorm = 44.4058, GNorm = 5.1996, lr_0 = 2.0117e-04
Loss = 1.6584e-01, PNorm = 44.4125, GNorm = 2.8938, lr_0 = 1.9379e-04
Loss = -7.8615e-03, PNorm = 44.4137, GNorm = 5.9049, lr_0 = 1.9307e-04
Validation rmse = 0.778999
Epoch 21
Loss = 1.3658e-01, PNorm = 44.4252, GNorm = 11.2498, lr_0 = 1.8599e-04
Loss = 2.1603e-01, PNorm = 44.4309, GNorm = 6.9003, lr_0 = 1.7916e-04
Validation rmse = 0.803999
Epoch 22
Loss = 1.3906e-01, PNorm = 44.4365, GNorm = 8.0410, lr_0 = 1.7195e-04
Loss = 1.5760e-01, PNorm = 44.4450, GNorm = 3.8531, lr_0 = 1.6564e-04
Validation rmse = 0.797551
Epoch 23
Loss = 1.1882e-01, PNorm = 44.4506, GNorm = 3.6239, lr_0 = 1.5956e-04
Loss = 1.9042e-01, PNorm = 44.4573, GNorm = 3.0795, lr_0 = 1.5371e-04
Validation rmse = 0.798600
Epoch 24
Loss = 1.5485e-01, PNorm = 44.4631, GNorm = 7.4317, lr_0 = 1.4751e-04
Loss = 1.5150e-01, PNorm = 44.4694, GNorm = 10.2433, lr_0 = 1.4210e-04
Loss = 1.7116e-01, PNorm = 44.4746, GNorm = 5.1398, lr_0 = 1.3689e-04
Validation rmse = 0.786743
Epoch 25
Loss = 1.6273e-01, PNorm = 44.4797, GNorm = 5.0137, lr_0 = 1.3187e-04
Loss = 1.7983e-01, PNorm = 44.4849, GNorm = 3.8594, lr_0 = 1.2703e-04
Validation rmse = 0.784509
Epoch 26
Loss = 1.4200e-01, PNorm = 44.4907, GNorm = 4.4517, lr_0 = 1.2191e-04
Loss = 1.2500e-01, PNorm = 44.4953, GNorm = 10.5955, lr_0 = 1.1744e-04
Validation rmse = 0.780728
Epoch 27
Loss = 1.3674e-01, PNorm = 44.5012, GNorm = 5.0163, lr_0 = 1.1271e-04
Loss = 1.3879e-01, PNorm = 44.5057, GNorm = 7.8815, lr_0 = 1.0857e-04
Validation rmse = 0.771362
Epoch 28
Loss = 2.0154e-01, PNorm = 44.5096, GNorm = 14.1139, lr_0 = 1.0459e-04
Loss = 1.4812e-01, PNorm = 44.5139, GNorm = 4.4038, lr_0 = 1.0075e-04
Validation rmse = 0.789072
Epoch 29
Loss = 1.4089e-01, PNorm = 44.5190, GNorm = 4.9250, lr_0 = 1.0000e-04
Loss = 7.9048e-02, PNorm = 44.5238, GNorm = 5.7825, lr_0 = 1.0000e-04
Loss = 1.7733e-01, PNorm = 44.5268, GNorm = 8.7127, lr_0 = 1.0000e-04
Validation rmse = 0.773841
Model 0 best validation rmse = 0.771362 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.607618
Ensemble test rmse = 0.607618
1-fold cross validation
	Seed 0 ==> test rmse = 0.607618
Overall test rmse = 0.607618 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9864e+00, PNorm = 43.3135, GNorm = 1.5839, lr_0 = 3.1522e-04
Loss = 1.4489e+00, PNorm = 43.3200, GNorm = 1.5572, lr_0 = 5.1087e-04
Validation rmse = 1.562939
Epoch 1
Loss = 1.3035e+00, PNorm = 43.3395, GNorm = 0.7620, lr_0 = 7.2609e-04
Loss = 1.2303e+00, PNorm = 43.3770, GNorm = 2.6869, lr_0 = 9.2174e-04
Validation rmse = 1.243591
Epoch 2
Loss = 9.1979e-01, PNorm = 43.4365, GNorm = 1.3335, lr_0 = 9.7528e-04
Loss = 9.7627e-01, PNorm = 43.5166, GNorm = 3.2299, lr_0 = 9.4103e-04
Validation rmse = 1.062276
Epoch 3
Loss = 7.9002e-01, PNorm = 43.5827, GNorm = 7.7534, lr_0 = 9.0474e-04
Loss = 7.1939e-01, PNorm = 43.6370, GNorm = 6.0935, lr_0 = 8.7296e-04
Loss = 6.4223e-01, PNorm = 43.7001, GNorm = 4.4729, lr_0 = 8.4230e-04
Validation rmse = 0.878775
Epoch 4
Loss = 5.0457e-01, PNorm = 43.7416, GNorm = 3.7360, lr_0 = 8.0981e-04
Loss = 6.5038e-01, PNorm = 43.7628, GNorm = 5.0518, lr_0 = 7.8137e-04
Validation rmse = 0.908761
Epoch 5
Loss = 5.2096e-01, PNorm = 43.8038, GNorm = 3.3978, lr_0 = 7.5393e-04
Loss = 5.1786e-01, PNorm = 43.8368, GNorm = 6.7344, lr_0 = 7.2745e-04
Validation rmse = 0.807108
Epoch 6
Loss = 5.4269e-01, PNorm = 43.8659, GNorm = 1.7730, lr_0 = 6.9939e-04
Loss = 4.4819e-01, PNorm = 43.8896, GNorm = 4.2243, lr_0 = 6.7483e-04
Loss = 4.8430e-01, PNorm = 43.9177, GNorm = 2.8139, lr_0 = 6.5113e-04
Validation rmse = 0.890434
Epoch 7
Loss = 5.3752e-01, PNorm = 43.9442, GNorm = 8.0354, lr_0 = 6.2601e-04
Loss = 4.6294e-01, PNorm = 43.9697, GNorm = 5.9183, lr_0 = 6.0403e-04
Validation rmse = 0.818307
Epoch 8
Loss = 4.1909e-01, PNorm = 43.9975, GNorm = 2.9105, lr_0 = 5.8073e-04
Loss = 3.8242e-01, PNorm = 44.0117, GNorm = 2.0975, lr_0 = 5.6033e-04
Validation rmse = 0.950564
Epoch 9
Loss = 5.8153e-01, PNorm = 44.0341, GNorm = 17.7701, lr_0 = 5.3872e-04
Loss = 6.1434e-01, PNorm = 44.0495, GNorm = 10.5037, lr_0 = 5.1980e-04
Loss = 5.2025e-01, PNorm = 44.0707, GNorm = 6.2962, lr_0 = 5.0155e-04
Validation rmse = 0.839918
Epoch 10
Loss = 4.1179e-01, PNorm = 44.0946, GNorm = 2.5945, lr_0 = 4.8393e-04
Loss = 3.4450e-01, PNorm = 44.1148, GNorm = 9.5339, lr_0 = 4.6693e-04
Validation rmse = 0.835369
Epoch 11
Loss = 2.7278e-01, PNorm = 44.1340, GNorm = 7.4952, lr_0 = 4.4893e-04
Loss = 3.4185e-01, PNorm = 44.1447, GNorm = 12.0095, lr_0 = 4.3316e-04
Validation rmse = 0.902035
Epoch 12
Loss = 4.5423e-01, PNorm = 44.1527, GNorm = 10.1703, lr_0 = 4.1645e-04
Loss = 3.1886e-01, PNorm = 44.1677, GNorm = 5.0231, lr_0 = 4.0183e-04
Loss = 3.6821e-01, PNorm = 44.1814, GNorm = 11.3248, lr_0 = 3.8771e-04
Validation rmse = 0.816670
Epoch 13
Loss = 3.3138e-01, PNorm = 44.1954, GNorm = 2.2310, lr_0 = 3.7276e-04
Loss = 2.6406e-01, PNorm = 44.2066, GNorm = 2.7739, lr_0 = 3.5967e-04
Validation rmse = 0.851376
Epoch 14
Loss = 2.4880e-01, PNorm = 44.2193, GNorm = 3.5935, lr_0 = 3.4580e-04
Loss = 3.4734e-01, PNorm = 44.2291, GNorm = 3.2253, lr_0 = 3.3365e-04
Validation rmse = 0.799286
Epoch 15
Loss = 1.3696e-01, PNorm = 44.2412, GNorm = 3.2097, lr_0 = 3.2193e-04
Loss = 2.8392e-01, PNorm = 44.2483, GNorm = 4.9097, lr_0 = 3.1062e-04
Loss = 2.5837e-01, PNorm = 44.2588, GNorm = 7.0417, lr_0 = 2.9971e-04
Validation rmse = 0.783492
Epoch 16
Loss = 2.0393e-01, PNorm = 44.2741, GNorm = 3.1932, lr_0 = 2.8816e-04
Loss = 2.9280e-01, PNorm = 44.2802, GNorm = 2.9011, lr_0 = 2.7803e-04
Validation rmse = 0.797966
Epoch 17
Loss = 1.8160e-01, PNorm = 44.2909, GNorm = 6.8939, lr_0 = 2.6731e-04
Loss = 2.9250e-01, PNorm = 44.2998, GNorm = 4.4245, lr_0 = 2.5792e-04
Validation rmse = 0.794134
Epoch 18
Loss = 1.8074e-01, PNorm = 44.3076, GNorm = 2.5165, lr_0 = 2.4798e-04
Loss = 2.2255e-01, PNorm = 44.3182, GNorm = 8.2048, lr_0 = 2.3927e-04
Loss = 2.3104e-01, PNorm = 44.3255, GNorm = 2.7526, lr_0 = 2.3086e-04
Loss = 5.4813e-01, PNorm = 44.3259, GNorm = 7.3301, lr_0 = 2.3004e-04
Validation rmse = 0.799865
Epoch 19
Loss = 2.0114e-01, PNorm = 44.3322, GNorm = 3.7168, lr_0 = 2.2196e-04
Loss = 2.2409e-01, PNorm = 44.3393, GNorm = 8.6517, lr_0 = 2.1416e-04
Validation rmse = 0.808364
Epoch 20
Loss = 2.1087e-01, PNorm = 44.3462, GNorm = 2.7198, lr_0 = 2.0664e-04
Loss = 1.6816e-01, PNorm = 44.3547, GNorm = 3.1601, lr_0 = 1.9938e-04
Validation rmse = 0.787123
Epoch 21
Loss = 2.0753e-01, PNorm = 44.3622, GNorm = 3.2971, lr_0 = 1.9169e-04
Loss = 2.0498e-01, PNorm = 44.3685, GNorm = 3.1778, lr_0 = 1.8496e-04
Loss = 1.6977e-01, PNorm = 44.3747, GNorm = 2.8099, lr_0 = 1.7846e-04
Loss = 5.0308e-01, PNorm = 44.3756, GNorm = 5.7890, lr_0 = 1.7783e-04
Validation rmse = 0.799906
Epoch 22
Loss = 2.0035e-01, PNorm = 44.3852, GNorm = 5.4272, lr_0 = 1.7158e-04
Loss = 2.0522e-01, PNorm = 44.3910, GNorm = 3.6325, lr_0 = 1.6556e-04
Validation rmse = 0.796743
Epoch 23
Loss = 1.7431e-01, PNorm = 44.3955, GNorm = 5.4951, lr_0 = 1.5917e-04
Loss = 2.2382e-01, PNorm = 44.3998, GNorm = 11.2851, lr_0 = 1.5358e-04
Validation rmse = 0.777109
Epoch 24
Loss = 1.2006e-01, PNorm = 44.4068, GNorm = 3.0229, lr_0 = 1.4766e-04
Loss = 1.4648e-01, PNorm = 44.4145, GNorm = 4.2499, lr_0 = 1.4247e-04
Loss = 2.1369e-01, PNorm = 44.4197, GNorm = 5.0547, lr_0 = 1.3747e-04
Validation rmse = 0.792033
Epoch 25
Loss = 1.4283e-01, PNorm = 44.4250, GNorm = 5.5633, lr_0 = 1.3264e-04
Loss = 1.9073e-01, PNorm = 44.4288, GNorm = 8.7179, lr_0 = 1.2798e-04
Validation rmse = 0.782076
Epoch 26
Loss = 1.6369e-01, PNorm = 44.4348, GNorm = 8.1867, lr_0 = 1.2304e-04
Loss = 1.7434e-01, PNorm = 44.4388, GNorm = 14.6467, lr_0 = 1.1872e-04
Validation rmse = 0.791029
Epoch 27
Loss = 1.4924e-01, PNorm = 44.4406, GNorm = 7.5084, lr_0 = 1.1414e-04
Loss = 2.1057e-01, PNorm = 44.4447, GNorm = 11.1947, lr_0 = 1.1014e-04
Validation rmse = 0.786410
Epoch 28
Loss = 2.1698e-01, PNorm = 44.4494, GNorm = 4.6951, lr_0 = 1.0589e-04
Loss = 1.3362e-01, PNorm = 44.4531, GNorm = 2.9886, lr_0 = 1.0217e-04
Loss = 1.8213e-01, PNorm = 44.4573, GNorm = 3.1069, lr_0 = 1.0000e-04
Validation rmse = 0.782405
Epoch 29
Loss = 1.1074e-01, PNorm = 44.4623, GNorm = 3.1402, lr_0 = 1.0000e-04
Loss = 1.6143e-01, PNorm = 44.4654, GNorm = 5.0345, lr_0 = 1.0000e-04
Validation rmse = 0.785590
Model 0 best validation rmse = 0.777109 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.592183
Ensemble test rmse = 0.592183
1-fold cross validation
	Seed 0 ==> test rmse = 0.592183
Overall test rmse = 0.592183 +/- 0.000000
Elapsed time = 0:01:57
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8604e+00, PNorm = 43.3117, GNorm = 2.5044, lr_0 = 3.0625e-04
Loss = 1.4613e+00, PNorm = 43.3171, GNorm = 1.6040, lr_0 = 4.9375e-04
Validation rmse = 1.557554
Epoch 1
Loss = 1.3187e+00, PNorm = 43.3338, GNorm = 1.2056, lr_0 = 6.8125e-04
Loss = 1.1658e+00, PNorm = 43.3710, GNorm = 2.8767, lr_0 = 8.6875e-04
Validation rmse = 1.225391
Epoch 2
Loss = 1.0055e+00, PNorm = 43.4269, GNorm = 3.0368, lr_0 = 9.8977e-04
Loss = 8.9800e-01, PNorm = 43.5129, GNorm = 2.9017, lr_0 = 9.5643e-04
Loss = 7.7929e-01, PNorm = 43.5897, GNorm = 7.1949, lr_0 = 9.2422e-04
Validation rmse = 1.025944
Epoch 3
Loss = 7.1784e-01, PNorm = 43.6409, GNorm = 3.1868, lr_0 = 8.9309e-04
Loss = 6.9672e-01, PNorm = 43.6900, GNorm = 1.9942, lr_0 = 8.6300e-04
Validation rmse = 1.010682
Epoch 4
Loss = 6.4558e-01, PNorm = 43.7311, GNorm = 5.5821, lr_0 = 8.3393e-04
Loss = 5.6873e-01, PNorm = 43.7709, GNorm = 4.0736, lr_0 = 8.0584e-04
Loss = 5.3607e-01, PNorm = 43.8021, GNorm = 6.5484, lr_0 = 7.7870e-04
Validation rmse = 0.916993
Epoch 5
Loss = 5.4494e-01, PNorm = 43.8352, GNorm = 2.0967, lr_0 = 7.5247e-04
Loss = 5.3755e-01, PNorm = 43.8694, GNorm = 2.4120, lr_0 = 7.2712e-04
Validation rmse = 0.824882
Epoch 6
Loss = 4.6173e-01, PNorm = 43.9048, GNorm = 2.4189, lr_0 = 7.0263e-04
Loss = 4.4703e-01, PNorm = 43.9363, GNorm = 2.1944, lr_0 = 6.7896e-04
Validation rmse = 0.811554
Epoch 7
Loss = 3.3410e-01, PNorm = 43.9602, GNorm = 4.8797, lr_0 = 6.5609e-04
Loss = 4.3868e-01, PNorm = 43.9906, GNorm = 5.6492, lr_0 = 6.3399e-04
Loss = 4.2791e-01, PNorm = 44.0157, GNorm = 2.8247, lr_0 = 6.1264e-04
Validation rmse = 0.797110
Epoch 8
Loss = 3.1815e-01, PNorm = 44.0411, GNorm = 8.4572, lr_0 = 5.9200e-04
Loss = 4.0009e-01, PNorm = 44.0578, GNorm = 10.2540, lr_0 = 5.7206e-04
Validation rmse = 0.858065
Epoch 9
Loss = 3.3181e-01, PNorm = 44.0838, GNorm = 2.6405, lr_0 = 5.5279e-04
Loss = 4.0242e-01, PNorm = 44.1033, GNorm = 10.6693, lr_0 = 5.3417e-04
Loss = 4.4496e-01, PNorm = 44.1223, GNorm = 1.8674, lr_0 = 5.1618e-04
Validation rmse = 0.864226
Epoch 10
Loss = 3.8914e-01, PNorm = 44.1477, GNorm = 9.1244, lr_0 = 4.9879e-04
Loss = 3.7706e-01, PNorm = 44.1642, GNorm = 3.6429, lr_0 = 4.8199e-04
Validation rmse = 0.822570
Epoch 11
Loss = 2.3890e-01, PNorm = 44.1824, GNorm = 4.0451, lr_0 = 4.6575e-04
Loss = 2.9328e-01, PNorm = 44.2043, GNorm = 4.7619, lr_0 = 4.5006e-04
Validation rmse = 0.797405
Epoch 12
Loss = 2.1531e-01, PNorm = 44.2122, GNorm = 2.1674, lr_0 = 4.3490e-04
Loss = 2.7514e-01, PNorm = 44.2342, GNorm = 3.9235, lr_0 = 4.2025e-04
Loss = 3.3498e-01, PNorm = 44.2487, GNorm = 3.0644, lr_0 = 4.0610e-04
Validation rmse = 0.846554
Epoch 13
Loss = 2.7589e-01, PNorm = 44.2633, GNorm = 5.9475, lr_0 = 3.9242e-04
Loss = 2.4588e-01, PNorm = 44.2775, GNorm = 4.7490, lr_0 = 3.7920e-04
Validation rmse = 0.811459
Epoch 14
Loss = 4.1074e-01, PNorm = 44.2886, GNorm = 9.3024, lr_0 = 3.6643e-04
Loss = 3.1771e-01, PNorm = 44.3059, GNorm = 4.6308, lr_0 = 3.5408e-04
Loss = 2.2323e-01, PNorm = 44.3238, GNorm = 3.0761, lr_0 = 3.4216e-04
Validation rmse = 0.805192
Epoch 15
Loss = 2.5344e-01, PNorm = 44.3380, GNorm = 3.9380, lr_0 = 3.3063e-04
Loss = 2.8748e-01, PNorm = 44.3484, GNorm = 4.0863, lr_0 = 3.1950e-04
Validation rmse = 0.796900
Epoch 16
Loss = 2.1997e-01, PNorm = 44.3595, GNorm = 6.9786, lr_0 = 3.0873e-04
Loss = 2.5009e-01, PNorm = 44.3695, GNorm = 3.6958, lr_0 = 2.9833e-04
Validation rmse = 0.803075
Epoch 17
Loss = 2.5145e-01, PNorm = 44.3773, GNorm = 2.9764, lr_0 = 2.8828e-04
Loss = 2.0648e-01, PNorm = 44.3872, GNorm = 3.2859, lr_0 = 2.7857e-04
Loss = 2.1277e-01, PNorm = 44.3987, GNorm = 3.0664, lr_0 = 2.6919e-04
Validation rmse = 0.796427
Epoch 18
Loss = 1.2343e-01, PNorm = 44.4108, GNorm = 6.5565, lr_0 = 2.6012e-04
Loss = 1.7070e-01, PNorm = 44.4204, GNorm = 3.6299, lr_0 = 2.5136e-04
Validation rmse = 0.789673
Epoch 19
Loss = 1.9968e-01, PNorm = 44.4283, GNorm = 6.2195, lr_0 = 2.4289e-04
Loss = 2.2482e-01, PNorm = 44.4391, GNorm = 3.8805, lr_0 = 2.3471e-04
Loss = 1.9987e-01, PNorm = 44.4445, GNorm = 11.4930, lr_0 = 2.2681e-04
Validation rmse = 0.775017
Epoch 20
Loss = 1.8124e-01, PNorm = 44.4543, GNorm = 2.3330, lr_0 = 2.1917e-04
Loss = 1.4908e-01, PNorm = 44.4634, GNorm = 7.4968, lr_0 = 2.1178e-04
Validation rmse = 0.780671
Epoch 21
Loss = 1.6900e-01, PNorm = 44.4696, GNorm = 8.4497, lr_0 = 2.0465e-04
Loss = 1.8061e-01, PNorm = 44.4780, GNorm = 5.3907, lr_0 = 1.9776e-04
Validation rmse = 0.778985
Epoch 22
Loss = 8.7809e-02, PNorm = 44.4869, GNorm = 6.0575, lr_0 = 1.9110e-04
Loss = 1.2554e-01, PNorm = 44.4939, GNorm = 4.5425, lr_0 = 1.8466e-04
Loss = 2.3464e-01, PNorm = 44.5009, GNorm = 7.3226, lr_0 = 1.7844e-04
Validation rmse = 0.773980
Epoch 23
Loss = 1.2553e-01, PNorm = 44.5081, GNorm = 3.5813, lr_0 = 1.7243e-04
Loss = 1.7701e-01, PNorm = 44.5156, GNorm = 5.4666, lr_0 = 1.6662e-04
Validation rmse = 0.761914
Epoch 24
Loss = 1.1288e-01, PNorm = 44.5227, GNorm = 5.6639, lr_0 = 1.6101e-04
Loss = 1.3852e-01, PNorm = 44.5294, GNorm = 4.1083, lr_0 = 1.5558e-04
Loss = 1.5432e-01, PNorm = 44.5358, GNorm = 4.0183, lr_0 = 1.5034e-04
Validation rmse = 0.768637
Epoch 25
Loss = 1.0764e-01, PNorm = 44.5408, GNorm = 6.3683, lr_0 = 1.4528e-04
Loss = 1.9210e-01, PNorm = 44.5464, GNorm = 6.3179, lr_0 = 1.4039e-04
Validation rmse = 0.773212
Epoch 26
Loss = 1.3177e-01, PNorm = 44.5524, GNorm = 4.1571, lr_0 = 1.3566e-04
Loss = 1.0571e-01, PNorm = 44.5595, GNorm = 5.5511, lr_0 = 1.3109e-04
Validation rmse = 0.773499
Epoch 27
Loss = 1.2317e-03, PNorm = 44.5625, GNorm = 3.1846, lr_0 = 1.2667e-04
Loss = 1.4781e-01, PNorm = 44.5673, GNorm = 5.3819, lr_0 = 1.2240e-04
Loss = 8.5679e-02, PNorm = 44.5727, GNorm = 3.3943, lr_0 = 1.1828e-04
Validation rmse = 0.772617
Epoch 28
Loss = 1.7569e-01, PNorm = 44.5773, GNorm = 4.5568, lr_0 = 1.1430e-04
Loss = 9.1072e-02, PNorm = 44.5815, GNorm = 5.3131, lr_0 = 1.1045e-04
Validation rmse = 0.761757
Epoch 29
Loss = 1.5210e-01, PNorm = 44.5869, GNorm = 3.9657, lr_0 = 1.0673e-04
Loss = 1.1442e-01, PNorm = 44.5915, GNorm = 5.3164, lr_0 = 1.0313e-04
Loss = 9.1147e-02, PNorm = 44.5950, GNorm = 5.5685, lr_0 = 1.0000e-04
Validation rmse = 0.767005
Model 0 best validation rmse = 0.761757 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.618919
Ensemble test rmse = 0.618919
1-fold cross validation
	Seed 0 ==> test rmse = 0.618919
Overall test rmse = 0.618919 +/- 0.000000
Elapsed time = 0:02:02
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6967e+00, PNorm = 43.3119, GNorm = 1.6147, lr_0 = 4.0937e-04
Validation rmse = 1.355738
Epoch 1
Loss = 1.4490e+00, PNorm = 43.3191, GNorm = 1.2980, lr_0 = 6.9063e-04
Loss = 1.3989e+00, PNorm = 43.3447, GNorm = 0.6947, lr_0 = 9.7187e-04
Validation rmse = 1.263424
Epoch 2
Loss = 1.3131e+00, PNorm = 43.3800, GNorm = 1.8334, lr_0 = 9.5480e-04
Validation rmse = 1.137589
Epoch 3
Loss = 1.1965e+00, PNorm = 43.4251, GNorm = 0.8082, lr_0 = 9.0696e-04
Loss = 1.1710e+00, PNorm = 43.4852, GNorm = 2.0481, lr_0 = 8.6152e-04
Validation rmse = 1.038289
Epoch 4
Loss = 1.0414e+00, PNorm = 43.5483, GNorm = 5.1307, lr_0 = 8.1836e-04
Loss = 9.7920e-01, PNorm = 43.6175, GNorm = 3.8337, lr_0 = 7.7737e-04
Validation rmse = 0.969184
Epoch 5
Loss = 8.5896e-01, PNorm = 43.6805, GNorm = 3.8413, lr_0 = 7.3842e-04
Validation rmse = 0.903992
Epoch 6
Loss = 8.4025e-01, PNorm = 43.7288, GNorm = 1.7078, lr_0 = 7.0143e-04
Loss = 8.4159e-01, PNorm = 43.7768, GNorm = 6.5086, lr_0 = 6.6629e-04
Validation rmse = 0.874738
Epoch 7
Loss = 8.2628e-01, PNorm = 43.8157, GNorm = 7.7364, lr_0 = 6.3291e-04
Validation rmse = 0.874136
Epoch 8
Loss = 7.0531e-01, PNorm = 43.8510, GNorm = 6.3179, lr_0 = 6.0120e-04
Loss = 7.9201e-01, PNorm = 43.8833, GNorm = 6.9387, lr_0 = 5.7108e-04
Validation rmse = 0.875340
Epoch 9
Loss = 7.0818e-01, PNorm = 43.9147, GNorm = 2.0715, lr_0 = 5.4247e-04
Loss = 6.9604e-01, PNorm = 43.9431, GNorm = 2.4120, lr_0 = 5.1529e-04
Validation rmse = 0.854883
Epoch 10
Loss = 5.9435e-01, PNorm = 43.9770, GNorm = 3.8731, lr_0 = 4.8948e-04
Validation rmse = 0.857063
Epoch 11
Loss = 5.9280e-01, PNorm = 44.0006, GNorm = 4.0232, lr_0 = 4.6495e-04
Loss = 5.8658e-01, PNorm = 44.0292, GNorm = 3.8753, lr_0 = 4.4166e-04
Validation rmse = 0.843170
Epoch 12
Loss = 5.1741e-01, PNorm = 44.0503, GNorm = 9.0123, lr_0 = 4.1953e-04
Validation rmse = 0.838219
Epoch 13
Loss = 5.3366e-01, PNorm = 44.0727, GNorm = 2.6804, lr_0 = 3.9852e-04
Loss = 5.4541e-01, PNorm = 44.0936, GNorm = 3.4244, lr_0 = 3.7855e-04
Validation rmse = 0.878153
Epoch 14
Loss = 5.6294e-01, PNorm = 44.1128, GNorm = 3.7320, lr_0 = 3.5959e-04
Loss = 5.3023e-01, PNorm = 44.1275, GNorm = 3.3933, lr_0 = 3.4157e-04
Validation rmse = 0.832997
Epoch 15
Loss = 5.0004e-01, PNorm = 44.1471, GNorm = 11.7925, lr_0 = 3.2446e-04
Validation rmse = 0.829204
Epoch 16
Loss = 4.7065e-01, PNorm = 44.1625, GNorm = 4.9712, lr_0 = 3.0820e-04
Loss = 4.9469e-01, PNorm = 44.1749, GNorm = 5.2501, lr_0 = 2.9276e-04
Validation rmse = 0.838396
Epoch 17
Loss = 3.9456e-01, PNorm = 44.1909, GNorm = 11.3749, lr_0 = 2.7810e-04
Validation rmse = 0.825668
Epoch 18
Loss = 5.1165e-01, PNorm = 44.2031, GNorm = 9.2140, lr_0 = 2.6416e-04
Loss = 5.2010e-01, PNorm = 44.2162, GNorm = 7.4962, lr_0 = 2.5093e-04
Validation rmse = 0.853717
Epoch 19
Loss = 4.7829e-01, PNorm = 44.2304, GNorm = 6.2950, lr_0 = 2.3836e-04
Loss = 4.3433e-01, PNorm = 44.2446, GNorm = 8.6086, lr_0 = 2.2642e-04
Validation rmse = 0.822514
Epoch 20
Loss = 3.9705e-01, PNorm = 44.2537, GNorm = 3.6263, lr_0 = 2.1507e-04
Validation rmse = 0.820870
Epoch 21
Loss = 4.2013e-01, PNorm = 44.2642, GNorm = 13.7789, lr_0 = 2.0430e-04
Loss = 4.4503e-01, PNorm = 44.2755, GNorm = 18.0110, lr_0 = 1.9406e-04
Validation rmse = 0.843627
Epoch 22
Loss = 4.2123e-01, PNorm = 44.2840, GNorm = 12.1333, lr_0 = 1.8434e-04
Validation rmse = 0.814053
Epoch 23
Loss = 4.6998e-01, PNorm = 44.2930, GNorm = 13.4775, lr_0 = 1.7511e-04
Loss = 4.1012e-01, PNorm = 44.3025, GNorm = 4.1358, lr_0 = 1.6633e-04
Validation rmse = 0.837217
Epoch 24
Loss = 3.5325e-01, PNorm = 44.3102, GNorm = 3.5394, lr_0 = 1.5800e-04
Loss = 3.9341e-01, PNorm = 44.3178, GNorm = 4.3390, lr_0 = 1.5009e-04
Validation rmse = 0.822690
Epoch 25
Loss = 4.0949e-01, PNorm = 44.3251, GNorm = 3.2235, lr_0 = 1.4257e-04
Validation rmse = 0.811947
Epoch 26
Loss = 3.4234e-01, PNorm = 44.3317, GNorm = 8.0717, lr_0 = 1.3542e-04
Loss = 3.8497e-01, PNorm = 44.3380, GNorm = 4.7023, lr_0 = 1.2864e-04
Validation rmse = 0.833976
Epoch 27
Loss = 3.8385e-01, PNorm = 44.3459, GNorm = 5.8189, lr_0 = 1.2220e-04
Validation rmse = 0.810637
Epoch 28
Loss = 4.9621e-01, PNorm = 44.3523, GNorm = 2.7652, lr_0 = 1.1607e-04
Loss = 3.4664e-01, PNorm = 44.3580, GNorm = 8.8836, lr_0 = 1.1026e-04
Validation rmse = 0.824336
Epoch 29
Loss = 3.1268e-01, PNorm = 44.3632, GNorm = 3.7043, lr_0 = 1.0473e-04
Loss = 3.6128e-01, PNorm = 44.3678, GNorm = 3.3810, lr_0 = 1.0000e-04
Validation rmse = 0.818057
Model 0 best validation rmse = 0.810637 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.681856
Ensemble test rmse = 0.681856
1-fold cross validation
	Seed 0 ==> test rmse = 0.681856
Overall test rmse = 0.681856 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9005e+00, PNorm = 43.3150, GNorm = 1.9901, lr_0 = 4.0937e-04
Validation rmse = 1.436437
Epoch 1
Loss = 1.4795e+00, PNorm = 43.3263, GNorm = 1.1297, lr_0 = 7.1875e-04
Loss = 1.3711e+00, PNorm = 43.3541, GNorm = 1.9214, lr_0 = 1.0000e-03
Validation rmse = 1.295954
Epoch 2
Loss = 1.2826e+00, PNorm = 43.3952, GNorm = 1.9406, lr_0 = 9.4990e-04
Loss = 1.1895e+00, PNorm = 43.4442, GNorm = 0.9246, lr_0 = 9.0231e-04
Validation rmse = 1.137360
Epoch 3
Loss = 1.1379e+00, PNorm = 43.5017, GNorm = 4.5405, lr_0 = 8.5711e-04
Validation rmse = 1.005246
Epoch 4
Loss = 8.9266e-01, PNorm = 43.5590, GNorm = 2.8281, lr_0 = 8.1417e-04
Loss = 9.8310e-01, PNorm = 43.6047, GNorm = 8.6324, lr_0 = 7.7338e-04
Validation rmse = 0.914245
Epoch 5
Loss = 8.0128e-01, PNorm = 43.6585, GNorm = 1.7734, lr_0 = 7.3463e-04
Loss = 8.5571e-01, PNorm = 43.6947, GNorm = 2.2902, lr_0 = 6.9783e-04
Loss = 8.6014e-01, PNorm = 43.6994, GNorm = 5.5913, lr_0 = 6.9425e-04
Validation rmse = 0.915197
Epoch 6
Loss = 7.6855e-01, PNorm = 43.7425, GNorm = 1.6835, lr_0 = 6.5947e-04
Validation rmse = 0.813833
Epoch 7
Loss = 7.4615e-01, PNorm = 43.7832, GNorm = 7.0705, lr_0 = 6.2643e-04
Loss = 6.3413e-01, PNorm = 43.8136, GNorm = 7.5098, lr_0 = 5.9505e-04
Validation rmse = 0.793646
Epoch 8
Loss = 6.3249e-01, PNorm = 43.8397, GNorm = 3.6011, lr_0 = 5.6524e-04
Loss = 6.3565e-01, PNorm = 43.8708, GNorm = 6.4836, lr_0 = 5.3692e-04
Validation rmse = 0.846218
Epoch 9
Loss = 5.5928e-01, PNorm = 43.8975, GNorm = 4.8173, lr_0 = 5.1002e-04
Validation rmse = 0.766045
Epoch 10
Loss = 6.1982e-01, PNorm = 43.9184, GNorm = 10.0921, lr_0 = 4.8447e-04
Loss = 5.3957e-01, PNorm = 43.9417, GNorm = 2.1809, lr_0 = 4.6020e-04
Validation rmse = 0.776989
Epoch 11
Loss = 5.6625e-01, PNorm = 43.9664, GNorm = 6.8118, lr_0 = 4.3490e-04
Loss = 5.1978e-01, PNorm = 43.9888, GNorm = 11.5300, lr_0 = 4.1312e-04
Validation rmse = 0.770081
Epoch 12
Loss = 5.0196e-01, PNorm = 44.0083, GNorm = 22.6142, lr_0 = 3.9242e-04
Validation rmse = 0.768902
Epoch 13
Loss = 4.5210e-01, PNorm = 44.0225, GNorm = 3.3880, lr_0 = 3.7276e-04
Loss = 4.5529e-01, PNorm = 44.0392, GNorm = 4.6144, lr_0 = 3.5408e-04
Validation rmse = 0.749458
Epoch 14
Loss = 4.1476e-01, PNorm = 44.0552, GNorm = 7.0166, lr_0 = 3.3635e-04
Loss = 4.7915e-01, PNorm = 44.0698, GNorm = 3.9747, lr_0 = 3.1950e-04
Validation rmse = 0.754771
Epoch 15
Loss = 4.6420e-01, PNorm = 44.0812, GNorm = 7.3160, lr_0 = 3.0349e-04
Validation rmse = 0.784121
Epoch 16
Loss = 5.7424e-01, PNorm = 44.0934, GNorm = 6.8976, lr_0 = 2.8681e-04
Loss = 4.5051e-01, PNorm = 44.1056, GNorm = 3.2880, lr_0 = 2.7244e-04
Validation rmse = 0.760367
Epoch 17
Loss = 4.4363e-01, PNorm = 44.1192, GNorm = 11.5613, lr_0 = 2.5879e-04
Loss = 4.4252e-01, PNorm = 44.1303, GNorm = 12.7153, lr_0 = 2.4582e-04
Validation rmse = 0.738741
Epoch 18
Loss = 3.9627e-01, PNorm = 44.1413, GNorm = 3.1842, lr_0 = 2.3351e-04
Validation rmse = 0.734498
Epoch 19
Loss = 4.1141e-01, PNorm = 44.1486, GNorm = 7.1050, lr_0 = 2.2181e-04
Loss = 3.6808e-01, PNorm = 44.1575, GNorm = 2.8876, lr_0 = 2.1070e-04
Validation rmse = 0.771850
Epoch 20
Loss = 3.9708e-01, PNorm = 44.1660, GNorm = 5.5025, lr_0 = 2.0014e-04
Loss = 4.0597e-01, PNorm = 44.1726, GNorm = 4.3782, lr_0 = 1.9012e-04
Validation rmse = 0.747203
Epoch 21
Loss = 3.3741e-01, PNorm = 44.1820, GNorm = 3.0651, lr_0 = 1.7967e-04
Validation rmse = 0.731532
Epoch 22
Loss = 4.2103e-01, PNorm = 44.1895, GNorm = 5.0864, lr_0 = 1.7066e-04
Loss = 3.4117e-01, PNorm = 44.1965, GNorm = 6.0603, lr_0 = 1.6211e-04
Validation rmse = 0.734524
Epoch 23
Loss = 3.2042e-01, PNorm = 44.2028, GNorm = 7.9500, lr_0 = 1.5399e-04
Loss = 3.1527e-01, PNorm = 44.2094, GNorm = 7.5800, lr_0 = 1.4628e-04
Validation rmse = 0.728178
Epoch 24
Loss = 2.9306e-01, PNorm = 44.2151, GNorm = 10.3367, lr_0 = 1.3895e-04
Loss = 3.2608e-01, PNorm = 44.2208, GNorm = 5.4618, lr_0 = 1.3199e-04
Validation rmse = 0.724973
Epoch 25
Loss = 3.3937e-01, PNorm = 44.2254, GNorm = 20.9854, lr_0 = 1.2538e-04
Validation rmse = 0.733712
Epoch 26
Loss = 2.7713e-01, PNorm = 44.2298, GNorm = 12.1795, lr_0 = 1.1848e-04
Loss = 3.6162e-01, PNorm = 44.2349, GNorm = 4.1762, lr_0 = 1.1255e-04
Validation rmse = 0.727941
Epoch 27
Loss = 2.6233e-01, PNorm = 44.2395, GNorm = 4.5474, lr_0 = 1.0691e-04
Loss = 3.6875e-01, PNorm = 44.2437, GNorm = 13.5505, lr_0 = 1.0155e-04
Validation rmse = 0.738801
Epoch 28
Loss = 3.1780e-01, PNorm = 44.2486, GNorm = 3.4196, lr_0 = 1.0000e-04
Validation rmse = 0.727260
Epoch 29
Loss = 2.9210e-01, PNorm = 44.2516, GNorm = 9.1940, lr_0 = 1.0000e-04
Loss = 3.1031e-01, PNorm = 44.2553, GNorm = 4.4521, lr_0 = 1.0000e-04
Validation rmse = 0.729160
Model 0 best validation rmse = 0.724973 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.761448
Ensemble test rmse = 0.761448
1-fold cross validation
	Seed 0 ==> test rmse = 0.761448
Overall test rmse = 0.761448 +/- 0.000000
Elapsed time = 0:01:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7362e+00, PNorm = 43.3132, GNorm = 1.3866, lr_0 = 3.9118e-04
Validation rmse = 1.441194
Epoch 1
Loss = 1.4419e+00, PNorm = 43.3246, GNorm = 0.9617, lr_0 = 6.8235e-04
Loss = 1.3227e+00, PNorm = 43.3566, GNorm = 1.7060, lr_0 = 9.4706e-04
Validation rmse = 1.263404
Epoch 2
Loss = 1.2318e+00, PNorm = 43.3990, GNorm = 1.3744, lr_0 = 9.6204e-04
Loss = 1.1164e+00, PNorm = 43.4575, GNorm = 1.5010, lr_0 = 9.1661e-04
Validation rmse = 1.174308
Epoch 3
Loss = 1.0167e+00, PNorm = 43.5259, GNorm = 5.2545, lr_0 = 8.6911e-04
Loss = 9.0499e-01, PNorm = 43.5890, GNorm = 4.0097, lr_0 = 8.2807e-04
Validation rmse = 0.896193
Epoch 4
Loss = 7.9333e-01, PNorm = 43.6431, GNorm = 7.9580, lr_0 = 7.8897e-04
Validation rmse = 0.834754
Epoch 5
Loss = 6.4984e-01, PNorm = 43.6919, GNorm = 1.9514, lr_0 = 7.5171e-04
Loss = 6.5240e-01, PNorm = 43.7400, GNorm = 2.1310, lr_0 = 7.1621e-04
Validation rmse = 0.852675
Epoch 6
Loss = 6.9843e-01, PNorm = 43.7828, GNorm = 6.3385, lr_0 = 6.7910e-04
Loss = 6.0984e-01, PNorm = 43.8246, GNorm = 2.0479, lr_0 = 6.4703e-04
Validation rmse = 0.771722
Epoch 7
Loss = 5.7248e-01, PNorm = 43.8557, GNorm = 4.9862, lr_0 = 6.1648e-04
Loss = 5.8043e-01, PNorm = 43.8824, GNorm = 6.5438, lr_0 = 5.8736e-04
Loss = 4.8427e-01, PNorm = 43.8847, GNorm = 4.7308, lr_0 = 5.8453e-04
Validation rmse = 0.792909
Epoch 8
Loss = 4.9293e-01, PNorm = 43.9147, GNorm = 6.5291, lr_0 = 5.5693e-04
Validation rmse = 0.764612
Epoch 9
Loss = 4.5567e-01, PNorm = 43.9415, GNorm = 5.7494, lr_0 = 5.3063e-04
Loss = 4.9685e-01, PNorm = 43.9661, GNorm = 3.3746, lr_0 = 5.0557e-04
Validation rmse = 0.730514
Epoch 10
Loss = 4.8730e-01, PNorm = 43.9899, GNorm = 11.0683, lr_0 = 4.8170e-04
Loss = 4.4178e-01, PNorm = 44.0123, GNorm = 2.8581, lr_0 = 4.5895e-04
Validation rmse = 0.729820
Epoch 11
Loss = 4.4526e-01, PNorm = 44.0409, GNorm = 5.2043, lr_0 = 4.3517e-04
Loss = 3.3914e-01, PNorm = 44.0588, GNorm = 8.5721, lr_0 = 4.1462e-04
Validation rmse = 0.723778
Epoch 12
Loss = 3.8953e-01, PNorm = 44.0756, GNorm = 3.4545, lr_0 = 3.9504e-04
Validation rmse = 0.711889
Epoch 13
Loss = 3.4359e-01, PNorm = 44.0965, GNorm = 6.1745, lr_0 = 3.7457e-04
Loss = 4.2023e-01, PNorm = 44.1107, GNorm = 2.1214, lr_0 = 3.5688e-04
Validation rmse = 0.719757
Epoch 14
Loss = 3.1896e-01, PNorm = 44.1253, GNorm = 3.6135, lr_0 = 3.4003e-04
Loss = 3.4432e-01, PNorm = 44.1395, GNorm = 9.9851, lr_0 = 3.2397e-04
Validation rmse = 0.745592
Epoch 15
Loss = 3.5757e-01, PNorm = 44.1513, GNorm = 4.4715, lr_0 = 3.0867e-04
Loss = 4.1426e-01, PNorm = 44.1614, GNorm = 18.2745, lr_0 = 2.9409e-04
Validation rmse = 0.711063
Epoch 16
Loss = 3.4273e-01, PNorm = 44.1748, GNorm = 6.1768, lr_0 = 2.7885e-04
Validation rmse = 0.700527
Epoch 17
Loss = 3.2219e-01, PNorm = 44.1864, GNorm = 4.8045, lr_0 = 2.6569e-04
Loss = 3.0208e-01, PNorm = 44.1989, GNorm = 5.4167, lr_0 = 2.5314e-04
Validation rmse = 0.706828
Epoch 18
Loss = 3.0487e-01, PNorm = 44.2096, GNorm = 12.1674, lr_0 = 2.4002e-04
Loss = 3.6237e-01, PNorm = 44.2165, GNorm = 6.4194, lr_0 = 2.2869e-04
Validation rmse = 0.725410
Epoch 19
Loss = 2.8959e-01, PNorm = 44.2276, GNorm = 5.5565, lr_0 = 2.1789e-04
Loss = 2.7429e-01, PNorm = 44.2367, GNorm = 2.8549, lr_0 = 2.0760e-04
Validation rmse = 0.692757
Epoch 20
Loss = 2.6473e-01, PNorm = 44.2450, GNorm = 4.3982, lr_0 = 1.9780e-04
Validation rmse = 0.700863
Epoch 21
Loss = 1.6531e-01, PNorm = 44.2539, GNorm = 3.9278, lr_0 = 1.8755e-04
Loss = 2.8761e-01, PNorm = 44.2611, GNorm = 17.2522, lr_0 = 1.7869e-04
Validation rmse = 0.703553
Epoch 22
Loss = 3.3670e-01, PNorm = 44.2679, GNorm = 3.9917, lr_0 = 1.7025e-04
Loss = 2.6295e-01, PNorm = 44.2756, GNorm = 6.3508, lr_0 = 1.6221e-04
Validation rmse = 0.688637
Epoch 23
Loss = 2.0896e-01, PNorm = 44.2837, GNorm = 7.7238, lr_0 = 1.5381e-04
Loss = 2.7082e-01, PNorm = 44.2903, GNorm = 7.6655, lr_0 = 1.4654e-04
Validation rmse = 0.691822
Epoch 24
Loss = 2.1788e-01, PNorm = 44.2967, GNorm = 9.4788, lr_0 = 1.3962e-04
Loss = 2.6621e-01, PNorm = 44.3024, GNorm = 5.4323, lr_0 = 1.3303e-04
Validation rmse = 0.693172
Epoch 25
Loss = 2.2351e-01, PNorm = 44.3071, GNorm = 4.5062, lr_0 = 1.2675e-04
Validation rmse = 0.695398
Epoch 26
Loss = 2.5690e-01, PNorm = 44.3127, GNorm = 3.5964, lr_0 = 1.2018e-04
Loss = 1.8576e-01, PNorm = 44.3185, GNorm = 8.0103, lr_0 = 1.1450e-04
Validation rmse = 0.689541
Epoch 27
Loss = 1.9915e-01, PNorm = 44.3233, GNorm = 5.1796, lr_0 = 1.0910e-04
Loss = 2.2526e-01, PNorm = 44.3280, GNorm = 17.9064, lr_0 = 1.0395e-04
Validation rmse = 0.691668
Epoch 28
Loss = 1.6977e-01, PNorm = 44.3321, GNorm = 3.8519, lr_0 = 1.0000e-04
Loss = 2.2582e-01, PNorm = 44.3355, GNorm = 4.6710, lr_0 = 1.0000e-04
Validation rmse = 0.704124
Epoch 29
Loss = 1.8263e-01, PNorm = 44.3403, GNorm = 9.8847, lr_0 = 1.0000e-04
Validation rmse = 0.693611
Model 0 best validation rmse = 0.688637 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.702557
Ensemble test rmse = 0.702557
1-fold cross validation
	Seed 0 ==> test rmse = 0.702557
Overall test rmse = 0.702557 +/- 0.000000
Elapsed time = 0:01:30
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8197e+00, PNorm = 43.3147, GNorm = 1.1541, lr_0 = 3.7500e-04
Validation rmse = 1.437431
Epoch 1
Loss = 1.4414e+00, PNorm = 43.3267, GNorm = 1.4678, lr_0 = 6.5000e-04
Loss = 1.3532e+00, PNorm = 43.3542, GNorm = 1.5169, lr_0 = 9.0000e-04
Validation rmse = 1.288556
Epoch 2
Loss = 1.2513e+00, PNorm = 43.4013, GNorm = 6.2965, lr_0 = 9.6853e-04
Loss = 1.1825e+00, PNorm = 43.4459, GNorm = 1.0960, lr_0 = 9.2527e-04
Validation rmse = 1.133828
Epoch 3
Loss = 1.0033e+00, PNorm = 43.5106, GNorm = 2.9308, lr_0 = 8.8395e-04
Loss = 9.1223e-01, PNorm = 43.5758, GNorm = 4.7838, lr_0 = 8.4448e-04
Validation rmse = 0.934709
Epoch 4
Loss = 8.9506e-01, PNorm = 43.6419, GNorm = 10.1019, lr_0 = 8.0309e-04
Loss = 7.0871e-01, PNorm = 43.6954, GNorm = 2.6864, lr_0 = 7.6722e-04
Validation rmse = 0.850861
Epoch 5
Loss = 6.0881e-01, PNorm = 43.7379, GNorm = 4.6849, lr_0 = 7.3296e-04
Loss = 6.1790e-01, PNorm = 43.7791, GNorm = 3.9952, lr_0 = 7.0023e-04
Loss = 6.5607e-01, PNorm = 43.7828, GNorm = 3.8497, lr_0 = 6.9703e-04
Validation rmse = 0.801378
Epoch 6
Loss = 5.9349e-01, PNorm = 43.8098, GNorm = 10.0029, lr_0 = 6.6591e-04
Validation rmse = 0.826136
Epoch 7
Loss = 5.5660e-01, PNorm = 43.8467, GNorm = 4.2093, lr_0 = 6.3327e-04
Loss = 5.5993e-01, PNorm = 43.8821, GNorm = 3.0340, lr_0 = 6.0499e-04
Validation rmse = 0.767393
Epoch 8
Loss = 4.4119e-01, PNorm = 43.9124, GNorm = 6.0198, lr_0 = 5.7797e-04
Loss = 4.7504e-01, PNorm = 43.9328, GNorm = 6.0046, lr_0 = 5.5216e-04
Validation rmse = 0.742277
Epoch 9
Loss = 4.3421e-01, PNorm = 43.9601, GNorm = 3.4900, lr_0 = 5.2510e-04
Loss = 4.3664e-01, PNorm = 43.9803, GNorm = 6.2857, lr_0 = 5.0165e-04
Validation rmse = 0.741696
Epoch 10
Loss = 4.2682e-01, PNorm = 43.9992, GNorm = 9.9932, lr_0 = 4.7924e-04
Loss = 4.7668e-01, PNorm = 44.0166, GNorm = 8.5488, lr_0 = 4.5784e-04
Validation rmse = 0.724068
Epoch 11
Loss = 3.8403e-01, PNorm = 44.0380, GNorm = 7.9235, lr_0 = 4.3540e-04
Loss = 3.7380e-01, PNorm = 44.0564, GNorm = 2.8926, lr_0 = 4.1596e-04
Loss = 2.5094e-01, PNorm = 44.0579, GNorm = 5.3199, lr_0 = 4.1406e-04
Validation rmse = 0.765396
Epoch 12
Loss = 3.8938e-01, PNorm = 44.0711, GNorm = 8.5285, lr_0 = 3.9557e-04
Validation rmse = 0.726093
Epoch 13
Loss = 5.4664e-01, PNorm = 44.0862, GNorm = 8.4819, lr_0 = 3.7790e-04
Loss = 3.6835e-01, PNorm = 44.1017, GNorm = 12.2584, lr_0 = 3.6103e-04
Validation rmse = 0.810087
Epoch 14
Loss = 3.6949e-01, PNorm = 44.1153, GNorm = 5.7615, lr_0 = 3.4333e-04
Loss = 3.7375e-01, PNorm = 44.1281, GNorm = 9.3510, lr_0 = 3.2800e-04
Validation rmse = 0.738942
Epoch 15
Loss = 3.3718e-01, PNorm = 44.1404, GNorm = 2.3618, lr_0 = 3.1335e-04
Loss = 3.3861e-01, PNorm = 44.1522, GNorm = 8.2772, lr_0 = 2.9936e-04
Validation rmse = 0.730910
Epoch 16
Loss = 3.2582e-01, PNorm = 44.1633, GNorm = 3.0466, lr_0 = 2.8469e-04
Loss = 2.7481e-01, PNorm = 44.1737, GNorm = 2.8318, lr_0 = 2.7197e-04
Validation rmse = 0.707156
Epoch 17
Loss = 2.7513e-01, PNorm = 44.1842, GNorm = 12.6886, lr_0 = 2.5864e-04
Loss = 2.7007e-01, PNorm = 44.1958, GNorm = 9.2889, lr_0 = 2.4709e-04
Validation rmse = 0.730438
Epoch 18
Loss = 3.1427e-01, PNorm = 44.2034, GNorm = 5.3715, lr_0 = 2.3606e-04
Validation rmse = 0.698608
Epoch 19
Loss = 9.9551e-02, PNorm = 44.2148, GNorm = 7.1779, lr_0 = 2.2449e-04
Loss = 2.5409e-01, PNorm = 44.2228, GNorm = 9.9969, lr_0 = 2.1446e-04
Validation rmse = 0.710141
Epoch 20
Loss = 1.9001e-01, PNorm = 44.2324, GNorm = 6.7780, lr_0 = 2.0488e-04
Loss = 2.1303e-01, PNorm = 44.2407, GNorm = 8.0894, lr_0 = 1.9573e-04
Validation rmse = 0.699884
Epoch 21
Loss = 2.1453e-01, PNorm = 44.2482, GNorm = 3.7090, lr_0 = 1.8614e-04
Loss = 2.4655e-01, PNorm = 44.2560, GNorm = 3.6272, lr_0 = 1.7783e-04
Validation rmse = 0.698887
Epoch 22
Loss = 3.3057e-01, PNorm = 44.2620, GNorm = 5.9442, lr_0 = 1.6911e-04
Loss = 2.5015e-01, PNorm = 44.2680, GNorm = 10.5943, lr_0 = 1.6156e-04
Validation rmse = 0.705511
Epoch 23
Loss = 1.9042e-01, PNorm = 44.2758, GNorm = 3.3452, lr_0 = 1.5434e-04
Loss = 2.3842e-01, PNorm = 44.2830, GNorm = 4.0939, lr_0 = 1.4745e-04
Validation rmse = 0.715754
Epoch 24
Loss = 1.4705e-01, PNorm = 44.2867, GNorm = 5.1892, lr_0 = 1.4022e-04
Loss = 2.5333e-01, PNorm = 44.2926, GNorm = 7.8908, lr_0 = 1.3396e-04
Validation rmse = 0.698694
Epoch 25
Loss = 2.0556e-01, PNorm = 44.2990, GNorm = 5.1926, lr_0 = 1.2798e-04
Validation rmse = 0.697146
Epoch 26
Loss = 1.6956e-01, PNorm = 44.3043, GNorm = 3.3519, lr_0 = 1.2171e-04
Loss = 1.9224e-01, PNorm = 44.3089, GNorm = 6.2263, lr_0 = 1.1627e-04
Validation rmse = 0.691891
Epoch 27
Loss = 2.7764e-01, PNorm = 44.3129, GNorm = 15.4280, lr_0 = 1.1057e-04
Loss = 1.7299e-01, PNorm = 44.3164, GNorm = 11.9693, lr_0 = 1.0564e-04
Validation rmse = 0.702400
Epoch 28
Loss = 1.5664e-01, PNorm = 44.3207, GNorm = 3.6934, lr_0 = 1.0092e-04
Loss = 2.2978e-01, PNorm = 44.3255, GNorm = 2.4591, lr_0 = 1.0000e-04
Validation rmse = 0.694022
Epoch 29
Loss = 1.7221e-01, PNorm = 44.3295, GNorm = 3.3233, lr_0 = 1.0000e-04
Loss = 1.9467e-01, PNorm = 44.3335, GNorm = 9.7403, lr_0 = 1.0000e-04
Validation rmse = 0.690390
Model 0 best validation rmse = 0.690390 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.687786
Ensemble test rmse = 0.687786
1-fold cross validation
	Seed 0 ==> test rmse = 0.687786
Overall test rmse = 0.687786 +/- 0.000000
Elapsed time = 1:39:13
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7746e+00, PNorm = 43.3156, GNorm = 1.8001, lr_0 = 3.6053e-04
Validation rmse = 1.505609
Epoch 1
Loss = 1.4148e+00, PNorm = 43.3267, GNorm = 1.1116, lr_0 = 6.2105e-04
Loss = 1.3167e+00, PNorm = 43.3534, GNorm = 1.6365, lr_0 = 8.5789e-04
Validation rmse = 1.267444
Epoch 2
Loss = 1.1477e+00, PNorm = 43.4071, GNorm = 1.4462, lr_0 = 9.7859e-04
Loss = 1.1014e+00, PNorm = 43.4634, GNorm = 1.5841, lr_0 = 9.3714e-04
Validation rmse = 1.100060
Epoch 3
Loss = 8.7527e-01, PNorm = 43.5340, GNorm = 5.2825, lr_0 = 8.9357e-04
Loss = 8.8955e-01, PNorm = 43.5935, GNorm = 2.4729, lr_0 = 8.5572e-04
Validation rmse = 0.840464
Epoch 4
Loss = 6.6220e-01, PNorm = 43.6598, GNorm = 2.5246, lr_0 = 8.1593e-04
Loss = 7.3403e-01, PNorm = 43.7089, GNorm = 4.4387, lr_0 = 7.8137e-04
Validation rmse = 0.844001
Epoch 5
Loss = 6.7967e-01, PNorm = 43.7609, GNorm = 13.4756, lr_0 = 7.4827e-04
Loss = 6.4995e-01, PNorm = 43.8029, GNorm = 9.1195, lr_0 = 7.1658e-04
Validation rmse = 0.754349
Epoch 6
Loss = 5.0991e-01, PNorm = 43.8473, GNorm = 6.7950, lr_0 = 6.8326e-04
Loss = 5.8800e-01, PNorm = 43.8831, GNorm = 3.5595, lr_0 = 6.5432e-04
Validation rmse = 0.785029
Epoch 7
Loss = 3.7922e-01, PNorm = 43.9272, GNorm = 9.6969, lr_0 = 6.2390e-04
Loss = 6.0444e-01, PNorm = 43.9537, GNorm = 1.8972, lr_0 = 5.9747e-04
Validation rmse = 0.711154
Epoch 8
Loss = 4.5894e-01, PNorm = 43.9886, GNorm = 5.4438, lr_0 = 5.6969e-04
Loss = 4.9157e-01, PNorm = 44.0119, GNorm = 2.8390, lr_0 = 5.4556e-04
Validation rmse = 0.757458
Epoch 9
Loss = 4.4550e-01, PNorm = 44.0417, GNorm = 8.8613, lr_0 = 5.2019e-04
Loss = 4.2310e-01, PNorm = 44.0680, GNorm = 5.0101, lr_0 = 4.9816e-04
Validation rmse = 0.725257
Epoch 10
Loss = 4.2093e-01, PNorm = 44.0855, GNorm = 3.8053, lr_0 = 4.7706e-04
Loss = 3.8638e-01, PNorm = 44.1078, GNorm = 10.7288, lr_0 = 4.5685e-04
Validation rmse = 0.691126
Epoch 11
Loss = 4.1134e-01, PNorm = 44.1268, GNorm = 14.4226, lr_0 = 4.3561e-04
Loss = 4.9430e-01, PNorm = 44.1461, GNorm = 11.6938, lr_0 = 4.1716e-04
Loss = 5.0224e-01, PNorm = 44.1477, GNorm = 5.5702, lr_0 = 4.1536e-04
Validation rmse = 0.695493
Epoch 12
Loss = 3.6869e-01, PNorm = 44.1656, GNorm = 5.6117, lr_0 = 3.9776e-04
Validation rmse = 0.763002
Epoch 13
Loss = 3.4212e-01, PNorm = 44.1834, GNorm = 9.6474, lr_0 = 3.7927e-04
Loss = 3.6681e-01, PNorm = 44.1980, GNorm = 4.6222, lr_0 = 3.6320e-04
Validation rmse = 0.674550
Epoch 14
Loss = 3.0745e-01, PNorm = 44.2131, GNorm = 10.3095, lr_0 = 3.4632e-04
Loss = 3.4349e-01, PNorm = 44.2281, GNorm = 2.4172, lr_0 = 3.3165e-04
Validation rmse = 0.692073
Epoch 15
Loss = 2.0204e-01, PNorm = 44.2392, GNorm = 4.4099, lr_0 = 3.1760e-04
Loss = 3.6534e-01, PNorm = 44.2525, GNorm = 7.9061, lr_0 = 3.0415e-04
Validation rmse = 0.715079
Epoch 16
Loss = 2.8538e-01, PNorm = 44.2654, GNorm = 4.4017, lr_0 = 2.9001e-04
Loss = 3.1494e-01, PNorm = 44.2739, GNorm = 6.3479, lr_0 = 2.7772e-04
Validation rmse = 0.718444
Epoch 17
Loss = 2.9673e-01, PNorm = 44.2883, GNorm = 11.8606, lr_0 = 2.6481e-04
Loss = 3.0985e-01, PNorm = 44.2974, GNorm = 4.5152, lr_0 = 2.5359e-04
Validation rmse = 0.783515
Epoch 18
Loss = 3.2140e-01, PNorm = 44.3069, GNorm = 5.0270, lr_0 = 2.4180e-04
Loss = 2.9337e-01, PNorm = 44.3178, GNorm = 3.2806, lr_0 = 2.3156e-04
Validation rmse = 0.720754
Epoch 19
Loss = 2.7206e-01, PNorm = 44.3258, GNorm = 3.4625, lr_0 = 2.2079e-04
Loss = 2.4753e-01, PNorm = 44.3350, GNorm = 12.4503, lr_0 = 2.1144e-04
Validation rmse = 0.700557
Epoch 20
Loss = 2.0123e-01, PNorm = 44.3425, GNorm = 9.2866, lr_0 = 2.0248e-04
Loss = 2.2910e-01, PNorm = 44.3493, GNorm = 4.3663, lr_0 = 1.9391e-04
Validation rmse = 0.686935
Epoch 21
Loss = 1.8791e-01, PNorm = 44.3588, GNorm = 6.3382, lr_0 = 1.8489e-04
Loss = 2.5007e-01, PNorm = 44.3652, GNorm = 3.0653, lr_0 = 1.7706e-04
Validation rmse = 0.673885
Epoch 22
Loss = 2.2515e-01, PNorm = 44.3717, GNorm = 6.5156, lr_0 = 1.6883e-04
Loss = 2.0591e-01, PNorm = 44.3785, GNorm = 5.8312, lr_0 = 1.6168e-04
Validation rmse = 0.688439
Epoch 23
Loss = 1.8345e-01, PNorm = 44.3855, GNorm = 4.1771, lr_0 = 1.5416e-04
Loss = 2.6757e-01, PNorm = 44.3905, GNorm = 4.8511, lr_0 = 1.4763e-04
Loss = 6.0376e-03, PNorm = 44.3910, GNorm = 5.0695, lr_0 = 1.4699e-04
Validation rmse = 0.681131
Epoch 24
Loss = 2.1515e-01, PNorm = 44.3969, GNorm = 11.0152, lr_0 = 1.4077e-04
Loss = 1.8845e-01, PNorm = 44.4034, GNorm = 6.8550, lr_0 = 1.3480e-04
Validation rmse = 0.677191
Epoch 25
Loss = 1.1589e-01, PNorm = 44.4088, GNorm = 4.2141, lr_0 = 1.2909e-04
Validation rmse = 0.688620
Epoch 26
Loss = 3.6591e-01, PNorm = 44.4133, GNorm = 6.9316, lr_0 = 1.2309e-04
Loss = 1.7623e-01, PNorm = 44.4179, GNorm = 10.3425, lr_0 = 1.1788e-04
Validation rmse = 0.715905
Epoch 27
Loss = 2.4740e-01, PNorm = 44.4228, GNorm = 9.4026, lr_0 = 1.1240e-04
Loss = 1.4616e-01, PNorm = 44.4273, GNorm = 8.1298, lr_0 = 1.0764e-04
Validation rmse = 0.673815
Epoch 28
Loss = 1.3916e-01, PNorm = 44.4317, GNorm = 3.8460, lr_0 = 1.0263e-04
Loss = 1.7531e-01, PNorm = 44.4355, GNorm = 9.8542, lr_0 = 1.0000e-04
Validation rmse = 0.703215
Epoch 29
Loss = 1.3286e-01, PNorm = 44.4411, GNorm = 3.6313, lr_0 = 1.0000e-04
Loss = 1.6819e-01, PNorm = 44.4454, GNorm = 3.4324, lr_0 = 1.0000e-04
Validation rmse = 0.677317
Model 0 best validation rmse = 0.673815 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.654919
Ensemble test rmse = 0.654919
1-fold cross validation
	Seed 0 ==> test rmse = 0.654919
Overall test rmse = 0.654919 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7757e+00, PNorm = 43.3133, GNorm = 1.1014, lr_0 = 3.4750e-04
Loss = 1.4741e+00, PNorm = 43.3194, GNorm = 1.5037, lr_0 = 5.7250e-04
Validation rmse = 1.544410
Epoch 1
Loss = 1.3693e+00, PNorm = 43.3399, GNorm = 1.4211, lr_0 = 7.9750e-04
Loss = 1.2108e+00, PNorm = 43.3797, GNorm = 0.9820, lr_0 = 9.9590e-04
Validation rmse = 1.308874
Epoch 2
Loss = 1.1659e+00, PNorm = 43.4339, GNorm = 2.1316, lr_0 = 9.5578e-04
Loss = 1.0175e+00, PNorm = 43.4996, GNorm = 6.2873, lr_0 = 9.1728e-04
Validation rmse = 1.003575
Epoch 3
Loss = 8.9057e-01, PNorm = 43.5597, GNorm = 1.9745, lr_0 = 8.8032e-04
Loss = 8.2188e-01, PNorm = 43.6299, GNorm = 12.9227, lr_0 = 8.4486e-04
Validation rmse = 0.869786
Epoch 4
Loss = 7.7899e-01, PNorm = 43.6791, GNorm = 2.5134, lr_0 = 8.1083e-04
Loss = 6.7971e-01, PNorm = 43.7283, GNorm = 3.8265, lr_0 = 7.7816e-04
Validation rmse = 0.736477
Epoch 5
Loss = 6.0754e-01, PNorm = 43.7793, GNorm = 3.6100, lr_0 = 7.4682e-04
Loss = 6.4446e-01, PNorm = 43.8113, GNorm = 10.6168, lr_0 = 7.1673e-04
Validation rmse = 0.724488
Epoch 6
Loss = 5.6083e-01, PNorm = 43.8484, GNorm = 8.6980, lr_0 = 6.8786e-04
Loss = 5.7354e-01, PNorm = 43.8792, GNorm = 3.0542, lr_0 = 6.6015e-04
Validation rmse = 0.704841
Epoch 7
Loss = 5.0899e-01, PNorm = 43.9139, GNorm = 9.1821, lr_0 = 6.3356e-04
Loss = 4.9046e-01, PNorm = 43.9464, GNorm = 2.8581, lr_0 = 6.0803e-04
Validation rmse = 0.667127
Epoch 8
Loss = 4.0390e-01, PNorm = 43.9724, GNorm = 5.9793, lr_0 = 5.8354e-04
Loss = 4.5679e-01, PNorm = 43.9985, GNorm = 2.1521, lr_0 = 5.6003e-04
Validation rmse = 0.673701
Epoch 9
Loss = 3.4835e-01, PNorm = 44.0324, GNorm = 6.7089, lr_0 = 5.3747e-04
Loss = 5.0765e-01, PNorm = 44.0477, GNorm = 3.3018, lr_0 = 5.1582e-04
Validation rmse = 0.696160
Epoch 10
Loss = 3.7721e-01, PNorm = 44.0729, GNorm = 6.6643, lr_0 = 4.9504e-04
Loss = 4.1440e-01, PNorm = 44.0959, GNorm = 4.1608, lr_0 = 4.7510e-04
Validation rmse = 0.689170
Epoch 11
Loss = 3.5818e-01, PNorm = 44.1163, GNorm = 5.1090, lr_0 = 4.5596e-04
Loss = 3.8867e-01, PNorm = 44.1357, GNorm = 13.9437, lr_0 = 4.3759e-04
Validation rmse = 0.748184
Epoch 12
Loss = 3.8187e-01, PNorm = 44.1530, GNorm = 11.9312, lr_0 = 4.1997e-04
Loss = 3.6702e-01, PNorm = 44.1758, GNorm = 4.9919, lr_0 = 4.0305e-04
Validation rmse = 0.655361
Epoch 13
Loss = 3.1269e-01, PNorm = 44.1873, GNorm = 5.8913, lr_0 = 3.8681e-04
Loss = 3.0782e-01, PNorm = 44.2040, GNorm = 13.1511, lr_0 = 3.7123e-04
Validation rmse = 0.638819
Epoch 14
Loss = 2.9572e-01, PNorm = 44.2198, GNorm = 2.3567, lr_0 = 3.5628e-04
Loss = 2.7775e-01, PNorm = 44.2357, GNorm = 8.4078, lr_0 = 3.4192e-04
Validation rmse = 0.641040
Epoch 15
Loss = 2.6629e-01, PNorm = 44.2501, GNorm = 10.6077, lr_0 = 3.2815e-04
Loss = 3.0793e-01, PNorm = 44.2615, GNorm = 3.4579, lr_0 = 3.1493e-04
Validation rmse = 0.677462
Epoch 16
Loss = 2.7696e-01, PNorm = 44.2746, GNorm = 4.7934, lr_0 = 3.0224e-04
Loss = 2.7010e-01, PNorm = 44.2881, GNorm = 5.0554, lr_0 = 2.9007e-04
Validation rmse = 0.657695
Epoch 17
Loss = 2.5156e-01, PNorm = 44.3005, GNorm = 5.3268, lr_0 = 2.7838e-04
Loss = 2.2241e-01, PNorm = 44.3082, GNorm = 7.0644, lr_0 = 2.6717e-04
Validation rmse = 0.645766
Epoch 18
Loss = 1.9190e-01, PNorm = 44.3182, GNorm = 9.5311, lr_0 = 2.5641e-04
Loss = 2.8894e-01, PNorm = 44.3289, GNorm = 3.9593, lr_0 = 2.4608e-04
Validation rmse = 0.630030
Epoch 19
Loss = 2.5739e-01, PNorm = 44.3382, GNorm = 4.8077, lr_0 = 2.3616e-04
Loss = 2.2812e-01, PNorm = 44.3480, GNorm = 12.1485, lr_0 = 2.2665e-04
Validation rmse = 0.660530
Epoch 20
Loss = 2.1393e-01, PNorm = 44.3591, GNorm = 1.9775, lr_0 = 2.1752e-04
Loss = 2.6224e-01, PNorm = 44.3660, GNorm = 4.1394, lr_0 = 2.0876e-04
Validation rmse = 0.667447
Epoch 21
Loss = 2.1606e-01, PNorm = 44.3722, GNorm = 3.4913, lr_0 = 2.0035e-04
Loss = 2.3257e-01, PNorm = 44.3807, GNorm = 3.2822, lr_0 = 1.9228e-04
Validation rmse = 0.655103
Epoch 22
Loss = 2.1625e-01, PNorm = 44.3904, GNorm = 4.1356, lr_0 = 1.8453e-04
Loss = 3.4110e-01, PNorm = 44.3934, GNorm = 4.5782, lr_0 = 1.7710e-04
Validation rmse = 0.650094
Epoch 23
Loss = 2.3043e-01, PNorm = 44.3993, GNorm = 11.2808, lr_0 = 1.6996e-04
Loss = 2.0935e-01, PNorm = 44.4072, GNorm = 6.8166, lr_0 = 1.6312e-04
Validation rmse = 0.641261
Epoch 24
Loss = 1.9683e-01, PNorm = 44.4139, GNorm = 6.2455, lr_0 = 1.5655e-04
Loss = 1.5154e-01, PNorm = 44.4202, GNorm = 12.4990, lr_0 = 1.5024e-04
Validation rmse = 0.645916
Epoch 25
Loss = 1.6588e-01, PNorm = 44.4256, GNorm = 3.4187, lr_0 = 1.4419e-04
Loss = 1.5736e-01, PNorm = 44.4314, GNorm = 2.4037, lr_0 = 1.3838e-04
Validation rmse = 0.655395
Epoch 26
Loss = 1.7588e-01, PNorm = 44.4374, GNorm = 14.7229, lr_0 = 1.3280e-04
Loss = 2.1190e-01, PNorm = 44.4404, GNorm = 11.5426, lr_0 = 1.2746e-04
Validation rmse = 0.667308
Epoch 27
Loss = 1.6666e-01, PNorm = 44.4461, GNorm = 3.6344, lr_0 = 1.2232e-04
Loss = 1.5936e-01, PNorm = 44.4507, GNorm = 3.3636, lr_0 = 1.1739e-04
Validation rmse = 0.646633
Epoch 28
Loss = 1.4165e-01, PNorm = 44.4560, GNorm = 5.5651, lr_0 = 1.1266e-04
Loss = 1.5325e-01, PNorm = 44.4608, GNorm = 5.4856, lr_0 = 1.0813e-04
Validation rmse = 0.647054
Epoch 29
Loss = 1.3761e-01, PNorm = 44.4639, GNorm = 12.8109, lr_0 = 1.0377e-04
Loss = 1.5991e-01, PNorm = 44.4678, GNorm = 3.2901, lr_0 = 1.0000e-04
Validation rmse = 0.646881
Model 0 best validation rmse = 0.630030 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.680646
Ensemble test rmse = 0.680646
1-fold cross validation
	Seed 0 ==> test rmse = 0.680646
Overall test rmse = 0.680646 +/- 0.000000
Elapsed time = 0:01:41
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8045e+00, PNorm = 43.3140, GNorm = 2.1050, lr_0 = 3.4750e-04
Loss = 1.4395e+00, PNorm = 43.3225, GNorm = 1.4232, lr_0 = 5.7250e-04
Loss = 1.3568e+00, PNorm = 43.3239, GNorm = 1.3527, lr_0 = 5.9500e-04
Validation rmse = 1.552059
Epoch 1
Loss = 1.2843e+00, PNorm = 43.3501, GNorm = 0.7507, lr_0 = 8.2000e-04
Loss = 1.1507e+00, PNorm = 43.4015, GNorm = 1.8836, lr_0 = 9.9181e-04
Validation rmse = 1.243028
Epoch 2
Loss = 1.0020e+00, PNorm = 43.4705, GNorm = 3.4999, lr_0 = 9.5186e-04
Loss = 8.8283e-01, PNorm = 43.5356, GNorm = 1.8893, lr_0 = 9.1351e-04
Validation rmse = 0.931413
Epoch 3
Loss = 7.4133e-01, PNorm = 43.5944, GNorm = 5.6647, lr_0 = 8.7671e-04
Loss = 7.3050e-01, PNorm = 43.6442, GNorm = 2.0561, lr_0 = 8.4140e-04
Validation rmse = 0.946609
Epoch 4
Loss = 7.1131e-01, PNorm = 43.6907, GNorm = 7.5220, lr_0 = 8.0750e-04
Loss = 7.6239e-01, PNorm = 43.7348, GNorm = 4.2186, lr_0 = 7.7497e-04
Validation rmse = 0.839728
Epoch 5
Loss = 6.1141e-01, PNorm = 43.7760, GNorm = 1.8996, lr_0 = 7.4375e-04
Loss = 5.1214e-01, PNorm = 43.8236, GNorm = 3.6468, lr_0 = 7.1379e-04
Validation rmse = 0.803801
Epoch 6
Loss = 5.4273e-01, PNorm = 43.8587, GNorm = 4.0548, lr_0 = 6.8223e-04
Loss = 5.3758e-01, PNorm = 43.8918, GNorm = 12.8005, lr_0 = 6.5474e-04
Validation rmse = 0.723419
Epoch 7
Loss = 6.0134e-01, PNorm = 43.9153, GNorm = 2.6553, lr_0 = 6.2837e-04
Loss = 4.6766e-01, PNorm = 43.9484, GNorm = 5.2903, lr_0 = 6.0306e-04
Validation rmse = 0.713876
Epoch 8
Loss = 3.2700e-01, PNorm = 43.9746, GNorm = 2.7590, lr_0 = 5.7876e-04
Loss = 4.2395e-01, PNorm = 43.9971, GNorm = 6.6927, lr_0 = 5.5545e-04
Validation rmse = 0.765858
Epoch 9
Loss = 4.6917e-01, PNorm = 44.0193, GNorm = 4.1609, lr_0 = 5.3307e-04
Loss = 3.7742e-01, PNorm = 44.0478, GNorm = 4.5822, lr_0 = 5.1160e-04
Validation rmse = 0.721086
Epoch 10
Loss = 4.0404e-01, PNorm = 44.0653, GNorm = 9.5464, lr_0 = 4.9099e-04
Loss = 3.5718e-01, PNorm = 44.0898, GNorm = 7.5924, lr_0 = 4.7121e-04
Validation rmse = 0.705937
Epoch 11
Loss = 1.8215e-01, PNorm = 44.1080, GNorm = 3.3321, lr_0 = 4.5037e-04
Loss = 3.0104e-01, PNorm = 44.1263, GNorm = 4.5629, lr_0 = 4.3223e-04
Validation rmse = 0.661091
Epoch 12
Loss = 4.1361e-01, PNorm = 44.1399, GNorm = 4.1109, lr_0 = 4.1482e-04
Loss = 2.5075e-01, PNorm = 44.1587, GNorm = 6.3826, lr_0 = 3.9811e-04
Loss = 3.0448e-01, PNorm = 44.1729, GNorm = 2.8342, lr_0 = 3.8207e-04
Validation rmse = 0.660810
Epoch 13
Loss = 2.4612e-01, PNorm = 44.1887, GNorm = 5.1516, lr_0 = 3.6668e-04
Loss = 4.1812e-01, PNorm = 44.1996, GNorm = 1.9510, lr_0 = 3.5191e-04
Validation rmse = 0.700069
Epoch 14
Loss = 3.3366e-01, PNorm = 44.2144, GNorm = 3.8920, lr_0 = 3.3773e-04
Loss = 2.1949e-01, PNorm = 44.2329, GNorm = 2.6236, lr_0 = 3.2413e-04
Validation rmse = 0.666224
Epoch 15
Loss = 2.3061e-01, PNorm = 44.2462, GNorm = 3.6110, lr_0 = 3.1107e-04
Loss = 2.3554e-01, PNorm = 44.2550, GNorm = 3.3965, lr_0 = 2.9854e-04
Validation rmse = 0.652467
Epoch 16
Loss = 1.9358e-01, PNorm = 44.2691, GNorm = 6.0694, lr_0 = 2.8534e-04
Loss = 2.4027e-01, PNorm = 44.2823, GNorm = 9.9931, lr_0 = 2.7384e-04
Validation rmse = 0.669114
Epoch 17
Loss = 2.7521e-01, PNorm = 44.2924, GNorm = 3.4565, lr_0 = 2.6281e-04
Loss = 1.9249e-01, PNorm = 44.3052, GNorm = 2.7067, lr_0 = 2.5222e-04
Validation rmse = 0.650443
Epoch 18
Loss = 1.8301e-01, PNorm = 44.3161, GNorm = 3.9425, lr_0 = 2.4206e-04
Loss = 2.2948e-01, PNorm = 44.3259, GNorm = 3.0207, lr_0 = 2.3231e-04
Validation rmse = 0.652883
Epoch 19
Loss = 2.3326e-01, PNorm = 44.3345, GNorm = 5.8693, lr_0 = 2.2295e-04
Loss = 1.8802e-01, PNorm = 44.3445, GNorm = 7.2064, lr_0 = 2.1397e-04
Validation rmse = 0.645059
Epoch 20
Loss = 1.0762e-01, PNorm = 44.3550, GNorm = 9.4969, lr_0 = 2.0535e-04
Loss = 1.5774e-01, PNorm = 44.3615, GNorm = 6.3345, lr_0 = 1.9708e-04
Validation rmse = 0.663085
Epoch 21
Loss = 1.7872e-01, PNorm = 44.3696, GNorm = 3.9081, lr_0 = 1.8836e-04
Loss = 1.6272e-01, PNorm = 44.3795, GNorm = 4.2597, lr_0 = 1.8078e-04
Validation rmse = 0.651211
Epoch 22
Loss = 2.0085e-01, PNorm = 44.3846, GNorm = 21.5176, lr_0 = 1.7349e-04
Loss = 1.8317e-01, PNorm = 44.3926, GNorm = 2.6137, lr_0 = 1.6651e-04
Validation rmse = 0.644332
Epoch 23
Loss = 2.1634e-02, PNorm = 44.3996, GNorm = 2.7500, lr_0 = 1.5980e-04
Loss = 1.3042e-01, PNorm = 44.4076, GNorm = 4.2065, lr_0 = 1.5336e-04
Validation rmse = 0.651157
Epoch 24
Loss = 3.4064e-01, PNorm = 44.4121, GNorm = 10.8441, lr_0 = 1.4718e-04
Loss = 1.4954e-01, PNorm = 44.4171, GNorm = 3.3244, lr_0 = 1.4125e-04
Loss = 1.3161e-01, PNorm = 44.4234, GNorm = 4.6457, lr_0 = 1.3556e-04
Validation rmse = 0.646477
Epoch 25
Loss = 1.1248e-01, PNorm = 44.4302, GNorm = 5.8105, lr_0 = 1.3010e-04
Loss = 1.9286e-01, PNorm = 44.4340, GNorm = 12.5615, lr_0 = 1.2486e-04
Loss = 1.6644e-01, PNorm = 44.4345, GNorm = 9.1991, lr_0 = 1.2435e-04
Validation rmse = 0.664942
Epoch 26
Loss = 1.3487e-01, PNorm = 44.4396, GNorm = 7.8501, lr_0 = 1.1934e-04
Loss = 1.8158e-01, PNorm = 44.4445, GNorm = 7.6384, lr_0 = 1.1453e-04
Validation rmse = 0.651021
Epoch 27
Loss = 1.4465e-01, PNorm = 44.4495, GNorm = 7.0116, lr_0 = 1.0992e-04
Loss = 1.5270e-01, PNorm = 44.4538, GNorm = 11.2436, lr_0 = 1.0549e-04
Validation rmse = 0.642828
Epoch 28
Loss = 6.0925e-02, PNorm = 44.4587, GNorm = 6.4302, lr_0 = 1.0124e-04
Loss = 1.7875e-01, PNorm = 44.4625, GNorm = 11.2753, lr_0 = 1.0000e-04
Validation rmse = 0.647304
Epoch 29
Loss = 1.6187e-01, PNorm = 44.4648, GNorm = 6.9390, lr_0 = 1.0000e-04
Loss = 9.6658e-02, PNorm = 44.4693, GNorm = 6.4000, lr_0 = 1.0000e-04
Validation rmse = 0.642181
Model 0 best validation rmse = 0.642181 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.656410
Ensemble test rmse = 0.656410
1-fold cross validation
	Seed 0 ==> test rmse = 0.656410
Overall test rmse = 0.656410 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8338e+00, PNorm = 43.3142, GNorm = 2.4054, lr_0 = 3.3571e-04
Loss = 1.4413e+00, PNorm = 43.3223, GNorm = 0.9965, lr_0 = 5.5000e-04
Validation rmse = 1.619080
Epoch 1
Loss = 1.2942e+00, PNorm = 43.3472, GNorm = 0.8649, lr_0 = 7.8571e-04
Loss = 1.1837e+00, PNorm = 43.3936, GNorm = 3.1419, lr_0 = 1.0000e-03
Validation rmse = 1.326648
Epoch 2
Loss = 1.0127e+00, PNorm = 43.4550, GNorm = 1.9303, lr_0 = 9.6160e-04
Loss = 9.4557e-01, PNorm = 43.5136, GNorm = 3.6604, lr_0 = 9.2467e-04
Validation rmse = 0.926650
Epoch 3
Loss = 8.2366e-01, PNorm = 43.5900, GNorm = 2.4940, lr_0 = 8.8568e-04
Loss = 7.1803e-01, PNorm = 43.6473, GNorm = 5.3351, lr_0 = 8.5167e-04
Validation rmse = 0.822536
Epoch 4
Loss = 6.1001e-01, PNorm = 43.6926, GNorm = 5.1687, lr_0 = 8.1896e-04
Loss = 6.3870e-01, PNorm = 43.7397, GNorm = 2.6233, lr_0 = 7.8751e-04
Validation rmse = 0.729405
Epoch 5
Loss = 6.1774e-01, PNorm = 43.7820, GNorm = 5.0574, lr_0 = 7.5727e-04
Loss = 5.5942e-01, PNorm = 43.8201, GNorm = 7.6505, lr_0 = 7.2819e-04
Validation rmse = 0.708291
Epoch 6
Loss = 7.0947e-01, PNorm = 43.8538, GNorm = 3.9620, lr_0 = 6.9749e-04
Loss = 4.7031e-01, PNorm = 43.8876, GNorm = 5.3631, lr_0 = 6.7070e-04
Loss = 3.7524e-01, PNorm = 43.9164, GNorm = 9.2030, lr_0 = 6.4495e-04
Validation rmse = 0.725802
Epoch 7
Loss = 4.0802e-01, PNorm = 43.9379, GNorm = 9.5270, lr_0 = 6.2018e-04
Loss = 4.3692e-01, PNorm = 43.9738, GNorm = 4.5182, lr_0 = 5.9636e-04
Validation rmse = 0.683117
Epoch 8
Loss = 3.6848e-01, PNorm = 43.9985, GNorm = 9.7643, lr_0 = 5.7122e-04
Loss = 4.0932e-01, PNorm = 44.0249, GNorm = 5.1230, lr_0 = 5.4928e-04
Validation rmse = 0.668751
Epoch 9
Loss = 3.3808e-01, PNorm = 44.0509, GNorm = 4.6758, lr_0 = 5.2819e-04
Loss = 3.5423e-01, PNorm = 44.0722, GNorm = 6.0388, lr_0 = 5.0790e-04
Validation rmse = 0.742220
Epoch 10
Loss = 3.6510e-01, PNorm = 44.0898, GNorm = 8.7719, lr_0 = 4.8840e-04
Loss = 3.0217e-01, PNorm = 44.1110, GNorm = 3.0826, lr_0 = 4.6964e-04
Validation rmse = 0.653193
Epoch 11
Loss = 2.1277e-01, PNorm = 44.1327, GNorm = 6.6569, lr_0 = 4.4984e-04
Loss = 2.7304e-01, PNorm = 44.1541, GNorm = 4.9233, lr_0 = 4.3257e-04
Validation rmse = 0.641879
Epoch 12
Loss = 3.2015e-01, PNorm = 44.1651, GNorm = 2.4506, lr_0 = 4.1596e-04
Loss = 2.6049e-01, PNorm = 44.1834, GNorm = 9.9583, lr_0 = 3.9998e-04
Loss = 2.8564e-01, PNorm = 44.1981, GNorm = 3.7670, lr_0 = 3.8462e-04
Loss = 3.5089e-01, PNorm = 44.1998, GNorm = 3.9662, lr_0 = 3.8312e-04
Validation rmse = 0.633711
Epoch 13
Loss = 2.9806e-01, PNorm = 44.2171, GNorm = 17.3106, lr_0 = 3.6841e-04
Loss = 2.4922e-01, PNorm = 44.2302, GNorm = 4.9980, lr_0 = 3.5426e-04
Validation rmse = 0.646333
Epoch 14
Loss = 2.5385e-01, PNorm = 44.2421, GNorm = 5.9752, lr_0 = 3.4065e-04
Loss = 2.6439e-01, PNorm = 44.2559, GNorm = 4.9377, lr_0 = 3.2757e-04
Validation rmse = 0.639889
Epoch 15
Loss = 2.2521e-01, PNorm = 44.2677, GNorm = 6.7500, lr_0 = 3.1499e-04
Loss = 2.3754e-01, PNorm = 44.2793, GNorm = 4.0181, lr_0 = 3.0290e-04
Validation rmse = 0.641133
Epoch 16
Loss = 2.3389e-01, PNorm = 44.2914, GNorm = 4.2634, lr_0 = 2.9012e-04
Loss = 1.9855e-01, PNorm = 44.3043, GNorm = 5.9246, lr_0 = 2.7898e-04
Validation rmse = 0.638683
Epoch 17
Loss = 2.2747e-01, PNorm = 44.3107, GNorm = 14.9812, lr_0 = 2.6827e-04
Loss = 2.5993e-01, PNorm = 44.3216, GNorm = 3.2162, lr_0 = 2.5797e-04
Validation rmse = 0.637781
Epoch 18
Loss = 1.9821e-01, PNorm = 44.3336, GNorm = 4.6616, lr_0 = 2.4709e-04
Loss = 9.6724e-02, PNorm = 44.3459, GNorm = 8.0355, lr_0 = 2.3760e-04
Loss = 3.0950e-01, PNorm = 44.3493, GNorm = 7.8803, lr_0 = 2.2848e-04
Validation rmse = 0.670774
Epoch 19
Loss = 2.4127e-01, PNorm = 44.3572, GNorm = 4.3564, lr_0 = 2.1970e-04
Loss = 1.6599e-01, PNorm = 44.3677, GNorm = 8.7855, lr_0 = 2.1127e-04
Validation rmse = 0.637715
Epoch 20
Loss = 1.3143e-01, PNorm = 44.3781, GNorm = 11.0095, lr_0 = 2.0315e-04
Loss = 2.1169e-01, PNorm = 44.3857, GNorm = 17.0197, lr_0 = 1.9535e-04
Validation rmse = 0.636142
Epoch 21
Loss = 1.3135e-01, PNorm = 44.3883, GNorm = 8.3725, lr_0 = 1.8712e-04
Loss = 1.7748e-01, PNorm = 44.3976, GNorm = 3.0181, lr_0 = 1.7993e-04
Validation rmse = 0.624880
Epoch 22
Loss = 1.5786e-01, PNorm = 44.4037, GNorm = 4.6252, lr_0 = 1.7302e-04
Loss = 1.5956e-01, PNorm = 44.4120, GNorm = 5.9801, lr_0 = 1.6638e-04
Validation rmse = 0.624844
Epoch 23
Loss = 1.6622e-01, PNorm = 44.4165, GNorm = 15.2405, lr_0 = 1.5936e-04
Loss = 1.1494e-01, PNorm = 44.4242, GNorm = 5.9999, lr_0 = 1.5324e-04
Validation rmse = 0.635010
Epoch 24
Loss = 1.1760e-01, PNorm = 44.4286, GNorm = 2.9023, lr_0 = 1.4736e-04
Loss = 1.3311e-01, PNorm = 44.4333, GNorm = 3.4622, lr_0 = 1.4170e-04
Loss = 1.3513e-01, PNorm = 44.4389, GNorm = 13.3742, lr_0 = 1.3626e-04
Validation rmse = 0.629549
Epoch 25
Loss = 9.5450e-02, PNorm = 44.4441, GNorm = 14.3630, lr_0 = 1.3102e-04
Loss = 1.3773e-01, PNorm = 44.4483, GNorm = 4.5277, lr_0 = 1.2599e-04
Validation rmse = 0.637061
Epoch 26
Loss = 1.5182e-01, PNorm = 44.4543, GNorm = 6.6912, lr_0 = 1.2068e-04
Loss = 9.6057e-02, PNorm = 44.4590, GNorm = 12.1075, lr_0 = 1.1604e-04
Validation rmse = 0.641861
Epoch 27
Loss = 4.0808e-02, PNorm = 44.4637, GNorm = 5.6365, lr_0 = 1.1159e-04
Loss = 1.4903e-01, PNorm = 44.4669, GNorm = 3.3587, lr_0 = 1.0730e-04
Validation rmse = 0.631400
Epoch 28
Loss = 1.4694e-01, PNorm = 44.4710, GNorm = 6.4551, lr_0 = 1.0278e-04
Loss = 8.2356e-02, PNorm = 44.4746, GNorm = 4.9589, lr_0 = 1.0000e-04
Validation rmse = 0.630547
Epoch 29
Loss = 1.5669e-01, PNorm = 44.4787, GNorm = 4.5128, lr_0 = 1.0000e-04
Loss = 1.0909e-01, PNorm = 44.4827, GNorm = 2.8506, lr_0 = 1.0000e-04
Validation rmse = 0.630971
Model 0 best validation rmse = 0.624844 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.637620
Ensemble test rmse = 0.637620
1-fold cross validation
	Seed 0 ==> test rmse = 0.637620
Overall test rmse = 0.637620 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7945e+00, PNorm = 43.3145, GNorm = 1.6813, lr_0 = 3.2500e-04
Loss = 1.4459e+00, PNorm = 43.3223, GNorm = 1.5594, lr_0 = 5.2955e-04
Validation rmse = 1.665429
Epoch 1
Loss = 1.2600e+00, PNorm = 43.3472, GNorm = 1.5636, lr_0 = 7.5455e-04
Loss = 1.1812e+00, PNorm = 43.3872, GNorm = 0.8744, lr_0 = 9.5909e-04
Validation rmse = 1.291112
Epoch 2
Loss = 1.0381e+00, PNorm = 43.4573, GNorm = 2.4893, lr_0 = 9.6692e-04
Loss = 9.0484e-01, PNorm = 43.5241, GNorm = 8.1728, lr_0 = 9.3144e-04
Validation rmse = 1.035853
Epoch 3
Loss = 7.3212e-01, PNorm = 43.5865, GNorm = 1.7428, lr_0 = 8.9727e-04
Loss = 6.9523e-01, PNorm = 43.6441, GNorm = 2.9155, lr_0 = 8.6435e-04
Validation rmse = 0.884013
Epoch 4
Loss = 7.7591e-01, PNorm = 43.6926, GNorm = 6.2765, lr_0 = 8.2953e-04
Loss = 5.7597e-01, PNorm = 43.7412, GNorm = 4.1886, lr_0 = 7.9909e-04
Loss = 5.6658e-01, PNorm = 43.7850, GNorm = 3.1677, lr_0 = 7.6977e-04
Validation rmse = 0.736722
Epoch 5
Loss = 5.0004e-01, PNorm = 43.8249, GNorm = 9.1355, lr_0 = 7.4153e-04
Loss = 5.4267e-01, PNorm = 43.8588, GNorm = 8.4609, lr_0 = 7.1433e-04
Validation rmse = 0.758739
Epoch 6
Loss = 5.6946e-01, PNorm = 43.8880, GNorm = 1.9314, lr_0 = 6.8555e-04
Loss = 4.5033e-01, PNorm = 43.9239, GNorm = 6.9558, lr_0 = 6.6040e-04
Validation rmse = 0.720304
Epoch 7
Loss = 3.7795e-01, PNorm = 43.9568, GNorm = 10.0854, lr_0 = 6.3379e-04
Loss = 5.3011e-01, PNorm = 43.9819, GNorm = 5.5226, lr_0 = 6.1054e-04
Validation rmse = 0.726687
Epoch 8
Loss = 4.5954e-01, PNorm = 44.0136, GNorm = 2.0473, lr_0 = 5.8814e-04
Loss = 4.4967e-01, PNorm = 44.0434, GNorm = 9.4127, lr_0 = 5.6656e-04
Loss = 4.7222e-01, PNorm = 44.0674, GNorm = 10.3677, lr_0 = 5.4577e-04
Validation rmse = 0.689468
Epoch 9
Loss = 3.2491e-01, PNorm = 44.0949, GNorm = 5.9963, lr_0 = 5.2379e-04
Loss = 4.0800e-01, PNorm = 44.1114, GNorm = 7.3421, lr_0 = 5.0457e-04
Validation rmse = 0.687037
Epoch 10
Loss = 4.2048e-01, PNorm = 44.1252, GNorm = 1.7944, lr_0 = 4.8606e-04
Loss = 3.5027e-01, PNorm = 44.1439, GNorm = 7.1473, lr_0 = 4.6822e-04
Validation rmse = 0.665004
Epoch 11
Loss = 2.9910e-01, PNorm = 44.1626, GNorm = 3.2839, lr_0 = 4.4936e-04
Loss = 3.3116e-01, PNorm = 44.1837, GNorm = 10.4045, lr_0 = 4.3288e-04
Validation rmse = 0.649647
Epoch 12
Loss = 2.8884e-01, PNorm = 44.1993, GNorm = 11.6283, lr_0 = 4.1544e-04
Loss = 3.2893e-01, PNorm = 44.2106, GNorm = 2.9053, lr_0 = 4.0020e-04
Loss = 2.8257e-01, PNorm = 44.2290, GNorm = 6.9128, lr_0 = 3.8551e-04
Validation rmse = 0.663624
Epoch 13
Loss = 2.7407e-01, PNorm = 44.2442, GNorm = 3.7083, lr_0 = 3.7137e-04
Loss = 3.0788e-01, PNorm = 44.2599, GNorm = 3.3902, lr_0 = 3.5774e-04
Validation rmse = 0.659985
Epoch 14
Loss = 2.6770e-01, PNorm = 44.2738, GNorm = 4.9371, lr_0 = 3.4333e-04
Loss = 2.5849e-01, PNorm = 44.2871, GNorm = 4.2338, lr_0 = 3.3074e-04
Validation rmse = 0.651141
Epoch 15
Loss = 2.9301e-01, PNorm = 44.2975, GNorm = 5.1911, lr_0 = 3.1860e-04
Loss = 2.5167e-01, PNorm = 44.3108, GNorm = 2.5793, lr_0 = 3.0691e-04
Validation rmse = 0.653623
Epoch 16
Loss = 2.0549e-01, PNorm = 44.3214, GNorm = 6.9918, lr_0 = 2.9455e-04
Loss = 2.7975e-01, PNorm = 44.3347, GNorm = 1.8803, lr_0 = 2.8374e-04
Loss = 2.3861e-01, PNorm = 44.3459, GNorm = 6.2427, lr_0 = 2.7333e-04
Loss = 7.2389e-01, PNorm = 44.3462, GNorm = 7.8054, lr_0 = 2.7231e-04
Validation rmse = 0.650249
Epoch 17
Loss = 1.9801e-01, PNorm = 44.3550, GNorm = 11.8334, lr_0 = 2.6232e-04
Loss = 2.2835e-01, PNorm = 44.3662, GNorm = 7.2471, lr_0 = 2.5270e-04
Validation rmse = 0.631842
Epoch 18
Loss = 1.9192e-01, PNorm = 44.3733, GNorm = 3.7928, lr_0 = 2.4342e-04
Loss = 1.6525e-01, PNorm = 44.3845, GNorm = 2.5140, lr_0 = 2.3449e-04
Validation rmse = 0.665723
Epoch 19
Loss = 2.2418e-01, PNorm = 44.3939, GNorm = 11.4041, lr_0 = 2.2505e-04
Loss = 2.4101e-01, PNorm = 44.4018, GNorm = 2.7937, lr_0 = 2.1679e-04
Validation rmse = 0.643962
Epoch 20
Loss = 2.4161e-01, PNorm = 44.4110, GNorm = 4.9024, lr_0 = 2.0884e-04
Loss = 1.9725e-01, PNorm = 44.4177, GNorm = 6.8912, lr_0 = 2.0117e-04
Loss = 1.6694e-01, PNorm = 44.4262, GNorm = 7.9446, lr_0 = 1.9379e-04
Loss = 3.3505e-01, PNorm = 44.4272, GNorm = 5.5137, lr_0 = 1.9307e-04
Validation rmse = 0.639340
Epoch 21
Loss = 1.6199e-01, PNorm = 44.4347, GNorm = 3.4438, lr_0 = 1.8599e-04
Loss = 1.9405e-01, PNorm = 44.4415, GNorm = 2.6316, lr_0 = 1.7916e-04
Validation rmse = 0.638914
Epoch 22
Loss = 1.4378e-01, PNorm = 44.4445, GNorm = 7.0951, lr_0 = 1.7195e-04
Loss = 1.4799e-01, PNorm = 44.4519, GNorm = 10.2392, lr_0 = 1.6564e-04
Validation rmse = 0.625986
Epoch 23
Loss = 6.8633e-02, PNorm = 44.4604, GNorm = 4.3506, lr_0 = 1.5956e-04
Loss = 1.6734e-01, PNorm = 44.4665, GNorm = 4.8860, lr_0 = 1.5371e-04
Validation rmse = 0.621284
Epoch 24
Loss = 2.3217e-02, PNorm = 44.4721, GNorm = 6.4019, lr_0 = 1.4751e-04
Loss = 2.0151e-01, PNorm = 44.4773, GNorm = 9.7530, lr_0 = 1.4210e-04
Loss = 1.1516e-01, PNorm = 44.4831, GNorm = 6.9998, lr_0 = 1.3689e-04
Validation rmse = 0.628754
Epoch 25
Loss = 1.2042e-01, PNorm = 44.4882, GNorm = 5.1948, lr_0 = 1.3187e-04
Loss = 1.6087e-01, PNorm = 44.4917, GNorm = 5.1229, lr_0 = 1.2703e-04
Validation rmse = 0.637179
Epoch 26
Loss = 1.3005e-01, PNorm = 44.4976, GNorm = 4.1055, lr_0 = 1.2191e-04
Loss = 1.1104e-01, PNorm = 44.5036, GNorm = 7.5354, lr_0 = 1.1744e-04
Validation rmse = 0.634995
Epoch 27
Loss = 1.3224e-01, PNorm = 44.5059, GNorm = 3.0878, lr_0 = 1.1271e-04
Loss = 9.8939e-02, PNorm = 44.5101, GNorm = 7.0030, lr_0 = 1.0857e-04
Validation rmse = 0.633910
Epoch 28
Loss = 1.3084e-01, PNorm = 44.5134, GNorm = 6.4259, lr_0 = 1.0459e-04
Loss = 7.4070e-02, PNorm = 44.5178, GNorm = 5.7733, lr_0 = 1.0075e-04
Validation rmse = 0.620909
Epoch 29
Loss = -4.1804e-02, PNorm = 44.5219, GNorm = 3.5469, lr_0 = 1.0000e-04
Loss = 1.1067e-01, PNorm = 44.5256, GNorm = 5.2216, lr_0 = 1.0000e-04
Loss = 1.3490e-01, PNorm = 44.5295, GNorm = 7.6681, lr_0 = 1.0000e-04
Validation rmse = 0.628225
Model 0 best validation rmse = 0.620909 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.632510
Ensemble test rmse = 0.632510
1-fold cross validation
	Seed 0 ==> test rmse = 0.632510
Overall test rmse = 0.632510 +/- 0.000000
Elapsed time = 0:01:56
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9093e+00, PNorm = 43.3129, GNorm = 1.1534, lr_0 = 3.1522e-04
Loss = 1.4711e+00, PNorm = 43.3187, GNorm = 1.0650, lr_0 = 5.1087e-04
Validation rmse = 1.569264
Epoch 1
Loss = 1.3120e+00, PNorm = 43.3399, GNorm = 0.9515, lr_0 = 7.2609e-04
Loss = 1.1536e+00, PNorm = 43.3820, GNorm = 1.8426, lr_0 = 9.2174e-04
Validation rmse = 1.228844
Epoch 2
Loss = 1.0632e+00, PNorm = 43.4378, GNorm = 1.7807, lr_0 = 9.7528e-04
Loss = 9.0295e-01, PNorm = 43.5052, GNorm = 2.9188, lr_0 = 9.4103e-04
Validation rmse = 0.995630
Epoch 3
Loss = 8.9914e-01, PNorm = 43.5717, GNorm = 5.0448, lr_0 = 9.0474e-04
Loss = 7.8621e-01, PNorm = 43.6259, GNorm = 5.2879, lr_0 = 8.7296e-04
Loss = 6.8971e-01, PNorm = 43.6824, GNorm = 5.5113, lr_0 = 8.4230e-04
Validation rmse = 0.836904
Epoch 4
Loss = 6.5536e-01, PNorm = 43.7320, GNorm = 1.9887, lr_0 = 8.0981e-04
Loss = 6.2138e-01, PNorm = 43.7747, GNorm = 2.6680, lr_0 = 7.8137e-04
Validation rmse = 0.787355
Epoch 5
Loss = 6.3630e-01, PNorm = 43.8102, GNorm = 4.1620, lr_0 = 7.5393e-04
Loss = 5.0907e-01, PNorm = 43.8503, GNorm = 4.0912, lr_0 = 7.2745e-04
Validation rmse = 0.798441
Epoch 6
Loss = 4.3357e-01, PNorm = 43.8775, GNorm = 9.3132, lr_0 = 6.9939e-04
Loss = 4.2455e-01, PNorm = 43.9082, GNorm = 5.9607, lr_0 = 6.7483e-04
Loss = 4.8607e-01, PNorm = 43.9346, GNorm = 3.2459, lr_0 = 6.5113e-04
Validation rmse = 0.725767
Epoch 7
Loss = 4.2031e-01, PNorm = 43.9662, GNorm = 2.9952, lr_0 = 6.2601e-04
Loss = 4.2522e-01, PNorm = 43.9913, GNorm = 3.5619, lr_0 = 6.0403e-04
Validation rmse = 0.712567
Epoch 8
Loss = 3.1786e-01, PNorm = 44.0155, GNorm = 4.0348, lr_0 = 5.8073e-04
Loss = 3.3364e-01, PNorm = 44.0416, GNorm = 3.6315, lr_0 = 5.6033e-04
Validation rmse = 0.694318
Epoch 9
Loss = 2.2879e-01, PNorm = 44.0607, GNorm = 4.7470, lr_0 = 5.3872e-04
Loss = 3.6239e-01, PNorm = 44.0813, GNorm = 7.1610, lr_0 = 5.1980e-04
Loss = 3.5606e-01, PNorm = 44.0941, GNorm = 3.6800, lr_0 = 5.0155e-04
Validation rmse = 0.701148
Epoch 10
Loss = 3.0863e-01, PNorm = 44.1145, GNorm = 5.6232, lr_0 = 4.8393e-04
Loss = 3.4934e-01, PNorm = 44.1346, GNorm = 6.6568, lr_0 = 4.6693e-04
Validation rmse = 0.700297
Epoch 11
Loss = 4.0759e-01, PNorm = 44.1447, GNorm = 6.2074, lr_0 = 4.4893e-04
Loss = 3.9417e-01, PNorm = 44.1628, GNorm = 2.6219, lr_0 = 4.3316e-04
Validation rmse = 0.704977
Epoch 12
Loss = 2.5075e-01, PNorm = 44.1801, GNorm = 4.2110, lr_0 = 4.1645e-04
Loss = 2.4776e-01, PNorm = 44.2026, GNorm = 3.2266, lr_0 = 4.0183e-04
Loss = 3.4671e-01, PNorm = 44.2111, GNorm = 5.3803, lr_0 = 3.8771e-04
Validation rmse = 0.670787
Epoch 13
Loss = 2.2612e-01, PNorm = 44.2258, GNorm = 7.5650, lr_0 = 3.7276e-04
Loss = 3.4731e-01, PNorm = 44.2383, GNorm = 5.1691, lr_0 = 3.5967e-04
Validation rmse = 0.689974
Epoch 14
Loss = 1.5996e-01, PNorm = 44.2522, GNorm = 6.4587, lr_0 = 3.4580e-04
Loss = 2.6767e-01, PNorm = 44.2650, GNorm = 2.3577, lr_0 = 3.3365e-04
Validation rmse = 0.666300
Epoch 15
Loss = 3.5708e-01, PNorm = 44.2747, GNorm = 3.0154, lr_0 = 3.2193e-04
Loss = 2.6191e-01, PNorm = 44.2855, GNorm = 9.2822, lr_0 = 3.1062e-04
Loss = 1.9406e-01, PNorm = 44.2992, GNorm = 3.1009, lr_0 = 2.9971e-04
Validation rmse = 0.654674
Epoch 16
Loss = 2.9664e-01, PNorm = 44.3108, GNorm = 3.7732, lr_0 = 2.8816e-04
Loss = 2.1614e-01, PNorm = 44.3205, GNorm = 4.0615, lr_0 = 2.7803e-04
Validation rmse = 0.657136
Epoch 17
Loss = 1.5954e-01, PNorm = 44.3300, GNorm = 4.7969, lr_0 = 2.6731e-04
Loss = 2.4246e-01, PNorm = 44.3394, GNorm = 2.7938, lr_0 = 2.5792e-04
Validation rmse = 0.665457
Epoch 18
Loss = 3.0188e-01, PNorm = 44.3451, GNorm = 10.3069, lr_0 = 2.4798e-04
Loss = 2.6590e-01, PNorm = 44.3533, GNorm = 5.1304, lr_0 = 2.3927e-04
Loss = 2.1698e-01, PNorm = 44.3648, GNorm = 4.9672, lr_0 = 2.3086e-04
Loss = 3.7869e-01, PNorm = 44.3662, GNorm = 6.5899, lr_0 = 2.3004e-04
Validation rmse = 0.655894
Epoch 19
Loss = 1.5209e-01, PNorm = 44.3777, GNorm = 9.1736, lr_0 = 2.2196e-04
Loss = 2.4638e-01, PNorm = 44.3840, GNorm = 3.3897, lr_0 = 2.1416e-04
Validation rmse = 0.658026
Epoch 20
Loss = 1.2605e-01, PNorm = 44.3910, GNorm = 5.2391, lr_0 = 2.0664e-04
Loss = 2.2035e-01, PNorm = 44.3981, GNorm = 7.3440, lr_0 = 1.9938e-04
Validation rmse = 0.648997
Epoch 21
Loss = 8.0656e-02, PNorm = 44.4068, GNorm = 2.9124, lr_0 = 1.9169e-04
Loss = 1.2594e-01, PNorm = 44.4157, GNorm = 6.5871, lr_0 = 1.8496e-04
Loss = 2.5264e-01, PNorm = 44.4222, GNorm = 5.6192, lr_0 = 1.7846e-04
Loss = 2.3036e-01, PNorm = 44.4223, GNorm = 12.1435, lr_0 = 1.7783e-04
Validation rmse = 0.662475
Epoch 22
Loss = 2.0053e-01, PNorm = 44.4277, GNorm = 3.8420, lr_0 = 1.7158e-04
Loss = 1.5127e-01, PNorm = 44.4352, GNorm = 5.0255, lr_0 = 1.6556e-04
Validation rmse = 0.666891
Epoch 23
Loss = 1.7174e-01, PNorm = 44.4409, GNorm = 3.6620, lr_0 = 1.5917e-04
Loss = 1.8115e-01, PNorm = 44.4459, GNorm = 4.0419, lr_0 = 1.5358e-04
Validation rmse = 0.646780
Epoch 24
Loss = 1.1470e-01, PNorm = 44.4521, GNorm = 3.4165, lr_0 = 1.4766e-04
Loss = 1.8725e-01, PNorm = 44.4557, GNorm = 3.3423, lr_0 = 1.4247e-04
Loss = 5.9187e-02, PNorm = 44.4616, GNorm = 6.4267, lr_0 = 1.3747e-04
Validation rmse = 0.648705
Epoch 25
Loss = 1.2585e-01, PNorm = 44.4673, GNorm = 8.7186, lr_0 = 1.3264e-04
Loss = 1.6833e-01, PNorm = 44.4713, GNorm = 3.6412, lr_0 = 1.2798e-04
Validation rmse = 0.643864
Epoch 26
Loss = 1.4039e-01, PNorm = 44.4759, GNorm = 4.9910, lr_0 = 1.2304e-04
Loss = 1.0783e-01, PNorm = 44.4813, GNorm = 4.9931, lr_0 = 1.1872e-04
Validation rmse = 0.656904
Epoch 27
Loss = 1.8926e-01, PNorm = 44.4852, GNorm = 10.7930, lr_0 = 1.1414e-04
Loss = 1.4375e-01, PNorm = 44.4887, GNorm = 9.7480, lr_0 = 1.1014e-04
Validation rmse = 0.640820
Epoch 28
Loss = 7.3712e-02, PNorm = 44.4942, GNorm = 2.7293, lr_0 = 1.0589e-04
Loss = 1.3469e-01, PNorm = 44.4977, GNorm = 4.0319, lr_0 = 1.0217e-04
Loss = 1.2694e-01, PNorm = 44.5018, GNorm = 2.8321, lr_0 = 1.0000e-04
Validation rmse = 0.645279
Epoch 29
Loss = 1.1441e-01, PNorm = 44.5058, GNorm = 3.9017, lr_0 = 1.0000e-04
Loss = 1.5309e-01, PNorm = 44.5078, GNorm = 4.9452, lr_0 = 1.0000e-04
Validation rmse = 0.644810
Model 0 best validation rmse = 0.640820 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.669802
Ensemble test rmse = 0.669802
1-fold cross validation
	Seed 0 ==> test rmse = 0.669802
Overall test rmse = 0.669802 +/- 0.000000
Elapsed time = 0:01:57
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7563e+00, PNorm = 43.3129, GNorm = 1.2349, lr_0 = 3.0625e-04
Loss = 1.4735e+00, PNorm = 43.3188, GNorm = 2.0591, lr_0 = 4.9375e-04
Validation rmse = 1.789542
Epoch 1
Loss = 1.2752e+00, PNorm = 43.3350, GNorm = 1.0394, lr_0 = 6.8125e-04
Loss = 1.2193e+00, PNorm = 43.3683, GNorm = 1.9290, lr_0 = 8.6875e-04
Validation rmse = 1.439115
Epoch 2
Loss = 1.0773e+00, PNorm = 43.4160, GNorm = 0.7279, lr_0 = 9.8977e-04
Loss = 9.1793e-01, PNorm = 43.4888, GNorm = 3.0711, lr_0 = 9.5643e-04
Loss = 8.4018e-01, PNorm = 43.5577, GNorm = 1.6789, lr_0 = 9.2422e-04
Validation rmse = 1.032927
Epoch 3
Loss = 7.7492e-01, PNorm = 43.6224, GNorm = 6.9107, lr_0 = 8.9309e-04
Loss = 6.3064e-01, PNorm = 43.6792, GNorm = 7.2959, lr_0 = 8.6300e-04
Validation rmse = 0.965253
Epoch 4
Loss = 6.4906e-01, PNorm = 43.7258, GNorm = 3.6711, lr_0 = 8.3393e-04
Loss = 6.9363e-01, PNorm = 43.7686, GNorm = 4.5290, lr_0 = 8.0584e-04
Loss = 5.9289e-01, PNorm = 43.8146, GNorm = 6.3299, lr_0 = 7.7870e-04
Validation rmse = 0.765109
Epoch 5
Loss = 5.1067e-01, PNorm = 43.8488, GNorm = 4.1189, lr_0 = 7.5247e-04
Loss = 4.5900e-01, PNorm = 43.8889, GNorm = 3.9042, lr_0 = 7.2712e-04
Validation rmse = 0.728559
Epoch 6
Loss = 4.4604e-01, PNorm = 43.9167, GNorm = 2.2894, lr_0 = 7.0263e-04
Loss = 4.6645e-01, PNorm = 43.9542, GNorm = 2.1710, lr_0 = 6.7896e-04
Validation rmse = 0.678573
Epoch 7
Loss = 4.6813e-01, PNorm = 43.9859, GNorm = 5.3812, lr_0 = 6.5609e-04
Loss = 3.8429e-01, PNorm = 44.0158, GNorm = 4.1522, lr_0 = 6.3399e-04
Loss = 4.2953e-01, PNorm = 44.0453, GNorm = 4.9220, lr_0 = 6.1264e-04
Validation rmse = 0.705345
Epoch 8
Loss = 3.2948e-01, PNorm = 44.0752, GNorm = 5.8036, lr_0 = 5.9200e-04
Loss = 3.7205e-01, PNorm = 44.1013, GNorm = 5.5457, lr_0 = 5.7206e-04
Validation rmse = 0.668665
Epoch 9
Loss = 3.4480e-01, PNorm = 44.1210, GNorm = 4.3196, lr_0 = 5.5279e-04
Loss = 3.5814e-01, PNorm = 44.1507, GNorm = 7.6735, lr_0 = 5.3417e-04
Loss = 5.4814e-01, PNorm = 44.1677, GNorm = 6.6119, lr_0 = 5.1618e-04
Validation rmse = 0.773481
Epoch 10
Loss = 4.3123e-01, PNorm = 44.1969, GNorm = 3.8147, lr_0 = 4.9879e-04
Loss = 3.4708e-01, PNorm = 44.2182, GNorm = 3.8076, lr_0 = 4.8199e-04
Validation rmse = 0.682479
Epoch 11
Loss = 2.8272e-01, PNorm = 44.2360, GNorm = 3.8711, lr_0 = 4.6575e-04
Loss = 3.0700e-01, PNorm = 44.2547, GNorm = 4.2959, lr_0 = 4.5006e-04
Validation rmse = 0.671957
Epoch 12
Loss = 2.8143e-01, PNorm = 44.2674, GNorm = 6.2766, lr_0 = 4.3490e-04
Loss = 3.0076e-01, PNorm = 44.2858, GNorm = 4.3895, lr_0 = 4.2025e-04
Loss = 3.1879e-01, PNorm = 44.3007, GNorm = 2.3683, lr_0 = 4.0610e-04
Validation rmse = 0.649938
Epoch 13
Loss = 2.3387e-01, PNorm = 44.3187, GNorm = 6.6013, lr_0 = 3.9242e-04
Loss = 3.0514e-01, PNorm = 44.3319, GNorm = 6.6978, lr_0 = 3.7920e-04
Validation rmse = 0.718554
Epoch 14
Loss = 3.5753e-01, PNorm = 44.3414, GNorm = 2.5038, lr_0 = 3.6643e-04
Loss = 2.5396e-01, PNorm = 44.3570, GNorm = 7.9632, lr_0 = 3.5408e-04
Loss = 2.8995e-01, PNorm = 44.3649, GNorm = 9.3185, lr_0 = 3.4216e-04
Validation rmse = 0.667950
Epoch 15
Loss = 2.0845e-01, PNorm = 44.3810, GNorm = 7.9253, lr_0 = 3.3063e-04
Loss = 2.6488e-01, PNorm = 44.3890, GNorm = 3.2752, lr_0 = 3.1950e-04
Validation rmse = 0.643298
Epoch 16
Loss = 2.1515e-01, PNorm = 44.4012, GNorm = 2.2211, lr_0 = 3.0873e-04
Loss = 2.4453e-01, PNorm = 44.4130, GNorm = 9.1635, lr_0 = 2.9833e-04
Validation rmse = 0.632435
Epoch 17
Loss = 2.3689e-01, PNorm = 44.4261, GNorm = 4.7760, lr_0 = 2.8828e-04
Loss = 2.0496e-01, PNorm = 44.4355, GNorm = 2.9816, lr_0 = 2.7857e-04
Loss = 1.8532e-01, PNorm = 44.4468, GNorm = 3.3184, lr_0 = 2.6919e-04
Validation rmse = 0.645929
Epoch 18
Loss = 1.1198e-01, PNorm = 44.4581, GNorm = 5.1416, lr_0 = 2.6012e-04
Loss = 2.7848e-01, PNorm = 44.4656, GNorm = 9.7434, lr_0 = 2.5136e-04
Validation rmse = 0.638520
Epoch 19
Loss = 2.5492e-01, PNorm = 44.4743, GNorm = 4.9678, lr_0 = 2.4289e-04
Loss = 2.2307e-01, PNorm = 44.4844, GNorm = 8.9221, lr_0 = 2.3471e-04
Loss = 1.5059e-01, PNorm = 44.4953, GNorm = 3.7676, lr_0 = 2.2681e-04
Validation rmse = 0.645238
Epoch 20
Loss = 1.1676e-01, PNorm = 44.5035, GNorm = 4.1291, lr_0 = 2.1917e-04
Loss = 2.9566e-01, PNorm = 44.5090, GNorm = 3.2925, lr_0 = 2.1178e-04
Validation rmse = 0.640791
Epoch 21
Loss = 1.5972e-01, PNorm = 44.5193, GNorm = 3.2294, lr_0 = 2.0465e-04
Loss = 1.9005e-01, PNorm = 44.5302, GNorm = 2.9424, lr_0 = 1.9776e-04
Validation rmse = 0.639421
Epoch 22
Loss = 2.3670e-01, PNorm = 44.5336, GNorm = 10.7564, lr_0 = 1.9110e-04
Loss = 1.8461e-01, PNorm = 44.5396, GNorm = 2.5648, lr_0 = 1.8466e-04
Loss = 1.1681e-01, PNorm = 44.5485, GNorm = 3.9984, lr_0 = 1.7844e-04
Validation rmse = 0.641412
Epoch 23
Loss = 8.0751e-02, PNorm = 44.5570, GNorm = 5.1522, lr_0 = 1.7243e-04
Loss = 1.7440e-01, PNorm = 44.5608, GNorm = 5.4037, lr_0 = 1.6662e-04
Validation rmse = 0.633317
Epoch 24
Loss = 8.9806e-02, PNorm = 44.5657, GNorm = 2.5133, lr_0 = 1.6101e-04
Loss = 1.6642e-01, PNorm = 44.5732, GNorm = 4.3396, lr_0 = 1.5558e-04
Loss = 1.1432e-01, PNorm = 44.5780, GNorm = 5.2400, lr_0 = 1.5034e-04
Validation rmse = 0.643506
Epoch 25
Loss = 7.8535e-02, PNorm = 44.5847, GNorm = 4.1395, lr_0 = 1.4528e-04
Loss = 1.7674e-01, PNorm = 44.5905, GNorm = 6.1954, lr_0 = 1.4039e-04
Validation rmse = 0.636094
Epoch 26
Loss = 1.0268e-01, PNorm = 44.5959, GNorm = 4.2460, lr_0 = 1.3566e-04
Loss = 1.3768e-01, PNorm = 44.6016, GNorm = 4.5228, lr_0 = 1.3109e-04
Validation rmse = 0.643102
Epoch 27
Loss = 1.0496e-01, PNorm = 44.6061, GNorm = 3.8980, lr_0 = 1.2667e-04
Loss = 9.8378e-02, PNorm = 44.6106, GNorm = 4.2553, lr_0 = 1.2240e-04
Loss = 1.0791e-01, PNorm = 44.6158, GNorm = 3.4687, lr_0 = 1.1828e-04
Validation rmse = 0.630444
Epoch 28
Loss = 1.3415e-01, PNorm = 44.6205, GNorm = 5.5923, lr_0 = 1.1430e-04
Loss = 6.2752e-02, PNorm = 44.6245, GNorm = 3.9255, lr_0 = 1.1045e-04
Validation rmse = 0.632417
Epoch 29
Loss = 1.2186e-01, PNorm = 44.6299, GNorm = 7.9978, lr_0 = 1.0673e-04
Loss = 1.2910e-01, PNorm = 44.6337, GNorm = 3.0299, lr_0 = 1.0313e-04
Loss = 7.2933e-02, PNorm = 44.6384, GNorm = 10.8485, lr_0 = 1.0000e-04
Validation rmse = 0.633925
Model 0 best validation rmse = 0.630444 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.639270
Ensemble test rmse = 0.639270
1-fold cross validation
	Seed 0 ==> test rmse = 0.639270
Overall test rmse = 0.639270 +/- 0.000000
Elapsed time = 0:02:01
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8036e+00, PNorm = 43.3106, GNorm = 1.4244, lr_0 = 4.0937e-04
Validation rmse = 1.210602
Epoch 1
Loss = 1.4985e+00, PNorm = 43.3172, GNorm = 1.2103, lr_0 = 6.9063e-04
Loss = 1.4111e+00, PNorm = 43.3379, GNorm = 1.0616, lr_0 = 9.7187e-04
Validation rmse = 1.109917
Epoch 2
Loss = 1.3521e+00, PNorm = 43.3683, GNorm = 1.2813, lr_0 = 9.5480e-04
Validation rmse = 0.995202
Epoch 3
Loss = 1.1844e+00, PNorm = 43.4048, GNorm = 1.0261, lr_0 = 9.0696e-04
Loss = 1.1969e+00, PNorm = 43.4511, GNorm = 0.8437, lr_0 = 8.6152e-04
Validation rmse = 0.914087
Epoch 4
Loss = 1.1106e+00, PNorm = 43.5132, GNorm = 8.0759, lr_0 = 8.1836e-04
Loss = 1.0778e+00, PNorm = 43.5697, GNorm = 3.9679, lr_0 = 7.7737e-04
Validation rmse = 0.860596
Epoch 5
Loss = 1.0267e+00, PNorm = 43.6307, GNorm = 1.3548, lr_0 = 7.3842e-04
Validation rmse = 0.783993
Epoch 6
Loss = 9.1536e-01, PNorm = 43.6828, GNorm = 8.3663, lr_0 = 7.0143e-04
Loss = 9.9802e-01, PNorm = 43.7143, GNorm = 4.5237, lr_0 = 6.6629e-04
Validation rmse = 0.802475
Epoch 7
Loss = 8.9133e-01, PNorm = 43.7581, GNorm = 9.8680, lr_0 = 6.3291e-04
Validation rmse = 0.739902
Epoch 8
Loss = 7.2655e-01, PNorm = 43.8055, GNorm = 2.7421, lr_0 = 6.0120e-04
Loss = 7.7852e-01, PNorm = 43.8453, GNorm = 2.6593, lr_0 = 5.7108e-04
Validation rmse = 0.727230
Epoch 9
Loss = 6.8313e-01, PNorm = 43.8780, GNorm = 2.2981, lr_0 = 5.4247e-04
Loss = 7.3754e-01, PNorm = 43.9126, GNorm = 8.6863, lr_0 = 5.1529e-04
Validation rmse = 0.689329
Epoch 10
Loss = 5.9598e-01, PNorm = 43.9458, GNorm = 8.3928, lr_0 = 4.8948e-04
Validation rmse = 0.692709
Epoch 11
Loss = 6.9305e-01, PNorm = 43.9708, GNorm = 2.5969, lr_0 = 4.6495e-04
Loss = 6.6405e-01, PNorm = 44.0016, GNorm = 13.6225, lr_0 = 4.4166e-04
Validation rmse = 0.682327
Epoch 12
Loss = 5.7926e-01, PNorm = 44.0318, GNorm = 5.5270, lr_0 = 4.1953e-04
Validation rmse = 0.673265
Epoch 13
Loss = 5.9136e-01, PNorm = 44.0546, GNorm = 7.3530, lr_0 = 3.9852e-04
Loss = 6.2799e-01, PNorm = 44.0769, GNorm = 8.9665, lr_0 = 3.7855e-04
Validation rmse = 0.765706
Epoch 14
Loss = 7.9538e-01, PNorm = 44.0900, GNorm = 11.1055, lr_0 = 3.5959e-04
Loss = 6.5166e-01, PNorm = 44.1074, GNorm = 5.0368, lr_0 = 3.4157e-04
Validation rmse = 0.722418
Epoch 15
Loss = 6.0503e-01, PNorm = 44.1277, GNorm = 10.4328, lr_0 = 3.2446e-04
Validation rmse = 0.691107
Epoch 16
Loss = 5.6162e-01, PNorm = 44.1427, GNorm = 3.6280, lr_0 = 3.0820e-04
Loss = 5.7967e-01, PNorm = 44.1575, GNorm = 15.5405, lr_0 = 2.9276e-04
Validation rmse = 0.677919
Epoch 17
Loss = 5.5223e-01, PNorm = 44.1703, GNorm = 2.9139, lr_0 = 2.7810e-04
Validation rmse = 0.676843
Epoch 18
Loss = 4.7263e-01, PNorm = 44.1828, GNorm = 3.8534, lr_0 = 2.6416e-04
Loss = 5.1312e-01, PNorm = 44.1944, GNorm = 6.1838, lr_0 = 2.5093e-04
Validation rmse = 0.654565
Epoch 19
Loss = 4.6933e-01, PNorm = 44.2059, GNorm = 3.3260, lr_0 = 2.3836e-04
Loss = 4.9950e-01, PNorm = 44.2175, GNorm = 7.7832, lr_0 = 2.2642e-04
Validation rmse = 0.672156
Epoch 20
Loss = 4.5434e-01, PNorm = 44.2291, GNorm = 3.9263, lr_0 = 2.1507e-04
Validation rmse = 0.667197
Epoch 21
Loss = 4.2013e-01, PNorm = 44.2397, GNorm = 2.6192, lr_0 = 2.0430e-04
Loss = 4.7590e-01, PNorm = 44.2493, GNorm = 8.0134, lr_0 = 1.9406e-04
Validation rmse = 0.668592
Epoch 22
Loss = 4.7809e-01, PNorm = 44.2587, GNorm = 16.1708, lr_0 = 1.8434e-04
Validation rmse = 0.653600
Epoch 23
Loss = 4.0622e-01, PNorm = 44.2669, GNorm = 3.5888, lr_0 = 1.7511e-04
Loss = 4.2032e-01, PNorm = 44.2747, GNorm = 5.6513, lr_0 = 1.6633e-04
Validation rmse = 0.651622
Epoch 24
Loss = 4.7976e-01, PNorm = 44.2815, GNorm = 2.7420, lr_0 = 1.5800e-04
Loss = 4.2507e-01, PNorm = 44.2889, GNorm = 5.7784, lr_0 = 1.5009e-04
Validation rmse = 0.659988
Epoch 25
Loss = 3.8866e-01, PNorm = 44.2956, GNorm = 6.3832, lr_0 = 1.4257e-04
Validation rmse = 0.657628
Epoch 26
Loss = 3.8756e-01, PNorm = 44.3015, GNorm = 4.2723, lr_0 = 1.3542e-04
Loss = 4.3935e-01, PNorm = 44.3082, GNorm = 9.7757, lr_0 = 1.2864e-04
Validation rmse = 0.653847
Epoch 27
Loss = 4.2348e-01, PNorm = 44.3137, GNorm = 12.2372, lr_0 = 1.2220e-04
Validation rmse = 0.653730
Epoch 28
Loss = 3.3439e-01, PNorm = 44.3193, GNorm = 3.3397, lr_0 = 1.1607e-04
Loss = 3.8666e-01, PNorm = 44.3244, GNorm = 4.8556, lr_0 = 1.1026e-04
Validation rmse = 0.671921
Epoch 29
Loss = 4.5183e-01, PNorm = 44.3293, GNorm = 7.9476, lr_0 = 1.0473e-04
Loss = 3.9185e-01, PNorm = 44.3338, GNorm = 3.4619, lr_0 = 1.0000e-04
Validation rmse = 0.660226
Model 0 best validation rmse = 0.651622 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.808862
Ensemble test rmse = 0.808862
1-fold cross validation
	Seed 0 ==> test rmse = 0.808862
Overall test rmse = 0.808862 +/- 0.000000
Elapsed time = 0:39:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8608e+00, PNorm = 43.3111, GNorm = 1.6807, lr_0 = 4.0937e-04
Validation rmse = 1.459676
Epoch 1
Loss = 1.4814e+00, PNorm = 43.3212, GNorm = 0.8539, lr_0 = 7.1875e-04
Loss = 1.4013e+00, PNorm = 43.3492, GNorm = 1.9809, lr_0 = 1.0000e-03
Validation rmse = 1.344152
Epoch 2
Loss = 1.2779e+00, PNorm = 43.3905, GNorm = 1.4959, lr_0 = 9.4990e-04
Loss = 1.2184e+00, PNorm = 43.4379, GNorm = 1.4354, lr_0 = 9.0231e-04
Validation rmse = 1.201554
Epoch 3
Loss = 1.1709e+00, PNorm = 43.4918, GNorm = 2.8417, lr_0 = 8.5711e-04
Validation rmse = 1.045028
Epoch 4
Loss = 9.9435e-01, PNorm = 43.5526, GNorm = 1.7897, lr_0 = 8.1417e-04
Loss = 9.3035e-01, PNorm = 43.6158, GNorm = 1.7603, lr_0 = 7.7338e-04
Validation rmse = 0.968833
Epoch 5
Loss = 8.0899e-01, PNorm = 43.6635, GNorm = 3.5364, lr_0 = 7.3463e-04
Loss = 8.4017e-01, PNorm = 43.7128, GNorm = 2.3107, lr_0 = 6.9783e-04
Loss = 8.9459e-01, PNorm = 43.7170, GNorm = 7.3274, lr_0 = 6.9425e-04
Validation rmse = 0.928183
Epoch 6
Loss = 7.9784e-01, PNorm = 43.7628, GNorm = 2.3069, lr_0 = 6.5947e-04
Validation rmse = 0.859402
Epoch 7
Loss = 7.0902e-01, PNorm = 43.8037, GNorm = 8.2201, lr_0 = 6.2643e-04
Loss = 6.9905e-01, PNorm = 43.8434, GNorm = 2.1145, lr_0 = 5.9505e-04
Validation rmse = 0.863414
Epoch 8
Loss = 6.4147e-01, PNorm = 43.8782, GNorm = 5.7339, lr_0 = 5.6524e-04
Loss = 7.5245e-01, PNorm = 43.9030, GNorm = 1.9488, lr_0 = 5.3692e-04
Validation rmse = 0.904193
Epoch 9
Loss = 7.1532e-01, PNorm = 43.9237, GNorm = 2.5870, lr_0 = 5.1002e-04
Validation rmse = 0.775247
Epoch 10
Loss = 6.2170e-01, PNorm = 43.9507, GNorm = 7.9034, lr_0 = 4.8447e-04
Loss = 7.1518e-01, PNorm = 43.9753, GNorm = 5.7366, lr_0 = 4.6020e-04
Validation rmse = 0.792000
Epoch 11
Loss = 4.6694e-01, PNorm = 44.0044, GNorm = 2.0172, lr_0 = 4.3490e-04
Loss = 6.2239e-01, PNorm = 44.0243, GNorm = 6.3742, lr_0 = 4.1312e-04
Validation rmse = 0.735672
Epoch 12
Loss = 5.9734e-01, PNorm = 44.0441, GNorm = 4.3246, lr_0 = 3.9242e-04
Validation rmse = 0.717622
Epoch 13
Loss = 4.8661e-01, PNorm = 44.0627, GNorm = 2.3693, lr_0 = 3.7276e-04
Loss = 4.7024e-01, PNorm = 44.0823, GNorm = 4.3459, lr_0 = 3.5408e-04
Validation rmse = 0.716455
Epoch 14
Loss = 5.0585e-01, PNorm = 44.0954, GNorm = 4.9699, lr_0 = 3.3635e-04
Loss = 4.8604e-01, PNorm = 44.1119, GNorm = 3.4014, lr_0 = 3.1950e-04
Validation rmse = 0.722380
Epoch 15
Loss = 4.4855e-01, PNorm = 44.1256, GNorm = 7.4754, lr_0 = 3.0349e-04
Validation rmse = 0.708197
Epoch 16
Loss = 5.1298e-01, PNorm = 44.1429, GNorm = 6.3690, lr_0 = 2.8681e-04
Loss = 4.7722e-01, PNorm = 44.1548, GNorm = 4.8640, lr_0 = 2.7244e-04
Validation rmse = 0.714316
Epoch 17
Loss = 4.2679e-01, PNorm = 44.1664, GNorm = 14.8723, lr_0 = 2.5879e-04
Loss = 4.3658e-01, PNorm = 44.1796, GNorm = 7.2216, lr_0 = 2.4582e-04
Validation rmse = 0.696494
Epoch 18
Loss = 4.2177e-01, PNorm = 44.1918, GNorm = 2.9228, lr_0 = 2.3351e-04
Validation rmse = 0.715717
Epoch 19
Loss = 5.6173e-01, PNorm = 44.2027, GNorm = 13.0459, lr_0 = 2.2181e-04
Loss = 4.2959e-01, PNorm = 44.2105, GNorm = 3.3922, lr_0 = 2.1070e-04
Validation rmse = 0.718663
Epoch 20
Loss = 3.2912e-01, PNorm = 44.2207, GNorm = 2.5374, lr_0 = 2.0014e-04
Loss = 4.2729e-01, PNorm = 44.2298, GNorm = 5.8817, lr_0 = 1.9012e-04
Validation rmse = 0.729960
Epoch 21
Loss = 3.7413e-01, PNorm = 44.2352, GNorm = 3.5096, lr_0 = 1.7967e-04
Validation rmse = 0.688471
Epoch 22
Loss = 3.3291e-01, PNorm = 44.2433, GNorm = 7.3260, lr_0 = 1.7066e-04
Loss = 3.6887e-01, PNorm = 44.2516, GNorm = 9.7644, lr_0 = 1.6211e-04
Validation rmse = 0.698816
Epoch 23
Loss = 4.9276e-01, PNorm = 44.2568, GNorm = 14.8642, lr_0 = 1.5399e-04
Loss = 3.7875e-01, PNorm = 44.2634, GNorm = 10.6568, lr_0 = 1.4628e-04
Validation rmse = 0.687937
Epoch 24
Loss = 3.4406e-01, PNorm = 44.2687, GNorm = 5.2216, lr_0 = 1.3895e-04
Loss = 3.7396e-01, PNorm = 44.2753, GNorm = 6.0822, lr_0 = 1.3199e-04
Validation rmse = 0.680747
Epoch 25
Loss = 3.1588e-01, PNorm = 44.2810, GNorm = 3.4713, lr_0 = 1.2538e-04
Validation rmse = 0.686930
Epoch 26
Loss = 3.1763e-01, PNorm = 44.2862, GNorm = 9.0316, lr_0 = 1.1848e-04
Loss = 3.5596e-01, PNorm = 44.2917, GNorm = 4.2820, lr_0 = 1.1255e-04
Validation rmse = 0.681958
Epoch 27
Loss = 3.4324e-01, PNorm = 44.2970, GNorm = 7.9767, lr_0 = 1.0691e-04
Loss = 3.1387e-01, PNorm = 44.3014, GNorm = 8.8647, lr_0 = 1.0155e-04
Validation rmse = 0.675356
Epoch 28
Loss = 3.3547e-01, PNorm = 44.3056, GNorm = 5.6091, lr_0 = 1.0000e-04
Validation rmse = 0.678232
Epoch 29
Loss = 2.6717e-01, PNorm = 44.3103, GNorm = 8.6175, lr_0 = 1.0000e-04
Loss = 3.2848e-01, PNorm = 44.3151, GNorm = 8.2381, lr_0 = 1.0000e-04
Validation rmse = 0.672019
Model 0 best validation rmse = 0.672019 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.843942
Ensemble test rmse = 0.843942
1-fold cross validation
	Seed 0 ==> test rmse = 0.843942
Overall test rmse = 0.843942 +/- 0.000000
Elapsed time = 0:01:24
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9247e+00, PNorm = 43.3120, GNorm = 1.1310, lr_0 = 3.9118e-04
Validation rmse = 1.536421
Epoch 1
Loss = 1.5108e+00, PNorm = 43.3233, GNorm = 1.0036, lr_0 = 6.8235e-04
Loss = 1.3445e+00, PNorm = 43.3539, GNorm = 1.0526, lr_0 = 9.4706e-04
Validation rmse = 1.440399
Epoch 2
Loss = 1.2947e+00, PNorm = 43.3962, GNorm = 1.7834, lr_0 = 9.6204e-04
Loss = 1.2150e+00, PNorm = 43.4434, GNorm = 1.6705, lr_0 = 9.1661e-04
Validation rmse = 1.212650
Epoch 3
Loss = 1.0439e+00, PNorm = 43.5085, GNorm = 2.3517, lr_0 = 8.6911e-04
Loss = 1.0426e+00, PNorm = 43.5744, GNorm = 3.1046, lr_0 = 8.2807e-04
Validation rmse = 1.090234
Epoch 4
Loss = 9.1110e-01, PNorm = 43.6401, GNorm = 3.3567, lr_0 = 7.8897e-04
Validation rmse = 0.985404
Epoch 5
Loss = 7.2888e-01, PNorm = 43.6922, GNorm = 2.3729, lr_0 = 7.5171e-04
Loss = 7.9975e-01, PNorm = 43.7451, GNorm = 8.3632, lr_0 = 7.1621e-04
Validation rmse = 0.937302
Epoch 6
Loss = 7.3368e-01, PNorm = 43.7928, GNorm = 5.2877, lr_0 = 6.7910e-04
Loss = 7.4801e-01, PNorm = 43.8388, GNorm = 4.7989, lr_0 = 6.4703e-04
Validation rmse = 0.889357
Epoch 7
Loss = 5.7226e-01, PNorm = 43.8808, GNorm = 4.7068, lr_0 = 6.1648e-04
Loss = 6.9781e-01, PNorm = 43.9149, GNorm = 7.6643, lr_0 = 5.8736e-04
Loss = 7.5563e-01, PNorm = 43.9188, GNorm = 4.7631, lr_0 = 5.8453e-04
Validation rmse = 0.909109
Epoch 8
Loss = 6.2210e-01, PNorm = 43.9594, GNorm = 7.0059, lr_0 = 5.5693e-04
Validation rmse = 1.054485
Epoch 9
Loss = 7.3050e-01, PNorm = 43.9947, GNorm = 12.3787, lr_0 = 5.3063e-04
Loss = 6.9199e-01, PNorm = 44.0215, GNorm = 6.4596, lr_0 = 5.0557e-04
Validation rmse = 1.023587
Epoch 10
Loss = 6.0435e-01, PNorm = 44.0500, GNorm = 4.4079, lr_0 = 4.8170e-04
Loss = 6.0984e-01, PNorm = 44.0755, GNorm = 6.8684, lr_0 = 4.5895e-04
Validation rmse = 0.929166
Epoch 11
Loss = 5.4012e-01, PNorm = 44.1032, GNorm = 2.5171, lr_0 = 4.3517e-04
Loss = 4.8090e-01, PNorm = 44.1243, GNorm = 9.8506, lr_0 = 4.1462e-04
Validation rmse = 0.843390
Epoch 12
Loss = 4.9982e-01, PNorm = 44.1398, GNorm = 4.7554, lr_0 = 3.9504e-04
Validation rmse = 0.845960
Epoch 13
Loss = 4.0298e-01, PNorm = 44.1619, GNorm = 5.1482, lr_0 = 3.7457e-04
Loss = 4.5860e-01, PNorm = 44.1869, GNorm = 4.7212, lr_0 = 3.5688e-04
Validation rmse = 0.844973
Epoch 14
Loss = 5.2771e-01, PNorm = 44.2032, GNorm = 4.2894, lr_0 = 3.4003e-04
Loss = 4.2590e-01, PNorm = 44.2191, GNorm = 3.4178, lr_0 = 3.2397e-04
Validation rmse = 0.809302
Epoch 15
Loss = 3.2172e-01, PNorm = 44.2354, GNorm = 2.5930, lr_0 = 3.0867e-04
Loss = 4.4051e-01, PNorm = 44.2503, GNorm = 2.7739, lr_0 = 2.9409e-04
Validation rmse = 0.815204
Epoch 16
Loss = 4.3263e-01, PNorm = 44.2630, GNorm = 10.1243, lr_0 = 2.7885e-04
Validation rmse = 0.806190
Epoch 17
Loss = 2.4554e-01, PNorm = 44.2780, GNorm = 2.3035, lr_0 = 2.6569e-04
Loss = 3.9388e-01, PNorm = 44.2923, GNorm = 9.9292, lr_0 = 2.5314e-04
Validation rmse = 0.761688
Epoch 18
Loss = 4.3030e-01, PNorm = 44.3022, GNorm = 3.9725, lr_0 = 2.4002e-04
Loss = 4.1961e-01, PNorm = 44.3123, GNorm = 5.3190, lr_0 = 2.2869e-04
Validation rmse = 0.764206
Epoch 19
Loss = 3.9143e-01, PNorm = 44.3224, GNorm = 7.2985, lr_0 = 2.1789e-04
Loss = 3.1689e-01, PNorm = 44.3324, GNorm = 5.0940, lr_0 = 2.0760e-04
Validation rmse = 0.771307
Epoch 20
Loss = 3.3741e-01, PNorm = 44.3419, GNorm = 8.8849, lr_0 = 1.9780e-04
Validation rmse = 0.821606
Epoch 21
Loss = 5.0046e-01, PNorm = 44.3526, GNorm = 7.4786, lr_0 = 1.8755e-04
Loss = 3.1447e-01, PNorm = 44.3629, GNorm = 4.4824, lr_0 = 1.7869e-04
Validation rmse = 0.770006
Epoch 22
Loss = 3.2248e-01, PNorm = 44.3704, GNorm = 7.1500, lr_0 = 1.7025e-04
Loss = 3.3700e-01, PNorm = 44.3782, GNorm = 4.9525, lr_0 = 1.6221e-04
Validation rmse = 0.776666
Epoch 23
Loss = 3.3843e-01, PNorm = 44.3843, GNorm = 3.9101, lr_0 = 1.5381e-04
Loss = 2.9707e-01, PNorm = 44.3907, GNorm = 2.6038, lr_0 = 1.4654e-04
Validation rmse = 0.761638
Epoch 24
Loss = 3.4857e-01, PNorm = 44.3990, GNorm = 4.0429, lr_0 = 1.3962e-04
Loss = 2.4560e-01, PNorm = 44.4061, GNorm = 6.9044, lr_0 = 1.3303e-04
Validation rmse = 0.769782
Epoch 25
Loss = 3.5684e-01, PNorm = 44.4084, GNorm = 3.0039, lr_0 = 1.2675e-04
Validation rmse = 0.768893
Epoch 26
Loss = 2.1394e-01, PNorm = 44.4155, GNorm = 5.0911, lr_0 = 1.2018e-04
Loss = 2.8877e-01, PNorm = 44.4215, GNorm = 4.2284, lr_0 = 1.1450e-04
Validation rmse = 0.768469
Epoch 27
Loss = 2.2172e-01, PNorm = 44.4258, GNorm = 2.7874, lr_0 = 1.0910e-04
Loss = 2.9193e-01, PNorm = 44.4310, GNorm = 5.7684, lr_0 = 1.0395e-04
Validation rmse = 0.783797
Epoch 28
Loss = 2.9523e-01, PNorm = 44.4362, GNorm = 7.4389, lr_0 = 1.0000e-04
Loss = 2.5070e-01, PNorm = 44.4404, GNorm = 5.7779, lr_0 = 1.0000e-04
Validation rmse = 0.743660
Epoch 29
Loss = 2.4615e-01, PNorm = 44.4455, GNorm = 3.1493, lr_0 = 1.0000e-04
Validation rmse = 0.775621
Model 0 best validation rmse = 0.743660 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.567546
Ensemble test rmse = 0.567546
1-fold cross validation
	Seed 0 ==> test rmse = 0.567546
Overall test rmse = 0.567546 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7661e+00, PNorm = 43.3122, GNorm = 2.9064, lr_0 = 3.7500e-04
Validation rmse = 1.424394
Epoch 1
Loss = 1.5025e+00, PNorm = 43.3201, GNorm = 1.4330, lr_0 = 6.5000e-04
Loss = 1.3530e+00, PNorm = 43.3461, GNorm = 1.1190, lr_0 = 9.0000e-04
Validation rmse = 1.191276
Epoch 2
Loss = 1.3146e+00, PNorm = 43.3889, GNorm = 4.0069, lr_0 = 9.6853e-04
Loss = 1.1220e+00, PNorm = 43.4391, GNorm = 3.6644, lr_0 = 9.2527e-04
Validation rmse = 1.123888
Epoch 3
Loss = 9.6492e-01, PNorm = 43.5038, GNorm = 5.5825, lr_0 = 8.8395e-04
Loss = 9.1157e-01, PNorm = 43.5749, GNorm = 6.1809, lr_0 = 8.4448e-04
Validation rmse = 0.984727
Epoch 4
Loss = 7.8434e-01, PNorm = 43.6321, GNorm = 1.6400, lr_0 = 8.0309e-04
Loss = 8.4554e-01, PNorm = 43.6783, GNorm = 6.1683, lr_0 = 7.6722e-04
Validation rmse = 0.919471
Epoch 5
Loss = 7.6067e-01, PNorm = 43.7303, GNorm = 5.7929, lr_0 = 7.3296e-04
Loss = 7.4505e-01, PNorm = 43.7695, GNorm = 6.4095, lr_0 = 7.0023e-04
Loss = 6.8952e-01, PNorm = 43.7726, GNorm = 4.4566, lr_0 = 6.9703e-04
Validation rmse = 0.870985
Epoch 6
Loss = 6.3611e-01, PNorm = 43.8162, GNorm = 2.1634, lr_0 = 6.6591e-04
Validation rmse = 0.834818
Epoch 7
Loss = 5.9876e-01, PNorm = 43.8628, GNorm = 8.8985, lr_0 = 6.3327e-04
Loss = 6.0490e-01, PNorm = 43.8979, GNorm = 4.6341, lr_0 = 6.0499e-04
Validation rmse = 0.804044
Epoch 8
Loss = 5.1335e-01, PNorm = 43.9335, GNorm = 4.0955, lr_0 = 5.7797e-04
Loss = 5.2617e-01, PNorm = 43.9639, GNorm = 2.6796, lr_0 = 5.5216e-04
Validation rmse = 0.806924
Epoch 9
Loss = 5.3614e-01, PNorm = 44.0016, GNorm = 5.2617, lr_0 = 5.2510e-04
Loss = 4.7665e-01, PNorm = 44.0319, GNorm = 7.9333, lr_0 = 5.0165e-04
Validation rmse = 0.754968
Epoch 10
Loss = 4.5808e-01, PNorm = 44.0597, GNorm = 4.4053, lr_0 = 4.7924e-04
Loss = 4.7641e-01, PNorm = 44.0870, GNorm = 5.4291, lr_0 = 4.5784e-04
Validation rmse = 0.877532
Epoch 11
Loss = 4.4101e-01, PNorm = 44.1154, GNorm = 8.3200, lr_0 = 4.3540e-04
Loss = 4.4160e-01, PNorm = 44.1326, GNorm = 2.8299, lr_0 = 4.1596e-04
Loss = 3.0565e-01, PNorm = 44.1341, GNorm = 9.2241, lr_0 = 4.1406e-04
Validation rmse = 0.740751
Epoch 12
Loss = 3.8953e-01, PNorm = 44.1554, GNorm = 5.7398, lr_0 = 3.9557e-04
Validation rmse = 0.748580
Epoch 13
Loss = 3.9516e-01, PNorm = 44.1741, GNorm = 3.0688, lr_0 = 3.7790e-04
Loss = 4.1184e-01, PNorm = 44.1867, GNorm = 5.4587, lr_0 = 3.6103e-04
Validation rmse = 0.760228
Epoch 14
Loss = 2.9718e-01, PNorm = 44.2013, GNorm = 5.6119, lr_0 = 3.4333e-04
Loss = 3.7245e-01, PNorm = 44.2168, GNorm = 4.1718, lr_0 = 3.2800e-04
Validation rmse = 0.792297
Epoch 15
Loss = 4.5240e-01, PNorm = 44.2324, GNorm = 10.8883, lr_0 = 3.1335e-04
Loss = 3.4860e-01, PNorm = 44.2449, GNorm = 2.8642, lr_0 = 2.9936e-04
Validation rmse = 0.737259
Epoch 16
Loss = 2.2018e-01, PNorm = 44.2589, GNorm = 3.2629, lr_0 = 2.8469e-04
Loss = 3.7646e-01, PNorm = 44.2726, GNorm = 3.9638, lr_0 = 2.7197e-04
Validation rmse = 0.750397
Epoch 17
Loss = 3.6441e-01, PNorm = 44.2770, GNorm = 7.2258, lr_0 = 2.5864e-04
Loss = 3.1904e-01, PNorm = 44.2871, GNorm = 6.5835, lr_0 = 2.4709e-04
Validation rmse = 0.733114
Epoch 18
Loss = 3.2667e-01, PNorm = 44.2989, GNorm = 2.6036, lr_0 = 2.3606e-04
Validation rmse = 0.745063
Epoch 19
Loss = 2.4437e-01, PNorm = 44.3080, GNorm = 16.7913, lr_0 = 2.2449e-04
Loss = 2.6347e-01, PNorm = 44.3179, GNorm = 5.9919, lr_0 = 2.1446e-04
Validation rmse = 0.728789
Epoch 20
Loss = 3.1522e-01, PNorm = 44.3256, GNorm = 8.8558, lr_0 = 2.0488e-04
Loss = 2.5609e-01, PNorm = 44.3363, GNorm = 12.5068, lr_0 = 1.9573e-04
Validation rmse = 0.728945
Epoch 21
Loss = 2.8498e-01, PNorm = 44.3468, GNorm = 3.1820, lr_0 = 1.8614e-04
Loss = 2.9702e-01, PNorm = 44.3542, GNorm = 7.9558, lr_0 = 1.7783e-04
Validation rmse = 0.730701
Epoch 22
Loss = 2.3166e-01, PNorm = 44.3612, GNorm = 12.4343, lr_0 = 1.6911e-04
Loss = 2.6353e-01, PNorm = 44.3668, GNorm = 10.3792, lr_0 = 1.6156e-04
Validation rmse = 0.733134
Epoch 23
Loss = 2.9696e-01, PNorm = 44.3730, GNorm = 12.5857, lr_0 = 1.5434e-04
Loss = 2.1930e-01, PNorm = 44.3804, GNorm = 7.7978, lr_0 = 1.4745e-04
Validation rmse = 0.734994
Epoch 24
Loss = 2.1380e-01, PNorm = 44.3876, GNorm = 8.5189, lr_0 = 1.4022e-04
Loss = 2.3127e-01, PNorm = 44.3929, GNorm = 5.3700, lr_0 = 1.3396e-04
Validation rmse = 0.728298
Epoch 25
Loss = 2.1531e-01, PNorm = 44.3995, GNorm = 3.9637, lr_0 = 1.2798e-04
Validation rmse = 0.732344
Epoch 26
Loss = 1.8977e-01, PNorm = 44.4066, GNorm = 2.6978, lr_0 = 1.2171e-04
Loss = 1.9271e-01, PNorm = 44.4110, GNorm = 13.0838, lr_0 = 1.1627e-04
Validation rmse = 0.724840
Epoch 27
Loss = 1.6946e-01, PNorm = 44.4151, GNorm = 3.6964, lr_0 = 1.1057e-04
Loss = 2.2082e-01, PNorm = 44.4199, GNorm = 7.0122, lr_0 = 1.0564e-04
Validation rmse = 0.739978
Epoch 28
Loss = 2.1346e-01, PNorm = 44.4254, GNorm = 7.7111, lr_0 = 1.0092e-04
Loss = 1.5785e-01, PNorm = 44.4298, GNorm = 9.3595, lr_0 = 1.0000e-04
Validation rmse = 0.722733
Epoch 29
Loss = 1.8118e-01, PNorm = 44.4348, GNorm = 4.8398, lr_0 = 1.0000e-04
Loss = 2.1553e-01, PNorm = 44.4393, GNorm = 17.9052, lr_0 = 1.0000e-04
Validation rmse = 0.721187
Model 0 best validation rmse = 0.721187 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.644122
Ensemble test rmse = 0.644122
1-fold cross validation
	Seed 0 ==> test rmse = 0.644122
Overall test rmse = 0.644122 +/- 0.000000
Elapsed time = 0:01:34
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7799e+00, PNorm = 43.3095, GNorm = 1.1829, lr_0 = 3.6053e-04
Validation rmse = 1.592146
Epoch 1
Loss = 1.3875e+00, PNorm = 43.3161, GNorm = 1.7082, lr_0 = 6.2105e-04
Loss = 1.3128e+00, PNorm = 43.3417, GNorm = 1.2627, lr_0 = 8.5789e-04
Validation rmse = 1.268399
Epoch 2
Loss = 1.1190e+00, PNorm = 43.3847, GNorm = 2.1885, lr_0 = 9.7859e-04
Loss = 1.0962e+00, PNorm = 43.4435, GNorm = 1.8374, lr_0 = 9.3714e-04
Validation rmse = 0.980063
Epoch 3
Loss = 9.1943e-01, PNorm = 43.5117, GNorm = 5.0654, lr_0 = 8.9357e-04
Loss = 9.0141e-01, PNorm = 43.5700, GNorm = 7.9675, lr_0 = 8.5572e-04
Validation rmse = 0.888998
Epoch 4
Loss = 7.6360e-01, PNorm = 43.6268, GNorm = 4.1571, lr_0 = 8.1593e-04
Loss = 7.6986e-01, PNorm = 43.6714, GNorm = 3.6371, lr_0 = 7.8137e-04
Validation rmse = 0.790450
Epoch 5
Loss = 8.3174e-01, PNorm = 43.7027, GNorm = 3.6925, lr_0 = 7.4827e-04
Loss = 7.6487e-01, PNorm = 43.7418, GNorm = 1.9476, lr_0 = 7.1658e-04
Validation rmse = 0.852263
Epoch 6
Loss = 7.7555e-01, PNorm = 43.7896, GNorm = 2.8440, lr_0 = 6.8326e-04
Loss = 6.2466e-01, PNorm = 43.8242, GNorm = 2.9951, lr_0 = 6.5432e-04
Validation rmse = 0.751396
Epoch 7
Loss = 6.3360e-01, PNorm = 43.8631, GNorm = 5.8073, lr_0 = 6.2390e-04
Loss = 6.2408e-01, PNorm = 43.8957, GNorm = 8.5937, lr_0 = 5.9747e-04
Validation rmse = 0.689879
Epoch 8
Loss = 5.7759e-01, PNorm = 43.9355, GNorm = 2.5043, lr_0 = 5.6969e-04
Loss = 5.8054e-01, PNorm = 43.9576, GNorm = 2.1175, lr_0 = 5.4556e-04
Validation rmse = 0.649839
Epoch 9
Loss = 5.2252e-01, PNorm = 43.9782, GNorm = 4.5386, lr_0 = 5.2019e-04
Loss = 5.2850e-01, PNorm = 43.9997, GNorm = 10.8558, lr_0 = 4.9816e-04
Validation rmse = 0.657626
Epoch 10
Loss = 4.8444e-01, PNorm = 44.0244, GNorm = 4.4019, lr_0 = 4.7706e-04
Loss = 5.1761e-01, PNorm = 44.0426, GNorm = 6.2955, lr_0 = 4.5685e-04
Validation rmse = 0.773543
Epoch 11
Loss = 5.6529e-01, PNorm = 44.0670, GNorm = 7.2507, lr_0 = 4.3561e-04
Loss = 5.0580e-01, PNorm = 44.0867, GNorm = 4.2994, lr_0 = 4.1716e-04
Loss = 4.5923e-01, PNorm = 44.0886, GNorm = 7.6651, lr_0 = 4.1536e-04
Validation rmse = 0.659864
Epoch 12
Loss = 4.0392e-01, PNorm = 44.1102, GNorm = 2.1614, lr_0 = 3.9776e-04
Validation rmse = 0.638208
Epoch 13
Loss = 4.9153e-01, PNorm = 44.1309, GNorm = 4.0555, lr_0 = 3.7927e-04
Loss = 3.6941e-01, PNorm = 44.1486, GNorm = 3.5739, lr_0 = 3.6320e-04
Validation rmse = 0.712467
Epoch 14
Loss = 6.1864e-01, PNorm = 44.1613, GNorm = 19.0693, lr_0 = 3.4632e-04
Loss = 4.9806e-01, PNorm = 44.1752, GNorm = 10.8610, lr_0 = 3.3165e-04
Validation rmse = 0.665082
Epoch 15
Loss = 3.2494e-01, PNorm = 44.1902, GNorm = 12.4413, lr_0 = 3.1760e-04
Loss = 4.3198e-01, PNorm = 44.2035, GNorm = 6.9012, lr_0 = 3.0415e-04
Validation rmse = 0.641243
Epoch 16
Loss = 3.6711e-01, PNorm = 44.2161, GNorm = 10.7604, lr_0 = 2.9001e-04
Loss = 4.1455e-01, PNorm = 44.2302, GNorm = 2.3536, lr_0 = 2.7772e-04
Validation rmse = 0.633176
Epoch 17
Loss = 3.4932e-01, PNorm = 44.2408, GNorm = 6.0089, lr_0 = 2.6481e-04
Loss = 3.5520e-01, PNorm = 44.2512, GNorm = 2.7350, lr_0 = 2.5359e-04
Validation rmse = 0.635993
Epoch 18
Loss = 2.5233e-01, PNorm = 44.2649, GNorm = 3.5891, lr_0 = 2.4180e-04
Loss = 3.8838e-01, PNorm = 44.2736, GNorm = 3.0645, lr_0 = 2.3156e-04
Validation rmse = 0.634748
Epoch 19
Loss = 3.3852e-01, PNorm = 44.2827, GNorm = 3.6601, lr_0 = 2.2079e-04
Loss = 3.2947e-01, PNorm = 44.2905, GNorm = 3.2146, lr_0 = 2.1144e-04
Validation rmse = 0.630803
Epoch 20
Loss = 2.9583e-01, PNorm = 44.3006, GNorm = 8.8709, lr_0 = 2.0248e-04
Loss = 3.0408e-01, PNorm = 44.3096, GNorm = 4.1447, lr_0 = 1.9391e-04
Validation rmse = 0.625978
Epoch 21
Loss = 2.6965e-01, PNorm = 44.3162, GNorm = 2.9954, lr_0 = 1.8489e-04
Loss = 3.8406e-01, PNorm = 44.3207, GNorm = 2.4761, lr_0 = 1.7706e-04
Validation rmse = 0.633095
Epoch 22
Loss = 3.1644e-01, PNorm = 44.3297, GNorm = 2.2427, lr_0 = 1.6883e-04
Loss = 2.7615e-01, PNorm = 44.3389, GNorm = 7.6800, lr_0 = 1.6168e-04
Validation rmse = 0.632489
Epoch 23
Loss = 2.4861e-01, PNorm = 44.3444, GNorm = 2.7497, lr_0 = 1.5416e-04
Loss = 2.9319e-01, PNorm = 44.3500, GNorm = 2.6914, lr_0 = 1.4763e-04
Loss = 2.6010e-01, PNorm = 44.3506, GNorm = 11.0431, lr_0 = 1.4699e-04
Validation rmse = 0.631894
Epoch 24
Loss = 2.5446e-01, PNorm = 44.3573, GNorm = 2.8888, lr_0 = 1.4077e-04
Loss = 2.3733e-01, PNorm = 44.3625, GNorm = 14.4665, lr_0 = 1.3480e-04
Validation rmse = 0.651579
Epoch 25
Loss = 2.8618e-01, PNorm = 44.3682, GNorm = 7.2645, lr_0 = 1.2909e-04
Validation rmse = 0.650673
Epoch 26
Loss = 8.1925e-02, PNorm = 44.3739, GNorm = 8.3232, lr_0 = 1.2309e-04
Loss = 2.6445e-01, PNorm = 44.3786, GNorm = 4.1166, lr_0 = 1.1788e-04
Validation rmse = 0.634275
Epoch 27
Loss = 2.0378e-01, PNorm = 44.3821, GNorm = 4.4820, lr_0 = 1.1240e-04
Loss = 2.5501e-01, PNorm = 44.3858, GNorm = 2.3834, lr_0 = 1.0764e-04
Validation rmse = 0.643550
Epoch 28
Loss = 2.6012e-01, PNorm = 44.3910, GNorm = 10.7494, lr_0 = 1.0263e-04
Loss = 2.5858e-01, PNorm = 44.3947, GNorm = 3.8787, lr_0 = 1.0000e-04
Validation rmse = 0.623355
Epoch 29
Loss = 1.8691e-01, PNorm = 44.3995, GNorm = 9.0905, lr_0 = 1.0000e-04
Loss = 2.6737e-01, PNorm = 44.4046, GNorm = 5.3219, lr_0 = 1.0000e-04
Validation rmse = 0.624886
Model 0 best validation rmse = 0.623355 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.589087
Ensemble test rmse = 0.589087
1-fold cross validation
	Seed 0 ==> test rmse = 0.589087
Overall test rmse = 0.589087 +/- 0.000000
Elapsed time = 0:01:38
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9092e+00, PNorm = 43.3111, GNorm = 1.8534, lr_0 = 3.4750e-04
Loss = 1.4570e+00, PNorm = 43.3176, GNorm = 1.3758, lr_0 = 5.7250e-04
Validation rmse = 1.656229
Epoch 1
Loss = 1.3794e+00, PNorm = 43.3373, GNorm = 1.0177, lr_0 = 7.9750e-04
Loss = 1.2284e+00, PNorm = 43.3797, GNorm = 2.4686, lr_0 = 9.9590e-04
Validation rmse = 1.356608
Epoch 2
Loss = 1.1293e+00, PNorm = 43.4393, GNorm = 2.1724, lr_0 = 9.5578e-04
Loss = 9.3251e-01, PNorm = 43.5117, GNorm = 3.5207, lr_0 = 9.1728e-04
Validation rmse = 1.051253
Epoch 3
Loss = 8.6086e-01, PNorm = 43.5752, GNorm = 1.2688, lr_0 = 8.8032e-04
Loss = 8.0251e-01, PNorm = 43.6320, GNorm = 6.1323, lr_0 = 8.4486e-04
Validation rmse = 0.930280
Epoch 4
Loss = 7.0132e-01, PNorm = 43.6871, GNorm = 3.1769, lr_0 = 8.1083e-04
Loss = 7.9215e-01, PNorm = 43.7213, GNorm = 8.3383, lr_0 = 7.7816e-04
Validation rmse = 1.094441
Epoch 5
Loss = 8.2546e-01, PNorm = 43.7603, GNorm = 2.1416, lr_0 = 7.4682e-04
Loss = 7.6140e-01, PNorm = 43.8068, GNorm = 6.7469, lr_0 = 7.1673e-04
Validation rmse = 0.925517
Epoch 6
Loss = 6.8572e-01, PNorm = 43.8542, GNorm = 2.9713, lr_0 = 6.8786e-04
Loss = 5.7652e-01, PNorm = 43.8905, GNorm = 11.4812, lr_0 = 6.6015e-04
Validation rmse = 0.825223
Epoch 7
Loss = 5.5202e-01, PNorm = 43.9152, GNorm = 1.7536, lr_0 = 6.3356e-04
Loss = 5.4474e-01, PNorm = 43.9457, GNorm = 3.4179, lr_0 = 6.0803e-04
Validation rmse = 0.823381
Epoch 8
Loss = 5.6479e-01, PNorm = 43.9713, GNorm = 3.3884, lr_0 = 5.8354e-04
Loss = 4.9922e-01, PNorm = 44.0039, GNorm = 3.6043, lr_0 = 5.6003e-04
Validation rmse = 0.807574
Epoch 9
Loss = 4.8910e-01, PNorm = 44.0276, GNorm = 7.3104, lr_0 = 5.3747e-04
Loss = 4.7119e-01, PNorm = 44.0486, GNorm = 2.5930, lr_0 = 5.1582e-04
Validation rmse = 0.785754
Epoch 10
Loss = 4.1047e-01, PNorm = 44.0726, GNorm = 7.6541, lr_0 = 4.9504e-04
Loss = 5.4370e-01, PNorm = 44.0951, GNorm = 4.0987, lr_0 = 4.7510e-04
Validation rmse = 0.837747
Epoch 11
Loss = 4.8925e-01, PNorm = 44.1189, GNorm = 5.6473, lr_0 = 4.5596e-04
Loss = 4.3858e-01, PNorm = 44.1383, GNorm = 7.5322, lr_0 = 4.3759e-04
Validation rmse = 0.815491
Epoch 12
Loss = 3.8289e-01, PNorm = 44.1606, GNorm = 2.8719, lr_0 = 4.1997e-04
Loss = 3.9107e-01, PNorm = 44.1772, GNorm = 3.4164, lr_0 = 4.0305e-04
Validation rmse = 0.784825
Epoch 13
Loss = 3.4866e-01, PNorm = 44.1943, GNorm = 2.3645, lr_0 = 3.8681e-04
Loss = 4.2994e-01, PNorm = 44.2104, GNorm = 4.8325, lr_0 = 3.7123e-04
Validation rmse = 0.774273
Epoch 14
Loss = 3.4394e-01, PNorm = 44.2302, GNorm = 2.6972, lr_0 = 3.5628e-04
Loss = 3.8901e-01, PNorm = 44.2449, GNorm = 6.5101, lr_0 = 3.4192e-04
Validation rmse = 0.782548
Epoch 15
Loss = 3.1911e-01, PNorm = 44.2606, GNorm = 4.5921, lr_0 = 3.2815e-04
Loss = 4.2217e-01, PNorm = 44.2730, GNorm = 12.8864, lr_0 = 3.1493e-04
Validation rmse = 0.786493
Epoch 16
Loss = 3.6593e-01, PNorm = 44.2871, GNorm = 8.8800, lr_0 = 3.0224e-04
Loss = 3.9014e-01, PNorm = 44.2989, GNorm = 8.1117, lr_0 = 2.9007e-04
Validation rmse = 0.750258
Epoch 17
Loss = 2.8873e-01, PNorm = 44.3135, GNorm = 2.6386, lr_0 = 2.7838e-04
Loss = 3.4700e-01, PNorm = 44.3240, GNorm = 3.2558, lr_0 = 2.6717e-04
Validation rmse = 0.747817
Epoch 18
Loss = 2.5431e-01, PNorm = 44.3334, GNorm = 7.4854, lr_0 = 2.5641e-04
Loss = 3.1973e-01, PNorm = 44.3436, GNorm = 4.4553, lr_0 = 2.4608e-04
Validation rmse = 0.763748
Epoch 19
Loss = 3.0706e-01, PNorm = 44.3519, GNorm = 10.5242, lr_0 = 2.3616e-04
Loss = 2.8013e-01, PNorm = 44.3621, GNorm = 10.5479, lr_0 = 2.2665e-04
Validation rmse = 0.771890
Epoch 20
Loss = 2.6827e-01, PNorm = 44.3722, GNorm = 7.8616, lr_0 = 2.1752e-04
Loss = 2.9681e-01, PNorm = 44.3811, GNorm = 4.0839, lr_0 = 2.0876e-04
Validation rmse = 0.748845
Epoch 21
Loss = 2.5066e-01, PNorm = 44.3912, GNorm = 4.1842, lr_0 = 2.0035e-04
Loss = 2.7709e-01, PNorm = 44.3980, GNorm = 4.2973, lr_0 = 1.9228e-04
Validation rmse = 0.748442
Epoch 22
Loss = 2.8542e-01, PNorm = 44.4056, GNorm = 15.3893, lr_0 = 1.8453e-04
Loss = 2.7332e-01, PNorm = 44.4128, GNorm = 2.4672, lr_0 = 1.7710e-04
Validation rmse = 0.729159
Epoch 23
Loss = 2.3016e-01, PNorm = 44.4223, GNorm = 5.3002, lr_0 = 1.6996e-04
Loss = 2.5512e-01, PNorm = 44.4301, GNorm = 5.2040, lr_0 = 1.6312e-04
Validation rmse = 0.744668
Epoch 24
Loss = 2.4784e-01, PNorm = 44.4362, GNorm = 8.6747, lr_0 = 1.5655e-04
Loss = 2.2168e-01, PNorm = 44.4420, GNorm = 8.6050, lr_0 = 1.5024e-04
Validation rmse = 0.753515
Epoch 25
Loss = 2.6032e-01, PNorm = 44.4489, GNorm = 3.8963, lr_0 = 1.4419e-04
Loss = 2.2942e-01, PNorm = 44.4541, GNorm = 2.8301, lr_0 = 1.3838e-04
Validation rmse = 0.738718
Epoch 26
Loss = 2.1708e-01, PNorm = 44.4603, GNorm = 5.3439, lr_0 = 1.3280e-04
Loss = 2.1743e-01, PNorm = 44.4664, GNorm = 4.7968, lr_0 = 1.2746e-04
Validation rmse = 0.729038
Epoch 27
Loss = 1.8339e-01, PNorm = 44.4723, GNorm = 3.7547, lr_0 = 1.2232e-04
Loss = 2.3339e-01, PNorm = 44.4771, GNorm = 4.8774, lr_0 = 1.1739e-04
Validation rmse = 0.729883
Epoch 28
Loss = 2.0037e-01, PNorm = 44.4817, GNorm = 8.5826, lr_0 = 1.1266e-04
Loss = 2.2655e-01, PNorm = 44.4856, GNorm = 8.5959, lr_0 = 1.0813e-04
Validation rmse = 0.726804
Epoch 29
Loss = 2.0046e-01, PNorm = 44.4893, GNorm = 4.4157, lr_0 = 1.0377e-04
Loss = 2.0151e-01, PNorm = 44.4937, GNorm = 3.3335, lr_0 = 1.0000e-04
Validation rmse = 0.725750
Model 0 best validation rmse = 0.725750 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.585843
Ensemble test rmse = 0.585843
1-fold cross validation
	Seed 0 ==> test rmse = 0.585843
Overall test rmse = 0.585843 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8579e+00, PNorm = 43.3105, GNorm = 2.7569, lr_0 = 3.4750e-04
Loss = 1.4878e+00, PNorm = 43.3149, GNorm = 1.3034, lr_0 = 5.7250e-04
Loss = 1.3710e+00, PNorm = 43.3160, GNorm = 1.5191, lr_0 = 5.9500e-04
Validation rmse = 1.627785
Epoch 1
Loss = 1.3644e+00, PNorm = 43.3394, GNorm = 1.3267, lr_0 = 8.2000e-04
Loss = 1.2228e+00, PNorm = 43.3774, GNorm = 1.3522, lr_0 = 9.9181e-04
Validation rmse = 1.383406
Epoch 2
Loss = 1.1149e+00, PNorm = 43.4320, GNorm = 1.3699, lr_0 = 9.5186e-04
Loss = 9.7435e-01, PNorm = 43.5044, GNorm = 2.3495, lr_0 = 9.1351e-04
Validation rmse = 1.003286
Epoch 3
Loss = 9.0873e-01, PNorm = 43.5762, GNorm = 3.5555, lr_0 = 8.7671e-04
Loss = 8.2480e-01, PNorm = 43.6408, GNorm = 1.6328, lr_0 = 8.4140e-04
Validation rmse = 0.942833
Epoch 4
Loss = 7.2541e-01, PNorm = 43.6917, GNorm = 1.7020, lr_0 = 8.0750e-04
Loss = 7.6374e-01, PNorm = 43.7328, GNorm = 4.4539, lr_0 = 7.7497e-04
Validation rmse = 0.954789
Epoch 5
Loss = 6.1266e-01, PNorm = 43.7867, GNorm = 2.3858, lr_0 = 7.4375e-04
Loss = 6.3051e-01, PNorm = 43.8276, GNorm = 1.7980, lr_0 = 7.1379e-04
Validation rmse = 0.783797
Epoch 6
Loss = 5.7049e-01, PNorm = 43.8703, GNorm = 2.7345, lr_0 = 6.8223e-04
Loss = 4.9838e-01, PNorm = 43.9093, GNorm = 3.9145, lr_0 = 6.5474e-04
Validation rmse = 0.790643
Epoch 7
Loss = 5.6186e-01, PNorm = 43.9373, GNorm = 7.9767, lr_0 = 6.2837e-04
Loss = 5.0476e-01, PNorm = 43.9756, GNorm = 9.4410, lr_0 = 6.0306e-04
Validation rmse = 0.774389
Epoch 8
Loss = 5.1323e-01, PNorm = 44.0053, GNorm = 2.3502, lr_0 = 5.7876e-04
Loss = 4.4424e-01, PNorm = 44.0398, GNorm = 5.4850, lr_0 = 5.5545e-04
Validation rmse = 0.740519
Epoch 9
Loss = 4.6046e-01, PNorm = 44.0635, GNorm = 8.5718, lr_0 = 5.3307e-04
Loss = 4.1409e-01, PNorm = 44.0939, GNorm = 6.4233, lr_0 = 5.1160e-04
Validation rmse = 0.771494
Epoch 10
Loss = 4.2014e-01, PNorm = 44.1194, GNorm = 2.6715, lr_0 = 4.9099e-04
Loss = 4.1407e-01, PNorm = 44.1425, GNorm = 2.7841, lr_0 = 4.7121e-04
Validation rmse = 0.716713
Epoch 11
Loss = 3.1139e-01, PNorm = 44.1681, GNorm = 5.4008, lr_0 = 4.5037e-04
Loss = 3.6668e-01, PNorm = 44.1908, GNorm = 1.9644, lr_0 = 4.3223e-04
Validation rmse = 0.732655
Epoch 12
Loss = 2.9827e-01, PNorm = 44.2078, GNorm = 3.2999, lr_0 = 4.1482e-04
Loss = 3.9815e-01, PNorm = 44.2277, GNorm = 8.2247, lr_0 = 3.9811e-04
Loss = 3.8120e-01, PNorm = 44.2490, GNorm = 4.1194, lr_0 = 3.8207e-04
Validation rmse = 0.704897
Epoch 13
Loss = 3.3520e-01, PNorm = 44.2706, GNorm = 11.4471, lr_0 = 3.6668e-04
Loss = 4.2672e-01, PNorm = 44.2809, GNorm = 6.1336, lr_0 = 3.5191e-04
Validation rmse = 0.783473
Epoch 14
Loss = 3.4997e-01, PNorm = 44.2939, GNorm = 2.6947, lr_0 = 3.3773e-04
Loss = 3.0076e-01, PNorm = 44.3108, GNorm = 6.5198, lr_0 = 3.2413e-04
Validation rmse = 0.721523
Epoch 15
Loss = 3.5969e-01, PNorm = 44.3232, GNorm = 4.7728, lr_0 = 3.1107e-04
Loss = 2.9500e-01, PNorm = 44.3366, GNorm = 3.6817, lr_0 = 2.9854e-04
Validation rmse = 0.697568
Epoch 16
Loss = 2.3495e-01, PNorm = 44.3513, GNorm = 5.1043, lr_0 = 2.8534e-04
Loss = 3.2446e-01, PNorm = 44.3622, GNorm = 3.0203, lr_0 = 2.7384e-04
Validation rmse = 0.694038
Epoch 17
Loss = 2.7824e-01, PNorm = 44.3743, GNorm = 3.1125, lr_0 = 2.6281e-04
Loss = 2.7057e-01, PNorm = 44.3889, GNorm = 4.3716, lr_0 = 2.5222e-04
Validation rmse = 0.709194
Epoch 18
Loss = 2.0989e-01, PNorm = 44.3994, GNorm = 3.2797, lr_0 = 2.4206e-04
Loss = 3.3482e-01, PNorm = 44.4102, GNorm = 6.0510, lr_0 = 2.3231e-04
Validation rmse = 0.735496
Epoch 19
Loss = 2.2009e-01, PNorm = 44.4194, GNorm = 5.7323, lr_0 = 2.2295e-04
Loss = 2.2979e-01, PNorm = 44.4306, GNorm = 5.9625, lr_0 = 2.1397e-04
Validation rmse = 0.684312
Epoch 20
Loss = 1.7746e-01, PNorm = 44.4366, GNorm = 2.6036, lr_0 = 2.0535e-04
Loss = 2.3044e-01, PNorm = 44.4449, GNorm = 6.2335, lr_0 = 1.9708e-04
Validation rmse = 0.693762
Epoch 21
Loss = 2.1708e-01, PNorm = 44.4542, GNorm = 2.7931, lr_0 = 1.8836e-04
Loss = 2.2641e-01, PNorm = 44.4629, GNorm = 5.0739, lr_0 = 1.8078e-04
Validation rmse = 0.685064
Epoch 22
Loss = 2.0607e-01, PNorm = 44.4707, GNorm = 4.3014, lr_0 = 1.7349e-04
Loss = 2.1762e-01, PNorm = 44.4796, GNorm = 6.0335, lr_0 = 1.6651e-04
Validation rmse = 0.686588
Epoch 23
Loss = 1.2072e-01, PNorm = 44.4855, GNorm = 4.6213, lr_0 = 1.5980e-04
Loss = 2.0326e-01, PNorm = 44.4902, GNorm = 3.8992, lr_0 = 1.5336e-04
Validation rmse = 0.675198
Epoch 24
Loss = 2.9948e-01, PNorm = 44.4980, GNorm = 5.2486, lr_0 = 1.4718e-04
Loss = 1.7036e-01, PNorm = 44.5070, GNorm = 5.0201, lr_0 = 1.4125e-04
Loss = 1.7393e-01, PNorm = 44.5100, GNorm = 3.7483, lr_0 = 1.3556e-04
Validation rmse = 0.679200
Epoch 25
Loss = 1.8045e-01, PNorm = 44.5154, GNorm = 5.4236, lr_0 = 1.3010e-04
Loss = 1.5339e-01, PNorm = 44.5209, GNorm = 7.3881, lr_0 = 1.2486e-04
Loss = 9.2340e-02, PNorm = 44.5215, GNorm = 3.2091, lr_0 = 1.2435e-04
Validation rmse = 0.689959
Epoch 26
Loss = 1.3216e-01, PNorm = 44.5275, GNorm = 3.9383, lr_0 = 1.1934e-04
Loss = 1.8704e-01, PNorm = 44.5330, GNorm = 5.4834, lr_0 = 1.1453e-04
Validation rmse = 0.679756
Epoch 27
Loss = 2.3936e-01, PNorm = 44.5360, GNorm = 5.6064, lr_0 = 1.0992e-04
Loss = 1.4748e-01, PNorm = 44.5403, GNorm = 3.8568, lr_0 = 1.0549e-04
Validation rmse = 0.673383
Epoch 28
Loss = 1.9991e-01, PNorm = 44.5442, GNorm = 6.7143, lr_0 = 1.0124e-04
Loss = 1.0466e-01, PNorm = 44.5493, GNorm = 4.3609, lr_0 = 1.0000e-04
Validation rmse = 0.674802
Epoch 29
Loss = 1.1795e-01, PNorm = 44.5536, GNorm = 3.9723, lr_0 = 1.0000e-04
Loss = 1.6069e-01, PNorm = 44.5569, GNorm = 3.4043, lr_0 = 1.0000e-04
Validation rmse = 0.673659
Model 0 best validation rmse = 0.673383 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.577525
Ensemble test rmse = 0.577525
1-fold cross validation
	Seed 0 ==> test rmse = 0.577525
Overall test rmse = 0.577525 +/- 0.000000
Elapsed time = 0:01:46
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9120e+00, PNorm = 43.3120, GNorm = 1.2544, lr_0 = 3.3571e-04
Loss = 1.4913e+00, PNorm = 43.3179, GNorm = 1.1949, lr_0 = 5.5000e-04
Validation rmse = 1.577273
Epoch 1
Loss = 1.3642e+00, PNorm = 43.3403, GNorm = 1.2428, lr_0 = 7.8571e-04
Loss = 1.1581e+00, PNorm = 43.3826, GNorm = 0.8361, lr_0 = 1.0000e-03
Validation rmse = 1.197233
Epoch 2
Loss = 1.0699e+00, PNorm = 43.4311, GNorm = 1.5716, lr_0 = 9.6160e-04
Loss = 9.8602e-01, PNorm = 43.4998, GNorm = 4.7906, lr_0 = 9.2467e-04
Validation rmse = 0.980171
Epoch 3
Loss = 8.4448e-01, PNorm = 43.5702, GNorm = 4.1801, lr_0 = 8.8568e-04
Loss = 8.1263e-01, PNorm = 43.6288, GNorm = 5.1108, lr_0 = 8.5167e-04
Validation rmse = 0.829658
Epoch 4
Loss = 8.2568e-01, PNorm = 43.6781, GNorm = 4.5110, lr_0 = 8.1896e-04
Loss = 7.2639e-01, PNorm = 43.7357, GNorm = 6.9947, lr_0 = 7.8751e-04
Validation rmse = 0.805881
Epoch 5
Loss = 7.6261e-01, PNorm = 43.7751, GNorm = 1.4943, lr_0 = 7.5727e-04
Loss = 6.1311e-01, PNorm = 43.8198, GNorm = 1.8491, lr_0 = 7.2819e-04
Validation rmse = 0.766049
Epoch 6
Loss = 4.6549e-01, PNorm = 43.8657, GNorm = 3.8067, lr_0 = 6.9749e-04
Loss = 5.4110e-01, PNorm = 43.8986, GNorm = 1.7772, lr_0 = 6.7070e-04
Loss = 6.0973e-01, PNorm = 43.9336, GNorm = 2.5009, lr_0 = 6.4495e-04
Validation rmse = 0.778987
Epoch 7
Loss = 5.1892e-01, PNorm = 43.9672, GNorm = 5.2340, lr_0 = 6.2018e-04
Loss = 4.7320e-01, PNorm = 44.0002, GNorm = 2.8919, lr_0 = 5.9636e-04
Validation rmse = 0.716754
Epoch 8
Loss = 5.1786e-01, PNorm = 44.0270, GNorm = 6.8022, lr_0 = 5.7122e-04
Loss = 4.7852e-01, PNorm = 44.0535, GNorm = 2.0271, lr_0 = 5.4928e-04
Validation rmse = 0.727230
Epoch 9
Loss = 4.2942e-01, PNorm = 44.0835, GNorm = 15.1887, lr_0 = 5.2819e-04
Loss = 4.1251e-01, PNorm = 44.1059, GNorm = 2.8682, lr_0 = 5.0790e-04
Validation rmse = 0.711289
Epoch 10
Loss = 3.2370e-01, PNorm = 44.1315, GNorm = 2.8613, lr_0 = 4.8840e-04
Loss = 3.8312e-01, PNorm = 44.1491, GNorm = 5.1877, lr_0 = 4.6964e-04
Validation rmse = 0.721509
Epoch 11
Loss = 3.6526e-01, PNorm = 44.1661, GNorm = 7.8226, lr_0 = 4.4984e-04
Loss = 3.6317e-01, PNorm = 44.1915, GNorm = 2.3402, lr_0 = 4.3257e-04
Validation rmse = 0.718117
Epoch 12
Loss = 3.6931e-01, PNorm = 44.2056, GNorm = 3.4481, lr_0 = 4.1596e-04
Loss = 3.6961e-01, PNorm = 44.2237, GNorm = 3.4175, lr_0 = 3.9998e-04
Loss = 3.4259e-01, PNorm = 44.2418, GNorm = 3.9450, lr_0 = 3.8462e-04
Loss = 4.2875e-01, PNorm = 44.2440, GNorm = 8.6258, lr_0 = 3.8312e-04
Validation rmse = 0.706621
Epoch 13
Loss = 3.0502e-01, PNorm = 44.2605, GNorm = 4.0268, lr_0 = 3.6841e-04
Loss = 3.1778e-01, PNorm = 44.2782, GNorm = 10.5991, lr_0 = 3.5426e-04
Validation rmse = 0.687973
Epoch 14
Loss = 2.6533e-01, PNorm = 44.2907, GNorm = 3.1095, lr_0 = 3.4065e-04
Loss = 3.7430e-01, PNorm = 44.3036, GNorm = 6.0398, lr_0 = 3.2757e-04
Validation rmse = 0.681959
Epoch 15
Loss = 3.0137e-01, PNorm = 44.3162, GNorm = 6.8850, lr_0 = 3.1499e-04
Loss = 3.1260e-01, PNorm = 44.3297, GNorm = 3.9213, lr_0 = 3.0290e-04
Validation rmse = 0.684672
Epoch 16
Loss = 1.9796e-01, PNorm = 44.3434, GNorm = 2.4292, lr_0 = 2.9012e-04
Loss = 2.6642e-01, PNorm = 44.3550, GNorm = 5.8492, lr_0 = 2.7898e-04
Validation rmse = 0.715910
Epoch 17
Loss = 2.6927e-01, PNorm = 44.3648, GNorm = 13.3538, lr_0 = 2.6827e-04
Loss = 2.3979e-01, PNorm = 44.3766, GNorm = 4.9169, lr_0 = 2.5797e-04
Validation rmse = 0.688864
Epoch 18
Loss = 3.2917e-01, PNorm = 44.3871, GNorm = 11.5949, lr_0 = 2.4709e-04
Loss = 2.1599e-01, PNorm = 44.3976, GNorm = 4.6456, lr_0 = 2.3760e-04
Loss = 2.6854e-01, PNorm = 44.4074, GNorm = 7.8607, lr_0 = 2.2848e-04
Validation rmse = 0.726355
Epoch 19
Loss = 2.5083e-01, PNorm = 44.4145, GNorm = 8.2603, lr_0 = 2.1970e-04
Loss = 2.1876e-01, PNorm = 44.4227, GNorm = 8.5953, lr_0 = 2.1127e-04
Validation rmse = 0.708580
Epoch 20
Loss = 2.3057e-01, PNorm = 44.4321, GNorm = 10.0444, lr_0 = 2.0315e-04
Loss = 1.9829e-01, PNorm = 44.4417, GNorm = 4.2461, lr_0 = 1.9535e-04
Validation rmse = 0.686826
Epoch 21
Loss = 1.9364e-01, PNorm = 44.4512, GNorm = 6.9286, lr_0 = 1.8712e-04
Loss = 2.0034e-01, PNorm = 44.4566, GNorm = 7.4413, lr_0 = 1.7993e-04
Validation rmse = 0.701903
Epoch 22
Loss = 1.0523e-01, PNorm = 44.4648, GNorm = 6.9319, lr_0 = 1.7302e-04
Loss = 1.6792e-01, PNorm = 44.4732, GNorm = 10.0320, lr_0 = 1.6638e-04
Validation rmse = 0.683924
Epoch 23
Loss = 1.9384e-01, PNorm = 44.4764, GNorm = 9.5016, lr_0 = 1.5936e-04
Loss = 1.9159e-01, PNorm = 44.4820, GNorm = 10.1588, lr_0 = 1.5324e-04
Validation rmse = 0.687031
Epoch 24
Loss = 2.0474e-01, PNorm = 44.4883, GNorm = 6.0263, lr_0 = 1.4736e-04
Loss = 1.7493e-01, PNorm = 44.4945, GNorm = 6.7513, lr_0 = 1.4170e-04
Loss = 1.7719e-01, PNorm = 44.5019, GNorm = 7.4649, lr_0 = 1.3626e-04
Validation rmse = 0.701233
Epoch 25
Loss = 2.0554e-01, PNorm = 44.5067, GNorm = 5.1356, lr_0 = 1.3102e-04
Loss = 1.3270e-01, PNorm = 44.5119, GNorm = 5.4290, lr_0 = 1.2599e-04
Validation rmse = 0.688470
Epoch 26
Loss = 1.0771e-01, PNorm = 44.5169, GNorm = 8.7994, lr_0 = 1.2068e-04
Loss = 1.6621e-01, PNorm = 44.5210, GNorm = 3.9749, lr_0 = 1.1604e-04
Validation rmse = 0.678943
Epoch 27
Loss = 9.6787e-02, PNorm = 44.5252, GNorm = 3.2052, lr_0 = 1.1159e-04
Loss = 1.7259e-01, PNorm = 44.5291, GNorm = 2.4091, lr_0 = 1.0730e-04
Validation rmse = 0.673489
Epoch 28
Loss = 1.0137e-01, PNorm = 44.5346, GNorm = 5.7532, lr_0 = 1.0278e-04
Loss = 2.1033e-01, PNorm = 44.5374, GNorm = 9.4808, lr_0 = 1.0000e-04
Validation rmse = 0.687612
Epoch 29
Loss = 1.0080e-01, PNorm = 44.5409, GNorm = 4.7796, lr_0 = 1.0000e-04
Loss = 1.5858e-01, PNorm = 44.5462, GNorm = 6.3334, lr_0 = 1.0000e-04
Validation rmse = 0.697140
Model 0 best validation rmse = 0.673489 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.557945
Ensemble test rmse = 0.557945
1-fold cross validation
	Seed 0 ==> test rmse = 0.557945
Overall test rmse = 0.557945 +/- 0.000000
Elapsed time = 0:01:51
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9063e+00, PNorm = 43.3111, GNorm = 2.9508, lr_0 = 3.2500e-04
Loss = 1.4710e+00, PNorm = 43.3143, GNorm = 1.6228, lr_0 = 5.2955e-04
Validation rmse = 1.717562
Epoch 1
Loss = 1.3570e+00, PNorm = 43.3313, GNorm = 1.7914, lr_0 = 7.5455e-04
Loss = 1.2300e+00, PNorm = 43.3665, GNorm = 2.8511, lr_0 = 9.5909e-04
Validation rmse = 1.329403
Epoch 2
Loss = 1.0369e+00, PNorm = 43.4284, GNorm = 1.8737, lr_0 = 9.6692e-04
Loss = 9.7197e-01, PNorm = 43.4949, GNorm = 2.0978, lr_0 = 9.3144e-04
Validation rmse = 1.009734
Epoch 3
Loss = 7.2472e-01, PNorm = 43.5733, GNorm = 2.4828, lr_0 = 8.9727e-04
Loss = 7.5756e-01, PNorm = 43.6362, GNorm = 1.9294, lr_0 = 8.6435e-04
Validation rmse = 0.895313
Epoch 4
Loss = 6.1419e-01, PNorm = 43.6847, GNorm = 2.1681, lr_0 = 8.2953e-04
Loss = 6.5107e-01, PNorm = 43.7282, GNorm = 4.2345, lr_0 = 7.9909e-04
Loss = 5.8060e-01, PNorm = 43.7759, GNorm = 2.7608, lr_0 = 7.6977e-04
Validation rmse = 0.825831
Epoch 5
Loss = 5.8316e-01, PNorm = 43.8062, GNorm = 1.6712, lr_0 = 7.4153e-04
Loss = 5.5952e-01, PNorm = 43.8469, GNorm = 2.9291, lr_0 = 7.1433e-04
Validation rmse = 0.812439
Epoch 6
Loss = 5.0284e-01, PNorm = 43.8850, GNorm = 7.1894, lr_0 = 6.8555e-04
Loss = 5.5053e-01, PNorm = 43.9137, GNorm = 3.8960, lr_0 = 6.6040e-04
Validation rmse = 0.749136
Epoch 7
Loss = 5.2402e-01, PNorm = 43.9465, GNorm = 2.1863, lr_0 = 6.3379e-04
Loss = 5.2026e-01, PNorm = 43.9666, GNorm = 9.8116, lr_0 = 6.1054e-04
Validation rmse = 0.737317
Epoch 8
Loss = 5.0200e-01, PNorm = 43.9960, GNorm = 2.0876, lr_0 = 5.8814e-04
Loss = 4.7734e-01, PNorm = 44.0159, GNorm = 2.1676, lr_0 = 5.6656e-04
Loss = 4.2649e-01, PNorm = 44.0434, GNorm = 7.7009, lr_0 = 5.4577e-04
Validation rmse = 0.712521
Epoch 9
Loss = 4.1574e-01, PNorm = 44.0579, GNorm = 5.2007, lr_0 = 5.2379e-04
Loss = 4.1287e-01, PNorm = 44.0787, GNorm = 3.5058, lr_0 = 5.0457e-04
Validation rmse = 0.725499
Epoch 10
Loss = 3.0106e-01, PNorm = 44.0986, GNorm = 3.8426, lr_0 = 4.8606e-04
Loss = 3.9131e-01, PNorm = 44.1186, GNorm = 10.7491, lr_0 = 4.6822e-04
Validation rmse = 0.715727
Epoch 11
Loss = 3.3392e-01, PNorm = 44.1380, GNorm = 3.6550, lr_0 = 4.4936e-04
Loss = 3.9893e-01, PNorm = 44.1518, GNorm = 5.7845, lr_0 = 4.3288e-04
Validation rmse = 0.736159
Epoch 12
Loss = 3.4858e-01, PNorm = 44.1714, GNorm = 15.4957, lr_0 = 4.1544e-04
Loss = 2.5676e-01, PNorm = 44.1888, GNorm = 4.9195, lr_0 = 4.0020e-04
Loss = 3.8623e-01, PNorm = 44.1988, GNorm = 2.3060, lr_0 = 3.8551e-04
Validation rmse = 0.722854
Epoch 13
Loss = 3.9971e-01, PNorm = 44.2109, GNorm = 11.7417, lr_0 = 3.7137e-04
Loss = 2.9895e-01, PNorm = 44.2266, GNorm = 3.0435, lr_0 = 3.5774e-04
Validation rmse = 0.722866
Epoch 14
Loss = 2.8910e-01, PNorm = 44.2409, GNorm = 6.0134, lr_0 = 3.4333e-04
Loss = 3.3126e-01, PNorm = 44.2525, GNorm = 10.9106, lr_0 = 3.3074e-04
Validation rmse = 0.705642
Epoch 15
Loss = 3.1567e-01, PNorm = 44.2640, GNorm = 5.0850, lr_0 = 3.1860e-04
Loss = 3.3702e-01, PNorm = 44.2772, GNorm = 3.9937, lr_0 = 3.0691e-04
Validation rmse = 0.688861
Epoch 16
Loss = 2.9758e-01, PNorm = 44.2901, GNorm = 2.1317, lr_0 = 2.9455e-04
Loss = 2.6758e-01, PNorm = 44.3033, GNorm = 8.9538, lr_0 = 2.8374e-04
Loss = 2.6716e-01, PNorm = 44.3124, GNorm = 7.6631, lr_0 = 2.7333e-04
Loss = 2.8509e-01, PNorm = 44.3126, GNorm = 12.6532, lr_0 = 2.7231e-04
Validation rmse = 0.689771
Epoch 17
Loss = 2.4267e-01, PNorm = 44.3208, GNorm = 3.3045, lr_0 = 2.6232e-04
Loss = 2.7551e-01, PNorm = 44.3315, GNorm = 4.8668, lr_0 = 2.5270e-04
Validation rmse = 0.680277
Epoch 18
Loss = 2.4001e-01, PNorm = 44.3381, GNorm = 7.7034, lr_0 = 2.4342e-04
Loss = 2.7166e-01, PNorm = 44.3475, GNorm = 3.3029, lr_0 = 2.3449e-04
Validation rmse = 0.689356
Epoch 19
Loss = 1.3171e-01, PNorm = 44.3555, GNorm = 2.9340, lr_0 = 2.2505e-04
Loss = 2.7678e-01, PNorm = 44.3623, GNorm = 5.4016, lr_0 = 2.1679e-04
Validation rmse = 0.721873
Epoch 20
Loss = 1.8027e-01, PNorm = 44.3646, GNorm = 4.6083, lr_0 = 2.0884e-04
Loss = 2.0016e-01, PNorm = 44.3748, GNorm = 10.1934, lr_0 = 2.0117e-04
Loss = 3.0455e-01, PNorm = 44.3825, GNorm = 3.9252, lr_0 = 1.9379e-04
Loss = 9.9165e-02, PNorm = 44.3830, GNorm = 8.3465, lr_0 = 1.9307e-04
Validation rmse = 0.663976
Epoch 21
Loss = 2.3664e-01, PNorm = 44.3889, GNorm = 3.4624, lr_0 = 1.8599e-04
Loss = 2.1272e-01, PNorm = 44.3981, GNorm = 5.0116, lr_0 = 1.7916e-04
Validation rmse = 0.678770
Epoch 22
Loss = 1.8626e-01, PNorm = 44.4066, GNorm = 5.2679, lr_0 = 1.7195e-04
Loss = 2.5524e-01, PNorm = 44.4109, GNorm = 13.9967, lr_0 = 1.6564e-04
Validation rmse = 0.663836
Epoch 23
Loss = 2.0220e-01, PNorm = 44.4161, GNorm = 14.3424, lr_0 = 1.5956e-04
Loss = 2.0799e-01, PNorm = 44.4226, GNorm = 8.5424, lr_0 = 1.5371e-04
Validation rmse = 0.722598
Epoch 24
Loss = 3.1627e-01, PNorm = 44.4251, GNorm = 23.3325, lr_0 = 1.4751e-04
Loss = 2.6273e-01, PNorm = 44.4279, GNorm = 3.9830, lr_0 = 1.4210e-04
Loss = 1.8788e-01, PNorm = 44.4330, GNorm = 3.4034, lr_0 = 1.3689e-04
Validation rmse = 0.666381
Epoch 25
Loss = 1.9681e-01, PNorm = 44.4383, GNorm = 9.9563, lr_0 = 1.3187e-04
Loss = 1.9364e-01, PNorm = 44.4429, GNorm = 10.3337, lr_0 = 1.2703e-04
Validation rmse = 0.676696
Epoch 26
Loss = 1.5071e-01, PNorm = 44.4478, GNorm = 7.2146, lr_0 = 1.2191e-04
Loss = 2.3046e-01, PNorm = 44.4520, GNorm = 6.9193, lr_0 = 1.1744e-04
Validation rmse = 0.660740
Epoch 27
Loss = 1.6515e-01, PNorm = 44.4562, GNorm = 11.2805, lr_0 = 1.1271e-04
Loss = 2.1579e-01, PNorm = 44.4600, GNorm = 4.2751, lr_0 = 1.0857e-04
Validation rmse = 0.666464
Epoch 28
Loss = 5.8803e-02, PNorm = 44.4645, GNorm = 7.5013, lr_0 = 1.0459e-04
Loss = 1.4735e-01, PNorm = 44.4694, GNorm = 4.6117, lr_0 = 1.0075e-04
Validation rmse = 0.678272
Epoch 29
Loss = 1.6555e-01, PNorm = 44.4721, GNorm = 3.6459, lr_0 = 1.0000e-04
Loss = 2.0979e-01, PNorm = 44.4746, GNorm = 8.0968, lr_0 = 1.0000e-04
Loss = 1.1431e-01, PNorm = 44.4791, GNorm = 4.5841, lr_0 = 1.0000e-04
Validation rmse = 0.657866
Model 0 best validation rmse = 0.657866 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.593586
Ensemble test rmse = 0.593586
1-fold cross validation
	Seed 0 ==> test rmse = 0.593586
Overall test rmse = 0.593586 +/- 0.000000
Elapsed time = 0:01:56
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7788e+00, PNorm = 43.3119, GNorm = 1.5791, lr_0 = 3.1522e-04
Loss = 1.4698e+00, PNorm = 43.3173, GNorm = 0.9936, lr_0 = 5.1087e-04
Validation rmse = 1.676050
Epoch 1
Loss = 1.2998e+00, PNorm = 43.3390, GNorm = 1.1308, lr_0 = 7.2609e-04
Loss = 1.1836e+00, PNorm = 43.3757, GNorm = 2.3303, lr_0 = 9.2174e-04
Validation rmse = 1.242471
Epoch 2
Loss = 9.7769e-01, PNorm = 43.4403, GNorm = 3.1675, lr_0 = 9.7528e-04
Loss = 9.0680e-01, PNorm = 43.5115, GNorm = 1.6438, lr_0 = 9.4103e-04
Validation rmse = 1.116313
Epoch 3
Loss = 9.4452e-01, PNorm = 43.5868, GNorm = 12.9964, lr_0 = 9.0474e-04
Loss = 7.4275e-01, PNorm = 43.6438, GNorm = 3.3950, lr_0 = 8.7296e-04
Loss = 7.2757e-01, PNorm = 43.6910, GNorm = 12.6055, lr_0 = 8.4230e-04
Validation rmse = 0.891567
Epoch 4
Loss = 6.4244e-01, PNorm = 43.7365, GNorm = 1.6212, lr_0 = 8.0981e-04
Loss = 5.7508e-01, PNorm = 43.7734, GNorm = 3.6148, lr_0 = 7.8137e-04
Validation rmse = 0.855687
Epoch 5
Loss = 5.5526e-01, PNorm = 43.8074, GNorm = 6.8798, lr_0 = 7.5393e-04
Loss = 5.6400e-01, PNorm = 43.8431, GNorm = 3.1505, lr_0 = 7.2745e-04
Validation rmse = 0.823927
Epoch 6
Loss = 3.3178e-01, PNorm = 43.8823, GNorm = 6.6614, lr_0 = 6.9939e-04
Loss = 4.8679e-01, PNorm = 43.9162, GNorm = 11.1312, lr_0 = 6.7483e-04
Loss = 5.5698e-01, PNorm = 43.9440, GNorm = 7.1821, lr_0 = 6.5113e-04
Validation rmse = 0.818837
Epoch 7
Loss = 4.3799e-01, PNorm = 43.9789, GNorm = 6.3061, lr_0 = 6.2601e-04
Loss = 5.4579e-01, PNorm = 44.0032, GNorm = 2.1538, lr_0 = 6.0403e-04
Validation rmse = 0.768043
Epoch 8
Loss = 4.1628e-01, PNorm = 44.0344, GNorm = 4.4999, lr_0 = 5.8073e-04
Loss = 4.0468e-01, PNorm = 44.0549, GNorm = 6.8377, lr_0 = 5.6033e-04
Validation rmse = 0.751058
Epoch 9
Loss = 3.1676e-01, PNorm = 44.0791, GNorm = 2.1472, lr_0 = 5.3872e-04
Loss = 4.2230e-01, PNorm = 44.1021, GNorm = 3.0978, lr_0 = 5.1980e-04
Loss = 3.9626e-01, PNorm = 44.1245, GNorm = 10.4281, lr_0 = 5.0155e-04
Validation rmse = 0.801586
Epoch 10
Loss = 4.0481e-01, PNorm = 44.1386, GNorm = 2.7294, lr_0 = 4.8393e-04
Loss = 3.5924e-01, PNorm = 44.1549, GNorm = 6.4899, lr_0 = 4.6693e-04
Validation rmse = 0.731522
Epoch 11
Loss = 3.6970e-01, PNorm = 44.1712, GNorm = 5.5170, lr_0 = 4.4893e-04
Loss = 3.6780e-01, PNorm = 44.1874, GNorm = 1.7685, lr_0 = 4.3316e-04
Validation rmse = 0.776131
Epoch 12
Loss = 4.0540e-01, PNorm = 44.2059, GNorm = 7.2460, lr_0 = 4.1645e-04
Loss = 3.6195e-01, PNorm = 44.2232, GNorm = 2.4906, lr_0 = 4.0183e-04
Loss = 3.7887e-01, PNorm = 44.2369, GNorm = 7.4546, lr_0 = 3.8771e-04
Validation rmse = 0.711726
Epoch 13
Loss = 3.6303e-01, PNorm = 44.2501, GNorm = 2.3248, lr_0 = 3.7276e-04
Loss = 2.7638e-01, PNorm = 44.2661, GNorm = 4.3690, lr_0 = 3.5967e-04
Validation rmse = 0.714273
Epoch 14
Loss = 2.6955e-01, PNorm = 44.2808, GNorm = 4.6041, lr_0 = 3.4580e-04
Loss = 2.6762e-01, PNorm = 44.2948, GNorm = 3.8329, lr_0 = 3.3365e-04
Validation rmse = 0.708380
Epoch 15
Loss = 2.2681e-01, PNorm = 44.3059, GNorm = 12.1908, lr_0 = 3.2193e-04
Loss = 2.5735e-01, PNorm = 44.3169, GNorm = 2.7542, lr_0 = 3.1062e-04
Loss = 2.5445e-01, PNorm = 44.3312, GNorm = 14.5359, lr_0 = 2.9971e-04
Validation rmse = 0.711859
Epoch 16
Loss = 2.5314e-01, PNorm = 44.3379, GNorm = 6.4856, lr_0 = 2.8816e-04
Loss = 3.0750e-01, PNorm = 44.3479, GNorm = 5.4220, lr_0 = 2.7803e-04
Validation rmse = 0.703954
Epoch 17
Loss = 2.0185e-01, PNorm = 44.3567, GNorm = 3.0061, lr_0 = 2.6731e-04
Loss = 2.3389e-01, PNorm = 44.3666, GNorm = 2.8519, lr_0 = 2.5792e-04
Validation rmse = 0.698308
Epoch 18
Loss = 2.2145e-01, PNorm = 44.3778, GNorm = 5.3209, lr_0 = 2.4798e-04
Loss = 1.6058e-01, PNorm = 44.3876, GNorm = 2.9165, lr_0 = 2.3927e-04
Loss = 2.6479e-01, PNorm = 44.3943, GNorm = 2.4322, lr_0 = 2.3086e-04
Loss = -1.2943e-01, PNorm = 44.3952, GNorm = 5.7209, lr_0 = 2.3004e-04
Validation rmse = 0.701628
Epoch 19
Loss = 2.4693e-01, PNorm = 44.4043, GNorm = 4.5172, lr_0 = 2.2196e-04
Loss = 1.8427e-01, PNorm = 44.4106, GNorm = 5.9988, lr_0 = 2.1416e-04
Validation rmse = 0.702264
Epoch 20
Loss = 1.3208e-01, PNorm = 44.4205, GNorm = 6.1716, lr_0 = 2.0664e-04
Loss = 2.0557e-01, PNorm = 44.4269, GNorm = 7.6214, lr_0 = 1.9938e-04
Validation rmse = 0.693936
Epoch 21
Loss = 1.5764e-01, PNorm = 44.4341, GNorm = 2.3465, lr_0 = 1.9169e-04
Loss = 1.4757e-01, PNorm = 44.4441, GNorm = 13.0137, lr_0 = 1.8496e-04
Loss = 2.2446e-01, PNorm = 44.4476, GNorm = 13.3488, lr_0 = 1.7846e-04
Loss = 1.6720e-01, PNorm = 44.4481, GNorm = 9.9494, lr_0 = 1.7783e-04
Validation rmse = 0.685893
Epoch 22
Loss = 1.8557e-01, PNorm = 44.4552, GNorm = 9.8978, lr_0 = 1.7158e-04
Loss = 1.9026e-01, PNorm = 44.4623, GNorm = 6.0600, lr_0 = 1.6556e-04
Validation rmse = 0.692557
Epoch 23
Loss = 2.3693e-01, PNorm = 44.4669, GNorm = 8.0683, lr_0 = 1.5917e-04
Loss = 1.6495e-01, PNorm = 44.4712, GNorm = 3.1841, lr_0 = 1.5358e-04
Validation rmse = 0.683883
Epoch 24
Loss = 1.6104e-01, PNorm = 44.4782, GNorm = 4.0601, lr_0 = 1.4766e-04
Loss = 1.6875e-01, PNorm = 44.4846, GNorm = 7.6935, lr_0 = 1.4247e-04
Loss = 1.3084e-01, PNorm = 44.4878, GNorm = 5.0848, lr_0 = 1.3747e-04
Validation rmse = 0.694193
Epoch 25
Loss = 1.7511e-01, PNorm = 44.4924, GNorm = 3.6768, lr_0 = 1.3264e-04
Loss = 2.0901e-01, PNorm = 44.4957, GNorm = 14.2895, lr_0 = 1.2798e-04
Validation rmse = 0.707479
Epoch 26
Loss = 1.8012e-01, PNorm = 44.5006, GNorm = 4.5969, lr_0 = 1.2304e-04
Loss = 1.4799e-01, PNorm = 44.5067, GNorm = 11.2402, lr_0 = 1.1872e-04
Validation rmse = 0.681671
Epoch 27
Loss = 1.3361e-01, PNorm = 44.5122, GNorm = 3.4885, lr_0 = 1.1414e-04
Loss = 1.3723e-01, PNorm = 44.5151, GNorm = 10.8115, lr_0 = 1.1014e-04
Validation rmse = 0.704936
Epoch 28
Loss = 3.6884e-01, PNorm = 44.5196, GNorm = 10.0146, lr_0 = 1.0589e-04
Loss = 1.6530e-01, PNorm = 44.5225, GNorm = 8.3486, lr_0 = 1.0217e-04
Loss = 1.2495e-01, PNorm = 44.5258, GNorm = 7.5122, lr_0 = 1.0000e-04
Validation rmse = 0.682295
Epoch 29
Loss = 1.2775e-01, PNorm = 44.5319, GNorm = 5.0750, lr_0 = 1.0000e-04
Loss = 1.5949e-01, PNorm = 44.5351, GNorm = 9.1172, lr_0 = 1.0000e-04
Validation rmse = 0.684717
Model 0 best validation rmse = 0.681671 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.563177
Ensemble test rmse = 0.563177
1-fold cross validation
	Seed 0 ==> test rmse = 0.563177
Overall test rmse = 0.563177 +/- 0.000000
Elapsed time = 0:01:59
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7699e+00, PNorm = 43.3109, GNorm = 1.1765, lr_0 = 3.0625e-04
Loss = 1.4646e+00, PNorm = 43.3146, GNorm = 1.8033, lr_0 = 4.9375e-04
Validation rmse = 1.737738
Epoch 1
Loss = 1.3110e+00, PNorm = 43.3299, GNorm = 0.9396, lr_0 = 6.8125e-04
Loss = 1.1884e+00, PNorm = 43.3647, GNorm = 1.2901, lr_0 = 8.6875e-04
Validation rmse = 1.221637
Epoch 2
Loss = 9.2131e-01, PNorm = 43.4348, GNorm = 1.3840, lr_0 = 9.8977e-04
Loss = 9.1091e-01, PNorm = 43.5118, GNorm = 5.5642, lr_0 = 9.5643e-04
Loss = 7.7597e-01, PNorm = 43.5840, GNorm = 5.3576, lr_0 = 9.2422e-04
Validation rmse = 0.881673
Epoch 3
Loss = 6.4471e-01, PNorm = 43.6454, GNorm = 7.1622, lr_0 = 8.9309e-04
Loss = 6.9773e-01, PNorm = 43.7023, GNorm = 3.4859, lr_0 = 8.6300e-04
Validation rmse = 0.834535
Epoch 4
Loss = 6.5880e-01, PNorm = 43.7485, GNorm = 7.0036, lr_0 = 8.3393e-04
Loss = 6.1755e-01, PNorm = 43.7837, GNorm = 12.7507, lr_0 = 8.0584e-04
Loss = 5.8967e-01, PNorm = 43.8228, GNorm = 2.0790, lr_0 = 7.7870e-04
Validation rmse = 0.802428
Epoch 5
Loss = 4.6500e-01, PNorm = 43.8653, GNorm = 5.3295, lr_0 = 7.5247e-04
Loss = 5.2794e-01, PNorm = 43.8889, GNorm = 3.2928, lr_0 = 7.2712e-04
Validation rmse = 0.763450
Epoch 6
Loss = 5.2254e-01, PNorm = 43.9192, GNorm = 5.4488, lr_0 = 7.0263e-04
Loss = 4.7944e-01, PNorm = 43.9498, GNorm = 2.1290, lr_0 = 6.7896e-04
Validation rmse = 0.751100
Epoch 7
Loss = 3.3240e-01, PNorm = 43.9820, GNorm = 6.8919, lr_0 = 6.5609e-04
Loss = 4.4201e-01, PNorm = 44.0096, GNorm = 2.9469, lr_0 = 6.3399e-04
Loss = 4.4244e-01, PNorm = 44.0375, GNorm = 4.6558, lr_0 = 6.1264e-04
Validation rmse = 0.735847
Epoch 8
Loss = 4.2017e-01, PNorm = 44.0585, GNorm = 5.4215, lr_0 = 5.9200e-04
Loss = 3.8769e-01, PNorm = 44.0887, GNorm = 6.9285, lr_0 = 5.7206e-04
Validation rmse = 0.713272
Epoch 9
Loss = 2.9972e-01, PNorm = 44.1052, GNorm = 2.2723, lr_0 = 5.5279e-04
Loss = 3.4566e-01, PNorm = 44.1259, GNorm = 3.1034, lr_0 = 5.3417e-04
Loss = 3.8221e-01, PNorm = 44.1500, GNorm = 9.2258, lr_0 = 5.1618e-04
Validation rmse = 0.719456
Epoch 10
Loss = 4.0323e-01, PNorm = 44.1690, GNorm = 7.2955, lr_0 = 4.9879e-04
Loss = 3.5144e-01, PNorm = 44.1868, GNorm = 7.3131, lr_0 = 4.8199e-04
Validation rmse = 0.688127
Epoch 11
Loss = 3.5829e-01, PNorm = 44.2099, GNorm = 10.0861, lr_0 = 4.6575e-04
Loss = 3.4092e-01, PNorm = 44.2235, GNorm = 5.3078, lr_0 = 4.5006e-04
Validation rmse = 0.680392
Epoch 12
Loss = 2.0242e-01, PNorm = 44.2425, GNorm = 10.9912, lr_0 = 4.3490e-04
Loss = 3.1939e-01, PNorm = 44.2629, GNorm = 3.1306, lr_0 = 4.2025e-04
Loss = 2.6972e-01, PNorm = 44.2740, GNorm = 2.4380, lr_0 = 4.0610e-04
Validation rmse = 0.694297
Epoch 13
Loss = 2.3834e-01, PNorm = 44.2897, GNorm = 3.1184, lr_0 = 3.9242e-04
Loss = 3.2919e-01, PNorm = 44.3068, GNorm = 13.5878, lr_0 = 3.7920e-04
Validation rmse = 0.681353
Epoch 14
Loss = 2.4743e-01, PNorm = 44.3211, GNorm = 8.9158, lr_0 = 3.6643e-04
Loss = 2.8065e-01, PNorm = 44.3347, GNorm = 9.3548, lr_0 = 3.5408e-04
Loss = 3.6435e-01, PNorm = 44.3449, GNorm = 5.8554, lr_0 = 3.4216e-04
Validation rmse = 0.695131
Epoch 15
Loss = 2.2396e-01, PNorm = 44.3609, GNorm = 4.0023, lr_0 = 3.3063e-04
Loss = 2.5883e-01, PNorm = 44.3761, GNorm = 5.7808, lr_0 = 3.1950e-04
Validation rmse = 0.692970
Epoch 16
Loss = 2.3668e-01, PNorm = 44.3850, GNorm = 4.1654, lr_0 = 3.0873e-04
Loss = 1.8762e-01, PNorm = 44.3975, GNorm = 5.8729, lr_0 = 2.9833e-04
Validation rmse = 0.778078
Epoch 17
Loss = 3.6658e-01, PNorm = 44.4067, GNorm = 10.2006, lr_0 = 2.8828e-04
Loss = 2.3590e-01, PNorm = 44.4179, GNorm = 5.1147, lr_0 = 2.7857e-04
Loss = 1.9840e-01, PNorm = 44.4267, GNorm = 8.4581, lr_0 = 2.6919e-04
Validation rmse = 0.685761
Epoch 18
Loss = 2.3250e-01, PNorm = 44.4375, GNorm = 12.4219, lr_0 = 2.6012e-04
Loss = 2.0866e-01, PNorm = 44.4479, GNorm = 7.9165, lr_0 = 2.5136e-04
Validation rmse = 0.673633
Epoch 19
Loss = 1.0128e-01, PNorm = 44.4583, GNorm = 7.9536, lr_0 = 2.4289e-04
Loss = 2.0075e-01, PNorm = 44.4679, GNorm = 3.9713, lr_0 = 2.3471e-04
Loss = 2.7284e-01, PNorm = 44.4725, GNorm = 12.6294, lr_0 = 2.2681e-04
Validation rmse = 0.689055
Epoch 20
Loss = 1.9007e-01, PNorm = 44.4812, GNorm = 7.0866, lr_0 = 2.1917e-04
Loss = 1.7075e-01, PNorm = 44.4895, GNorm = 8.2284, lr_0 = 2.1178e-04
Validation rmse = 0.674435
Epoch 21
Loss = 1.7648e-01, PNorm = 44.4948, GNorm = 11.7467, lr_0 = 2.0465e-04
Loss = 2.1863e-01, PNorm = 44.5003, GNorm = 5.3178, lr_0 = 1.9776e-04
Validation rmse = 0.683222
Epoch 22
Loss = 1.0196e-01, PNorm = 44.5090, GNorm = 3.8679, lr_0 = 1.9110e-04
Loss = 1.8407e-01, PNorm = 44.5153, GNorm = 15.0899, lr_0 = 1.8466e-04
Loss = 1.8327e-01, PNorm = 44.5232, GNorm = 8.4462, lr_0 = 1.7844e-04
Validation rmse = 0.736742
Epoch 23
Loss = 1.4908e-01, PNorm = 44.5293, GNorm = 7.7031, lr_0 = 1.7243e-04
Loss = 1.5148e-01, PNorm = 44.5362, GNorm = 8.5437, lr_0 = 1.6662e-04
Validation rmse = 0.672645
Epoch 24
Loss = 1.6837e-01, PNorm = 44.5415, GNorm = 5.9078, lr_0 = 1.6101e-04
Loss = 7.6367e-02, PNorm = 44.5487, GNorm = 2.9065, lr_0 = 1.5558e-04
Loss = 1.9590e-01, PNorm = 44.5534, GNorm = 3.8087, lr_0 = 1.5034e-04
Validation rmse = 0.674080
Epoch 25
Loss = 1.3111e-01, PNorm = 44.5587, GNorm = 2.9852, lr_0 = 1.4528e-04
Loss = 1.3019e-01, PNorm = 44.5641, GNorm = 5.4209, lr_0 = 1.4039e-04
Validation rmse = 0.657388
Epoch 26
Loss = 1.2351e-01, PNorm = 44.5686, GNorm = 7.1784, lr_0 = 1.3566e-04
Loss = 1.3172e-01, PNorm = 44.5747, GNorm = 8.7683, lr_0 = 1.3109e-04
Validation rmse = 0.676833
Epoch 27
Loss = 2.0790e-01, PNorm = 44.5790, GNorm = 3.5387, lr_0 = 1.2667e-04
Loss = 1.3063e-01, PNorm = 44.5838, GNorm = 7.4707, lr_0 = 1.2240e-04
Loss = 1.0914e-01, PNorm = 44.5878, GNorm = 4.8585, lr_0 = 1.1828e-04
Validation rmse = 0.655256
Epoch 28
Loss = 3.4240e-02, PNorm = 44.5935, GNorm = 3.4871, lr_0 = 1.1430e-04
Loss = 1.6366e-01, PNorm = 44.5965, GNorm = 6.1849, lr_0 = 1.1045e-04
Validation rmse = 0.658160
Epoch 29
Loss = 5.3526e-02, PNorm = 44.6005, GNorm = 8.7984, lr_0 = 1.0673e-04
Loss = 1.3475e-01, PNorm = 44.6054, GNorm = 6.4212, lr_0 = 1.0313e-04
Loss = 1.3355e-01, PNorm = 44.6090, GNorm = 6.1038, lr_0 = 1.0000e-04
Validation rmse = 0.674744
Model 0 best validation rmse = 0.655256 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.623751
Ensemble test rmse = 0.623751
1-fold cross validation
	Seed 0 ==> test rmse = 0.623751
Overall test rmse = 0.623751 +/- 0.000000
Elapsed time = 0:02:04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.430129
Epoch 1
Loss = 1.4729e+00, PNorm = 43.3163, GNorm = 1.4697, lr_0 = 7.1875e-04
Validation rmse = 1.305232
Epoch 2
Loss = 1.4167e+00, PNorm = 43.3526, GNorm = 0.8070, lr_0 = 9.4990e-04
Validation rmse = 1.274560
Epoch 3
Loss = 1.3222e+00, PNorm = 43.3945, GNorm = 0.5360, lr_0 = 8.5711e-04
Validation rmse = 1.228403
Epoch 4
Loss = 1.2736e+00, PNorm = 43.4401, GNorm = 1.4101, lr_0 = 7.7338e-04
Validation rmse = 1.207169
Epoch 5
Validation rmse = 1.129259
Epoch 6
Loss = 1.1092e+00, PNorm = 43.4992, GNorm = 0.7196, lr_0 = 6.9783e-04
Validation rmse = 1.073949
Epoch 7
Loss = 1.0576e+00, PNorm = 43.5676, GNorm = 0.7007, lr_0 = 6.2966e-04
Validation rmse = 1.019643
Epoch 8
Loss = 9.8360e-01, PNorm = 43.6303, GNorm = 1.0343, lr_0 = 5.6815e-04
Validation rmse = 0.963619
Epoch 9
Loss = 9.2640e-01, PNorm = 43.6729, GNorm = 1.0496, lr_0 = 5.1265e-04
Validation rmse = 0.956284
Epoch 10
Validation rmse = 0.952532
Epoch 11
Loss = 7.9366e-01, PNorm = 43.7123, GNorm = 2.5750, lr_0 = 4.6257e-04
Validation rmse = 0.905119
Epoch 12
Loss = 8.4204e-01, PNorm = 43.7450, GNorm = 7.4677, lr_0 = 4.1738e-04
Validation rmse = 0.880085
Epoch 13
Loss = 7.4750e-01, PNorm = 43.7766, GNorm = 1.7510, lr_0 = 3.7661e-04
Validation rmse = 0.892847
Epoch 14
Loss = 7.4997e-01, PNorm = 43.8069, GNorm = 7.0905, lr_0 = 3.3982e-04
Validation rmse = 0.883490
Epoch 15
Validation rmse = 0.846675
Epoch 16
Loss = 6.9670e-01, PNorm = 43.8345, GNorm = 2.0375, lr_0 = 3.0662e-04
Validation rmse = 0.880337
Epoch 17
Loss = 7.1292e-01, PNorm = 43.8571, GNorm = 3.9732, lr_0 = 2.7667e-04
Validation rmse = 0.884770
Epoch 18
Loss = 7.2048e-01, PNorm = 43.8786, GNorm = 7.6378, lr_0 = 2.4964e-04
Validation rmse = 0.831570
Epoch 19
Loss = 6.6107e-01, PNorm = 43.8979, GNorm = 2.7116, lr_0 = 2.2526e-04
Validation rmse = 0.827333
Epoch 20
Validation rmse = 0.827319
Epoch 21
Loss = 7.2312e-01, PNorm = 43.9161, GNorm = 2.4504, lr_0 = 2.0325e-04
Validation rmse = 0.839797
Epoch 22
Loss = 6.5561e-01, PNorm = 43.9316, GNorm = 3.7146, lr_0 = 1.8340e-04
Validation rmse = 0.826001
Epoch 23
Loss = 5.9096e-01, PNorm = 43.9466, GNorm = 4.5747, lr_0 = 1.6548e-04
Validation rmse = 0.814335
Epoch 24
Loss = 5.9443e-01, PNorm = 43.9612, GNorm = 2.2518, lr_0 = 1.4932e-04
Validation rmse = 0.812560
Epoch 25
Validation rmse = 0.813398
Epoch 26
Loss = 6.1769e-01, PNorm = 43.9730, GNorm = 3.2721, lr_0 = 1.3473e-04
Validation rmse = 0.804567
Epoch 27
Loss = 6.3631e-01, PNorm = 43.9841, GNorm = 7.4136, lr_0 = 1.2157e-04
Validation rmse = 0.805143
Epoch 28
Loss = 5.9795e-01, PNorm = 43.9933, GNorm = 3.8433, lr_0 = 1.0969e-04
Validation rmse = 0.815674
Epoch 29
Loss = 5.7537e-01, PNorm = 44.0020, GNorm = 4.7596, lr_0 = 1.0000e-04
Validation rmse = 0.826983
Model 0 best validation rmse = 0.804567 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.733009
Ensemble test rmse = 0.733009
1-fold cross validation
	Seed 0 ==> test rmse = 0.733009
Overall test rmse = 0.733009 +/- 0.000000
Elapsed time = 0:01:32
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.487184
Epoch 1
Loss = 1.5142e+00, PNorm = 43.3209, GNorm = 1.2275, lr_0 = 7.7500e-04
Validation rmse = 1.405159
Epoch 2
Loss = 1.3597e+00, PNorm = 43.3678, GNorm = 0.9037, lr_0 = 9.4019e-04
Validation rmse = 1.349136
Epoch 3
Loss = 1.2467e+00, PNorm = 43.4221, GNorm = 2.2692, lr_0 = 8.4834e-04
Validation rmse = 1.220149
Epoch 4
Loss = 1.1499e+00, PNorm = 43.4736, GNorm = 0.9244, lr_0 = 7.6547e-04
Validation rmse = 1.094308
Epoch 5
Loss = 1.0519e+00, PNorm = 43.5330, GNorm = 0.9433, lr_0 = 6.9069e-04
Validation rmse = 0.969865
Epoch 6
Loss = 9.3739e-01, PNorm = 43.5948, GNorm = 1.2887, lr_0 = 6.1685e-04
Validation rmse = 1.078371
Epoch 7
Loss = 8.4285e-01, PNorm = 43.6435, GNorm = 3.4215, lr_0 = 5.5659e-04
Validation rmse = 0.853448
Epoch 8
Validation rmse = 0.857513
Epoch 9
Loss = 7.0242e-01, PNorm = 43.6827, GNorm = 5.3116, lr_0 = 5.0222e-04
Validation rmse = 0.893583
Epoch 10
Loss = 6.8316e-01, PNorm = 43.7187, GNorm = 5.6794, lr_0 = 4.5316e-04
Validation rmse = 0.793576
Epoch 11
Loss = 6.6949e-01, PNorm = 43.7542, GNorm = 7.4753, lr_0 = 4.0471e-04
Validation rmse = 0.874091
Epoch 12
Loss = 6.5903e-01, PNorm = 43.7797, GNorm = 7.1296, lr_0 = 3.6517e-04
Validation rmse = 0.857311
Epoch 13
Loss = 5.7437e-01, PNorm = 43.8044, GNorm = 1.7638, lr_0 = 3.2950e-04
Validation rmse = 0.762778
Epoch 14
Loss = 5.9363e-01, PNorm = 43.8262, GNorm = 4.3358, lr_0 = 2.9731e-04
Validation rmse = 0.756925
Epoch 15
Loss = 5.2975e-01, PNorm = 43.8480, GNorm = 3.2951, lr_0 = 2.6827e-04
Loss = 7.7573e-01, PNorm = 43.8497, GNorm = 5.8403, lr_0 = 2.6553e-04
Validation rmse = 0.782128
Epoch 16
Validation rmse = 0.773349
Epoch 17
Loss = 5.3698e-01, PNorm = 43.8660, GNorm = 1.3552, lr_0 = 2.3959e-04
Validation rmse = 0.741351
Epoch 18
Loss = 5.1486e-01, PNorm = 43.8817, GNorm = 9.7778, lr_0 = 2.1618e-04
Validation rmse = 0.725824
Epoch 19
Loss = 5.4055e-01, PNorm = 43.8958, GNorm = 3.1643, lr_0 = 1.9506e-04
Validation rmse = 0.727230
Epoch 20
Loss = 4.8519e-01, PNorm = 43.9087, GNorm = 1.6043, lr_0 = 1.7601e-04
Validation rmse = 0.728196
Epoch 21
Loss = 4.9142e-01, PNorm = 43.9208, GNorm = 3.0662, lr_0 = 1.5719e-04
Validation rmse = 0.724831
Epoch 22
Loss = 4.4576e-01, PNorm = 43.9324, GNorm = 2.1352, lr_0 = 1.4184e-04
Validation rmse = 0.717797
Epoch 23
Loss = 4.6106e-01, PNorm = 43.9410, GNorm = 3.4541, lr_0 = 1.2798e-04
Validation rmse = 0.716810
Epoch 24
Loss = 4.5223e-01, PNorm = 43.9489, GNorm = 4.1375, lr_0 = 1.1548e-04
Validation rmse = 0.721097
Epoch 25
Validation rmse = 0.751939
Epoch 26
Loss = 4.7485e-01, PNorm = 43.9573, GNorm = 6.4778, lr_0 = 1.0313e-04
Validation rmse = 0.745773
Epoch 27
Loss = 4.4507e-01, PNorm = 43.9637, GNorm = 4.3602, lr_0 = 1.0000e-04
Validation rmse = 0.710099
Epoch 28
Loss = 4.4059e-01, PNorm = 43.9708, GNorm = 4.7756, lr_0 = 1.0000e-04
Validation rmse = 0.705778
Epoch 29
Loss = 4.0590e-01, PNorm = 43.9769, GNorm = 10.9235, lr_0 = 1.0000e-04
Validation rmse = 0.708839
Model 0 best validation rmse = 0.705778 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.700424
Ensemble test rmse = 0.700424
1-fold cross validation
	Seed 0 ==> test rmse = 0.700424
Overall test rmse = 0.700424 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.548808
Epoch 1
Loss = 1.4914e+00, PNorm = 43.3221, GNorm = 1.4289, lr_0 = 7.0000e-04
Validation rmse = 1.493329
Epoch 2
Loss = 1.3161e+00, PNorm = 43.3662, GNorm = 1.0735, lr_0 = 9.6411e-04
Validation rmse = 1.341083
Epoch 3
Loss = 1.1866e+00, PNorm = 43.4322, GNorm = 1.6028, lr_0 = 8.7192e-04
Validation rmse = 1.244296
Epoch 4
Loss = 1.1323e+00, PNorm = 43.4918, GNorm = 4.0651, lr_0 = 7.9578e-04
Validation rmse = 1.034808
Epoch 5
Loss = 9.0890e-01, PNorm = 43.5504, GNorm = 3.3187, lr_0 = 7.2629e-04
Validation rmse = 0.924586
Epoch 6
Loss = 8.1224e-01, PNorm = 43.6185, GNorm = 1.0714, lr_0 = 6.5684e-04
Validation rmse = 0.923237
Epoch 7
Loss = 7.7867e-01, PNorm = 43.6736, GNorm = 2.9857, lr_0 = 5.9948e-04
Validation rmse = 0.924392
Epoch 8
Loss = 6.8480e-01, PNorm = 43.7214, GNorm = 3.3636, lr_0 = 5.4216e-04
Validation rmse = 0.805985
Epoch 9
Loss = 5.8840e-01, PNorm = 43.7615, GNorm = 5.3526, lr_0 = 4.9482e-04
Validation rmse = 0.790447
Epoch 10
Loss = 5.6721e-01, PNorm = 43.7898, GNorm = 5.1783, lr_0 = 4.5161e-04
Validation rmse = 0.774986
Epoch 11
Loss = 5.1595e-01, PNorm = 43.8243, GNorm = 2.1214, lr_0 = 4.0842e-04
Validation rmse = 0.763756
Epoch 12
Loss = 5.1250e-01, PNorm = 43.8501, GNorm = 3.2430, lr_0 = 3.7276e-04
Validation rmse = 0.745665
Epoch 13
Loss = 4.9254e-01, PNorm = 43.8749, GNorm = 3.6244, lr_0 = 3.3711e-04
Validation rmse = 0.746055
Epoch 14
Loss = 4.8182e-01, PNorm = 43.8975, GNorm = 2.7830, lr_0 = 3.0768e-04
Validation rmse = 0.727002
Epoch 15
Loss = 4.7518e-01, PNorm = 43.9169, GNorm = 10.1581, lr_0 = 2.8081e-04
Validation rmse = 0.730685
Epoch 16
Loss = 4.8065e-01, PNorm = 43.9370, GNorm = 4.1684, lr_0 = 2.5396e-04
Validation rmse = 0.718690
Epoch 17
Loss = 4.0837e-01, PNorm = 43.9527, GNorm = 2.5882, lr_0 = 2.3178e-04
Validation rmse = 0.723981
Epoch 18
Loss = 4.2989e-01, PNorm = 43.9687, GNorm = 2.8198, lr_0 = 2.0962e-04
Validation rmse = 0.721564
Epoch 19
Loss = 3.9617e-01, PNorm = 43.9828, GNorm = 3.5166, lr_0 = 1.9131e-04
Validation rmse = 0.722172
Epoch 20
Loss = 4.0967e-01, PNorm = 43.9933, GNorm = 7.2742, lr_0 = 1.7461e-04
Validation rmse = 0.730486
Epoch 21
Loss = 4.1537e-01, PNorm = 44.0054, GNorm = 4.4643, lr_0 = 1.5791e-04
Validation rmse = 0.725716
Epoch 22
Loss = 3.9547e-01, PNorm = 44.0152, GNorm = 6.8529, lr_0 = 1.4412e-04
Loss = 2.6033e-01, PNorm = 44.0160, GNorm = 7.7318, lr_0 = 1.4281e-04
Validation rmse = 0.719261
Epoch 23
Loss = 3.9168e-01, PNorm = 44.0247, GNorm = 6.3792, lr_0 = 1.3034e-04
Validation rmse = 0.731458
Epoch 24
Loss = 3.7622e-01, PNorm = 44.0326, GNorm = 3.1502, lr_0 = 1.1896e-04
Validation rmse = 0.721148
Epoch 25
Validation rmse = 0.713474
Epoch 26
Loss = 4.0821e-01, PNorm = 44.0400, GNorm = 1.7699, lr_0 = 1.0758e-04
Validation rmse = 0.711200
Epoch 27
Loss = 3.9950e-01, PNorm = 44.0464, GNorm = 3.8247, lr_0 = 1.0000e-04
Validation rmse = 0.711845
Epoch 28
Loss = 3.7066e-01, PNorm = 44.0535, GNorm = 2.1462, lr_0 = 1.0000e-04
Validation rmse = 0.713616
Epoch 29
Loss = 3.0219e-01, PNorm = 44.0595, GNorm = 2.2272, lr_0 = 1.0000e-04
Validation rmse = 0.710606
Model 0 best validation rmse = 0.710606 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.668846
Ensemble test rmse = 0.668846
1-fold cross validation
	Seed 0 ==> test rmse = 0.668846
Overall test rmse = 0.668846 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8611e+00, PNorm = 43.3178, GNorm = 2.6313, lr_0 = 5.9500e-04
Loss = 1.5059e+00, PNorm = 43.3194, GNorm = 3.1172, lr_0 = 6.4000e-04
Validation rmse = 1.731109
Epoch 1
Loss = 1.4436e+00, PNorm = 43.3537, GNorm = 0.8634, lr_0 = 9.8369e-04
Loss = 1.2555e+00, PNorm = 43.3591, GNorm = 1.0716, lr_0 = 9.7563e-04
Validation rmse = 1.633929
Epoch 2
Loss = 1.2332e+00, PNorm = 43.4160, GNorm = 1.1041, lr_0 = 8.9861e-04
Validation rmse = 1.514073
Epoch 3
Loss = 1.0910e+00, PNorm = 43.4769, GNorm = 1.2155, lr_0 = 8.2767e-04
Validation rmse = 1.335469
Epoch 4
Loss = 9.5392e-01, PNorm = 43.5530, GNorm = 1.7295, lr_0 = 7.5609e-04
Validation rmse = 1.133089
Epoch 5
Loss = 8.0161e-01, PNorm = 43.6190, GNorm = 3.0853, lr_0 = 6.9640e-04
Validation rmse = 1.029948
Epoch 6
Loss = 6.9182e-01, PNorm = 43.6801, GNorm = 3.7367, lr_0 = 6.3617e-04
Validation rmse = 1.018941
Epoch 7
Loss = 6.7841e-01, PNorm = 43.7240, GNorm = 2.2885, lr_0 = 5.8115e-04
Validation rmse = 0.964385
Epoch 8
Loss = 5.7647e-01, PNorm = 43.7629, GNorm = 2.9566, lr_0 = 5.3527e-04
Validation rmse = 0.999793
Epoch 9
Loss = 5.8746e-01, PNorm = 43.7925, GNorm = 2.9150, lr_0 = 4.8897e-04
Validation rmse = 0.947721
Epoch 10
Loss = 5.0352e-01, PNorm = 43.8235, GNorm = 1.9178, lr_0 = 4.5037e-04
Validation rmse = 0.922280
Epoch 11
Loss = 4.9714e-01, PNorm = 43.8520, GNorm = 2.9063, lr_0 = 4.1142e-04
Validation rmse = 0.891271
Epoch 12
Loss = 4.5033e-01, PNorm = 43.8768, GNorm = 1.7578, lr_0 = 3.7584e-04
Validation rmse = 0.898116
Epoch 13
Loss = 4.4950e-01, PNorm = 43.8958, GNorm = 7.9389, lr_0 = 3.4617e-04
Validation rmse = 0.891862
Epoch 14
Loss = 4.1227e-01, PNorm = 43.9170, GNorm = 6.8374, lr_0 = 3.1623e-04
Validation rmse = 0.914951
Epoch 15
Loss = 4.3112e-01, PNorm = 43.9353, GNorm = 8.9595, lr_0 = 2.9126e-04
Validation rmse = 0.875736
Epoch 16
Loss = 3.9248e-01, PNorm = 43.9544, GNorm = 3.6401, lr_0 = 2.6607e-04
Validation rmse = 0.882888
Epoch 17
Loss = 3.6046e-01, PNorm = 43.9697, GNorm = 5.0989, lr_0 = 2.4306e-04
Validation rmse = 0.881635
Epoch 18
Loss = 3.4252e-01, PNorm = 43.9840, GNorm = 2.6381, lr_0 = 2.2387e-04
Validation rmse = 0.879212
Epoch 19
Loss = 3.9101e-01, PNorm = 43.9986, GNorm = 2.8468, lr_0 = 2.0451e-04
Validation rmse = 0.863853
Epoch 20
Loss = 3.6124e-01, PNorm = 44.0096, GNorm = 2.9365, lr_0 = 1.8836e-04
Validation rmse = 0.866833
Epoch 21
Loss = 3.2031e-01, PNorm = 44.0211, GNorm = 2.6931, lr_0 = 1.7207e-04
Validation rmse = 0.882861
Epoch 22
Loss = 3.6847e-01, PNorm = 44.0314, GNorm = 3.8534, lr_0 = 1.5719e-04
Validation rmse = 0.861381
Epoch 23
Loss = 2.3021e-01, PNorm = 44.0403, GNorm = 2.5782, lr_0 = 1.4478e-04
Validation rmse = 0.865705
Epoch 24
Loss = 4.2200e-01, PNorm = 44.0484, GNorm = 6.9376, lr_0 = 1.3226e-04
Loss = 3.1295e-01, PNorm = 44.0551, GNorm = 9.7551, lr_0 = 1.2182e-04
Validation rmse = 0.859890
Epoch 25
Loss = 3.0030e-01, PNorm = 44.0623, GNorm = 6.3147, lr_0 = 1.1220e-04
Loss = 2.8637e-01, PNorm = 44.0629, GNorm = 5.5191, lr_0 = 1.1128e-04
Validation rmse = 0.850759
Epoch 26
Loss = 3.0611e-01, PNorm = 44.0680, GNorm = 13.1133, lr_0 = 1.0250e-04
Loss = 3.7397e-01, PNorm = 44.0685, GNorm = 5.6465, lr_0 = 1.0166e-04
Validation rmse = 0.862030
Epoch 27
Loss = 2.9962e-01, PNorm = 44.0741, GNorm = 3.3010, lr_0 = 1.0000e-04
Validation rmse = 0.858104
Epoch 28
Loss = 2.9253e-01, PNorm = 44.0796, GNorm = 13.2237, lr_0 = 1.0000e-04
Validation rmse = 0.854476
Epoch 29
Loss = 3.1245e-01, PNorm = 44.0852, GNorm = 3.4654, lr_0 = 1.0000e-04
Validation rmse = 0.852200
Model 0 best validation rmse = 0.850759 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.632166
Ensemble test rmse = 0.632166
1-fold cross validation
	Seed 0 ==> test rmse = 0.632166
Overall test rmse = 0.632166 +/- 0.000000
Elapsed time = 0:01:55
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8507e+00, PNorm = 43.3168, GNorm = 1.7235, lr_0 = 5.5000e-04
Validation rmse = 1.550216
Epoch 1
Loss = 1.4335e+00, PNorm = 43.3487, GNorm = 0.9518, lr_0 = 1.0000e-03
Validation rmse = 1.484451
Epoch 2
Loss = 1.2156e+00, PNorm = 43.4122, GNorm = 1.6606, lr_0 = 9.2106e-04
Validation rmse = 1.297930
Epoch 3
Loss = 1.0570e+00, PNorm = 43.4785, GNorm = 1.6639, lr_0 = 8.4834e-04
Validation rmse = 1.185068
Epoch 4
Loss = 9.2458e-01, PNorm = 43.5550, GNorm = 2.3387, lr_0 = 7.8137e-04
Validation rmse = 1.019223
Epoch 5
Loss = 7.9495e-01, PNorm = 43.6186, GNorm = 4.8104, lr_0 = 7.2509e-04
Validation rmse = 0.949819
Epoch 6
Loss = 6.9272e-01, PNorm = 43.6763, GNorm = 3.9644, lr_0 = 6.6784e-04
Validation rmse = 0.939269
Epoch 7
Loss = 6.6460e-01, PNorm = 43.7234, GNorm = 5.1954, lr_0 = 6.1512e-04
Validation rmse = 0.908710
Epoch 8
Loss = 5.0461e-01, PNorm = 43.7661, GNorm = 2.7577, lr_0 = 5.6656e-04
Loss = 5.9724e-01, PNorm = 43.7973, GNorm = 6.4183, lr_0 = 5.2575e-04
Loss = 4.5664e-01, PNorm = 43.8010, GNorm = 2.8356, lr_0 = 5.2183e-04
Validation rmse = 0.902504
Epoch 9
Loss = 5.4254e-01, PNorm = 43.8328, GNorm = 5.8959, lr_0 = 4.8424e-04
Validation rmse = 0.953200
Epoch 10
Loss = 5.3464e-01, PNorm = 43.8569, GNorm = 7.5408, lr_0 = 4.4936e-04
Validation rmse = 0.879945
Epoch 11
Loss = 4.4368e-01, PNorm = 43.8814, GNorm = 5.4853, lr_0 = 4.1389e-04
Validation rmse = 0.881436
Epoch 12
Loss = 4.7264e-01, PNorm = 43.9045, GNorm = 1.5262, lr_0 = 3.8121e-04
Validation rmse = 0.852271
Epoch 13
Loss = 4.5124e-01, PNorm = 43.9268, GNorm = 6.1039, lr_0 = 3.5112e-04
Validation rmse = 0.876249
Epoch 14
Loss = 4.2052e-01, PNorm = 43.9484, GNorm = 6.7295, lr_0 = 3.2340e-04
Validation rmse = 0.854547
Epoch 15
Loss = 4.2863e-01, PNorm = 43.9649, GNorm = 1.5059, lr_0 = 3.0010e-04
Validation rmse = 0.861653
Epoch 16
Loss = 3.8520e-01, PNorm = 43.9820, GNorm = 2.0972, lr_0 = 2.7641e-04
Loss = 3.8237e-01, PNorm = 43.9943, GNorm = 3.7336, lr_0 = 2.5650e-04
Loss = 4.1390e-01, PNorm = 43.9957, GNorm = 15.3952, lr_0 = 2.5459e-04
Validation rmse = 0.868597
Epoch 17
Loss = 4.0806e-01, PNorm = 44.0088, GNorm = 4.0999, lr_0 = 2.3625e-04
Validation rmse = 0.856197
Epoch 18
Loss = 3.6530e-01, PNorm = 44.0218, GNorm = 4.5303, lr_0 = 2.1760e-04
Validation rmse = 0.846748
Epoch 19
Loss = 3.6218e-01, PNorm = 44.0323, GNorm = 2.1104, lr_0 = 2.0042e-04
Validation rmse = 0.848752
Epoch 20
Loss = 3.4034e-01, PNorm = 44.0427, GNorm = 2.7773, lr_0 = 1.8599e-04
Validation rmse = 0.841371
Epoch 21
Loss = 2.9645e-01, PNorm = 44.0527, GNorm = 3.4381, lr_0 = 1.7130e-04
Validation rmse = 0.851254
Epoch 22
Loss = 2.9043e-01, PNorm = 44.0629, GNorm = 4.6301, lr_0 = 1.5778e-04
Validation rmse = 0.846291
Epoch 23
Loss = 3.5144e-01, PNorm = 44.0690, GNorm = 10.1248, lr_0 = 1.4532e-04
Validation rmse = 0.845353
Epoch 24
Loss = 2.7734e-01, PNorm = 44.0765, GNorm = 2.1315, lr_0 = 1.3385e-04
Loss = 3.1702e-01, PNorm = 44.0839, GNorm = 6.0811, lr_0 = 1.2421e-04
Validation rmse = 0.848346
Epoch 25
Loss = 3.2191e-01, PNorm = 44.0895, GNorm = 4.4125, lr_0 = 1.1526e-04
Validation rmse = 0.842632
Epoch 26
Loss = 3.0788e-01, PNorm = 44.0957, GNorm = 3.8919, lr_0 = 1.0616e-04
Validation rmse = 0.857171
Epoch 27
Loss = 3.2117e-01, PNorm = 44.1003, GNorm = 2.7250, lr_0 = 1.0000e-04
Validation rmse = 0.840218
Epoch 28
Loss = 3.0032e-01, PNorm = 44.1060, GNorm = 6.2737, lr_0 = 1.0000e-04
Validation rmse = 0.838273
Epoch 29
Loss = 2.5482e-01, PNorm = 44.1116, GNorm = 8.4912, lr_0 = 1.0000e-04
Validation rmse = 0.837811
Model 0 best validation rmse = 0.837811 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.625999
Ensemble test rmse = 0.625999
1-fold cross validation
	Seed 0 ==> test rmse = 0.625999
Overall test rmse = 0.625999 +/- 0.000000
Elapsed time = 0:02:10
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8355e+00, PNorm = 43.3157, GNorm = 1.5933, lr_0 = 5.1250e-04
Validation rmse = 1.657873
Epoch 1
Loss = 1.4386e+00, PNorm = 43.3390, GNorm = 1.3091, lr_0 = 8.8750e-04
Validation rmse = 1.499380
Epoch 2
Loss = 1.2111e+00, PNorm = 43.3940, GNorm = 0.9869, lr_0 = 9.5316e-04
Validation rmse = 1.404317
Epoch 3
Loss = 1.0567e+00, PNorm = 43.4577, GNorm = 2.7736, lr_0 = 8.9003e-04
Validation rmse = 1.132760
Epoch 4
Loss = 8.0112e-01, PNorm = 43.5364, GNorm = 1.6485, lr_0 = 8.3108e-04
Loss = 7.8211e-01, PNorm = 43.6097, GNorm = 1.8869, lr_0 = 7.7603e-04
Validation rmse = 1.003905
Epoch 5
Loss = 6.6655e-01, PNorm = 43.6697, GNorm = 1.4982, lr_0 = 7.2463e-04
Validation rmse = 1.085682
Epoch 6
Loss = 6.1873e-01, PNorm = 43.7145, GNorm = 1.8697, lr_0 = 6.7664e-04
Validation rmse = 0.923653
Epoch 7
Loss = 5.3844e-01, PNorm = 43.7469, GNorm = 2.4944, lr_0 = 6.3182e-04
Validation rmse = 0.905654
Epoch 8
Loss = 4.6826e-01, PNorm = 43.7844, GNorm = 3.5361, lr_0 = 5.8997e-04
Validation rmse = 0.901342
Epoch 9
Loss = 4.8526e-01, PNorm = 43.8141, GNorm = 6.8281, lr_0 = 5.5090e-04
Loss = 4.6059e-01, PNorm = 43.8438, GNorm = 8.2454, lr_0 = 5.1441e-04
Validation rmse = 0.870115
Epoch 10
Loss = 4.2302e-01, PNorm = 43.8696, GNorm = 2.2201, lr_0 = 4.8034e-04
Validation rmse = 0.862236
Epoch 11
Loss = 3.8647e-01, PNorm = 43.8957, GNorm = 2.3391, lr_0 = 4.4852e-04
Validation rmse = 0.877822
Epoch 12
Loss = 3.5694e-01, PNorm = 43.9163, GNorm = 13.0170, lr_0 = 4.1882e-04
Validation rmse = 0.866596
Epoch 13
Loss = 3.5226e-01, PNorm = 43.9381, GNorm = 1.9042, lr_0 = 3.9108e-04
Validation rmse = 0.878070
Epoch 14
Loss = 4.0543e-01, PNorm = 43.9550, GNorm = 3.1062, lr_0 = 3.6517e-04
Loss = 3.5014e-01, PNorm = 43.9738, GNorm = 16.1138, lr_0 = 3.4099e-04
Validation rmse = 0.847594
Epoch 15
Loss = 3.4980e-01, PNorm = 43.9897, GNorm = 3.1360, lr_0 = 3.1840e-04
Validation rmse = 0.840484
Epoch 16
Loss = 3.2857e-01, PNorm = 44.0038, GNorm = 4.1327, lr_0 = 2.9731e-04
Validation rmse = 0.843206
Epoch 17
Loss = 3.2621e-01, PNorm = 44.0134, GNorm = 3.3741, lr_0 = 2.7762e-04
Validation rmse = 0.861220
Epoch 18
Loss = 2.6929e-01, PNorm = 44.0272, GNorm = 6.2783, lr_0 = 2.5923e-04
Validation rmse = 0.845058
Epoch 19
Loss = 2.9637e-01, PNorm = 44.0382, GNorm = 6.2738, lr_0 = 2.4206e-04
Loss = 3.2186e-01, PNorm = 44.0480, GNorm = 2.4884, lr_0 = 2.2603e-04
Validation rmse = 0.832091
Epoch 20
Loss = 2.9429e-01, PNorm = 44.0575, GNorm = 12.7309, lr_0 = 2.1106e-04
Validation rmse = 0.873896
Epoch 21
Loss = 3.2923e-01, PNorm = 44.0655, GNorm = 3.1610, lr_0 = 1.9708e-04
Validation rmse = 0.827427
Epoch 22
Loss = 2.3545e-01, PNorm = 44.0745, GNorm = 2.6163, lr_0 = 1.8403e-04
Validation rmse = 0.829107
Epoch 23
Loss = 2.6141e-01, PNorm = 44.0815, GNorm = 5.0954, lr_0 = 1.7184e-04
Validation rmse = 0.830504
Epoch 24
Loss = 2.1036e-01, PNorm = 44.0888, GNorm = 3.7313, lr_0 = 1.6046e-04
Loss = 2.9095e-01, PNorm = 44.0952, GNorm = 6.3282, lr_0 = 1.4983e-04
Validation rmse = 0.839109
Epoch 25
Loss = 2.7116e-01, PNorm = 44.1005, GNorm = 5.0295, lr_0 = 1.3991e-04
Validation rmse = 0.824566
Epoch 26
Loss = 2.5722e-01, PNorm = 44.1075, GNorm = 13.7600, lr_0 = 1.3064e-04
Validation rmse = 0.832051
Epoch 27
Loss = 2.5755e-01, PNorm = 44.1126, GNorm = 3.0220, lr_0 = 1.2199e-04
Validation rmse = 0.825635
Epoch 28
Loss = 3.2599e-01, PNorm = 44.1174, GNorm = 4.2331, lr_0 = 1.1391e-04
Validation rmse = 0.825922
Epoch 29
Loss = 2.7253e-01, PNorm = 44.1223, GNorm = 4.9240, lr_0 = 1.0636e-04
Loss = 2.4641e-01, PNorm = 44.1269, GNorm = 4.9215, lr_0 = 1.0000e-04
Validation rmse = 0.823124
Model 0 best validation rmse = 0.823124 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.626607
Ensemble test rmse = 0.626607
1-fold cross validation
	Seed 0 ==> test rmse = 0.626607
Overall test rmse = 0.626607 +/- 0.000000
Elapsed time = 0:02:09
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.464314
Epoch 1
Loss = 1.4910e+00, PNorm = 43.3157, GNorm = 1.3725, lr_0 = 7.1875e-04
Validation rmse = 1.332144
Epoch 2
Loss = 1.4342e+00, PNorm = 43.3500, GNorm = 0.8265, lr_0 = 9.4990e-04
Validation rmse = 1.328868
Epoch 3
Loss = 1.3516e+00, PNorm = 43.3931, GNorm = 0.9304, lr_0 = 8.5711e-04
Validation rmse = 1.260479
Epoch 4
Loss = 1.2931e+00, PNorm = 43.4320, GNorm = 0.9195, lr_0 = 7.7338e-04
Validation rmse = 1.202801
Epoch 5
Validation rmse = 1.123514
Epoch 6
Loss = 1.1784e+00, PNorm = 43.4795, GNorm = 0.6522, lr_0 = 6.9783e-04
Validation rmse = 1.066330
Epoch 7
Loss = 1.0964e+00, PNorm = 43.5386, GNorm = 1.1966, lr_0 = 6.2966e-04
Validation rmse = 1.004149
Epoch 8
Loss = 9.9220e-01, PNorm = 43.5979, GNorm = 3.4278, lr_0 = 5.6815e-04
Validation rmse = 0.955713
Epoch 9
Loss = 9.4438e-01, PNorm = 43.6505, GNorm = 1.7377, lr_0 = 5.1265e-04
Validation rmse = 0.954592
Epoch 10
Validation rmse = 0.909339
Epoch 11
Loss = 8.2255e-01, PNorm = 43.6966, GNorm = 7.7067, lr_0 = 4.6257e-04
Validation rmse = 0.978977
Epoch 12
Loss = 7.9359e-01, PNorm = 43.7296, GNorm = 3.8509, lr_0 = 4.1738e-04
Validation rmse = 0.936703
Epoch 13
Loss = 8.0589e-01, PNorm = 43.7578, GNorm = 1.3463, lr_0 = 3.7661e-04
Validation rmse = 0.884394
Epoch 14
Loss = 7.5466e-01, PNorm = 43.7869, GNorm = 10.8219, lr_0 = 3.3982e-04
Validation rmse = 0.866605
Epoch 15
Validation rmse = 0.858905
Epoch 16
Loss = 6.7011e-01, PNorm = 43.8131, GNorm = 4.1391, lr_0 = 3.0662e-04
Validation rmse = 0.866136
Epoch 17
Loss = 6.8211e-01, PNorm = 43.8357, GNorm = 16.2769, lr_0 = 2.7667e-04
Validation rmse = 0.852256
Epoch 18
Loss = 6.6438e-01, PNorm = 43.8542, GNorm = 4.5413, lr_0 = 2.4964e-04
Validation rmse = 0.855810
Epoch 19
Loss = 6.5193e-01, PNorm = 43.8711, GNorm = 2.6171, lr_0 = 2.2526e-04
Validation rmse = 0.858676
Epoch 20
Validation rmse = 0.842963
Epoch 21
Loss = 6.1946e-01, PNorm = 43.8865, GNorm = 1.7037, lr_0 = 2.0325e-04
Validation rmse = 0.841360
Epoch 22
Loss = 6.4487e-01, PNorm = 43.9005, GNorm = 2.1026, lr_0 = 1.8340e-04
Validation rmse = 0.836006
Epoch 23
Loss = 5.9708e-01, PNorm = 43.9132, GNorm = 4.7975, lr_0 = 1.6548e-04
Validation rmse = 0.841650
Epoch 24
Loss = 5.8593e-01, PNorm = 43.9252, GNorm = 3.9247, lr_0 = 1.4932e-04
Validation rmse = 0.839180
Epoch 25
Validation rmse = 0.835861
Epoch 26
Loss = 5.4849e-01, PNorm = 43.9354, GNorm = 11.0054, lr_0 = 1.3473e-04
Validation rmse = 0.832063
Epoch 27
Loss = 5.9630e-01, PNorm = 43.9453, GNorm = 2.8851, lr_0 = 1.2157e-04
Validation rmse = 0.830253
Epoch 28
Loss = 5.5775e-01, PNorm = 43.9540, GNorm = 3.4390, lr_0 = 1.0969e-04
Validation rmse = 0.851140
Epoch 29
Loss = 5.4310e-01, PNorm = 43.9615, GNorm = 2.8610, lr_0 = 1.0000e-04
Validation rmse = 0.836563
Model 0 best validation rmse = 0.830253 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.708653
Ensemble test rmse = 0.708653
1-fold cross validation
	Seed 0 ==> test rmse = 0.708653
Overall test rmse = 0.708653 +/- 0.000000
Elapsed time = 0:01:32
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.595777
Epoch 1
Loss = 1.5174e+00, PNorm = 43.3212, GNorm = 1.5073, lr_0 = 7.7500e-04
Validation rmse = 1.444349
Epoch 2
Loss = 1.3639e+00, PNorm = 43.3640, GNorm = 0.6678, lr_0 = 9.4019e-04
Validation rmse = 1.378403
Epoch 3
Loss = 1.2445e+00, PNorm = 43.4178, GNorm = 0.5796, lr_0 = 8.4834e-04
Validation rmse = 1.195692
Epoch 4
Loss = 1.1212e+00, PNorm = 43.4741, GNorm = 1.4015, lr_0 = 7.6547e-04
Validation rmse = 1.093636
Epoch 5
Loss = 1.0293e+00, PNorm = 43.5304, GNorm = 3.0830, lr_0 = 6.9069e-04
Validation rmse = 1.130170
Epoch 6
Loss = 9.8143e-01, PNorm = 43.5823, GNorm = 6.3386, lr_0 = 6.1685e-04
Validation rmse = 0.942813
Epoch 7
Loss = 8.7403e-01, PNorm = 43.6264, GNorm = 1.8839, lr_0 = 5.5659e-04
Validation rmse = 0.906751
Epoch 8
Validation rmse = 0.856475
Epoch 9
Loss = 7.2852e-01, PNorm = 43.6663, GNorm = 3.3506, lr_0 = 5.0222e-04
Validation rmse = 0.814721
Epoch 10
Loss = 7.6659e-01, PNorm = 43.6994, GNorm = 6.2945, lr_0 = 4.5316e-04
Validation rmse = 0.797734
Epoch 11
Loss = 7.1187e-01, PNorm = 43.7325, GNorm = 5.3033, lr_0 = 4.0471e-04
Validation rmse = 0.825037
Epoch 12
Loss = 7.0926e-01, PNorm = 43.7600, GNorm = 7.8526, lr_0 = 3.6517e-04
Validation rmse = 0.772840
Epoch 13
Loss = 7.1842e-01, PNorm = 43.7838, GNorm = 14.7113, lr_0 = 3.2950e-04
Validation rmse = 0.787366
Epoch 14
Loss = 6.6719e-01, PNorm = 43.8027, GNorm = 8.8423, lr_0 = 2.9731e-04
Validation rmse = 0.755004
Epoch 15
Loss = 6.0511e-01, PNorm = 43.8210, GNorm = 6.3956, lr_0 = 2.6827e-04
Loss = 7.5445e-01, PNorm = 43.8224, GNorm = 2.9413, lr_0 = 2.6553e-04
Validation rmse = 0.743502
Epoch 16
Validation rmse = 0.752537
Epoch 17
Loss = 6.2020e-01, PNorm = 43.8380, GNorm = 8.5228, lr_0 = 2.3959e-04
Validation rmse = 0.747091
Epoch 18
Loss = 5.1483e-01, PNorm = 43.8526, GNorm = 2.4113, lr_0 = 2.1618e-04
Validation rmse = 0.724413
Epoch 19
Loss = 5.1665e-01, PNorm = 43.8656, GNorm = 3.4092, lr_0 = 1.9506e-04
Validation rmse = 0.729642
Epoch 20
Loss = 5.6508e-01, PNorm = 43.8769, GNorm = 9.6913, lr_0 = 1.7601e-04
Validation rmse = 0.725981
Epoch 21
Loss = 5.2271e-01, PNorm = 43.8892, GNorm = 6.3247, lr_0 = 1.5719e-04
Validation rmse = 0.739218
Epoch 22
Loss = 5.2568e-01, PNorm = 43.8989, GNorm = 2.3714, lr_0 = 1.4184e-04
Validation rmse = 0.721098
Epoch 23
Loss = 5.0112e-01, PNorm = 43.9080, GNorm = 7.3955, lr_0 = 1.2798e-04
Validation rmse = 0.711044
Epoch 24
Loss = 4.9125e-01, PNorm = 43.9159, GNorm = 6.6041, lr_0 = 1.1548e-04
Validation rmse = 0.710345
Epoch 25
Validation rmse = 0.715793
Epoch 26
Loss = 5.4958e-01, PNorm = 43.9234, GNorm = 1.9385, lr_0 = 1.0313e-04
Validation rmse = 0.712612
Epoch 27
Loss = 4.6903e-01, PNorm = 43.9300, GNorm = 3.7569, lr_0 = 1.0000e-04
Validation rmse = 0.707356
Epoch 28
Loss = 4.7842e-01, PNorm = 43.9369, GNorm = 3.3002, lr_0 = 1.0000e-04
Validation rmse = 0.703092
Epoch 29
Loss = 4.5084e-01, PNorm = 43.9438, GNorm = 9.4520, lr_0 = 1.0000e-04
Validation rmse = 0.712183
Model 0 best validation rmse = 0.703092 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.745170
Ensemble test rmse = 0.745170
1-fold cross validation
	Seed 0 ==> test rmse = 0.745170
Overall test rmse = 0.745170 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.626466
Epoch 1
Loss = 1.4803e+00, PNorm = 43.3213, GNorm = 1.3564, lr_0 = 7.0000e-04
Validation rmse = 1.472596
Epoch 2
Loss = 1.3258e+00, PNorm = 43.3622, GNorm = 0.9108, lr_0 = 9.6411e-04
Validation rmse = 1.380345
Epoch 3
Loss = 1.1086e+00, PNorm = 43.4284, GNorm = 0.6362, lr_0 = 8.7192e-04
Validation rmse = 1.264145
Epoch 4
Loss = 1.0268e+00, PNorm = 43.4843, GNorm = 2.4132, lr_0 = 7.9578e-04
Validation rmse = 1.123048
Epoch 5
Loss = 9.1984e-01, PNorm = 43.5406, GNorm = 1.2534, lr_0 = 7.2629e-04
Validation rmse = 0.978513
Epoch 6
Loss = 8.4020e-01, PNorm = 43.6004, GNorm = 4.0290, lr_0 = 6.5684e-04
Validation rmse = 0.967828
Epoch 7
Loss = 6.5712e-01, PNorm = 43.6501, GNorm = 3.5887, lr_0 = 5.9948e-04
Validation rmse = 0.853596
Epoch 8
Loss = 7.1483e-01, PNorm = 43.6949, GNorm = 7.2369, lr_0 = 5.4216e-04
Validation rmse = 0.821098
Epoch 9
Loss = 6.0378e-01, PNorm = 43.7295, GNorm = 4.5138, lr_0 = 4.9482e-04
Validation rmse = 0.795924
Epoch 10
Loss = 6.0808e-01, PNorm = 43.7613, GNorm = 1.9430, lr_0 = 4.5161e-04
Validation rmse = 0.821172
Epoch 11
Loss = 5.3044e-01, PNorm = 43.7918, GNorm = 10.0276, lr_0 = 4.0842e-04
Validation rmse = 0.782255
Epoch 12
Loss = 5.2882e-01, PNorm = 43.8132, GNorm = 2.5227, lr_0 = 3.7276e-04
Validation rmse = 0.813975
Epoch 13
Loss = 5.3891e-01, PNorm = 43.8373, GNorm = 7.0640, lr_0 = 3.3711e-04
Validation rmse = 0.754352
Epoch 14
Loss = 5.2626e-01, PNorm = 43.8565, GNorm = 12.6128, lr_0 = 3.0768e-04
Validation rmse = 0.759096
Epoch 15
Loss = 4.8750e-01, PNorm = 43.8704, GNorm = 14.4161, lr_0 = 2.8081e-04
Validation rmse = 0.778046
Epoch 16
Loss = 5.0939e-01, PNorm = 43.8849, GNorm = 2.2400, lr_0 = 2.5396e-04
Validation rmse = 0.748627
Epoch 17
Loss = 4.8235e-01, PNorm = 43.8982, GNorm = 4.4656, lr_0 = 2.3178e-04
Validation rmse = 0.752929
Epoch 18
Loss = 4.6730e-01, PNorm = 43.9113, GNorm = 7.9501, lr_0 = 2.0962e-04
Validation rmse = 0.755611
Epoch 19
Loss = 4.3028e-01, PNorm = 43.9215, GNorm = 7.3699, lr_0 = 1.9131e-04
Validation rmse = 0.771382
Epoch 20
Loss = 4.0619e-01, PNorm = 43.9307, GNorm = 8.9531, lr_0 = 1.7461e-04
Validation rmse = 0.745989
Epoch 21
Loss = 4.1174e-01, PNorm = 43.9401, GNorm = 2.5910, lr_0 = 1.5791e-04
Validation rmse = 0.737883
Epoch 22
Loss = 3.9928e-01, PNorm = 43.9481, GNorm = 5.2846, lr_0 = 1.4412e-04
Loss = 3.4235e-01, PNorm = 43.9488, GNorm = 2.5363, lr_0 = 1.4281e-04
Validation rmse = 0.734556
Epoch 23
Loss = 3.8945e-01, PNorm = 43.9557, GNorm = 2.6145, lr_0 = 1.3034e-04
Validation rmse = 0.744151
Epoch 24
Loss = 3.7620e-01, PNorm = 43.9616, GNorm = 4.5367, lr_0 = 1.1896e-04
Validation rmse = 0.732246
Epoch 25
Validation rmse = 0.745043
Epoch 26
Loss = 4.7210e-01, PNorm = 43.9684, GNorm = 6.2029, lr_0 = 1.0758e-04
Validation rmse = 0.769898
Epoch 27
Loss = 4.4045e-01, PNorm = 43.9735, GNorm = 9.5827, lr_0 = 1.0000e-04
Validation rmse = 0.744163
Epoch 28
Loss = 3.6392e-01, PNorm = 43.9787, GNorm = 4.7117, lr_0 = 1.0000e-04
Validation rmse = 0.757283
Epoch 29
Loss = 3.5369e-01, PNorm = 43.9833, GNorm = 8.9564, lr_0 = 1.0000e-04
Validation rmse = 0.734757
Model 0 best validation rmse = 0.732246 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.680266
Ensemble test rmse = 0.680266
1-fold cross validation
	Seed 0 ==> test rmse = 0.680266
Overall test rmse = 0.680266 +/- 0.000000
Elapsed time = 0:01:42
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7210e+00, PNorm = 43.3166, GNorm = 1.9834, lr_0 = 5.9500e-04
Loss = 1.4854e+00, PNorm = 43.3182, GNorm = 1.9766, lr_0 = 6.4000e-04
Validation rmse = 1.679853
Epoch 1
Loss = 1.4215e+00, PNorm = 43.3544, GNorm = 0.8263, lr_0 = 9.8369e-04
Loss = 1.1692e+00, PNorm = 43.3600, GNorm = 1.1494, lr_0 = 9.7563e-04
Validation rmse = 1.516766
Epoch 2
Loss = 1.2173e+00, PNorm = 43.4116, GNorm = 2.7856, lr_0 = 8.9861e-04
Validation rmse = 1.351533
Epoch 3
Loss = 1.0817e+00, PNorm = 43.4657, GNorm = 1.2042, lr_0 = 8.2767e-04
Validation rmse = 1.181860
Epoch 4
Loss = 9.4443e-01, PNorm = 43.5325, GNorm = 1.3303, lr_0 = 7.5609e-04
Validation rmse = 1.028993
Epoch 5
Loss = 7.7663e-01, PNorm = 43.5967, GNorm = 2.3842, lr_0 = 6.9640e-04
Validation rmse = 0.900097
Epoch 6
Loss = 7.4045e-01, PNorm = 43.6490, GNorm = 5.5668, lr_0 = 6.3617e-04
Validation rmse = 0.824685
Epoch 7
Loss = 6.2769e-01, PNorm = 43.6967, GNorm = 5.5419, lr_0 = 5.8115e-04
Validation rmse = 0.783321
Epoch 8
Loss = 5.7852e-01, PNorm = 43.7337, GNorm = 3.7537, lr_0 = 5.3527e-04
Validation rmse = 0.752469
Epoch 9
Loss = 5.6992e-01, PNorm = 43.7692, GNorm = 8.2874, lr_0 = 4.8897e-04
Validation rmse = 0.734761
Epoch 10
Loss = 5.4726e-01, PNorm = 43.7956, GNorm = 6.0794, lr_0 = 4.5037e-04
Validation rmse = 0.708107
Epoch 11
Loss = 4.5171e-01, PNorm = 43.8256, GNorm = 3.4854, lr_0 = 4.1142e-04
Validation rmse = 0.693569
Epoch 12
Loss = 4.9275e-01, PNorm = 43.8479, GNorm = 2.4246, lr_0 = 3.7584e-04
Validation rmse = 0.685363
Epoch 13
Loss = 4.3171e-01, PNorm = 43.8692, GNorm = 5.9211, lr_0 = 3.4617e-04
Validation rmse = 0.669420
Epoch 14
Loss = 4.4369e-01, PNorm = 43.8888, GNorm = 8.2032, lr_0 = 3.1623e-04
Validation rmse = 0.676514
Epoch 15
Loss = 3.7842e-01, PNorm = 43.9052, GNorm = 5.6779, lr_0 = 2.9126e-04
Validation rmse = 0.664188
Epoch 16
Loss = 3.6063e-01, PNorm = 43.9224, GNorm = 2.4492, lr_0 = 2.6607e-04
Validation rmse = 0.664762
Epoch 17
Loss = 3.8434e-01, PNorm = 43.9379, GNorm = 9.5015, lr_0 = 2.4306e-04
Validation rmse = 0.659177
Epoch 18
Loss = 3.5387e-01, PNorm = 43.9490, GNorm = 5.7293, lr_0 = 2.2387e-04
Validation rmse = 0.652752
Epoch 19
Loss = 4.1843e-01, PNorm = 43.9628, GNorm = 2.7313, lr_0 = 2.0451e-04
Validation rmse = 0.649639
Epoch 20
Loss = 3.0255e-01, PNorm = 43.9740, GNorm = 11.1773, lr_0 = 1.8836e-04
Validation rmse = 0.661600
Epoch 21
Loss = 3.1243e-01, PNorm = 43.9838, GNorm = 2.3365, lr_0 = 1.7207e-04
Validation rmse = 0.645009
Epoch 22
Loss = 3.7032e-01, PNorm = 43.9931, GNorm = 12.1869, lr_0 = 1.5719e-04
Validation rmse = 0.650555
Epoch 23
Loss = 2.4286e-01, PNorm = 44.0004, GNorm = 6.8395, lr_0 = 1.4478e-04
Validation rmse = 0.646453
Epoch 24
Loss = 3.3450e-01, PNorm = 44.0080, GNorm = 4.9323, lr_0 = 1.3226e-04
Loss = 3.6025e-01, PNorm = 44.0131, GNorm = 3.2517, lr_0 = 1.2182e-04
Validation rmse = 0.676787
Epoch 25
Loss = 3.4797e-01, PNorm = 44.0185, GNorm = 4.5874, lr_0 = 1.1220e-04
Loss = 3.6978e-01, PNorm = 44.0192, GNorm = 8.0625, lr_0 = 1.1128e-04
Validation rmse = 0.644077
Epoch 26
Loss = 3.1362e-01, PNorm = 44.0252, GNorm = 3.7280, lr_0 = 1.0250e-04
Loss = 2.6072e-01, PNorm = 44.0258, GNorm = 3.3457, lr_0 = 1.0166e-04
Validation rmse = 0.652683
Epoch 27
Loss = 3.3521e-01, PNorm = 44.0304, GNorm = 2.4268, lr_0 = 1.0000e-04
Validation rmse = 0.649478
Epoch 28
Loss = 3.1706e-01, PNorm = 44.0358, GNorm = 3.3628, lr_0 = 1.0000e-04
Validation rmse = 0.638919
Epoch 29
Loss = 3.0912e-01, PNorm = 44.0403, GNorm = 5.6743, lr_0 = 1.0000e-04
Validation rmse = 0.639382
Model 0 best validation rmse = 0.638919 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.669100
Ensemble test rmse = 0.669100
1-fold cross validation
	Seed 0 ==> test rmse = 0.669100
Overall test rmse = 0.669100 +/- 0.000000
Elapsed time = 0:01:50
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7587e+00, PNorm = 43.3158, GNorm = 1.8180, lr_0 = 5.5000e-04
Validation rmse = 1.648578
Epoch 1
Loss = 1.4115e+00, PNorm = 43.3465, GNorm = 0.9286, lr_0 = 1.0000e-03
Validation rmse = 1.444946
Epoch 2
Loss = 1.1536e+00, PNorm = 43.4119, GNorm = 2.0080, lr_0 = 9.2106e-04
Validation rmse = 1.195426
Epoch 3
Loss = 9.8917e-01, PNorm = 43.4851, GNorm = 1.0790, lr_0 = 8.4834e-04
Validation rmse = 1.028953
Epoch 4
Loss = 8.5099e-01, PNorm = 43.5556, GNorm = 3.5284, lr_0 = 7.8137e-04
Validation rmse = 0.955813
Epoch 5
Loss = 7.4048e-01, PNorm = 43.6081, GNorm = 2.3191, lr_0 = 7.2509e-04
Validation rmse = 0.925831
Epoch 6
Loss = 7.2806e-01, PNorm = 43.6480, GNorm = 3.2442, lr_0 = 6.6784e-04
Validation rmse = 0.825780
Epoch 7
Loss = 6.2024e-01, PNorm = 43.6893, GNorm = 8.8779, lr_0 = 6.1512e-04
Validation rmse = 0.871346
Epoch 8
Loss = 6.1833e-01, PNorm = 43.7225, GNorm = 9.0207, lr_0 = 5.6656e-04
Loss = 5.8727e-01, PNorm = 43.7564, GNorm = 6.4287, lr_0 = 5.2575e-04
Loss = 6.2096e-01, PNorm = 43.7588, GNorm = 9.5077, lr_0 = 5.2183e-04
Validation rmse = 0.785512
Epoch 9
Loss = 5.4266e-01, PNorm = 43.7858, GNorm = 6.2655, lr_0 = 4.8424e-04
Validation rmse = 0.756946
Epoch 10
Loss = 4.9563e-01, PNorm = 43.8123, GNorm = 6.0013, lr_0 = 4.4936e-04
Validation rmse = 0.801405
Epoch 11
Loss = 5.0786e-01, PNorm = 43.8365, GNorm = 5.3425, lr_0 = 4.1389e-04
Validation rmse = 0.733966
Epoch 12
Loss = 4.9027e-01, PNorm = 43.8610, GNorm = 8.9948, lr_0 = 3.8121e-04
Validation rmse = 0.726224
Epoch 13
Loss = 4.2582e-01, PNorm = 43.8833, GNorm = 3.7877, lr_0 = 3.5112e-04
Validation rmse = 0.718730
Epoch 14
Loss = 3.9282e-01, PNorm = 43.8997, GNorm = 5.2931, lr_0 = 3.2340e-04
Validation rmse = 0.722303
Epoch 15
Loss = 3.6962e-01, PNorm = 43.9138, GNorm = 3.6273, lr_0 = 3.0010e-04
Validation rmse = 0.710314
Epoch 16
Loss = 3.1093e-01, PNorm = 43.9290, GNorm = 3.7032, lr_0 = 2.7641e-04
Loss = 4.0186e-01, PNorm = 43.9420, GNorm = 8.8386, lr_0 = 2.5650e-04
Loss = 6.4784e-01, PNorm = 43.9429, GNorm = 8.9032, lr_0 = 2.5459e-04
Validation rmse = 0.723963
Epoch 17
Loss = 3.6356e-01, PNorm = 43.9540, GNorm = 3.0639, lr_0 = 2.3625e-04
Validation rmse = 0.702490
Epoch 18
Loss = 3.3952e-01, PNorm = 43.9660, GNorm = 3.3810, lr_0 = 2.1760e-04
Validation rmse = 0.713211
Epoch 19
Loss = 3.7409e-01, PNorm = 43.9764, GNorm = 5.4980, lr_0 = 2.0042e-04
Validation rmse = 0.723868
Epoch 20
Loss = 3.8715e-01, PNorm = 43.9851, GNorm = 5.7482, lr_0 = 1.8599e-04
Validation rmse = 0.699671
Epoch 21
Loss = 3.2434e-01, PNorm = 43.9939, GNorm = 7.5874, lr_0 = 1.7130e-04
Validation rmse = 0.703656
Epoch 22
Loss = 3.3200e-01, PNorm = 44.0025, GNorm = 2.1915, lr_0 = 1.5778e-04
Validation rmse = 0.717353
Epoch 23
Loss = 3.2816e-01, PNorm = 44.0086, GNorm = 5.0084, lr_0 = 1.4532e-04
Validation rmse = 0.695290
Epoch 24
Loss = 2.3345e-01, PNorm = 44.0153, GNorm = 1.4167, lr_0 = 1.3385e-04
Loss = 3.3915e-01, PNorm = 44.0218, GNorm = 10.3266, lr_0 = 1.2421e-04
Validation rmse = 0.693410
Epoch 25
Loss = 3.1476e-01, PNorm = 44.0267, GNorm = 2.8122, lr_0 = 1.1526e-04
Validation rmse = 0.695168
Epoch 26
Loss = 2.8322e-01, PNorm = 44.0327, GNorm = 2.1765, lr_0 = 1.0616e-04
Validation rmse = 0.686552
Epoch 27
Loss = 2.5070e-01, PNorm = 44.0373, GNorm = 4.5233, lr_0 = 1.0000e-04
Validation rmse = 0.687353
Epoch 28
Loss = 2.8488e-01, PNorm = 44.0415, GNorm = 4.2900, lr_0 = 1.0000e-04
Validation rmse = 0.683819
Epoch 29
Loss = 2.8265e-01, PNorm = 44.0461, GNorm = 4.9762, lr_0 = 1.0000e-04
Validation rmse = 0.685179
Model 0 best validation rmse = 0.683819 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.671554
Ensemble test rmse = 0.671554
1-fold cross validation
	Seed 0 ==> test rmse = 0.671554
Overall test rmse = 0.671554 +/- 0.000000
Elapsed time = 0:01:57
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7411e+00, PNorm = 43.3167, GNorm = 2.0689, lr_0 = 5.1250e-04
Validation rmse = 1.708471
Epoch 1
Loss = 1.4461e+00, PNorm = 43.3420, GNorm = 1.1898, lr_0 = 8.8750e-04
Validation rmse = 1.504106
Epoch 2
Loss = 1.2197e+00, PNorm = 43.3964, GNorm = 1.7583, lr_0 = 9.5316e-04
Validation rmse = 1.316118
Epoch 3
Loss = 1.0647e+00, PNorm = 43.4558, GNorm = 0.8124, lr_0 = 8.9003e-04
Validation rmse = 1.109105
Epoch 4
Loss = 9.1605e-01, PNorm = 43.5268, GNorm = 4.3342, lr_0 = 8.3108e-04
Loss = 8.0539e-01, PNorm = 43.5961, GNorm = 1.5315, lr_0 = 7.7603e-04
Validation rmse = 0.892701
Epoch 5
Loss = 6.8211e-01, PNorm = 43.6593, GNorm = 5.2758, lr_0 = 7.2463e-04
Validation rmse = 0.782988
Epoch 6
Loss = 6.1282e-01, PNorm = 43.7133, GNorm = 1.9322, lr_0 = 6.7664e-04
Validation rmse = 0.726854
Epoch 7
Loss = 5.5058e-01, PNorm = 43.7609, GNorm = 1.9998, lr_0 = 6.3182e-04
Validation rmse = 0.732489
Epoch 8
Loss = 4.6445e-01, PNorm = 43.8036, GNorm = 2.2031, lr_0 = 5.8997e-04
Validation rmse = 0.683456
Epoch 9
Loss = 4.3891e-01, PNorm = 43.8358, GNorm = 3.7115, lr_0 = 5.5090e-04
Loss = 5.1396e-01, PNorm = 43.8691, GNorm = 9.6267, lr_0 = 5.1441e-04
Validation rmse = 0.671894
Epoch 10
Loss = 4.1919e-01, PNorm = 43.8996, GNorm = 3.3447, lr_0 = 4.8034e-04
Validation rmse = 0.684093
Epoch 11
Loss = 4.1169e-01, PNorm = 43.9227, GNorm = 4.9882, lr_0 = 4.4852e-04
Validation rmse = 0.662539
Epoch 12
Loss = 3.3269e-01, PNorm = 43.9462, GNorm = 5.2138, lr_0 = 4.1882e-04
Validation rmse = 0.673121
Epoch 13
Loss = 3.4728e-01, PNorm = 43.9667, GNorm = 4.3166, lr_0 = 3.9108e-04
Validation rmse = 0.687583
Epoch 14
Loss = 3.5495e-01, PNorm = 43.9854, GNorm = 6.1777, lr_0 = 3.6517e-04
Loss = 3.8652e-01, PNorm = 44.0036, GNorm = 8.1466, lr_0 = 3.4099e-04
Validation rmse = 0.665355
Epoch 15
Loss = 3.5608e-01, PNorm = 44.0206, GNorm = 9.4489, lr_0 = 3.1840e-04
Validation rmse = 0.636398
Epoch 16
Loss = 3.3443e-01, PNorm = 44.0332, GNorm = 6.1644, lr_0 = 2.9731e-04
Validation rmse = 0.654545
Epoch 17
Loss = 2.8394e-01, PNorm = 44.0473, GNorm = 5.4920, lr_0 = 2.7762e-04
Validation rmse = 0.741638
Epoch 18
Loss = 2.9973e-01, PNorm = 44.0581, GNorm = 13.8270, lr_0 = 2.5923e-04
Validation rmse = 0.646469
Epoch 19
Loss = 4.2038e-01, PNorm = 44.0687, GNorm = 6.2739, lr_0 = 2.4206e-04
Loss = 2.9320e-01, PNorm = 44.0810, GNorm = 3.9995, lr_0 = 2.2603e-04
Validation rmse = 0.652765
Epoch 20
Loss = 3.1712e-01, PNorm = 44.0898, GNorm = 12.9763, lr_0 = 2.1106e-04
Validation rmse = 0.637335
Epoch 21
Loss = 3.1705e-01, PNorm = 44.0983, GNorm = 12.6841, lr_0 = 1.9708e-04
Validation rmse = 0.620684
Epoch 22
Loss = 3.2408e-01, PNorm = 44.1065, GNorm = 2.0682, lr_0 = 1.8403e-04
Validation rmse = 0.642782
Epoch 23
Loss = 2.3385e-01, PNorm = 44.1147, GNorm = 8.5031, lr_0 = 1.7184e-04
Validation rmse = 0.622712
Epoch 24
Loss = 2.3535e-01, PNorm = 44.1220, GNorm = 7.9972, lr_0 = 1.6046e-04
Loss = 2.6348e-01, PNorm = 44.1291, GNorm = 2.9310, lr_0 = 1.4983e-04
Validation rmse = 0.625618
Epoch 25
Loss = 2.4880e-01, PNorm = 44.1362, GNorm = 4.2037, lr_0 = 1.3991e-04
Validation rmse = 0.636419
Epoch 26
Loss = 2.4114e-01, PNorm = 44.1419, GNorm = 3.8804, lr_0 = 1.3064e-04
Validation rmse = 0.628287
Epoch 27
Loss = 2.4853e-01, PNorm = 44.1471, GNorm = 3.6823, lr_0 = 1.2199e-04
Validation rmse = 0.629111
Epoch 28
Loss = 2.6629e-01, PNorm = 44.1523, GNorm = 9.2558, lr_0 = 1.1391e-04
Validation rmse = 0.625516
Epoch 29
Loss = 1.6393e-01, PNorm = 44.1577, GNorm = 2.7152, lr_0 = 1.0636e-04
Loss = 2.5037e-01, PNorm = 44.1627, GNorm = 6.0869, lr_0 = 1.0000e-04
Validation rmse = 0.625260
Model 0 best validation rmse = 0.620684 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.657589
Ensemble test rmse = 0.657589
1-fold cross validation
	Seed 0 ==> test rmse = 0.657589
Overall test rmse = 0.657589 +/- 0.000000
Elapsed time = 0:02:06
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.296906
Epoch 1
Loss = 1.5383e+00, PNorm = 43.3144, GNorm = 1.9384, lr_0 = 7.1875e-04
Validation rmse = 1.165483
Epoch 2
Loss = 1.4837e+00, PNorm = 43.3442, GNorm = 0.9048, lr_0 = 9.4990e-04
Validation rmse = 1.125177
Epoch 3
Loss = 1.3579e+00, PNorm = 43.3820, GNorm = 0.7739, lr_0 = 8.5711e-04
Validation rmse = 1.080886
Epoch 4
Loss = 1.3092e+00, PNorm = 43.4169, GNorm = 0.5973, lr_0 = 7.7338e-04
Validation rmse = 1.019626
Epoch 5
Validation rmse = 0.982106
Epoch 6
Loss = 1.2567e+00, PNorm = 43.4609, GNorm = 0.5806, lr_0 = 6.9783e-04
Validation rmse = 0.914224
Epoch 7
Loss = 1.1610e+00, PNorm = 43.5090, GNorm = 1.0234, lr_0 = 6.2966e-04
Validation rmse = 0.890620
Epoch 8
Loss = 1.0939e+00, PNorm = 43.5601, GNorm = 0.9138, lr_0 = 5.6815e-04
Validation rmse = 0.813842
Epoch 9
Loss = 9.9233e-01, PNorm = 43.6185, GNorm = 1.4718, lr_0 = 5.1265e-04
Validation rmse = 0.784988
Epoch 10
Validation rmse = 0.763716
Epoch 11
Loss = 8.8942e-01, PNorm = 43.6710, GNorm = 2.8943, lr_0 = 4.6257e-04
Validation rmse = 0.742107
Epoch 12
Loss = 8.3701e-01, PNorm = 43.7118, GNorm = 3.1086, lr_0 = 4.1738e-04
Validation rmse = 0.747995
Epoch 13
Loss = 8.3178e-01, PNorm = 43.7426, GNorm = 2.1267, lr_0 = 3.7661e-04
Validation rmse = 0.742783
Epoch 14
Loss = 8.1914e-01, PNorm = 43.7699, GNorm = 8.2259, lr_0 = 3.3982e-04
Validation rmse = 0.699006
Epoch 15
Validation rmse = 0.703687
Epoch 16
Loss = 7.2018e-01, PNorm = 43.7938, GNorm = 1.6628, lr_0 = 3.0662e-04
Validation rmse = 0.706657
Epoch 17
Loss = 7.0546e-01, PNorm = 43.8184, GNorm = 3.1487, lr_0 = 2.7667e-04
Validation rmse = 0.686428
Epoch 18
Loss = 6.8997e-01, PNorm = 43.8403, GNorm = 3.8508, lr_0 = 2.4964e-04
Validation rmse = 0.683567
Epoch 19
Loss = 6.8697e-01, PNorm = 43.8597, GNorm = 7.7160, lr_0 = 2.2526e-04
Validation rmse = 0.683715
Epoch 20
Validation rmse = 0.669337
Epoch 21
Loss = 6.3487e-01, PNorm = 43.8773, GNorm = 4.8702, lr_0 = 2.0325e-04
Validation rmse = 0.677924
Epoch 22
Loss = 6.7188e-01, PNorm = 43.8941, GNorm = 4.6120, lr_0 = 1.8340e-04
Validation rmse = 0.672063
Epoch 23
Loss = 6.1777e-01, PNorm = 43.9088, GNorm = 1.9698, lr_0 = 1.6548e-04
Validation rmse = 0.669805
Epoch 24
Loss = 6.1470e-01, PNorm = 43.9218, GNorm = 2.0317, lr_0 = 1.4932e-04
Validation rmse = 0.662848
Epoch 25
Validation rmse = 0.664956
Epoch 26
Loss = 5.7869e-01, PNorm = 43.9337, GNorm = 3.6391, lr_0 = 1.3473e-04
Validation rmse = 0.669531
Epoch 27
Loss = 5.9005e-01, PNorm = 43.9442, GNorm = 3.5155, lr_0 = 1.2157e-04
Validation rmse = 0.664971
Epoch 28
Loss = 5.6753e-01, PNorm = 43.9534, GNorm = 9.9051, lr_0 = 1.0969e-04
Validation rmse = 0.657917
Epoch 29
Loss = 5.7019e-01, PNorm = 43.9613, GNorm = 2.8499, lr_0 = 1.0000e-04
Validation rmse = 0.663120
Model 0 best validation rmse = 0.657917 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.852826
Ensemble test rmse = 0.852826
1-fold cross validation
	Seed 0 ==> test rmse = 0.852826
Overall test rmse = 0.852826 +/- 0.000000
Elapsed time = 0:01:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.529662
Epoch 1
Loss = 1.5621e+00, PNorm = 43.3191, GNorm = 1.4338, lr_0 = 7.7500e-04
Validation rmse = 1.370325
Epoch 2
Loss = 1.3874e+00, PNorm = 43.3622, GNorm = 0.8551, lr_0 = 9.4019e-04
Validation rmse = 1.347559
Epoch 3
Loss = 1.2241e+00, PNorm = 43.4147, GNorm = 0.6767, lr_0 = 8.4834e-04
Validation rmse = 1.186963
Epoch 4
Loss = 1.1494e+00, PNorm = 43.4627, GNorm = 0.5629, lr_0 = 7.6547e-04
Validation rmse = 1.123047
Epoch 5
Loss = 1.0559e+00, PNorm = 43.5167, GNorm = 3.0662, lr_0 = 6.9069e-04
Validation rmse = 1.007751
Epoch 6
Loss = 9.8025e-01, PNorm = 43.5762, GNorm = 2.3721, lr_0 = 6.1685e-04
Validation rmse = 0.928399
Epoch 7
Loss = 9.0861e-01, PNorm = 43.6283, GNorm = 5.6737, lr_0 = 5.5659e-04
Validation rmse = 0.895888
Epoch 8
Validation rmse = 0.865356
Epoch 9
Loss = 7.3674e-01, PNorm = 43.6743, GNorm = 4.4291, lr_0 = 5.0222e-04
Validation rmse = 0.926380
Epoch 10
Loss = 7.7515e-01, PNorm = 43.7113, GNorm = 1.6381, lr_0 = 4.5316e-04
Validation rmse = 0.838921
Epoch 11
Loss = 8.4965e-01, PNorm = 43.7465, GNorm = 12.3355, lr_0 = 4.0471e-04
Validation rmse = 0.827985
Epoch 12
Loss = 6.8073e-01, PNorm = 43.7762, GNorm = 1.4383, lr_0 = 3.6517e-04
Validation rmse = 0.938299
Epoch 13
Loss = 7.2824e-01, PNorm = 43.8025, GNorm = 9.2896, lr_0 = 3.2950e-04
Validation rmse = 0.919716
Epoch 14
Loss = 7.0774e-01, PNorm = 43.8273, GNorm = 5.5745, lr_0 = 2.9731e-04
Validation rmse = 0.825887
Epoch 15
Loss = 6.6451e-01, PNorm = 43.8459, GNorm = 5.9735, lr_0 = 2.6827e-04
Loss = 7.2866e-01, PNorm = 43.8477, GNorm = 2.5119, lr_0 = 2.6553e-04
Validation rmse = 0.798157
Epoch 16
Validation rmse = 0.797727
Epoch 17
Loss = 5.2279e-01, PNorm = 43.8667, GNorm = 3.8718, lr_0 = 2.3959e-04
Validation rmse = 0.778151
Epoch 18
Loss = 6.7460e-01, PNorm = 43.8837, GNorm = 10.5772, lr_0 = 2.1618e-04
Validation rmse = 0.782278
Epoch 19
Loss = 6.1594e-01, PNorm = 43.8986, GNorm = 1.3693, lr_0 = 1.9506e-04
Validation rmse = 0.846031
Epoch 20
Loss = 5.8340e-01, PNorm = 43.9124, GNorm = 11.1507, lr_0 = 1.7601e-04
Validation rmse = 0.820950
Epoch 21
Loss = 5.6713e-01, PNorm = 43.9259, GNorm = 4.3212, lr_0 = 1.5719e-04
Validation rmse = 0.803849
Epoch 22
Loss = 5.6884e-01, PNorm = 43.9368, GNorm = 7.8049, lr_0 = 1.4184e-04
Validation rmse = 0.785215
Epoch 23
Loss = 5.4420e-01, PNorm = 43.9472, GNorm = 4.0351, lr_0 = 1.2798e-04
Validation rmse = 0.776578
Epoch 24
Loss = 5.2040e-01, PNorm = 43.9567, GNorm = 4.0210, lr_0 = 1.1548e-04
Validation rmse = 0.787602
Epoch 25
Validation rmse = 0.831482
Epoch 26
Loss = 5.7334e-01, PNorm = 43.9652, GNorm = 7.8598, lr_0 = 1.0313e-04
Validation rmse = 0.816077
Epoch 27
Loss = 4.9198e-01, PNorm = 43.9727, GNorm = 2.7109, lr_0 = 1.0000e-04
Validation rmse = 0.779178
Epoch 28
Loss = 5.1692e-01, PNorm = 43.9803, GNorm = 1.6901, lr_0 = 1.0000e-04
Validation rmse = 0.786732
Epoch 29
Loss = 4.5406e-01, PNorm = 43.9880, GNorm = 4.5181, lr_0 = 1.0000e-04
Validation rmse = 0.806999
Model 0 best validation rmse = 0.776578 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.626944
Ensemble test rmse = 0.626944
1-fold cross validation
	Seed 0 ==> test rmse = 0.626944
Overall test rmse = 0.626944 +/- 0.000000
Elapsed time = 0:01:34
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.505618
Epoch 1
Loss = 1.4819e+00, PNorm = 43.3169, GNorm = 2.3796, lr_0 = 7.0000e-04
Validation rmse = 1.324027
Epoch 2
Loss = 1.3200e+00, PNorm = 43.3529, GNorm = 0.8454, lr_0 = 9.6411e-04
Validation rmse = 1.229508
Epoch 3
Loss = 1.1602e+00, PNorm = 43.4084, GNorm = 1.4431, lr_0 = 8.7192e-04
Validation rmse = 1.092717
Epoch 4
Loss = 1.0548e+00, PNorm = 43.4629, GNorm = 1.1456, lr_0 = 7.9578e-04
Validation rmse = 1.046110
Epoch 5
Loss = 1.0334e+00, PNorm = 43.5213, GNorm = 5.1867, lr_0 = 7.2629e-04
Validation rmse = 0.909149
Epoch 6
Loss = 9.3712e-01, PNorm = 43.5781, GNorm = 4.3334, lr_0 = 6.5684e-04
Validation rmse = 0.885154
Epoch 7
Loss = 8.4091e-01, PNorm = 43.6243, GNorm = 4.6773, lr_0 = 5.9948e-04
Validation rmse = 0.798008
Epoch 8
Loss = 8.0075e-01, PNorm = 43.6702, GNorm = 5.5024, lr_0 = 5.4216e-04
Validation rmse = 0.812932
Epoch 9
Loss = 7.4034e-01, PNorm = 43.7061, GNorm = 1.6163, lr_0 = 4.9482e-04
Validation rmse = 0.751198
Epoch 10
Loss = 6.7437e-01, PNorm = 43.7403, GNorm = 4.0680, lr_0 = 4.5161e-04
Validation rmse = 0.752355
Epoch 11
Loss = 6.5538e-01, PNorm = 43.7740, GNorm = 1.5555, lr_0 = 4.0842e-04
Validation rmse = 0.743914
Epoch 12
Loss = 5.9870e-01, PNorm = 43.8017, GNorm = 3.7012, lr_0 = 3.7276e-04
Validation rmse = 0.720731
Epoch 13
Loss = 5.6010e-01, PNorm = 43.8302, GNorm = 2.4464, lr_0 = 3.3711e-04
Validation rmse = 0.702125
Epoch 14
Loss = 5.9398e-01, PNorm = 43.8512, GNorm = 6.2485, lr_0 = 3.0768e-04
Validation rmse = 0.699705
Epoch 15
Loss = 5.6956e-01, PNorm = 43.8702, GNorm = 4.9331, lr_0 = 2.8081e-04
Validation rmse = 0.715488
Epoch 16
Loss = 5.5851e-01, PNorm = 43.8914, GNorm = 5.8285, lr_0 = 2.5396e-04
Validation rmse = 0.727533
Epoch 17
Loss = 5.3605e-01, PNorm = 43.9081, GNorm = 1.6898, lr_0 = 2.3178e-04
Validation rmse = 0.696198
Epoch 18
Loss = 5.2368e-01, PNorm = 43.9233, GNorm = 9.1877, lr_0 = 2.0962e-04
Validation rmse = 0.684751
Epoch 19
Loss = 5.2872e-01, PNorm = 43.9354, GNorm = 8.1399, lr_0 = 1.9131e-04
Validation rmse = 0.684747
Epoch 20
Loss = 4.9428e-01, PNorm = 43.9481, GNorm = 5.0340, lr_0 = 1.7461e-04
Validation rmse = 0.687145
Epoch 21
Loss = 4.7665e-01, PNorm = 43.9595, GNorm = 5.6025, lr_0 = 1.5791e-04
Validation rmse = 0.680819
Epoch 22
Loss = 4.7121e-01, PNorm = 43.9696, GNorm = 2.3131, lr_0 = 1.4412e-04
Loss = 3.6714e-01, PNorm = 43.9706, GNorm = 3.0848, lr_0 = 1.4281e-04
Validation rmse = 0.683527
Epoch 23
Loss = 4.6392e-01, PNorm = 43.9792, GNorm = 4.7918, lr_0 = 1.3034e-04
Validation rmse = 0.679900
Epoch 24
Loss = 4.3838e-01, PNorm = 43.9877, GNorm = 2.4770, lr_0 = 1.1896e-04
Validation rmse = 0.713443
Epoch 25
Validation rmse = 0.676854
Epoch 26
Loss = 3.7750e-01, PNorm = 43.9963, GNorm = 1.9280, lr_0 = 1.0758e-04
Validation rmse = 0.677110
Epoch 27
Loss = 3.5579e-01, PNorm = 44.0031, GNorm = 3.4900, lr_0 = 1.0000e-04
Validation rmse = 0.675319
Epoch 28
Loss = 4.0569e-01, PNorm = 44.0104, GNorm = 2.3107, lr_0 = 1.0000e-04
Validation rmse = 0.672958
Epoch 29
Loss = 4.0888e-01, PNorm = 44.0169, GNorm = 6.7279, lr_0 = 1.0000e-04
Validation rmse = 0.677106
Model 0 best validation rmse = 0.672958 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.658239
Ensemble test rmse = 0.658239
1-fold cross validation
	Seed 0 ==> test rmse = 0.658239
Overall test rmse = 0.658239 +/- 0.000000
Elapsed time = 0:01:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7446e+00, PNorm = 43.3153, GNorm = 1.9896, lr_0 = 5.9500e-04
Loss = 1.4994e+00, PNorm = 43.3166, GNorm = 2.3302, lr_0 = 6.4000e-04
Validation rmse = 1.589583
Epoch 1
Loss = 1.4118e+00, PNorm = 43.3500, GNorm = 1.0276, lr_0 = 9.8369e-04
Loss = 1.2549e+00, PNorm = 43.3554, GNorm = 1.0418, lr_0 = 9.7563e-04
Validation rmse = 1.398651
Epoch 2
Loss = 1.1870e+00, PNorm = 43.4118, GNorm = 0.6704, lr_0 = 8.9861e-04
Validation rmse = 1.228043
Epoch 3
Loss = 1.0378e+00, PNorm = 43.4712, GNorm = 0.7887, lr_0 = 8.2767e-04
Validation rmse = 1.062191
Epoch 4
Loss = 9.0785e-01, PNorm = 43.5403, GNorm = 4.5457, lr_0 = 7.5609e-04
Validation rmse = 0.982022
Epoch 5
Loss = 7.9758e-01, PNorm = 43.5992, GNorm = 3.3501, lr_0 = 6.9640e-04
Validation rmse = 0.910775
Epoch 6
Loss = 7.2595e-01, PNorm = 43.6487, GNorm = 2.6530, lr_0 = 6.3617e-04
Validation rmse = 0.851826
Epoch 7
Loss = 6.3345e-01, PNorm = 43.6961, GNorm = 1.6356, lr_0 = 5.8115e-04
Validation rmse = 0.812188
Epoch 8
Loss = 6.1124e-01, PNorm = 43.7303, GNorm = 4.6330, lr_0 = 5.3527e-04
Validation rmse = 0.790959
Epoch 9
Loss = 5.7802e-01, PNorm = 43.7690, GNorm = 1.6169, lr_0 = 4.8897e-04
Validation rmse = 0.794604
Epoch 10
Loss = 5.7135e-01, PNorm = 43.7995, GNorm = 3.8543, lr_0 = 4.5037e-04
Validation rmse = 0.786589
Epoch 11
Loss = 5.6217e-01, PNorm = 43.8293, GNorm = 7.4259, lr_0 = 4.1142e-04
Validation rmse = 0.769258
Epoch 12
Loss = 5.3170e-01, PNorm = 43.8537, GNorm = 7.1095, lr_0 = 3.7584e-04
Validation rmse = 0.740689
Epoch 13
Loss = 5.1393e-01, PNorm = 43.8795, GNorm = 4.1655, lr_0 = 3.4617e-04
Validation rmse = 0.750044
Epoch 14
Loss = 4.6599e-01, PNorm = 43.9003, GNorm = 4.5881, lr_0 = 3.1623e-04
Validation rmse = 0.758172
Epoch 15
Loss = 5.1018e-01, PNorm = 43.9157, GNorm = 16.3915, lr_0 = 2.9126e-04
Validation rmse = 0.739164
Epoch 16
Loss = 4.6186e-01, PNorm = 43.9329, GNorm = 15.2382, lr_0 = 2.6607e-04
Validation rmse = 0.741848
Epoch 17
Loss = 4.3948e-01, PNorm = 43.9476, GNorm = 7.2859, lr_0 = 2.4306e-04
Validation rmse = 0.744997
Epoch 18
Loss = 4.2776e-01, PNorm = 43.9602, GNorm = 4.4875, lr_0 = 2.2387e-04
Validation rmse = 0.724410
Epoch 19
Loss = 3.7316e-01, PNorm = 43.9721, GNorm = 3.3151, lr_0 = 2.0451e-04
Validation rmse = 0.713302
Epoch 20
Loss = 3.7107e-01, PNorm = 43.9818, GNorm = 5.4339, lr_0 = 1.8836e-04
Validation rmse = 0.721289
Epoch 21
Loss = 4.8270e-01, PNorm = 43.9924, GNorm = 4.9509, lr_0 = 1.7207e-04
Validation rmse = 0.716908
Epoch 22
Loss = 4.1105e-01, PNorm = 44.0020, GNorm = 2.1332, lr_0 = 1.5719e-04
Validation rmse = 0.709220
Epoch 23
Loss = 3.2750e-01, PNorm = 44.0107, GNorm = 1.9996, lr_0 = 1.4478e-04
Validation rmse = 0.707496
Epoch 24
Loss = 3.3514e-01, PNorm = 44.0177, GNorm = 3.8571, lr_0 = 1.3226e-04
Loss = 3.6254e-01, PNorm = 44.0244, GNorm = 3.1601, lr_0 = 1.2182e-04
Validation rmse = 0.704161
Epoch 25
Loss = 3.5617e-01, PNorm = 44.0298, GNorm = 3.7846, lr_0 = 1.1220e-04
Loss = 2.5797e-01, PNorm = 44.0305, GNorm = 6.9574, lr_0 = 1.1128e-04
Validation rmse = 0.705774
Epoch 26
Loss = 3.6289e-01, PNorm = 44.0372, GNorm = 8.0548, lr_0 = 1.0250e-04
Loss = 2.6915e-01, PNorm = 44.0375, GNorm = 5.4164, lr_0 = 1.0166e-04
Validation rmse = 0.708212
Epoch 27
Loss = 3.5219e-01, PNorm = 44.0412, GNorm = 6.5643, lr_0 = 1.0000e-04
Validation rmse = 0.700462
Epoch 28
Loss = 3.4878e-01, PNorm = 44.0462, GNorm = 2.7758, lr_0 = 1.0000e-04
Validation rmse = 0.700757
Epoch 29
Loss = 3.3744e-01, PNorm = 44.0521, GNorm = 9.7981, lr_0 = 1.0000e-04
Validation rmse = 0.700783
Model 0 best validation rmse = 0.700462 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.621654
Ensemble test rmse = 0.621654
1-fold cross validation
	Seed 0 ==> test rmse = 0.621654
Overall test rmse = 0.621654 +/- 0.000000
Elapsed time = 0:01:50
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7559e+00, PNorm = 43.3137, GNorm = 1.7596, lr_0 = 5.5000e-04
Validation rmse = 1.745779
Epoch 1
Loss = 1.4064e+00, PNorm = 43.3418, GNorm = 1.1494, lr_0 = 1.0000e-03
Validation rmse = 1.528529
Epoch 2
Loss = 1.1515e+00, PNorm = 43.4005, GNorm = 1.3445, lr_0 = 9.2106e-04
Validation rmse = 1.276561
Epoch 3
Loss = 1.0234e+00, PNorm = 43.4623, GNorm = 1.3203, lr_0 = 8.4834e-04
Validation rmse = 1.236607
Epoch 4
Loss = 9.7237e-01, PNorm = 43.5278, GNorm = 1.1166, lr_0 = 7.8137e-04
Validation rmse = 1.097451
Epoch 5
Loss = 7.9213e-01, PNorm = 43.5865, GNorm = 5.2059, lr_0 = 7.2509e-04
Validation rmse = 0.964242
Epoch 6
Loss = 7.3395e-01, PNorm = 43.6400, GNorm = 1.1922, lr_0 = 6.6784e-04
Validation rmse = 0.939430
Epoch 7
Loss = 6.5643e-01, PNorm = 43.6897, GNorm = 1.5831, lr_0 = 6.1512e-04
Validation rmse = 0.877629
Epoch 8
Loss = 7.0149e-01, PNorm = 43.7314, GNorm = 1.7944, lr_0 = 5.6656e-04
Loss = 5.8712e-01, PNorm = 43.7625, GNorm = 4.8159, lr_0 = 5.2575e-04
Loss = 7.6786e-01, PNorm = 43.7650, GNorm = 8.9161, lr_0 = 5.2183e-04
Validation rmse = 0.864300
Epoch 9
Loss = 5.7246e-01, PNorm = 43.7958, GNorm = 2.2784, lr_0 = 4.8424e-04
Validation rmse = 0.857108
Epoch 10
Loss = 5.2805e-01, PNorm = 43.8209, GNorm = 6.0418, lr_0 = 4.4936e-04
Validation rmse = 0.836115
Epoch 11
Loss = 5.4063e-01, PNorm = 43.8491, GNorm = 2.4305, lr_0 = 4.1389e-04
Validation rmse = 0.841974
Epoch 12
Loss = 4.6812e-01, PNorm = 43.8754, GNorm = 2.5841, lr_0 = 3.8121e-04
Validation rmse = 0.808277
Epoch 13
Loss = 4.8186e-01, PNorm = 43.8971, GNorm = 2.9226, lr_0 = 3.5112e-04
Validation rmse = 0.818529
Epoch 14
Loss = 4.5713e-01, PNorm = 43.9183, GNorm = 1.8930, lr_0 = 3.2340e-04
Validation rmse = 0.796545
Epoch 15
Loss = 5.1333e-01, PNorm = 43.9323, GNorm = 2.7047, lr_0 = 3.0010e-04
Validation rmse = 0.776698
Epoch 16
Loss = 3.8655e-01, PNorm = 43.9469, GNorm = 1.5157, lr_0 = 2.7641e-04
Loss = 4.1121e-01, PNorm = 43.9608, GNorm = 4.4280, lr_0 = 2.5650e-04
Loss = 5.9050e-01, PNorm = 43.9622, GNorm = 7.6005, lr_0 = 2.5459e-04
Validation rmse = 0.785351
Epoch 17
Loss = 4.3588e-01, PNorm = 43.9736, GNorm = 6.8847, lr_0 = 2.3625e-04
Validation rmse = 0.773858
Epoch 18
Loss = 3.9322e-01, PNorm = 43.9885, GNorm = 2.8555, lr_0 = 2.1760e-04
Validation rmse = 0.772571
Epoch 19
Loss = 3.5379e-01, PNorm = 44.0013, GNorm = 1.8289, lr_0 = 2.0042e-04
Validation rmse = 0.783130
Epoch 20
Loss = 3.2103e-01, PNorm = 44.0091, GNorm = 5.3151, lr_0 = 1.8599e-04
Validation rmse = 0.759748
Epoch 21
Loss = 3.5873e-01, PNorm = 44.0196, GNorm = 3.0065, lr_0 = 1.7130e-04
Validation rmse = 0.763527
Epoch 22
Loss = 3.5342e-01, PNorm = 44.0287, GNorm = 2.0092, lr_0 = 1.5778e-04
Validation rmse = 0.762092
Epoch 23
Loss = 3.1864e-01, PNorm = 44.0377, GNorm = 2.1468, lr_0 = 1.4532e-04
Validation rmse = 0.766053
Epoch 24
Loss = 3.6698e-01, PNorm = 44.0451, GNorm = 11.6140, lr_0 = 1.3385e-04
Loss = 3.5623e-01, PNorm = 44.0506, GNorm = 6.9704, lr_0 = 1.2421e-04
Validation rmse = 0.764670
Epoch 25
Loss = 3.2969e-01, PNorm = 44.0569, GNorm = 3.5494, lr_0 = 1.1526e-04
Validation rmse = 0.763904
Epoch 26
Loss = 3.3326e-01, PNorm = 44.0638, GNorm = 7.7365, lr_0 = 1.0616e-04
Validation rmse = 0.760119
Epoch 27
Loss = 3.2314e-01, PNorm = 44.0682, GNorm = 2.9499, lr_0 = 1.0000e-04
Validation rmse = 0.757596
Epoch 28
Loss = 3.1300e-01, PNorm = 44.0746, GNorm = 3.6630, lr_0 = 1.0000e-04
Validation rmse = 0.751888
Epoch 29
Loss = 3.3580e-01, PNorm = 44.0807, GNorm = 2.6619, lr_0 = 1.0000e-04
Validation rmse = 0.756931
Model 0 best validation rmse = 0.751888 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.613186
Ensemble test rmse = 0.613186
1-fold cross validation
	Seed 0 ==> test rmse = 0.613186
Overall test rmse = 0.613186 +/- 0.000000
Elapsed time = 0:01:59
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7091e+00, PNorm = 43.3137, GNorm = 2.0423, lr_0 = 5.1250e-04
Validation rmse = 1.617309
Epoch 1
Loss = 1.3977e+00, PNorm = 43.3359, GNorm = 1.3393, lr_0 = 8.8750e-04
Validation rmse = 1.432812
Epoch 2
Loss = 1.1381e+00, PNorm = 43.3941, GNorm = 2.1095, lr_0 = 9.5316e-04
Validation rmse = 1.199449
Epoch 3
Loss = 9.4940e-01, PNorm = 43.4559, GNorm = 1.1541, lr_0 = 8.9003e-04
Validation rmse = 1.044318
Epoch 4
Loss = 8.3658e-01, PNorm = 43.5382, GNorm = 2.8105, lr_0 = 8.3108e-04
Loss = 8.0008e-01, PNorm = 43.5953, GNorm = 5.1584, lr_0 = 7.7603e-04
Validation rmse = 0.954997
Epoch 5
Loss = 7.2635e-01, PNorm = 43.6518, GNorm = 4.3079, lr_0 = 7.2463e-04
Validation rmse = 1.019897
Epoch 6
Loss = 7.4024e-01, PNorm = 43.6942, GNorm = 6.3450, lr_0 = 6.7664e-04
Validation rmse = 0.904308
Epoch 7
Loss = 6.4837e-01, PNorm = 43.7325, GNorm = 1.6463, lr_0 = 6.3182e-04
Validation rmse = 0.883765
Epoch 8
Loss = 5.8781e-01, PNorm = 43.7694, GNorm = 5.9884, lr_0 = 5.8997e-04
Validation rmse = 0.854791
Epoch 9
Loss = 5.3434e-01, PNorm = 43.8002, GNorm = 4.6515, lr_0 = 5.5090e-04
Loss = 5.4172e-01, PNorm = 43.8335, GNorm = 4.8375, lr_0 = 5.1441e-04
Validation rmse = 0.848126
Epoch 10
Loss = 5.0884e-01, PNorm = 43.8601, GNorm = 5.0192, lr_0 = 4.8034e-04
Validation rmse = 0.844921
Epoch 11
Loss = 4.9561e-01, PNorm = 43.8869, GNorm = 4.3618, lr_0 = 4.4852e-04
Validation rmse = 0.814513
Epoch 12
Loss = 4.2170e-01, PNorm = 43.9112, GNorm = 1.3512, lr_0 = 4.1882e-04
Validation rmse = 0.789068
Epoch 13
Loss = 3.9763e-01, PNorm = 43.9343, GNorm = 3.7205, lr_0 = 3.9108e-04
Validation rmse = 0.784546
Epoch 14
Loss = 3.9928e-01, PNorm = 43.9580, GNorm = 5.6871, lr_0 = 3.6517e-04
Loss = 4.0850e-01, PNorm = 43.9773, GNorm = 8.1179, lr_0 = 3.4099e-04
Validation rmse = 0.787354
Epoch 15
Loss = 4.0263e-01, PNorm = 43.9993, GNorm = 2.4115, lr_0 = 3.1840e-04
Validation rmse = 0.767207
Epoch 16
Loss = 3.6534e-01, PNorm = 44.0160, GNorm = 3.2138, lr_0 = 2.9731e-04
Validation rmse = 0.806886
Epoch 17
Loss = 3.8006e-01, PNorm = 44.0333, GNorm = 6.1399, lr_0 = 2.7762e-04
Validation rmse = 0.778718
Epoch 18
Loss = 3.8126e-01, PNorm = 44.0472, GNorm = 5.4651, lr_0 = 2.5923e-04
Validation rmse = 0.763424
Epoch 19
Loss = 3.0058e-01, PNorm = 44.0621, GNorm = 2.6168, lr_0 = 2.4206e-04
Loss = 3.4570e-01, PNorm = 44.0735, GNorm = 2.2364, lr_0 = 2.2603e-04
Validation rmse = 0.764609
Epoch 20
Loss = 3.1864e-01, PNorm = 44.0862, GNorm = 5.5459, lr_0 = 2.1106e-04
Validation rmse = 0.777293
Epoch 21
Loss = 3.1510e-01, PNorm = 44.0979, GNorm = 3.0817, lr_0 = 1.9708e-04
Validation rmse = 0.754944
Epoch 22
Loss = 2.9020e-01, PNorm = 44.1085, GNorm = 3.1552, lr_0 = 1.8403e-04
Validation rmse = 0.750174
Epoch 23
Loss = 2.6300e-01, PNorm = 44.1188, GNorm = 5.0087, lr_0 = 1.7184e-04
Validation rmse = 0.747513
Epoch 24
Loss = 3.2779e-01, PNorm = 44.1284, GNorm = 2.8901, lr_0 = 1.6046e-04
Loss = 2.7653e-01, PNorm = 44.1374, GNorm = 3.1648, lr_0 = 1.4983e-04
Validation rmse = 0.744201
Epoch 25
Loss = 2.7994e-01, PNorm = 44.1450, GNorm = 5.2208, lr_0 = 1.3991e-04
Validation rmse = 0.745614
Epoch 26
Loss = 2.4082e-01, PNorm = 44.1525, GNorm = 2.9660, lr_0 = 1.3064e-04
Validation rmse = 0.739406
Epoch 27
Loss = 2.7843e-01, PNorm = 44.1599, GNorm = 3.3710, lr_0 = 1.2199e-04
Validation rmse = 0.742729
Epoch 28
Loss = 1.8074e-01, PNorm = 44.1667, GNorm = 4.5892, lr_0 = 1.1391e-04
Validation rmse = 0.739357
Epoch 29
Loss = 2.4619e-01, PNorm = 44.1731, GNorm = 3.7757, lr_0 = 1.0636e-04
Loss = 2.5450e-01, PNorm = 44.1790, GNorm = 4.2278, lr_0 = 1.0000e-04
Validation rmse = 0.742936
Model 0 best validation rmse = 0.739357 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.618476
Ensemble test rmse = 0.618476
1-fold cross validation
	Seed 0 ==> test rmse = 0.618476
Overall test rmse = 0.618476 +/- 0.000000
Elapsed time = 0:02:06
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7971e+00, PNorm = 43.3115, GNorm = 2.0024, lr_0 = 2.5469e-04
Loss = 1.4659e+00, PNorm = 43.3112, GNorm = 0.9890, lr_0 = 3.9531e-04
Loss = 1.4318e+00, PNorm = 43.3168, GNorm = 1.2475, lr_0 = 5.3594e-04
Validation rmse = 1.299754
Epoch 1
Loss = 1.3380e+00, PNorm = 43.3318, GNorm = 1.6819, lr_0 = 6.7656e-04
Loss = 1.3459e+00, PNorm = 43.3541, GNorm = 1.0295, lr_0 = 8.1719e-04
Loss = 1.2892e+00, PNorm = 43.3891, GNorm = 2.4086, lr_0 = 9.5781e-04
Validation rmse = 1.169368
Epoch 2
Loss = 1.1357e+00, PNorm = 43.4442, GNorm = 5.3831, lr_0 = 9.8217e-04
Loss = 1.2026e+00, PNorm = 43.5018, GNorm = 1.2008, lr_0 = 9.5725e-04
Loss = 1.1855e+00, PNorm = 43.5636, GNorm = 1.4678, lr_0 = 9.3297e-04
Validation rmse = 1.164411
Epoch 3
Loss = 1.1150e+00, PNorm = 43.6273, GNorm = 2.3643, lr_0 = 9.0930e-04
Loss = 1.0181e+00, PNorm = 43.6937, GNorm = 3.1221, lr_0 = 8.8623e-04
Loss = 9.1025e-01, PNorm = 43.7384, GNorm = 1.6736, lr_0 = 8.6374e-04
Validation rmse = 0.940922
Epoch 4
Loss = 8.0235e-01, PNorm = 43.7893, GNorm = 4.3859, lr_0 = 8.4183e-04
Loss = 8.3129e-01, PNorm = 43.8279, GNorm = 6.0293, lr_0 = 8.2047e-04
Loss = 9.2860e-01, PNorm = 43.8640, GNorm = 4.4547, lr_0 = 7.9965e-04
Loss = 9.2614e-01, PNorm = 43.8958, GNorm = 6.0813, lr_0 = 7.7937e-04
Validation rmse = 0.892394
Epoch 5
Loss = 8.0514e-01, PNorm = 43.9395, GNorm = 3.3396, lr_0 = 7.5959e-04
Loss = 8.1402e-01, PNorm = 43.9867, GNorm = 6.7027, lr_0 = 7.4032e-04
Loss = 8.2023e-01, PNorm = 44.0243, GNorm = 6.1850, lr_0 = 7.2154e-04
Validation rmse = 0.868052
Epoch 6
Loss = 7.2361e-01, PNorm = 44.0540, GNorm = 3.0961, lr_0 = 7.0323e-04
Loss = 7.0456e-01, PNorm = 44.0918, GNorm = 5.4645, lr_0 = 6.8539e-04
Loss = 7.2859e-01, PNorm = 44.1238, GNorm = 4.2741, lr_0 = 6.6800e-04
Validation rmse = 0.816306
Epoch 7
Loss = 7.4906e-01, PNorm = 44.1401, GNorm = 7.1905, lr_0 = 6.5105e-04
Loss = 6.7794e-01, PNorm = 44.1703, GNorm = 3.1195, lr_0 = 6.3453e-04
Loss = 6.8047e-01, PNorm = 44.2089, GNorm = 3.5385, lr_0 = 6.1844e-04
Validation rmse = 0.916313
Epoch 8
Loss = 7.8425e-01, PNorm = 44.2350, GNorm = 9.0157, lr_0 = 6.0275e-04
Loss = 6.2085e-01, PNorm = 44.2659, GNorm = 2.5534, lr_0 = 5.8745e-04
Loss = 6.8045e-01, PNorm = 44.2917, GNorm = 5.2248, lr_0 = 5.7255e-04
Validation rmse = 0.952854
Epoch 9
Loss = 6.3917e-01, PNorm = 44.3167, GNorm = 3.9287, lr_0 = 5.5802e-04
Loss = 5.6129e-01, PNorm = 44.3492, GNorm = 3.9874, lr_0 = 5.4386e-04
Loss = 7.3477e-01, PNorm = 44.3822, GNorm = 14.5680, lr_0 = 5.3007e-04
Loss = 7.3037e-01, PNorm = 44.4027, GNorm = 8.0023, lr_0 = 5.1662e-04
Validation rmse = 0.823987
Epoch 10
Loss = 5.8064e-01, PNorm = 44.4208, GNorm = 2.9052, lr_0 = 5.0351e-04
Loss = 6.2866e-01, PNorm = 44.4504, GNorm = 5.0193, lr_0 = 4.9074e-04
Loss = 5.7882e-01, PNorm = 44.4740, GNorm = 2.9957, lr_0 = 4.7829e-04
Validation rmse = 0.830755
Epoch 11
Loss = 5.9205e-01, PNorm = 44.4843, GNorm = 3.4481, lr_0 = 4.6615e-04
Loss = 6.4958e-01, PNorm = 44.5093, GNorm = 4.6195, lr_0 = 4.5432e-04
Loss = 5.8645e-01, PNorm = 44.5371, GNorm = 4.1234, lr_0 = 4.4280e-04
Validation rmse = 0.799212
Epoch 12
Loss = 4.5680e-01, PNorm = 44.5557, GNorm = 12.6007, lr_0 = 4.3156e-04
Loss = 6.2147e-01, PNorm = 44.5681, GNorm = 5.3773, lr_0 = 4.2061e-04
Loss = 6.1121e-01, PNorm = 44.5838, GNorm = 9.1922, lr_0 = 4.0994e-04
Validation rmse = 0.812538
Epoch 13
Loss = 5.1368e-01, PNorm = 44.6063, GNorm = 14.8895, lr_0 = 3.9954e-04
Loss = 5.1918e-01, PNorm = 44.6244, GNorm = 4.0611, lr_0 = 3.8941e-04
Loss = 5.2633e-01, PNorm = 44.6407, GNorm = 3.3360, lr_0 = 3.7953e-04
Validation rmse = 0.808796
Epoch 14
Loss = 4.2435e-01, PNorm = 44.6555, GNorm = 4.2646, lr_0 = 3.6990e-04
Loss = 4.8352e-01, PNorm = 44.6760, GNorm = 13.3180, lr_0 = 3.6051e-04
Loss = 4.9139e-01, PNorm = 44.6920, GNorm = 4.8802, lr_0 = 3.5137e-04
Loss = 4.8302e-01, PNorm = 44.7086, GNorm = 7.9547, lr_0 = 3.4245e-04
Validation rmse = 0.803085
Epoch 15
Loss = 3.9793e-01, PNorm = 44.7224, GNorm = 14.5421, lr_0 = 3.3376e-04
Loss = 3.8631e-01, PNorm = 44.7372, GNorm = 2.8248, lr_0 = 3.2529e-04
Loss = 5.2718e-01, PNorm = 44.7483, GNorm = 8.7825, lr_0 = 3.1704e-04
Validation rmse = 0.823162
Epoch 16
Loss = 4.7324e-01, PNorm = 44.7598, GNorm = 5.6443, lr_0 = 3.0900e-04
Loss = 4.5580e-01, PNorm = 44.7762, GNorm = 9.5485, lr_0 = 3.0116e-04
Loss = 4.5634e-01, PNorm = 44.7908, GNorm = 6.2347, lr_0 = 2.9352e-04
Validation rmse = 0.830961
Epoch 17
Loss = 3.7195e-01, PNorm = 44.8047, GNorm = 5.3704, lr_0 = 2.8607e-04
Loss = 4.4060e-01, PNorm = 44.8178, GNorm = 5.4434, lr_0 = 2.7881e-04
Loss = 4.3620e-01, PNorm = 44.8271, GNorm = 3.3309, lr_0 = 2.7174e-04
Validation rmse = 0.795725
Epoch 18
Loss = 4.2514e-01, PNorm = 44.8390, GNorm = 2.5388, lr_0 = 2.6484e-04
Loss = 4.1589e-01, PNorm = 44.8564, GNorm = 7.6858, lr_0 = 2.5813e-04
Loss = 3.8446e-01, PNorm = 44.8718, GNorm = 4.4800, lr_0 = 2.5158e-04
Validation rmse = 0.799958
Epoch 19
Loss = 2.3558e-01, PNorm = 44.8795, GNorm = 5.7134, lr_0 = 2.4519e-04
Loss = 3.4908e-01, PNorm = 44.8923, GNorm = 3.8303, lr_0 = 2.3897e-04
Loss = 4.4073e-01, PNorm = 44.9032, GNorm = 3.0587, lr_0 = 2.3291e-04
Loss = 3.5527e-01, PNorm = 44.9121, GNorm = 7.1730, lr_0 = 2.2700e-04
Validation rmse = 0.782063
Epoch 20
Loss = 3.6407e-01, PNorm = 44.9251, GNorm = 6.3257, lr_0 = 2.2124e-04
Loss = 3.6107e-01, PNorm = 44.9370, GNorm = 5.3795, lr_0 = 2.1563e-04
Loss = 4.1168e-01, PNorm = 44.9441, GNorm = 5.7887, lr_0 = 2.1016e-04
Validation rmse = 0.803889
Epoch 21
Loss = 4.4061e-01, PNorm = 44.9521, GNorm = 4.8991, lr_0 = 2.0483e-04
Loss = 3.1711e-01, PNorm = 44.9650, GNorm = 9.8006, lr_0 = 1.9963e-04
Loss = 3.2690e-01, PNorm = 44.9747, GNorm = 12.3016, lr_0 = 1.9456e-04
Validation rmse = 0.778549
Epoch 22
Loss = 3.9265e-01, PNorm = 44.9782, GNorm = 11.0179, lr_0 = 1.8963e-04
Loss = 3.3406e-01, PNorm = 44.9880, GNorm = 5.1526, lr_0 = 1.8482e-04
Loss = 3.1062e-01, PNorm = 44.9977, GNorm = 5.9315, lr_0 = 1.8013e-04
Validation rmse = 0.787382
Epoch 23
Loss = 3.0495e-01, PNorm = 45.0083, GNorm = 10.7414, lr_0 = 1.7556e-04
Loss = 2.5066e-01, PNorm = 45.0176, GNorm = 10.0384, lr_0 = 1.7110e-04
Loss = 3.1722e-01, PNorm = 45.0269, GNorm = 8.0343, lr_0 = 1.6676e-04
Validation rmse = 0.824758
Epoch 24
Loss = 4.5111e-01, PNorm = 45.0329, GNorm = 4.8601, lr_0 = 1.6253e-04
Loss = 2.2749e-01, PNorm = 45.0401, GNorm = 13.0612, lr_0 = 1.5841e-04
Loss = 3.0249e-01, PNorm = 45.0487, GNorm = 6.6922, lr_0 = 1.5439e-04
Loss = 3.1466e-01, PNorm = 45.0571, GNorm = 3.5497, lr_0 = 1.5047e-04
Validation rmse = 0.808305
Epoch 25
Loss = 2.3852e-01, PNorm = 45.0635, GNorm = 3.9648, lr_0 = 1.4665e-04
Loss = 3.2028e-01, PNorm = 45.0698, GNorm = 11.4017, lr_0 = 1.4293e-04
Loss = 2.7439e-01, PNorm = 45.0773, GNorm = 4.0354, lr_0 = 1.3931e-04
Validation rmse = 0.785217
Epoch 26
Loss = 2.8454e-01, PNorm = 45.0838, GNorm = 6.6765, lr_0 = 1.3577e-04
Loss = 2.8782e-01, PNorm = 45.0893, GNorm = 4.8843, lr_0 = 1.3233e-04
Loss = 2.0568e-01, PNorm = 45.0967, GNorm = 10.2695, lr_0 = 1.2897e-04
Validation rmse = 0.801374
Epoch 27
Loss = 3.5852e-01, PNorm = 45.1034, GNorm = 4.9097, lr_0 = 1.2570e-04
Loss = 3.5938e-01, PNorm = 45.1068, GNorm = 9.2491, lr_0 = 1.2251e-04
Loss = 2.0515e-01, PNorm = 45.1114, GNorm = 5.5147, lr_0 = 1.1940e-04
Validation rmse = 0.778685
Epoch 28
Loss = 3.2155e-01, PNorm = 45.1178, GNorm = 4.8373, lr_0 = 1.1637e-04
Loss = 1.7952e-01, PNorm = 45.1238, GNorm = 11.7788, lr_0 = 1.1342e-04
Loss = 2.8526e-01, PNorm = 45.1296, GNorm = 5.5488, lr_0 = 1.1054e-04
Validation rmse = 0.789406
Epoch 29
Loss = 2.2612e-01, PNorm = 45.1353, GNorm = 6.8395, lr_0 = 1.0774e-04
Loss = 2.0776e-01, PNorm = 45.1431, GNorm = 12.0301, lr_0 = 1.0500e-04
Loss = 1.8157e-01, PNorm = 45.1489, GNorm = 4.7955, lr_0 = 1.0234e-04
Loss = 2.7981e-01, PNorm = 45.1513, GNorm = 10.4500, lr_0 = 1.0000e-04
Validation rmse = 0.793386
Model 0 best validation rmse = 0.778549 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.683330
Ensemble test rmse = 0.683330
1-fold cross validation
	Seed 0 ==> test rmse = 0.683330
Overall test rmse = 0.683330 +/- 0.000000
Elapsed time = 0:01:27
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,025 | train size = 820 | val size = 102 | test size = 103
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9978e+00, PNorm = 43.3126, GNorm = 3.5794, lr_0 = 2.5469e-04
Loss = 1.4669e+00, PNorm = 43.3148, GNorm = 1.8343, lr_0 = 3.9531e-04
Loss = 1.4705e+00, PNorm = 43.3226, GNorm = 1.2891, lr_0 = 5.3594e-04
Validation rmse = 1.339664
Epoch 1
Loss = 1.3628e+00, PNorm = 43.3401, GNorm = 1.9583, lr_0 = 6.9063e-04
Loss = 1.2474e+00, PNorm = 43.3649, GNorm = 1.2051, lr_0 = 8.3125e-04
Loss = 1.2770e+00, PNorm = 43.3988, GNorm = 1.0550, lr_0 = 9.7187e-04
Validation rmse = 1.199954
Epoch 2
Loss = 1.1413e+00, PNorm = 43.4537, GNorm = 1.5572, lr_0 = 9.7965e-04
Loss = 1.0474e+00, PNorm = 43.5153, GNorm = 3.3237, lr_0 = 9.5480e-04
Loss = 1.0607e+00, PNorm = 43.5667, GNorm = 3.3795, lr_0 = 9.3057e-04
Validation rmse = 0.959209
Epoch 3
Loss = 8.3748e-01, PNorm = 43.6286, GNorm = 2.1668, lr_0 = 9.0696e-04
Loss = 8.6572e-01, PNorm = 43.6811, GNorm = 4.6466, lr_0 = 8.8395e-04
Loss = 1.0062e+00, PNorm = 43.7215, GNorm = 1.7416, lr_0 = 8.6152e-04
Loss = 9.0574e-01, PNorm = 43.7646, GNorm = 3.4061, lr_0 = 8.3967e-04
Validation rmse = 0.865904
Epoch 4
Loss = 7.8617e-01, PNorm = 43.8125, GNorm = 6.8651, lr_0 = 8.1836e-04
Loss = 8.1816e-01, PNorm = 43.8532, GNorm = 5.4484, lr_0 = 7.9760e-04
Loss = 8.5709e-01, PNorm = 43.8933, GNorm = 4.7447, lr_0 = 7.7737e-04
Validation rmse = 1.084295
Epoch 5
Loss = 8.2676e-01, PNorm = 43.9354, GNorm = 7.3025, lr_0 = 7.5764e-04
Loss = 7.7084e-01, PNorm = 43.9690, GNorm = 9.9388, lr_0 = 7.3842e-04
Loss = 7.9146e-01, PNorm = 43.9978, GNorm = 2.4982, lr_0 = 7.1969e-04
Validation rmse = 0.830103
Epoch 6
Loss = 5.7690e-01, PNorm = 44.0398, GNorm = 3.2746, lr_0 = 6.9963e-04
Loss = 6.5860e-01, PNorm = 44.0722, GNorm = 6.1342, lr_0 = 6.8188e-04
Loss = 8.0938e-01, PNorm = 44.0898, GNorm = 2.9329, lr_0 = 6.6458e-04
Validation rmse = 0.881785
Epoch 7
Loss = 5.2985e-01, PNorm = 44.1176, GNorm = 2.1854, lr_0 = 6.4771e-04
Loss = 6.8429e-01, PNorm = 44.1578, GNorm = 3.8499, lr_0 = 6.3128e-04
Loss = 6.1894e-01, PNorm = 44.1872, GNorm = 3.9359, lr_0 = 6.1527e-04
Loss = 6.0921e-01, PNorm = 44.2104, GNorm = 3.6951, lr_0 = 5.9966e-04
Validation rmse = 0.818334
Epoch 8
Loss = 5.5181e-01, PNorm = 44.2357, GNorm = 3.7530, lr_0 = 5.8444e-04
Loss = 5.9652e-01, PNorm = 44.2616, GNorm = 8.1300, lr_0 = 5.6961e-04
Loss = 5.7774e-01, PNorm = 44.2821, GNorm = 3.0196, lr_0 = 5.5516e-04
Validation rmse = 0.822403
Epoch 9
Loss = 4.3872e-01, PNorm = 44.3068, GNorm = 3.9118, lr_0 = 5.4108e-04
Loss = 5.2531e-01, PNorm = 44.3347, GNorm = 8.9548, lr_0 = 5.2735e-04
Loss = 5.2604e-01, PNorm = 44.3530, GNorm = 6.4625, lr_0 = 5.1397e-04
Validation rmse = 0.803839
Epoch 10
Loss = 3.7652e-01, PNorm = 44.3756, GNorm = 5.3489, lr_0 = 5.0093e-04
Loss = 5.5070e-01, PNorm = 44.3947, GNorm = 5.0143, lr_0 = 4.8822e-04
Loss = 6.2148e-01, PNorm = 44.4177, GNorm = 8.2029, lr_0 = 4.7583e-04
Loss = 6.0990e-01, PNorm = 44.4379, GNorm = 2.7495, lr_0 = 4.6376e-04
Loss = 3.9232e-01, PNorm = 44.4406, GNorm = 3.9617, lr_0 = 4.6257e-04
Validation rmse = 0.854110
Epoch 11
Loss = 4.6928e-01, PNorm = 44.4670, GNorm = 5.8806, lr_0 = 4.5084e-04
Loss = 4.3829e-01, PNorm = 44.4838, GNorm = 2.6277, lr_0 = 4.3940e-04
Loss = 5.0729e-01, PNorm = 44.5006, GNorm = 3.8373, lr_0 = 4.2825e-04
Validation rmse = 0.814707
Epoch 12
Loss = 4.4407e-01, PNorm = 44.5129, GNorm = 3.3117, lr_0 = 4.1738e-04
Loss = 4.1588e-01, PNorm = 44.5349, GNorm = 7.5627, lr_0 = 4.0679e-04
Loss = 5.2033e-01, PNorm = 44.5542, GNorm = 6.4734, lr_0 = 3.9647e-04
Validation rmse = 0.828404
Epoch 13
Loss = 4.5551e-01, PNorm = 44.5725, GNorm = 5.2346, lr_0 = 3.8641e-04
Loss = 4.3981e-01, PNorm = 44.5902, GNorm = 16.5820, lr_0 = 3.7661e-04
Loss = 4.4945e-01, PNorm = 44.6070, GNorm = 3.1543, lr_0 = 3.6706e-04
Validation rmse = 0.813711
Epoch 14
Loss = 2.4494e-01, PNorm = 44.6145, GNorm = 8.0690, lr_0 = 3.5774e-04
Loss = 4.4833e-01, PNorm = 44.6268, GNorm = 4.5470, lr_0 = 3.4867e-04
Loss = 4.8997e-01, PNorm = 44.6429, GNorm = 5.8645, lr_0 = 3.3982e-04
Loss = 4.9765e-01, PNorm = 44.6539, GNorm = 2.9589, lr_0 = 3.3120e-04
Validation rmse = 0.821663
Epoch 15
Loss = 4.4611e-01, PNorm = 44.6697, GNorm = 11.6330, lr_0 = 3.2280e-04
Loss = 3.2865e-01, PNorm = 44.6851, GNorm = 3.3503, lr_0 = 3.1461e-04
Loss = 4.9073e-01, PNorm = 44.6978, GNorm = 3.4278, lr_0 = 3.0662e-04
Validation rmse = 0.801432
Epoch 16
Loss = 4.0995e-01, PNorm = 44.7151, GNorm = 2.9426, lr_0 = 2.9808e-04
Loss = 3.7784e-01, PNorm = 44.7307, GNorm = 5.9651, lr_0 = 2.9052e-04
Loss = 4.3419e-01, PNorm = 44.7403, GNorm = 7.7955, lr_0 = 2.8315e-04
Validation rmse = 0.834187
Epoch 17
Loss = 3.6627e-01, PNorm = 44.7493, GNorm = 3.9172, lr_0 = 2.7596e-04
Loss = 3.0357e-01, PNorm = 44.7614, GNorm = 6.1111, lr_0 = 2.6896e-04
Loss = 3.6053e-01, PNorm = 44.7759, GNorm = 6.8527, lr_0 = 2.6214e-04
Loss = 3.5577e-01, PNorm = 44.7861, GNorm = 4.4376, lr_0 = 2.5549e-04
Validation rmse = 0.787926
Epoch 18
Loss = 2.7013e-01, PNorm = 44.7963, GNorm = 9.0394, lr_0 = 2.4900e-04
Loss = 2.7628e-01, PNorm = 44.8068, GNorm = 3.6259, lr_0 = 2.4269e-04
Loss = 3.6356e-01, PNorm = 44.8150, GNorm = 7.4091, lr_0 = 2.3653e-04
Validation rmse = 0.779225
Epoch 19
Loss = 2.5195e-01, PNorm = 44.8233, GNorm = 5.5757, lr_0 = 2.3053e-04
Loss = 2.0393e-01, PNorm = 44.8378, GNorm = 4.1795, lr_0 = 2.2468e-04
Loss = 4.5067e-01, PNorm = 44.8465, GNorm = 16.2530, lr_0 = 2.1898e-04
Validation rmse = 0.794618
Epoch 20
Loss = 1.8484e-01, PNorm = 44.8513, GNorm = 3.4518, lr_0 = 2.1342e-04
Loss = 2.7583e-01, PNorm = 44.8627, GNorm = 6.0488, lr_0 = 2.0801e-04
Loss = 3.2875e-01, PNorm = 44.8759, GNorm = 10.8312, lr_0 = 2.0273e-04
Validation rmse = 0.794583
Epoch 21
Loss = 3.7776e-01, PNorm = 44.8808, GNorm = 3.7728, lr_0 = 1.9708e-04
Loss = 1.6420e-01, PNorm = 44.8904, GNorm = 4.1795, lr_0 = 1.9208e-04
Loss = 2.9424e-01, PNorm = 44.8978, GNorm = 12.3117, lr_0 = 1.8721e-04
Loss = 3.7034e-01, PNorm = 44.9040, GNorm = 6.4525, lr_0 = 1.8246e-04
Validation rmse = 0.796871
Epoch 22
Loss = 2.6827e-01, PNorm = 44.9093, GNorm = 7.2071, lr_0 = 1.7783e-04
Loss = 2.6924e-01, PNorm = 44.9157, GNorm = 7.1718, lr_0 = 1.7332e-04
Loss = 2.5906e-01, PNorm = 44.9244, GNorm = 3.5911, lr_0 = 1.6892e-04
Validation rmse = 0.774598
Epoch 23
Loss = 2.6432e-01, PNorm = 44.9340, GNorm = 7.4014, lr_0 = 1.6463e-04
Loss = 2.0019e-01, PNorm = 44.9421, GNorm = 6.5783, lr_0 = 1.6046e-04
Loss = 2.9966e-01, PNorm = 44.9436, GNorm = 12.6993, lr_0 = 1.5639e-04
Validation rmse = 0.776745
Epoch 24
Loss = 3.2416e-01, PNorm = 44.9486, GNorm = 11.1381, lr_0 = 1.5242e-04
Loss = 2.3648e-01, PNorm = 44.9553, GNorm = 7.2210, lr_0 = 1.4855e-04
Loss = 2.3616e-01, PNorm = 44.9632, GNorm = 12.4405, lr_0 = 1.4478e-04
Loss = 1.9022e-01, PNorm = 44.9691, GNorm = 5.0991, lr_0 = 1.4111e-04
Validation rmse = 0.809996
Epoch 25
Loss = 1.5561e-01, PNorm = 44.9759, GNorm = 6.0096, lr_0 = 1.3753e-04
Loss = 2.8894e-01, PNorm = 44.9826, GNorm = 5.9686, lr_0 = 1.3404e-04
Loss = 2.0611e-01, PNorm = 44.9881, GNorm = 4.6941, lr_0 = 1.3064e-04
Validation rmse = 0.786512
Epoch 26
Loss = 1.8265e-01, PNorm = 44.9912, GNorm = 4.7125, lr_0 = 1.2700e-04
Loss = 1.9201e-01, PNorm = 44.9967, GNorm = 12.1638, lr_0 = 1.2378e-04
Loss = 1.5611e-01, PNorm = 45.0018, GNorm = 5.1613, lr_0 = 1.2063e-04
Validation rmse = 0.801339
Epoch 27
Loss = 2.5232e-01, PNorm = 45.0067, GNorm = 6.3522, lr_0 = 1.1757e-04
Loss = 2.6696e-01, PNorm = 45.0108, GNorm = 6.5971, lr_0 = 1.1459e-04
Loss = 1.6683e-01, PNorm = 45.0158, GNorm = 6.4348, lr_0 = 1.1168e-04
Validation rmse = 0.783002
Epoch 28
Loss = 2.1003e-01, PNorm = 45.0211, GNorm = 12.2108, lr_0 = 1.0885e-04
Loss = 1.1865e-01, PNorm = 45.0278, GNorm = 10.3957, lr_0 = 1.0609e-04
Loss = 2.3202e-01, PNorm = 45.0325, GNorm = 5.0977, lr_0 = 1.0340e-04
Loss = 1.7493e-01, PNorm = 45.0352, GNorm = 11.6545, lr_0 = 1.0077e-04
Validation rmse = 0.778854
Epoch 29
Loss = 1.0454e-01, PNorm = 45.0390, GNorm = 6.0819, lr_0 = 1.0000e-04
Loss = 1.6939e-01, PNorm = 45.0442, GNorm = 6.8236, lr_0 = 1.0000e-04
Loss = 1.4288e-01, PNorm = 45.0487, GNorm = 5.2323, lr_0 = 1.0000e-04
Validation rmse = 0.784993
Model 0 best validation rmse = 0.774598 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.644892
Ensemble test rmse = 0.644892
1-fold cross validation
	Seed 0 ==> test rmse = 0.644892
Overall test rmse = 0.644892 +/- 0.000000
Elapsed time = 0:01:24
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0394e+00, PNorm = 43.3138, GNorm = 2.6199, lr_0 = 2.5000e-04
Loss = 1.4135e+00, PNorm = 43.3147, GNorm = 0.9818, lr_0 = 3.8636e-04
Loss = 1.4525e+00, PNorm = 43.3210, GNorm = 1.6750, lr_0 = 5.2273e-04
Validation rmse = 1.376170
Epoch 1
Loss = 1.3337e+00, PNorm = 43.3359, GNorm = 1.6951, lr_0 = 6.7273e-04
Loss = 1.2306e+00, PNorm = 43.3633, GNorm = 3.8979, lr_0 = 8.0909e-04
Loss = 1.2138e+00, PNorm = 43.4015, GNorm = 1.2766, lr_0 = 9.4545e-04
Validation rmse = 1.164140
Epoch 2
Loss = 1.1482e+00, PNorm = 43.4432, GNorm = 3.5270, lr_0 = 9.8516e-04
Loss = 1.0942e+00, PNorm = 43.5043, GNorm = 5.8348, lr_0 = 9.6091e-04
Loss = 1.0179e+00, PNorm = 43.5628, GNorm = 2.2858, lr_0 = 9.3726e-04
Loss = 1.0918e+00, PNorm = 43.6052, GNorm = 1.8375, lr_0 = 9.1420e-04
Loss = 8.9609e-01, PNorm = 43.6092, GNorm = 1.5870, lr_0 = 9.1192e-04
Validation rmse = 1.009047
Epoch 3
Loss = 9.2330e-01, PNorm = 43.6638, GNorm = 4.7285, lr_0 = 8.8948e-04
Loss = 8.2477e-01, PNorm = 43.7186, GNorm = 2.3346, lr_0 = 8.6758e-04
Loss = 8.1816e-01, PNorm = 43.7600, GNorm = 4.8305, lr_0 = 8.4623e-04
Validation rmse = 0.902707
Epoch 4
Loss = 6.9314e-01, PNorm = 43.7979, GNorm = 5.7326, lr_0 = 8.2540e-04
Loss = 7.4198e-01, PNorm = 43.8548, GNorm = 10.1793, lr_0 = 8.0509e-04
Loss = 7.6390e-01, PNorm = 43.8891, GNorm = 2.5730, lr_0 = 7.8527e-04
Validation rmse = 0.871376
Epoch 5
Loss = 7.0790e-01, PNorm = 43.9183, GNorm = 5.5865, lr_0 = 7.6595e-04
Loss = 6.5215e-01, PNorm = 43.9521, GNorm = 4.5455, lr_0 = 7.4710e-04
Loss = 6.8585e-01, PNorm = 43.9854, GNorm = 7.7993, lr_0 = 7.2871e-04
Loss = 6.8214e-01, PNorm = 44.0136, GNorm = 9.3708, lr_0 = 7.1077e-04
Validation rmse = 0.915312
Epoch 6
Loss = 6.1271e-01, PNorm = 44.0443, GNorm = 3.1660, lr_0 = 6.9156e-04
Loss = 6.5435e-01, PNorm = 44.0771, GNorm = 12.1256, lr_0 = 6.7453e-04
Loss = 6.1844e-01, PNorm = 44.1043, GNorm = 3.0861, lr_0 = 6.5793e-04
Validation rmse = 0.831704
Epoch 7
Loss = 4.4765e-01, PNorm = 44.1409, GNorm = 2.6450, lr_0 = 6.4174e-04
Loss = 5.0770e-01, PNorm = 44.1625, GNorm = 2.5298, lr_0 = 6.2595e-04
Loss = 6.2273e-01, PNorm = 44.1812, GNorm = 3.6037, lr_0 = 6.1054e-04
Validation rmse = 0.784834
Epoch 8
Loss = 4.9162e-01, PNorm = 44.2111, GNorm = 5.8909, lr_0 = 5.9403e-04
Loss = 5.7921e-01, PNorm = 44.2319, GNorm = 3.6199, lr_0 = 5.7941e-04
Loss = 4.8389e-01, PNorm = 44.2576, GNorm = 5.5774, lr_0 = 5.6515e-04
Loss = 4.8572e-01, PNorm = 44.2824, GNorm = 9.8682, lr_0 = 5.5124e-04
Validation rmse = 0.764062
Epoch 9
Loss = 5.0271e-01, PNorm = 44.2984, GNorm = 7.3162, lr_0 = 5.3767e-04
Loss = 5.4576e-01, PNorm = 44.3128, GNorm = 6.7061, lr_0 = 5.2444e-04
Loss = 4.7711e-01, PNorm = 44.3396, GNorm = 4.6341, lr_0 = 5.1153e-04
Validation rmse = 0.793759
Epoch 10
Loss = 3.8979e-01, PNorm = 44.3605, GNorm = 4.8208, lr_0 = 4.9894e-04
Loss = 4.0699e-01, PNorm = 44.3791, GNorm = 11.1078, lr_0 = 4.8666e-04
Loss = 6.3738e-01, PNorm = 44.3930, GNorm = 7.5979, lr_0 = 4.7469e-04
Validation rmse = 0.753760
Epoch 11
Loss = 2.6612e-01, PNorm = 44.4125, GNorm = 2.3032, lr_0 = 4.6185e-04
Loss = 4.3558e-01, PNorm = 44.4385, GNorm = 7.4881, lr_0 = 4.5048e-04
Loss = 3.7605e-01, PNorm = 44.4569, GNorm = 3.8484, lr_0 = 4.3940e-04
Loss = 3.8700e-01, PNorm = 44.4733, GNorm = 7.3162, lr_0 = 4.2858e-04
Validation rmse = 0.734251
Epoch 12
Loss = 2.6123e-01, PNorm = 44.4853, GNorm = 5.7106, lr_0 = 4.1803e-04
Loss = 4.7221e-01, PNorm = 44.4967, GNorm = 12.5841, lr_0 = 4.0775e-04
Loss = 5.5775e-01, PNorm = 44.5134, GNorm = 9.3231, lr_0 = 3.9771e-04
Validation rmse = 0.756190
Epoch 13
Loss = 3.5083e-01, PNorm = 44.5336, GNorm = 4.9318, lr_0 = 3.8696e-04
Loss = 4.0292e-01, PNorm = 44.5506, GNorm = 7.9893, lr_0 = 3.7743e-04
Loss = 3.8852e-01, PNorm = 44.5639, GNorm = 9.8935, lr_0 = 3.6814e-04
Loss = 4.1716e-01, PNorm = 44.5808, GNorm = 8.3209, lr_0 = 3.5908e-04
Validation rmse = 0.851130
Epoch 14
Loss = 3.8149e-01, PNorm = 44.5964, GNorm = 8.4315, lr_0 = 3.5025e-04
Loss = 2.9142e-01, PNorm = 44.6142, GNorm = 3.4891, lr_0 = 3.4163e-04
Loss = 4.2448e-01, PNorm = 44.6268, GNorm = 3.3273, lr_0 = 3.3322e-04
Validation rmse = 0.774153
Epoch 15
Loss = 3.6058e-01, PNorm = 44.6372, GNorm = 11.7519, lr_0 = 3.2502e-04
Loss = 3.3751e-01, PNorm = 44.6433, GNorm = 5.7598, lr_0 = 3.1702e-04
Loss = 3.1794e-01, PNorm = 44.6536, GNorm = 5.0804, lr_0 = 3.0921e-04
Validation rmse = 0.787469
Epoch 16
Loss = 2.5556e-01, PNorm = 44.6643, GNorm = 5.9847, lr_0 = 3.0085e-04
Loss = 3.1448e-01, PNorm = 44.6743, GNorm = 10.2524, lr_0 = 2.9345e-04
Loss = 3.1008e-01, PNorm = 44.6900, GNorm = 11.6747, lr_0 = 2.8623e-04
Loss = 4.0337e-01, PNorm = 44.6960, GNorm = 10.7490, lr_0 = 2.7918e-04
Validation rmse = 0.747783
Epoch 17
Loss = 3.1385e-01, PNorm = 44.7067, GNorm = 12.9424, lr_0 = 2.7231e-04
Loss = 3.0835e-01, PNorm = 44.7210, GNorm = 8.6965, lr_0 = 2.6561e-04
Loss = 2.4894e-01, PNorm = 44.7330, GNorm = 9.1646, lr_0 = 2.5907e-04
Validation rmse = 0.794479
Epoch 18
Loss = 3.5307e-01, PNorm = 44.7408, GNorm = 6.1769, lr_0 = 2.5207e-04
Loss = 2.8105e-01, PNorm = 44.7536, GNorm = 5.0274, lr_0 = 2.4586e-04
Loss = 2.0933e-01, PNorm = 44.7671, GNorm = 8.4468, lr_0 = 2.3981e-04
Validation rmse = 0.729088
Epoch 19
Loss = 2.3591e-01, PNorm = 44.7765, GNorm = 4.5097, lr_0 = 2.3391e-04
Loss = 2.1321e-01, PNorm = 44.7852, GNorm = 6.7854, lr_0 = 2.2815e-04
Loss = 2.9569e-01, PNorm = 44.7923, GNorm = 8.1078, lr_0 = 2.2254e-04
Loss = 2.1431e-01, PNorm = 44.8009, GNorm = 3.0636, lr_0 = 2.1706e-04
Validation rmse = 0.752069
Epoch 20
Loss = 1.5676e-01, PNorm = 44.8101, GNorm = 5.3350, lr_0 = 2.1172e-04
Loss = 2.4330e-01, PNorm = 44.8206, GNorm = 9.9629, lr_0 = 2.0651e-04
Loss = 2.7688e-01, PNorm = 44.8278, GNorm = 6.6819, lr_0 = 2.0142e-04
Validation rmse = 0.762034
Epoch 21
Loss = 2.9993e-01, PNorm = 44.8354, GNorm = 4.4999, lr_0 = 1.9598e-04
Loss = 1.6407e-01, PNorm = 44.8467, GNorm = 6.9411, lr_0 = 1.9115e-04
Loss = 1.9008e-01, PNorm = 44.8565, GNorm = 6.2594, lr_0 = 1.8645e-04
Validation rmse = 0.731035
Epoch 22
Loss = 2.5098e-01, PNorm = 44.8605, GNorm = 3.6557, lr_0 = 1.8186e-04
Loss = 1.7407e-01, PNorm = 44.8660, GNorm = 3.9601, lr_0 = 1.7739e-04
Loss = 2.8286e-01, PNorm = 44.8739, GNorm = 5.2831, lr_0 = 1.7302e-04
Loss = 1.6338e-01, PNorm = 44.8790, GNorm = 3.9079, lr_0 = 1.6876e-04
Validation rmse = 0.721641
Epoch 23
Loss = 1.9096e-01, PNorm = 44.8879, GNorm = 4.8301, lr_0 = 1.6420e-04
Loss = 1.4880e-01, PNorm = 44.8968, GNorm = 8.1032, lr_0 = 1.6016e-04
Loss = 2.3055e-01, PNorm = 44.9029, GNorm = 15.0024, lr_0 = 1.5622e-04
Validation rmse = 0.731858
Epoch 24
Loss = 1.7197e-01, PNorm = 44.9086, GNorm = 8.6679, lr_0 = 1.5237e-04
Loss = 1.7949e-01, PNorm = 44.9148, GNorm = 6.3575, lr_0 = 1.4862e-04
Loss = 1.5100e-01, PNorm = 44.9227, GNorm = 7.3015, lr_0 = 1.4496e-04
Loss = 2.1909e-01, PNorm = 44.9281, GNorm = 7.8748, lr_0 = 1.4139e-04
Validation rmse = 0.756590
Epoch 25
Loss = 1.3602e-01, PNorm = 44.9335, GNorm = 4.7240, lr_0 = 1.3791e-04
Loss = 1.1507e-01, PNorm = 44.9406, GNorm = 20.4243, lr_0 = 1.3452e-04
Loss = 1.2905e-01, PNorm = 44.9460, GNorm = 19.4154, lr_0 = 1.3121e-04
Validation rmse = 0.759798
Epoch 26
Loss = 1.7286e-01, PNorm = 44.9506, GNorm = 11.7047, lr_0 = 1.2766e-04
Loss = 1.2444e-01, PNorm = 44.9566, GNorm = 14.6141, lr_0 = 1.2452e-04
Loss = 2.5956e-01, PNorm = 44.9618, GNorm = 6.6929, lr_0 = 1.2146e-04
Validation rmse = 0.744997
Epoch 27
Loss = 1.3663e-01, PNorm = 44.9662, GNorm = 8.2194, lr_0 = 1.1847e-04
Loss = 1.4682e-01, PNorm = 44.9719, GNorm = 5.4408, lr_0 = 1.1555e-04
Loss = 6.5049e-02, PNorm = 44.9783, GNorm = 12.9016, lr_0 = 1.1271e-04
Loss = 1.1352e-01, PNorm = 44.9816, GNorm = 4.7560, lr_0 = 1.0993e-04
Loss = 5.6757e-01, PNorm = 44.9820, GNorm = 12.3546, lr_0 = 1.0966e-04
Validation rmse = 0.729236
Epoch 28
Loss = 8.1901e-02, PNorm = 44.9868, GNorm = 4.6106, lr_0 = 1.0696e-04
Loss = 1.8941e-01, PNorm = 44.9904, GNorm = 4.3556, lr_0 = 1.0433e-04
Loss = 7.2607e-02, PNorm = 44.9954, GNorm = 7.9402, lr_0 = 1.0176e-04
Validation rmse = 0.724450
Epoch 29
Loss = 9.3525e-02, PNorm = 44.9996, GNorm = 4.6275, lr_0 = 1.0000e-04
Loss = 8.3674e-02, PNorm = 45.0041, GNorm = 8.0942, lr_0 = 1.0000e-04
Loss = 1.0148e-01, PNorm = 45.0089, GNorm = 7.1707, lr_0 = 1.0000e-04
Validation rmse = 0.723425
Model 0 best validation rmse = 0.721641 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.663944
Ensemble test rmse = 0.663944
1-fold cross validation
	Seed 0 ==> test rmse = 0.663944
Overall test rmse = 0.663944 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,075 | train size = 860 | val size = 107 | test size = 108
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1400e+00, PNorm = 43.3131, GNorm = 3.0889, lr_0 = 2.4559e-04
Loss = 1.4351e+00, PNorm = 43.3147, GNorm = 2.0907, lr_0 = 3.7794e-04
Loss = 1.4349e+00, PNorm = 43.3208, GNorm = 1.8231, lr_0 = 5.1029e-04
Validation rmse = 1.478281
Epoch 1
Loss = 1.2605e+00, PNorm = 43.3358, GNorm = 0.9495, lr_0 = 6.5588e-04
Loss = 1.3124e+00, PNorm = 43.3612, GNorm = 2.2446, lr_0 = 7.8824e-04
Loss = 1.2569e+00, PNorm = 43.3976, GNorm = 1.5671, lr_0 = 9.2059e-04
Validation rmse = 1.297967
Epoch 2
Loss = 9.1959e-01, PNorm = 43.4533, GNorm = 1.6245, lr_0 = 9.8798e-04
Loss = 1.0365e+00, PNorm = 43.5196, GNorm = 2.3599, lr_0 = 9.6437e-04
Loss = 9.8198e-01, PNorm = 43.5808, GNorm = 15.4708, lr_0 = 9.4132e-04
Loss = 9.7534e-01, PNorm = 43.6200, GNorm = 1.7216, lr_0 = 9.1883e-04
Validation rmse = 0.990618
Epoch 3
Loss = 7.7410e-01, PNorm = 43.6669, GNorm = 3.7289, lr_0 = 8.9687e-04
Loss = 8.9694e-01, PNorm = 43.6968, GNorm = 4.1171, lr_0 = 8.7544e-04
Loss = 8.4693e-01, PNorm = 43.7332, GNorm = 5.8101, lr_0 = 8.5452e-04
Validation rmse = 1.018720
Epoch 4
Loss = 9.5239e-01, PNorm = 43.7680, GNorm = 4.0153, lr_0 = 8.3209e-04
Loss = 9.3320e-01, PNorm = 43.8060, GNorm = 3.3915, lr_0 = 8.1220e-04
Loss = 8.7459e-01, PNorm = 43.8465, GNorm = 4.0324, lr_0 = 7.9279e-04
Loss = 6.6777e-01, PNorm = 43.8883, GNorm = 2.5456, lr_0 = 7.7385e-04
Validation rmse = 0.891352
Epoch 5
Loss = 6.5284e-01, PNorm = 43.9212, GNorm = 7.3877, lr_0 = 7.5536e-04
Loss = 7.6532e-01, PNorm = 43.9486, GNorm = 3.9081, lr_0 = 7.3730e-04
Loss = 7.5003e-01, PNorm = 43.9846, GNorm = 2.5848, lr_0 = 7.1969e-04
Validation rmse = 0.943215
Epoch 6
Loss = 6.6429e-01, PNorm = 44.0183, GNorm = 4.9969, lr_0 = 7.0079e-04
Loss = 6.0128e-01, PNorm = 44.0508, GNorm = 2.5584, lr_0 = 6.8404e-04
Loss = 6.0403e-01, PNorm = 44.0745, GNorm = 3.7920, lr_0 = 6.6770e-04
Loss = 5.9084e-01, PNorm = 44.0962, GNorm = 2.7461, lr_0 = 6.5174e-04
Loss = 4.0131e-01, PNorm = 44.0977, GNorm = 6.0212, lr_0 = 6.5017e-04
Validation rmse = 0.782037
Epoch 7
Loss = 5.5233e-01, PNorm = 44.1268, GNorm = 5.5102, lr_0 = 6.3463e-04
Loss = 5.5037e-01, PNorm = 44.1599, GNorm = 4.6871, lr_0 = 6.1947e-04
Loss = 6.7720e-01, PNorm = 44.1717, GNorm = 3.3131, lr_0 = 6.0466e-04
Validation rmse = 0.781574
Epoch 8
Loss = 5.4840e-01, PNorm = 44.1987, GNorm = 2.2777, lr_0 = 5.9021e-04
Loss = 5.5786e-01, PNorm = 44.2360, GNorm = 5.8664, lr_0 = 5.7611e-04
Loss = 6.4159e-01, PNorm = 44.2554, GNorm = 3.9642, lr_0 = 5.6234e-04
Validation rmse = 0.842295
Epoch 9
Loss = 3.0460e-01, PNorm = 44.2839, GNorm = 4.8070, lr_0 = 5.4758e-04
Loss = 5.5300e-01, PNorm = 44.3184, GNorm = 2.9297, lr_0 = 5.3449e-04
Loss = 4.9448e-01, PNorm = 44.3330, GNorm = 5.6313, lr_0 = 5.2172e-04
Loss = 4.8160e-01, PNorm = 44.3474, GNorm = 4.8661, lr_0 = 5.0925e-04
Validation rmse = 0.736919
Epoch 10
Loss = 4.1452e-01, PNorm = 44.3663, GNorm = 3.6737, lr_0 = 4.9708e-04
Loss = 4.6996e-01, PNorm = 44.3931, GNorm = 9.1769, lr_0 = 4.8520e-04
Loss = 5.0735e-01, PNorm = 44.4161, GNorm = 5.3170, lr_0 = 4.7361e-04
Validation rmse = 0.704124
Epoch 11
Loss = 3.3074e-01, PNorm = 44.4227, GNorm = 2.4127, lr_0 = 4.6117e-04
Loss = 4.9074e-01, PNorm = 44.4351, GNorm = 7.1139, lr_0 = 4.5015e-04
Loss = 4.5675e-01, PNorm = 44.4561, GNorm = 3.9461, lr_0 = 4.3940e-04
Loss = 4.8320e-01, PNorm = 44.4765, GNorm = 8.0096, lr_0 = 4.2890e-04
Validation rmse = 0.671778
Epoch 12
Loss = 3.4781e-01, PNorm = 44.5018, GNorm = 7.1683, lr_0 = 4.1764e-04
Loss = 4.2944e-01, PNorm = 44.5230, GNorm = 2.8813, lr_0 = 4.0766e-04
Loss = 4.5009e-01, PNorm = 44.5325, GNorm = 6.4983, lr_0 = 3.9791e-04
Validation rmse = 0.711811
Epoch 13
Loss = 3.9837e-01, PNorm = 44.5413, GNorm = 3.3224, lr_0 = 3.8841e-04
Loss = 4.1168e-01, PNorm = 44.5563, GNorm = 6.8987, lr_0 = 3.7912e-04
Loss = 3.7562e-01, PNorm = 44.5774, GNorm = 6.0450, lr_0 = 3.7006e-04
Loss = 4.0746e-01, PNorm = 44.5904, GNorm = 5.5798, lr_0 = 3.6122e-04
Validation rmse = 0.698876
Epoch 14
Loss = 3.3598e-01, PNorm = 44.6080, GNorm = 3.0579, lr_0 = 3.5174e-04
Loss = 3.4510e-01, PNorm = 44.6270, GNorm = 4.7820, lr_0 = 3.4333e-04
Loss = 3.6600e-01, PNorm = 44.6348, GNorm = 3.7098, lr_0 = 3.3513e-04
Validation rmse = 0.704551
Epoch 15
Loss = 1.6105e-01, PNorm = 44.6393, GNorm = 3.1977, lr_0 = 3.2712e-04
Loss = 3.6130e-01, PNorm = 44.6551, GNorm = 3.5108, lr_0 = 3.1930e-04
Loss = 3.3636e-01, PNorm = 44.6689, GNorm = 4.3238, lr_0 = 3.1167e-04
Loss = 4.2498e-01, PNorm = 44.6791, GNorm = 3.7330, lr_0 = 3.0422e-04
Loss = 1.3523e-01, PNorm = 44.6802, GNorm = 13.1476, lr_0 = 3.0349e-04
Validation rmse = 0.692663
Epoch 16
Loss = 2.8103e-01, PNorm = 44.6969, GNorm = 7.2054, lr_0 = 2.9624e-04
Loss = 2.9859e-01, PNorm = 44.7092, GNorm = 3.8436, lr_0 = 2.8916e-04
Loss = 3.4375e-01, PNorm = 44.7174, GNorm = 8.0233, lr_0 = 2.8225e-04
Validation rmse = 0.655679
Epoch 17
Loss = 2.9252e-01, PNorm = 44.7248, GNorm = 7.2897, lr_0 = 2.7484e-04
Loss = 2.4009e-01, PNorm = 44.7374, GNorm = 5.4803, lr_0 = 2.6827e-04
Loss = 3.6882e-01, PNorm = 44.7493, GNorm = 6.5974, lr_0 = 2.6186e-04
Validation rmse = 0.655315
Epoch 18
Loss = 7.2223e-02, PNorm = 44.7568, GNorm = 3.5604, lr_0 = 2.5560e-04
Loss = 2.3418e-01, PNorm = 44.7672, GNorm = 3.2993, lr_0 = 2.4949e-04
Loss = 3.2599e-01, PNorm = 44.7807, GNorm = 5.5453, lr_0 = 2.4353e-04
Loss = 2.9496e-01, PNorm = 44.7915, GNorm = 4.0638, lr_0 = 2.3771e-04
Validation rmse = 0.725215
Epoch 19
Loss = 3.0133e-01, PNorm = 44.7978, GNorm = 6.5817, lr_0 = 2.3147e-04
Loss = 2.2212e-01, PNorm = 44.8104, GNorm = 4.3093, lr_0 = 2.2594e-04
Loss = 3.3704e-01, PNorm = 44.8165, GNorm = 8.6192, lr_0 = 2.2054e-04
Validation rmse = 0.656052
Epoch 20
Loss = 3.5711e-01, PNorm = 44.8228, GNorm = 3.2401, lr_0 = 2.1527e-04
Loss = 2.8303e-01, PNorm = 44.8311, GNorm = 4.7439, lr_0 = 2.1013e-04
Loss = 2.1798e-01, PNorm = 44.8426, GNorm = 3.1506, lr_0 = 2.0510e-04
Loss = 1.8406e-01, PNorm = 44.8511, GNorm = 3.9628, lr_0 = 2.0020e-04
Validation rmse = 0.628907
Epoch 21
Loss = 2.3581e-01, PNorm = 44.8571, GNorm = 6.2143, lr_0 = 1.9495e-04
Loss = 3.5623e-01, PNorm = 44.8626, GNorm = 23.5744, lr_0 = 1.9029e-04
Loss = 3.0018e-01, PNorm = 44.8689, GNorm = 3.1692, lr_0 = 1.8574e-04
Validation rmse = 0.640404
Epoch 22
Loss = 2.6812e-01, PNorm = 44.8800, GNorm = 6.7744, lr_0 = 1.8086e-04
Loss = 1.4222e-01, PNorm = 44.8895, GNorm = 13.1437, lr_0 = 1.7654e-04
Loss = 2.6342e-01, PNorm = 44.8976, GNorm = 5.0413, lr_0 = 1.7232e-04
Loss = 2.7622e-01, PNorm = 44.9004, GNorm = 5.4644, lr_0 = 1.6821e-04
Validation rmse = 0.699519
Epoch 23
Loss = 2.1390e-01, PNorm = 44.9055, GNorm = 8.7739, lr_0 = 1.6419e-04
Loss = 2.0160e-01, PNorm = 44.9123, GNorm = 7.6728, lr_0 = 1.6026e-04
Loss = 1.6266e-01, PNorm = 44.9201, GNorm = 8.0334, lr_0 = 1.5643e-04
Validation rmse = 0.686402
Epoch 24
Loss = 1.7453e-01, PNorm = 44.9278, GNorm = 4.9633, lr_0 = 1.5233e-04
Loss = 1.9300e-01, PNorm = 44.9329, GNorm = 6.5888, lr_0 = 1.4869e-04
Loss = 2.2983e-01, PNorm = 44.9378, GNorm = 7.1676, lr_0 = 1.4513e-04
Loss = 1.4767e-01, PNorm = 44.9429, GNorm = 16.1881, lr_0 = 1.4166e-04
Validation rmse = 0.669801
Epoch 25
Loss = 1.7238e-01, PNorm = 44.9477, GNorm = 5.7032, lr_0 = 1.3828e-04
Loss = 1.7529e-01, PNorm = 44.9528, GNorm = 5.3540, lr_0 = 1.3497e-04
Loss = 1.5410e-01, PNorm = 44.9572, GNorm = 4.8354, lr_0 = 1.3175e-04
Validation rmse = 0.634014
Epoch 26
Loss = 1.5312e-01, PNorm = 44.9633, GNorm = 4.6749, lr_0 = 1.2829e-04
Loss = 1.7597e-01, PNorm = 44.9690, GNorm = 5.5953, lr_0 = 1.2522e-04
Loss = 1.8362e-01, PNorm = 44.9755, GNorm = 8.8539, lr_0 = 1.2223e-04
Validation rmse = 0.654389
Epoch 27
Loss = 2.4297e-02, PNorm = 44.9794, GNorm = 5.4722, lr_0 = 1.1902e-04
Loss = 1.3475e-01, PNorm = 44.9831, GNorm = 7.0351, lr_0 = 1.1618e-04
Loss = 1.7090e-01, PNorm = 44.9882, GNorm = 4.0114, lr_0 = 1.1340e-04
Loss = 1.9887e-01, PNorm = 44.9913, GNorm = 5.9707, lr_0 = 1.1069e-04
Validation rmse = 0.664965
Epoch 28
Loss = 1.5932e-01, PNorm = 44.9954, GNorm = 5.8314, lr_0 = 1.0805e-04
Loss = 1.1348e-01, PNorm = 45.0005, GNorm = 5.8244, lr_0 = 1.0547e-04
Loss = 1.8078e-01, PNorm = 45.0051, GNorm = 8.0503, lr_0 = 1.0294e-04
Validation rmse = 0.662678
Epoch 29
Loss = 4.2432e-02, PNorm = 45.0088, GNorm = 4.8763, lr_0 = 1.0024e-04
Loss = 1.5007e-01, PNorm = 45.0140, GNorm = 11.1609, lr_0 = 1.0000e-04
Loss = 1.8101e-01, PNorm = 45.0175, GNorm = 7.4233, lr_0 = 1.0000e-04
Loss = 1.2933e-01, PNorm = 45.0207, GNorm = 6.4896, lr_0 = 1.0000e-04
Validation rmse = 0.678548
Model 0 best validation rmse = 0.628907 on epoch 20
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.690038
Ensemble test rmse = 0.690038
1-fold cross validation
	Seed 0 ==> test rmse = 0.690038
Overall test rmse = 0.690038 +/- 0.000000
Elapsed time = 0:01:31
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9067e+00, PNorm = 43.3118, GNorm = 2.4518, lr_0 = 2.4143e-04
Loss = 1.5231e+00, PNorm = 43.3136, GNorm = 2.1089, lr_0 = 3.7000e-04
Loss = 1.4195e+00, PNorm = 43.3208, GNorm = 1.3446, lr_0 = 4.9857e-04
Validation rmse = 1.428752
Epoch 1
Loss = 1.3043e+00, PNorm = 43.3376, GNorm = 1.5422, lr_0 = 6.4000e-04
Loss = 1.2816e+00, PNorm = 43.3629, GNorm = 2.0632, lr_0 = 7.6857e-04
Loss = 1.1630e+00, PNorm = 43.3976, GNorm = 4.6061, lr_0 = 8.9714e-04
Loss = 1.1990e+00, PNorm = 43.4484, GNorm = 2.1173, lr_0 = 9.9531e-04
Loss = 1.3910e+00, PNorm = 43.4548, GNorm = 3.1004, lr_0 = 9.9298e-04
Validation rmse = 1.150007
Epoch 2
Loss = 1.0636e+00, PNorm = 43.5172, GNorm = 1.7389, lr_0 = 9.6992e-04
Loss = 9.2805e-01, PNorm = 43.5942, GNorm = 2.6374, lr_0 = 9.4739e-04
Loss = 8.3515e-01, PNorm = 43.6390, GNorm = 12.5108, lr_0 = 9.2539e-04
Validation rmse = 1.246538
Epoch 3
Loss = 8.7272e-01, PNorm = 43.6929, GNorm = 2.1438, lr_0 = 9.0178e-04
Loss = 8.0282e-01, PNorm = 43.7454, GNorm = 5.3428, lr_0 = 8.8084e-04
Loss = 8.4292e-01, PNorm = 43.7877, GNorm = 7.4504, lr_0 = 8.6039e-04
Loss = 6.6624e-01, PNorm = 43.8269, GNorm = 2.8034, lr_0 = 8.4041e-04
Loss = 1.2658e+00, PNorm = 43.8295, GNorm = 11.1219, lr_0 = 8.3843e-04
Validation rmse = 0.830829
Epoch 4
Loss = 7.1284e-01, PNorm = 43.8689, GNorm = 1.9581, lr_0 = 8.1896e-04
Loss = 6.7052e-01, PNorm = 43.9019, GNorm = 3.0341, lr_0 = 7.9995e-04
Loss = 7.0248e-01, PNorm = 43.9231, GNorm = 5.2610, lr_0 = 7.8137e-04
Validation rmse = 0.861664
Epoch 5
Loss = 6.8178e-01, PNorm = 43.9661, GNorm = 2.0418, lr_0 = 7.6323e-04
Loss = 6.9488e-01, PNorm = 44.0009, GNorm = 4.2780, lr_0 = 7.4550e-04
Loss = 7.1198e-01, PNorm = 44.0375, GNorm = 4.2350, lr_0 = 7.2819e-04
Loss = 5.9338e-01, PNorm = 44.0688, GNorm = 2.8336, lr_0 = 7.1128e-04
Validation rmse = 0.822024
Epoch 6
Loss = 5.8547e-01, PNorm = 44.1058, GNorm = 3.6128, lr_0 = 6.9313e-04
Loss = 5.9486e-01, PNorm = 44.1322, GNorm = 6.6642, lr_0 = 6.7704e-04
Loss = 4.9823e-01, PNorm = 44.1604, GNorm = 8.5665, lr_0 = 6.6131e-04
Validation rmse = 0.825666
Epoch 7
Loss = 4.4528e-01, PNorm = 44.1832, GNorm = 4.9333, lr_0 = 6.4444e-04
Loss = 5.4617e-01, PNorm = 44.2134, GNorm = 5.2433, lr_0 = 6.2948e-04
Loss = 4.9866e-01, PNorm = 44.2423, GNorm = 7.3155, lr_0 = 6.1486e-04
Loss = 5.5614e-01, PNorm = 44.2641, GNorm = 2.7325, lr_0 = 6.0058e-04
Validation rmse = 0.709196
Epoch 8
Loss = 6.0434e-01, PNorm = 44.2733, GNorm = 2.2018, lr_0 = 5.8526e-04
Loss = 6.6010e-01, PNorm = 44.2901, GNorm = 2.8308, lr_0 = 5.7167e-04
Loss = 5.1781e-01, PNorm = 44.3193, GNorm = 8.2544, lr_0 = 5.5839e-04
Validation rmse = 0.691829
Epoch 9
Loss = 3.9849e-01, PNorm = 44.3607, GNorm = 2.2575, lr_0 = 5.4414e-04
Loss = 4.5452e-01, PNorm = 44.3820, GNorm = 4.4326, lr_0 = 5.3151e-04
Loss = 4.7294e-01, PNorm = 44.3950, GNorm = 2.8093, lr_0 = 5.1917e-04
Loss = 5.0770e-01, PNorm = 44.4121, GNorm = 3.0066, lr_0 = 5.0711e-04
Validation rmse = 0.763493
Epoch 10
Loss = 4.2188e-01, PNorm = 44.4339, GNorm = 3.1888, lr_0 = 4.9533e-04
Loss = 4.1200e-01, PNorm = 44.4542, GNorm = 8.5239, lr_0 = 4.8383e-04
Loss = 3.9687e-01, PNorm = 44.4682, GNorm = 7.7377, lr_0 = 4.7260e-04
Validation rmse = 0.772150
Epoch 11
Loss = 4.2164e-01, PNorm = 44.4865, GNorm = 2.8836, lr_0 = 4.6054e-04
Loss = 5.4655e-01, PNorm = 44.5011, GNorm = 1.9810, lr_0 = 4.4984e-04
Loss = 3.9666e-01, PNorm = 44.5221, GNorm = 8.6474, lr_0 = 4.3940e-04
Loss = 4.2902e-01, PNorm = 44.5433, GNorm = 9.6273, lr_0 = 4.2919e-04
Validation rmse = 0.673569
Epoch 12
Loss = 3.8189e-01, PNorm = 44.5619, GNorm = 18.2847, lr_0 = 4.1824e-04
Loss = 5.0287e-01, PNorm = 44.5712, GNorm = 4.2139, lr_0 = 4.0853e-04
Loss = 4.4524e-01, PNorm = 44.5889, GNorm = 4.5849, lr_0 = 3.9904e-04
Validation rmse = 0.651625
Epoch 13
Loss = 4.2441e-01, PNorm = 44.6100, GNorm = 3.1972, lr_0 = 3.8886e-04
Loss = 3.7304e-01, PNorm = 44.6264, GNorm = 9.0096, lr_0 = 3.7983e-04
Loss = 3.0807e-01, PNorm = 44.6459, GNorm = 8.1342, lr_0 = 3.7101e-04
Loss = 3.7228e-01, PNorm = 44.6591, GNorm = 7.1895, lr_0 = 3.6240e-04
Validation rmse = 0.686501
Epoch 14
Loss = 3.1391e-01, PNorm = 44.6740, GNorm = 4.0158, lr_0 = 3.5315e-04
Loss = 4.4456e-01, PNorm = 44.6832, GNorm = 5.7737, lr_0 = 3.4495e-04
Loss = 3.2092e-01, PNorm = 44.7008, GNorm = 4.0471, lr_0 = 3.3694e-04
Validation rmse = 0.690453
Epoch 15
Loss = 3.5751e-01, PNorm = 44.7169, GNorm = 12.0726, lr_0 = 3.2911e-04
Loss = 2.1612e-01, PNorm = 44.7335, GNorm = 9.4273, lr_0 = 3.2147e-04
Loss = 2.8788e-01, PNorm = 44.7450, GNorm = 3.5010, lr_0 = 3.1401e-04
Loss = 3.5921e-01, PNorm = 44.7519, GNorm = 3.3400, lr_0 = 3.0671e-04
Validation rmse = 0.669606
Epoch 16
Loss = 2.4846e-01, PNorm = 44.7653, GNorm = 2.6269, lr_0 = 2.9889e-04
Loss = 1.8447e-01, PNorm = 44.7830, GNorm = 5.5153, lr_0 = 2.9195e-04
Loss = 4.0999e-01, PNorm = 44.7942, GNorm = 11.1485, lr_0 = 2.8517e-04
Validation rmse = 0.641596
Epoch 17
Loss = 2.5660e-01, PNorm = 44.8055, GNorm = 5.0211, lr_0 = 2.7789e-04
Loss = 3.3432e-01, PNorm = 44.8196, GNorm = 5.0978, lr_0 = 2.7144e-04
Loss = 1.5431e-01, PNorm = 44.8338, GNorm = 4.8007, lr_0 = 2.6514e-04
Loss = 2.7824e-01, PNorm = 44.8480, GNorm = 9.7267, lr_0 = 2.5898e-04
Validation rmse = 0.717082
Epoch 18
Loss = 2.3932e-01, PNorm = 44.8571, GNorm = 5.2070, lr_0 = 2.5237e-04
Loss = 1.8071e-01, PNorm = 44.8713, GNorm = 3.2925, lr_0 = 2.4651e-04
Loss = 2.2265e-01, PNorm = 44.8782, GNorm = 3.3074, lr_0 = 2.4079e-04
Validation rmse = 0.652964
Epoch 19
Loss = 1.1847e-01, PNorm = 44.8860, GNorm = 5.6495, lr_0 = 2.3464e-04
Loss = 2.6383e-01, PNorm = 44.8971, GNorm = 8.8892, lr_0 = 2.2919e-04
Loss = 1.5232e-01, PNorm = 44.9112, GNorm = 8.0449, lr_0 = 2.2387e-04
Loss = 3.0502e-01, PNorm = 44.9178, GNorm = 12.9841, lr_0 = 2.1867e-04
Validation rmse = 0.716313
Epoch 20
Loss = 2.8691e-01, PNorm = 44.9217, GNorm = 7.2810, lr_0 = 2.1360e-04
Loss = 2.7984e-01, PNorm = 44.9320, GNorm = 4.6845, lr_0 = 2.0864e-04
Loss = 1.8867e-01, PNorm = 44.9419, GNorm = 5.4091, lr_0 = 2.0379e-04
Validation rmse = 0.736168
Epoch 21
Loss = 7.0835e-02, PNorm = 44.9534, GNorm = 5.5360, lr_0 = 1.9859e-04
Loss = 1.8934e-01, PNorm = 44.9621, GNorm = 7.1536, lr_0 = 1.9398e-04
Loss = 1.4745e-01, PNorm = 44.9707, GNorm = 8.7415, lr_0 = 1.8947e-04
Loss = 2.2787e-01, PNorm = 44.9799, GNorm = 4.0705, lr_0 = 1.8507e-04
Validation rmse = 0.704816
Epoch 22
Loss = 1.9707e-01, PNorm = 44.9894, GNorm = 4.1891, lr_0 = 1.8035e-04
Loss = 1.1566e-01, PNorm = 44.9970, GNorm = 3.8731, lr_0 = 1.7616e-04
Loss = 1.8927e-01, PNorm = 45.0050, GNorm = 4.1212, lr_0 = 1.7207e-04
Validation rmse = 0.658351
Epoch 23
Loss = -1.2050e-01, PNorm = 45.0104, GNorm = 6.1904, lr_0 = 1.6768e-04
Loss = 1.8998e-01, PNorm = 45.0195, GNorm = 3.5832, lr_0 = 1.6379e-04
Loss = 1.2748e-01, PNorm = 45.0285, GNorm = 4.2795, lr_0 = 1.5999e-04
Loss = 2.2029e-01, PNorm = 45.0342, GNorm = 9.0355, lr_0 = 1.5627e-04
Validation rmse = 0.687980
Epoch 24
Loss = 1.2936e-01, PNorm = 45.0403, GNorm = 6.1825, lr_0 = 1.5228e-04
Loss = 1.6134e-01, PNorm = 45.0473, GNorm = 4.4133, lr_0 = 1.4875e-04
Loss = 2.2835e-01, PNorm = 45.0540, GNorm = 13.4204, lr_0 = 1.4529e-04
Loss = 1.8687e-01, PNorm = 45.0587, GNorm = 9.7821, lr_0 = 1.4192e-04
Validation rmse = 0.661080
Epoch 25
Loss = 1.4928e-01, PNorm = 45.0629, GNorm = 4.1022, lr_0 = 1.3862e-04
Loss = 1.3809e-01, PNorm = 45.0703, GNorm = 6.9941, lr_0 = 1.3540e-04
Loss = 1.4212e-01, PNorm = 45.0773, GNorm = 6.6399, lr_0 = 1.3226e-04
Validation rmse = 0.647331
Epoch 26
Loss = 1.7271e-01, PNorm = 45.0824, GNorm = 12.1115, lr_0 = 1.2889e-04
Loss = 1.0628e-01, PNorm = 45.0884, GNorm = 8.8060, lr_0 = 1.2589e-04
Loss = 1.8476e-01, PNorm = 45.0923, GNorm = 4.1369, lr_0 = 1.2297e-04
Loss = 1.3091e-01, PNorm = 45.0957, GNorm = 6.4585, lr_0 = 1.2011e-04
Loss = 7.6140e-01, PNorm = 45.0961, GNorm = 21.4861, lr_0 = 1.1983e-04
Validation rmse = 0.699944
Epoch 27
Loss = 1.1987e-01, PNorm = 45.1003, GNorm = 3.4398, lr_0 = 1.1705e-04
Loss = 1.2080e-01, PNorm = 45.1059, GNorm = 5.4787, lr_0 = 1.1433e-04
Loss = 1.1855e-01, PNorm = 45.1122, GNorm = 12.3401, lr_0 = 1.1168e-04
Validation rmse = 0.677047
Epoch 28
Loss = 3.7843e-02, PNorm = 45.1178, GNorm = 9.7062, lr_0 = 1.0883e-04
Loss = 1.1150e-01, PNorm = 45.1230, GNorm = 8.5954, lr_0 = 1.0630e-04
Loss = 1.5912e-01, PNorm = 45.1270, GNorm = 12.0887, lr_0 = 1.0383e-04
Loss = 7.5908e-02, PNorm = 45.1308, GNorm = 3.8413, lr_0 = 1.0142e-04
Loss = 8.2451e-02, PNorm = 45.1310, GNorm = 14.5321, lr_0 = 1.0118e-04
Validation rmse = 0.704168
Epoch 29
Loss = 1.1256e-01, PNorm = 45.1349, GNorm = 4.9580, lr_0 = 1.0000e-04
Loss = 6.8380e-03, PNorm = 45.1393, GNorm = 8.6692, lr_0 = 1.0000e-04
Loss = 1.5440e-01, PNorm = 45.1445, GNorm = 7.8468, lr_0 = 1.0000e-04
Validation rmse = 0.669098
Model 0 best validation rmse = 0.641596 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.680574
Ensemble test rmse = 0.680574
1-fold cross validation
	Seed 0 ==> test rmse = 0.680574
Overall test rmse = 0.680574 +/- 0.000000
Elapsed time = 0:01:29
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,125 | train size = 900 | val size = 112 | test size = 113
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8171e+00, PNorm = 43.3110, GNorm = 1.3554, lr_0 = 2.3750e-04
Loss = 1.5563e+00, PNorm = 43.3117, GNorm = 1.8335, lr_0 = 3.6250e-04
Loss = 1.4599e+00, PNorm = 43.3176, GNorm = 1.4531, lr_0 = 4.8750e-04
Validation rmse = 1.349296
Epoch 1
Loss = 1.2673e+00, PNorm = 43.3313, GNorm = 1.3218, lr_0 = 6.1250e-04
Loss = 1.2582e+00, PNorm = 43.3559, GNorm = 2.2653, lr_0 = 7.3750e-04
Loss = 1.2115e+00, PNorm = 43.3889, GNorm = 2.1844, lr_0 = 8.6250e-04
Loss = 1.1584e+00, PNorm = 43.4411, GNorm = 3.3616, lr_0 = 9.8750e-04
Validation rmse = 0.966553
Epoch 2
Loss = 1.0025e+00, PNorm = 43.4973, GNorm = 2.3273, lr_0 = 9.7965e-04
Loss = 1.0316e+00, PNorm = 43.5624, GNorm = 3.2840, lr_0 = 9.5753e-04
Loss = 8.8482e-01, PNorm = 43.6308, GNorm = 5.9014, lr_0 = 9.3590e-04
Validation rmse = 0.810210
Epoch 3
Loss = 8.7633e-01, PNorm = 43.6752, GNorm = 6.0688, lr_0 = 9.1476e-04
Loss = 8.7947e-01, PNorm = 43.7263, GNorm = 6.1482, lr_0 = 8.9411e-04
Loss = 7.5970e-01, PNorm = 43.7793, GNorm = 4.0159, lr_0 = 8.7391e-04
Loss = 6.8213e-01, PNorm = 43.8234, GNorm = 5.1586, lr_0 = 8.5418e-04
Validation rmse = 0.833373
Epoch 4
Loss = 6.6988e-01, PNorm = 43.8576, GNorm = 2.6450, lr_0 = 8.3489e-04
Loss = 6.2658e-01, PNorm = 43.8964, GNorm = 4.4728, lr_0 = 8.1603e-04
Loss = 6.4160e-01, PNorm = 43.9396, GNorm = 9.8333, lr_0 = 7.9760e-04
Loss = 7.2824e-01, PNorm = 43.9675, GNorm = 1.9573, lr_0 = 7.7959e-04
Validation rmse = 0.848704
Epoch 5
Loss = 6.8256e-01, PNorm = 43.9947, GNorm = 5.0204, lr_0 = 7.6198e-04
Loss = 6.0787e-01, PNorm = 44.0340, GNorm = 7.0531, lr_0 = 7.4477e-04
Loss = 6.2374e-01, PNorm = 44.0631, GNorm = 5.7894, lr_0 = 7.2795e-04
Validation rmse = 0.679997
Epoch 6
Loss = 4.8867e-01, PNorm = 44.0967, GNorm = 4.6631, lr_0 = 7.1151e-04
Loss = 5.4632e-01, PNorm = 44.1225, GNorm = 4.4150, lr_0 = 6.9544e-04
Loss = 4.9009e-01, PNorm = 44.1430, GNorm = 4.6736, lr_0 = 6.7974e-04
Loss = 7.1175e-01, PNorm = 44.1674, GNorm = 10.8084, lr_0 = 6.6439e-04
Validation rmse = 0.686733
Epoch 7
Loss = 5.7116e-01, PNorm = 44.1966, GNorm = 4.2513, lr_0 = 6.4938e-04
Loss = 5.0000e-01, PNorm = 44.2304, GNorm = 3.5189, lr_0 = 6.3472e-04
Loss = 5.1137e-01, PNorm = 44.2584, GNorm = 8.3092, lr_0 = 6.2038e-04
Validation rmse = 0.673582
Epoch 8
Loss = 3.7823e-01, PNorm = 44.2768, GNorm = 4.2694, lr_0 = 6.0637e-04
Loss = 4.3988e-01, PNorm = 44.3124, GNorm = 4.8847, lr_0 = 5.9268e-04
Loss = 4.0974e-01, PNorm = 44.3353, GNorm = 4.0235, lr_0 = 5.7929e-04
Loss = 4.7476e-01, PNorm = 44.3491, GNorm = 12.5338, lr_0 = 5.6621e-04
Validation rmse = 0.640491
Epoch 9
Loss = 3.9376e-01, PNorm = 44.3677, GNorm = 2.1324, lr_0 = 5.5342e-04
Loss = 3.9256e-01, PNorm = 44.3976, GNorm = 4.9079, lr_0 = 5.4092e-04
Loss = 3.1943e-01, PNorm = 44.4256, GNorm = 7.7318, lr_0 = 5.2871e-04
Loss = 4.8921e-01, PNorm = 44.4278, GNorm = 5.7730, lr_0 = 5.1677e-04
Validation rmse = 0.652424
Epoch 10
Loss = 4.6827e-01, PNorm = 44.4476, GNorm = 7.0535, lr_0 = 5.0509e-04
Loss = 4.4474e-01, PNorm = 44.4759, GNorm = 8.4048, lr_0 = 4.9369e-04
Loss = 5.4444e-01, PNorm = 44.4917, GNorm = 21.7673, lr_0 = 4.8254e-04
Validation rmse = 0.674564
Epoch 11
Loss = 3.2758e-01, PNorm = 44.5064, GNorm = 4.6914, lr_0 = 4.7164e-04
Loss = 4.2197e-01, PNorm = 44.5325, GNorm = 5.2557, lr_0 = 4.6099e-04
Loss = 4.0593e-01, PNorm = 44.5544, GNorm = 3.0764, lr_0 = 4.5058e-04
Loss = 3.7158e-01, PNorm = 44.5734, GNorm = 6.0369, lr_0 = 4.4040e-04
Validation rmse = 0.648184
Epoch 12
Loss = 2.8007e-01, PNorm = 44.5938, GNorm = 10.5732, lr_0 = 4.3046e-04
Loss = 3.2009e-01, PNorm = 44.6158, GNorm = 3.9440, lr_0 = 4.2073e-04
Loss = 3.5204e-01, PNorm = 44.6286, GNorm = 9.8432, lr_0 = 4.1123e-04
Validation rmse = 0.633331
Epoch 13
Loss = 2.1142e-01, PNorm = 44.6384, GNorm = 8.9543, lr_0 = 4.0195e-04
Loss = 3.7452e-01, PNorm = 44.6549, GNorm = 6.0717, lr_0 = 3.9287e-04
Loss = 3.2562e-01, PNorm = 44.6740, GNorm = 4.0954, lr_0 = 3.8399e-04
Loss = 4.3746e-01, PNorm = 44.6842, GNorm = 3.6959, lr_0 = 3.7532e-04
Validation rmse = 0.623148
Epoch 14
Loss = 3.7123e-01, PNorm = 44.7024, GNorm = 5.2437, lr_0 = 3.6685e-04
Loss = 2.5201e-01, PNorm = 44.7280, GNorm = 4.5621, lr_0 = 3.5856e-04
Loss = 2.9803e-01, PNorm = 44.7412, GNorm = 7.0073, lr_0 = 3.5046e-04
Loss = 3.8439e-01, PNorm = 44.7484, GNorm = 3.0842, lr_0 = 3.4255e-04
Validation rmse = 0.608647
Epoch 15
Loss = 2.4982e-01, PNorm = 44.7598, GNorm = 2.8714, lr_0 = 3.3481e-04
Loss = 2.2385e-01, PNorm = 44.7834, GNorm = 4.5520, lr_0 = 3.2725e-04
Loss = 3.2043e-01, PNorm = 44.7929, GNorm = 5.0692, lr_0 = 3.1986e-04
Validation rmse = 0.607168
Epoch 16
Loss = 2.6035e-01, PNorm = 44.8043, GNorm = 4.5372, lr_0 = 3.1264e-04
Loss = 2.0524e-01, PNorm = 44.8181, GNorm = 8.4997, lr_0 = 3.0558e-04
Loss = 2.5320e-01, PNorm = 44.8259, GNorm = 2.7269, lr_0 = 2.9867e-04
Loss = 2.4407e-01, PNorm = 44.8366, GNorm = 11.4674, lr_0 = 2.9193e-04
Validation rmse = 0.597132
Epoch 17
Loss = 1.3980e-01, PNorm = 44.8534, GNorm = 7.5311, lr_0 = 2.8534e-04
Loss = 2.4541e-01, PNorm = 44.8671, GNorm = 4.0667, lr_0 = 2.7889e-04
Loss = 2.7328e-01, PNorm = 44.8765, GNorm = 13.9347, lr_0 = 2.7259e-04
Validation rmse = 0.615351
Epoch 18
Loss = 2.1097e-01, PNorm = 44.8819, GNorm = 12.2384, lr_0 = 2.6644e-04
Loss = 1.8291e-01, PNorm = 44.8945, GNorm = 5.9024, lr_0 = 2.6042e-04
Loss = 2.6432e-01, PNorm = 44.9094, GNorm = 8.6010, lr_0 = 2.5454e-04
Loss = 2.5946e-01, PNorm = 44.9177, GNorm = 3.7518, lr_0 = 2.4879e-04
Validation rmse = 0.589233
Epoch 19
Loss = 1.4659e-01, PNorm = 44.9217, GNorm = 6.9366, lr_0 = 2.4317e-04
Loss = 2.3679e-01, PNorm = 44.9311, GNorm = 17.6857, lr_0 = 2.3768e-04
Loss = 2.1927e-01, PNorm = 44.9405, GNorm = 8.2235, lr_0 = 2.3231e-04
Loss = 1.9530e-01, PNorm = 44.9524, GNorm = 4.1544, lr_0 = 2.2707e-04
Validation rmse = 0.617732
Epoch 20
Loss = 1.4911e-01, PNorm = 44.9629, GNorm = 10.4754, lr_0 = 2.2194e-04
Loss = 1.7373e-01, PNorm = 44.9727, GNorm = 7.0703, lr_0 = 2.1692e-04
Loss = 2.0712e-01, PNorm = 44.9806, GNorm = 11.4085, lr_0 = 2.1203e-04
Validation rmse = 0.592790
Epoch 21
Loss = 2.1734e-01, PNorm = 44.9886, GNorm = 13.8493, lr_0 = 2.0724e-04
Loss = 1.8684e-01, PNorm = 44.9997, GNorm = 3.5017, lr_0 = 2.0256e-04
Loss = 1.5618e-01, PNorm = 45.0070, GNorm = 3.8002, lr_0 = 1.9798e-04
Loss = 2.4397e-01, PNorm = 45.0148, GNorm = 3.5365, lr_0 = 1.9351e-04
Validation rmse = 0.636453
Epoch 22
Loss = 1.9179e-01, PNorm = 45.0242, GNorm = 3.0180, lr_0 = 1.8914e-04
Loss = 1.9748e-01, PNorm = 45.0327, GNorm = 3.8955, lr_0 = 1.8487e-04
Loss = 7.6798e-02, PNorm = 45.0411, GNorm = 9.6359, lr_0 = 1.8069e-04
Validation rmse = 0.575561
Epoch 23
Loss = 1.1092e-01, PNorm = 45.0452, GNorm = 8.4213, lr_0 = 1.7661e-04
Loss = 1.3065e-01, PNorm = 45.0500, GNorm = 4.0638, lr_0 = 1.7262e-04
Loss = 1.8338e-01, PNorm = 45.0567, GNorm = 7.5853, lr_0 = 1.6873e-04
Loss = 1.2398e-01, PNorm = 45.0612, GNorm = 13.3069, lr_0 = 1.6492e-04
Validation rmse = 0.625359
Epoch 24
Loss = 2.4325e-01, PNorm = 45.0664, GNorm = 3.1044, lr_0 = 1.6119e-04
Loss = 2.1489e-01, PNorm = 45.0744, GNorm = 7.1465, lr_0 = 1.5755e-04
Loss = 8.9841e-02, PNorm = 45.0837, GNorm = 7.7587, lr_0 = 1.5399e-04
Loss = 1.6748e-01, PNorm = 45.0879, GNorm = 5.2261, lr_0 = 1.5051e-04
Validation rmse = 0.577742
Epoch 25
Loss = 4.8486e-02, PNorm = 45.0957, GNorm = 4.0098, lr_0 = 1.4712e-04
Loss = 1.4934e-01, PNorm = 45.1037, GNorm = 12.4768, lr_0 = 1.4379e-04
Loss = 1.0175e-01, PNorm = 45.1069, GNorm = 3.5871, lr_0 = 1.4055e-04
Validation rmse = 0.593152
Epoch 26
Loss = 1.8224e-01, PNorm = 45.1114, GNorm = 7.7228, lr_0 = 1.3737e-04
Loss = 9.8286e-02, PNorm = 45.1188, GNorm = 10.6784, lr_0 = 1.3427e-04
Loss = 9.8071e-02, PNorm = 45.1247, GNorm = 4.2161, lr_0 = 1.3124e-04
Loss = 1.1514e-01, PNorm = 45.1302, GNorm = 8.3511, lr_0 = 1.2827e-04
Validation rmse = 0.575674
Epoch 27
Loss = 1.3593e-03, PNorm = 45.1366, GNorm = 5.3227, lr_0 = 1.2538e-04
Loss = 9.6478e-02, PNorm = 45.1408, GNorm = 6.1223, lr_0 = 1.2254e-04
Loss = 1.4863e-01, PNorm = 45.1443, GNorm = 3.2755, lr_0 = 1.1978e-04
Validation rmse = 0.598011
Epoch 28
Loss = 1.9629e-01, PNorm = 45.1497, GNorm = 7.6860, lr_0 = 1.1707e-04
Loss = -4.6453e-02, PNorm = 45.1548, GNorm = 5.0837, lr_0 = 1.1443e-04
Loss = 2.5000e-02, PNorm = 45.1603, GNorm = 4.1775, lr_0 = 1.1184e-04
Loss = 1.7823e-01, PNorm = 45.1644, GNorm = 10.4709, lr_0 = 1.0932e-04
Validation rmse = 0.575505
Epoch 29
Loss = 1.4225e-01, PNorm = 45.1676, GNorm = 7.0474, lr_0 = 1.0685e-04
Loss = 4.1884e-02, PNorm = 45.1719, GNorm = 4.0866, lr_0 = 1.0444e-04
Loss = 1.1632e-02, PNorm = 45.1776, GNorm = 10.2975, lr_0 = 1.0208e-04
Loss = 5.2860e-02, PNorm = 45.1815, GNorm = 9.6310, lr_0 = 1.0000e-04
Validation rmse = 0.579372
Model 0 best validation rmse = 0.575505 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.609983
Ensemble test rmse = 0.609983
1-fold cross validation
	Seed 0 ==> test rmse = 0.609983
Overall test rmse = 0.609983 +/- 0.000000
Elapsed time = 0:01:31
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9096e+00, PNorm = 43.3126, GNorm = 2.5952, lr_0 = 2.3750e-04
Loss = 1.5039e+00, PNorm = 43.3153, GNorm = 1.5629, lr_0 = 3.6250e-04
Loss = 1.4599e+00, PNorm = 43.3215, GNorm = 2.4479, lr_0 = 4.8750e-04
Validation rmse = 1.352944
Epoch 1
Loss = 1.3496e+00, PNorm = 43.3365, GNorm = 1.1074, lr_0 = 6.2500e-04
Loss = 1.2476e+00, PNorm = 43.3602, GNorm = 2.8103, lr_0 = 7.5000e-04
Loss = 1.1586e+00, PNorm = 43.3998, GNorm = 1.4204, lr_0 = 8.7500e-04
Loss = 1.0905e+00, PNorm = 43.4640, GNorm = 2.4235, lr_0 = 1.0000e-03
Validation rmse = 1.010725
Epoch 2
Loss = 9.5339e-01, PNorm = 43.5275, GNorm = 2.8034, lr_0 = 9.7742e-04
Loss = 9.2793e-01, PNorm = 43.5915, GNorm = 9.6047, lr_0 = 9.5534e-04
Loss = 9.5100e-01, PNorm = 43.6429, GNorm = 2.0656, lr_0 = 9.3377e-04
Loss = 8.3768e-01, PNorm = 43.6914, GNorm = 5.2621, lr_0 = 9.1268e-04
Validation rmse = 0.902980
Epoch 3
Loss = 7.7988e-01, PNorm = 43.7347, GNorm = 15.8263, lr_0 = 8.9207e-04
Loss = 7.9158e-01, PNorm = 43.7744, GNorm = 3.5811, lr_0 = 8.7192e-04
Loss = 7.1580e-01, PNorm = 43.8187, GNorm = 2.5185, lr_0 = 8.5223e-04
Validation rmse = 0.755580
Epoch 4
Loss = 5.6969e-01, PNorm = 43.8417, GNorm = 2.1252, lr_0 = 8.3298e-04
Loss = 6.1868e-01, PNorm = 43.8701, GNorm = 9.0095, lr_0 = 8.1417e-04
Loss = 6.4372e-01, PNorm = 43.9025, GNorm = 2.9003, lr_0 = 7.9578e-04
Loss = 6.1982e-01, PNorm = 43.9294, GNorm = 3.4504, lr_0 = 7.7781e-04
Validation rmse = 0.762590
Epoch 5
Loss = 5.9665e-01, PNorm = 43.9645, GNorm = 8.1409, lr_0 = 7.6024e-04
Loss = 6.6201e-01, PNorm = 43.9928, GNorm = 5.2739, lr_0 = 7.4307e-04
Loss = 7.1202e-01, PNorm = 44.0219, GNorm = 1.9255, lr_0 = 7.2629e-04
Loss = 6.1720e-01, PNorm = 44.0534, GNorm = 2.5439, lr_0 = 7.0989e-04
Loss = 4.2063e-01, PNorm = 44.0562, GNorm = 3.3691, lr_0 = 7.0827e-04
Validation rmse = 0.730829
Epoch 6
Loss = 5.8998e-01, PNorm = 44.0963, GNorm = 2.7944, lr_0 = 6.9227e-04
Loss = 4.9205e-01, PNorm = 44.1280, GNorm = 7.4398, lr_0 = 6.7664e-04
Loss = 5.3171e-01, PNorm = 44.1459, GNorm = 2.6638, lr_0 = 6.6136e-04
Validation rmse = 0.869646
Epoch 7
Loss = 5.9838e-01, PNorm = 44.1740, GNorm = 4.8892, lr_0 = 6.4642e-04
Loss = 5.2407e-01, PNorm = 44.1956, GNorm = 4.3650, lr_0 = 6.3182e-04
Loss = 5.0976e-01, PNorm = 44.2173, GNorm = 3.1420, lr_0 = 6.1755e-04
Loss = 4.9827e-01, PNorm = 44.2344, GNorm = 2.6448, lr_0 = 6.0361e-04
Validation rmse = 0.710265
Epoch 8
Loss = 4.0532e-01, PNorm = 44.2606, GNorm = 3.0360, lr_0 = 5.8997e-04
Loss = 3.8534e-01, PNorm = 44.2850, GNorm = 3.8832, lr_0 = 5.7665e-04
Loss = 4.7199e-01, PNorm = 44.3065, GNorm = 3.3467, lr_0 = 5.6363e-04
Loss = 4.7502e-01, PNorm = 44.3157, GNorm = 4.1897, lr_0 = 5.5090e-04
Validation rmse = 0.733259
Epoch 9
Loss = 4.1377e-01, PNorm = 44.3439, GNorm = 4.1192, lr_0 = 5.3846e-04
Loss = 3.5865e-01, PNorm = 44.3709, GNorm = 3.0906, lr_0 = 5.2630e-04
Loss = 4.2921e-01, PNorm = 44.3944, GNorm = 4.2040, lr_0 = 5.1441e-04
Validation rmse = 0.706686
Epoch 10
Loss = 3.0190e-01, PNorm = 44.4076, GNorm = 6.5073, lr_0 = 5.0279e-04
Loss = 4.1595e-01, PNorm = 44.4275, GNorm = 10.0682, lr_0 = 4.9144e-04
Loss = 3.3978e-01, PNorm = 44.4516, GNorm = 5.6225, lr_0 = 4.8034e-04
Loss = 4.0283e-01, PNorm = 44.4698, GNorm = 4.1074, lr_0 = 4.6949e-04
Validation rmse = 0.800849
Epoch 11
Loss = 4.1541e-01, PNorm = 44.4842, GNorm = 9.9372, lr_0 = 4.5784e-04
Loss = 5.0572e-01, PNorm = 44.5006, GNorm = 6.4049, lr_0 = 4.4750e-04
Loss = 3.5714e-01, PNorm = 44.5224, GNorm = 3.1208, lr_0 = 4.3739e-04
Loss = 3.5095e-01, PNorm = 44.5421, GNorm = 4.0219, lr_0 = 4.2752e-04
Validation rmse = 0.696398
Epoch 12
Loss = 2.5991e-01, PNorm = 44.5523, GNorm = 4.7190, lr_0 = 4.1786e-04
Loss = 3.2784e-01, PNorm = 44.5672, GNorm = 5.1201, lr_0 = 4.0842e-04
Loss = 3.2402e-01, PNorm = 44.5848, GNorm = 5.2044, lr_0 = 3.9920e-04
Validation rmse = 0.744574
Epoch 13
Loss = 3.4209e-01, PNorm = 44.5977, GNorm = 3.4071, lr_0 = 3.9018e-04
Loss = 3.5217e-01, PNorm = 44.6128, GNorm = 4.4874, lr_0 = 3.8137e-04
Loss = 3.2115e-01, PNorm = 44.6316, GNorm = 4.5788, lr_0 = 3.7276e-04
Loss = 3.5340e-01, PNorm = 44.6486, GNorm = 6.2209, lr_0 = 3.6434e-04
Validation rmse = 0.740583
Epoch 14
Loss = 2.0738e-01, PNorm = 44.6647, GNorm = 11.3417, lr_0 = 3.5611e-04
Loss = 2.8872e-01, PNorm = 44.6742, GNorm = 8.6592, lr_0 = 3.4807e-04
Loss = 3.0021e-01, PNorm = 44.6881, GNorm = 7.1710, lr_0 = 3.4021e-04
Loss = 2.7332e-01, PNorm = 44.6989, GNorm = 6.8539, lr_0 = 3.3253e-04
Validation rmse = 0.674165
Epoch 15
Loss = 1.6557e-01, PNorm = 44.7146, GNorm = 8.0188, lr_0 = 3.2502e-04
Loss = 1.8534e-01, PNorm = 44.7257, GNorm = 3.7854, lr_0 = 3.1768e-04
Loss = 4.4101e-01, PNorm = 44.7304, GNorm = 3.4698, lr_0 = 3.1050e-04
Validation rmse = 0.670235
Epoch 16
Loss = 3.6390e-01, PNorm = 44.7423, GNorm = 3.7386, lr_0 = 3.0280e-04
Loss = 3.1353e-01, PNorm = 44.7588, GNorm = 5.2193, lr_0 = 2.9596e-04
Loss = 2.2372e-01, PNorm = 44.7747, GNorm = 9.0096, lr_0 = 2.8927e-04
Loss = 2.3648e-01, PNorm = 44.7849, GNorm = 9.8965, lr_0 = 2.8274e-04
Validation rmse = 0.684362
Epoch 17
Loss = 1.4668e-01, PNorm = 44.7957, GNorm = 5.3902, lr_0 = 2.7636e-04
Loss = 1.9409e-01, PNorm = 44.8069, GNorm = 5.2302, lr_0 = 2.7011e-04
Loss = 2.5266e-01, PNorm = 44.8142, GNorm = 10.1418, lr_0 = 2.6401e-04
Loss = 2.4726e-01, PNorm = 44.8203, GNorm = 4.5585, lr_0 = 2.5805e-04
Validation rmse = 0.675552
Epoch 18
Loss = 1.4327e-01, PNorm = 44.8319, GNorm = 8.9930, lr_0 = 2.5222e-04
Loss = 2.0071e-01, PNorm = 44.8453, GNorm = 3.6401, lr_0 = 2.4653e-04
Loss = 1.9116e-01, PNorm = 44.8536, GNorm = 8.6288, lr_0 = 2.4096e-04
Validation rmse = 0.692109
Epoch 19
Loss = 2.0704e-01, PNorm = 44.8591, GNorm = 3.4465, lr_0 = 2.3552e-04
Loss = 1.5779e-01, PNorm = 44.8697, GNorm = 4.3675, lr_0 = 2.3020e-04
Loss = 2.6217e-01, PNorm = 44.8799, GNorm = 14.6028, lr_0 = 2.2500e-04
Loss = 1.9729e-01, PNorm = 44.8895, GNorm = 5.1227, lr_0 = 2.1992e-04
Validation rmse = 0.679455
Epoch 20
Loss = 1.1180e-01, PNorm = 44.8960, GNorm = 6.4283, lr_0 = 2.1495e-04
Loss = 1.6105e-01, PNorm = 44.9033, GNorm = 5.8026, lr_0 = 2.1010e-04
Loss = 1.9526e-01, PNorm = 44.9056, GNorm = 5.3048, lr_0 = 2.0535e-04
Loss = 2.5145e-01, PNorm = 44.9118, GNorm = 3.9477, lr_0 = 2.0071e-04
Validation rmse = 0.666838
Epoch 21
Loss = 8.7478e-02, PNorm = 44.9215, GNorm = 4.0082, lr_0 = 1.9573e-04
Loss = 1.2761e-01, PNorm = 44.9318, GNorm = 6.7308, lr_0 = 1.9131e-04
Loss = 1.9198e-01, PNorm = 44.9383, GNorm = 7.8716, lr_0 = 1.8699e-04
Validation rmse = 0.653388
Epoch 22
Loss = -2.0741e-01, PNorm = 44.9436, GNorm = 7.2095, lr_0 = 1.8277e-04
Loss = 1.6005e-01, PNorm = 44.9521, GNorm = 5.9135, lr_0 = 1.7864e-04
Loss = 1.5863e-01, PNorm = 44.9584, GNorm = 9.4243, lr_0 = 1.7461e-04
Loss = 2.0544e-01, PNorm = 44.9650, GNorm = 4.5343, lr_0 = 1.7066e-04
Validation rmse = 0.658752
Epoch 23
Loss = 2.0087e-02, PNorm = 44.9722, GNorm = 7.8914, lr_0 = 1.6681e-04
Loss = 9.8634e-02, PNorm = 44.9800, GNorm = 7.5547, lr_0 = 1.6304e-04
Loss = 1.9355e-01, PNorm = 44.9869, GNorm = 5.5940, lr_0 = 1.5936e-04
Loss = 1.9303e-01, PNorm = 44.9906, GNorm = 19.2412, lr_0 = 1.5576e-04
Validation rmse = 0.660640
Epoch 24
Loss = 1.2857e-01, PNorm = 44.9969, GNorm = 4.8818, lr_0 = 1.5224e-04
Loss = 6.7142e-02, PNorm = 45.0060, GNorm = 14.2314, lr_0 = 1.4881e-04
Loss = 1.4941e-01, PNorm = 45.0099, GNorm = 5.5088, lr_0 = 1.4544e-04
Loss = 1.8838e-01, PNorm = 45.0138, GNorm = 4.1707, lr_0 = 1.4216e-04
Validation rmse = 0.647322
Epoch 25
Loss = 4.0031e-02, PNorm = 45.0192, GNorm = 12.5308, lr_0 = 1.3895e-04
Loss = 2.2088e-01, PNorm = 45.0256, GNorm = 13.7006, lr_0 = 1.3581e-04
Loss = 1.1464e-01, PNorm = 45.0311, GNorm = 3.6478, lr_0 = 1.3274e-04
Validation rmse = 0.663391
Epoch 26
Loss = 9.1937e-02, PNorm = 45.0356, GNorm = 5.9283, lr_0 = 1.2945e-04
Loss = 7.3912e-02, PNorm = 45.0408, GNorm = 16.1731, lr_0 = 1.2653e-04
Loss = 1.1618e-01, PNorm = 45.0457, GNorm = 8.3184, lr_0 = 1.2367e-04
Loss = 1.0457e-01, PNorm = 45.0497, GNorm = 11.4204, lr_0 = 1.2088e-04
Validation rmse = 0.655714
Epoch 27
Loss = 4.0536e-02, PNorm = 45.0555, GNorm = 3.6503, lr_0 = 1.1815e-04
Loss = 1.3475e-01, PNorm = 45.0603, GNorm = 6.8297, lr_0 = 1.1548e-04
Loss = 3.1139e-02, PNorm = 45.0651, GNorm = 11.4769, lr_0 = 1.1287e-04
Loss = 1.1979e-01, PNorm = 45.0697, GNorm = 6.7592, lr_0 = 1.1032e-04
Validation rmse = 0.660947
Epoch 28
Loss = 7.9601e-02, PNorm = 45.0742, GNorm = 10.7028, lr_0 = 1.0783e-04
Loss = 3.5988e-02, PNorm = 45.0788, GNorm = 9.8169, lr_0 = 1.0539e-04
Loss = 9.0539e-02, PNorm = 45.0821, GNorm = 6.2438, lr_0 = 1.0301e-04
Validation rmse = 0.658556
Epoch 29
Loss = 2.0057e-02, PNorm = 45.0860, GNorm = 8.4933, lr_0 = 1.0069e-04
Loss = 2.4777e-02, PNorm = 45.0906, GNorm = 7.1648, lr_0 = 1.0000e-04
Loss = 8.2090e-02, PNorm = 45.0954, GNorm = 20.0575, lr_0 = 1.0000e-04
Loss = 1.6998e-01, PNorm = 45.0971, GNorm = 6.1615, lr_0 = 1.0000e-04
Validation rmse = 0.652139
Model 0 best validation rmse = 0.647322 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.597941
Ensemble test rmse = 0.597941
1-fold cross validation
	Seed 0 ==> test rmse = 0.597941
Overall test rmse = 0.597941 +/- 0.000000
Elapsed time = 0:18:06
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,175 | train size = 940 | val size = 117 | test size = 118
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8772e+00, PNorm = 43.3119, GNorm = 1.3277, lr_0 = 2.3378e-04
Loss = 1.4641e+00, PNorm = 43.3140, GNorm = 0.8888, lr_0 = 3.5541e-04
Loss = 1.4399e+00, PNorm = 43.3209, GNorm = 1.3158, lr_0 = 4.7703e-04
Validation rmse = 1.563236
Epoch 1
Loss = 1.2271e+00, PNorm = 43.3371, GNorm = 1.5799, lr_0 = 6.1081e-04
Loss = 1.2432e+00, PNorm = 43.3581, GNorm = 1.3895, lr_0 = 7.3243e-04
Loss = 1.1893e+00, PNorm = 43.4035, GNorm = 3.3034, lr_0 = 8.5405e-04
Loss = 1.0382e+00, PNorm = 43.4655, GNorm = 6.3741, lr_0 = 9.7568e-04
Validation rmse = 1.642732
Epoch 2
Loss = 1.1154e+00, PNorm = 43.5199, GNorm = 3.2860, lr_0 = 9.8238e-04
Loss = 1.0166e+00, PNorm = 43.5848, GNorm = 1.6298, lr_0 = 9.6078e-04
Loss = 9.1995e-01, PNorm = 43.6494, GNorm = 3.1989, lr_0 = 9.3966e-04
Loss = 7.7402e-01, PNorm = 43.7030, GNorm = 2.5322, lr_0 = 9.1901e-04
Validation rmse = 0.901212
Epoch 3
Loss = 7.8678e-01, PNorm = 43.7536, GNorm = 3.3607, lr_0 = 8.9681e-04
Loss = 6.7579e-01, PNorm = 43.8009, GNorm = 2.8954, lr_0 = 8.7710e-04
Loss = 6.8080e-01, PNorm = 43.8519, GNorm = 3.6679, lr_0 = 8.5782e-04
Loss = 6.7618e-01, PNorm = 43.8815, GNorm = 3.1513, lr_0 = 8.3897e-04
Validation rmse = 0.829639
Epoch 4
Loss = 6.7309e-01, PNorm = 43.9222, GNorm = 7.2811, lr_0 = 8.2053e-04
Loss = 5.7320e-01, PNorm = 43.9594, GNorm = 3.0031, lr_0 = 8.0249e-04
Loss = 6.2875e-01, PNorm = 43.9949, GNorm = 2.7093, lr_0 = 7.8485e-04
Validation rmse = 0.765183
Epoch 5
Loss = 4.2692e-01, PNorm = 44.0202, GNorm = 3.6185, lr_0 = 7.6760e-04
Loss = 5.4271e-01, PNorm = 44.0513, GNorm = 6.3162, lr_0 = 7.5073e-04
Loss = 5.2140e-01, PNorm = 44.0896, GNorm = 3.2955, lr_0 = 7.3423e-04
Loss = 6.2050e-01, PNorm = 44.1229, GNorm = 3.6524, lr_0 = 7.1809e-04
Validation rmse = 0.818601
Epoch 6
Loss = 4.5048e-01, PNorm = 44.1521, GNorm = 2.4226, lr_0 = 7.0074e-04
Loss = 5.0467e-01, PNorm = 44.1766, GNorm = 9.6401, lr_0 = 6.8534e-04
Loss = 5.4948e-01, PNorm = 44.2011, GNorm = 2.1757, lr_0 = 6.7028e-04
Loss = 4.9360e-01, PNorm = 44.2364, GNorm = 4.3462, lr_0 = 6.5554e-04
Validation rmse = 0.755343
Epoch 7
Loss = 3.8589e-01, PNorm = 44.2708, GNorm = 4.1788, lr_0 = 6.4114e-04
Loss = 5.2197e-01, PNorm = 44.2903, GNorm = 3.8366, lr_0 = 6.2704e-04
Loss = 4.6179e-01, PNorm = 44.3155, GNorm = 4.0395, lr_0 = 6.1326e-04
Loss = 5.1358e-01, PNorm = 44.3348, GNorm = 2.2194, lr_0 = 5.9978e-04
Loss = 3.5781e-01, PNorm = 44.3368, GNorm = 6.5302, lr_0 = 5.9845e-04
Validation rmse = 0.755872
Epoch 8
Loss = 3.9752e-01, PNorm = 44.3611, GNorm = 2.5680, lr_0 = 5.8529e-04
Loss = 4.6991e-01, PNorm = 44.3765, GNorm = 9.9660, lr_0 = 5.7243e-04
Loss = 4.0445e-01, PNorm = 44.3982, GNorm = 4.2093, lr_0 = 5.5985e-04
Validation rmse = 0.755824
Epoch 9
Loss = 2.2847e-01, PNorm = 44.4183, GNorm = 2.4242, lr_0 = 5.4754e-04
Loss = 4.1195e-01, PNorm = 44.4467, GNorm = 12.6179, lr_0 = 5.3551e-04
Loss = 3.8788e-01, PNorm = 44.4697, GNorm = 3.1741, lr_0 = 5.2374e-04
Loss = 3.5416e-01, PNorm = 44.4882, GNorm = 5.2849, lr_0 = 5.1222e-04
Validation rmse = 0.754648
Epoch 10
Loss = 3.7816e-01, PNorm = 44.5054, GNorm = 10.7168, lr_0 = 5.0096e-04
Loss = 3.0426e-01, PNorm = 44.5266, GNorm = 2.8233, lr_0 = 4.8995e-04
Loss = 3.2973e-01, PNorm = 44.5446, GNorm = 8.3460, lr_0 = 4.7918e-04
Loss = 4.6172e-01, PNorm = 44.5603, GNorm = 8.5857, lr_0 = 4.6865e-04
Validation rmse = 0.809627
Epoch 11
Loss = 4.0783e-01, PNorm = 44.5847, GNorm = 8.6168, lr_0 = 4.5733e-04
Loss = 2.3650e-01, PNorm = 44.6113, GNorm = 5.3138, lr_0 = 4.4728e-04
Loss = 3.5636e-01, PNorm = 44.6262, GNorm = 6.3693, lr_0 = 4.3745e-04
Loss = 3.5895e-01, PNorm = 44.6420, GNorm = 4.2407, lr_0 = 4.2783e-04
Validation rmse = 0.781089
Epoch 12
Loss = 2.7820e-01, PNorm = 44.6632, GNorm = 4.7601, lr_0 = 4.1843e-04
Loss = 2.5202e-01, PNorm = 44.6822, GNorm = 3.5999, lr_0 = 4.0923e-04
Loss = 2.4993e-01, PNorm = 44.6976, GNorm = 5.8219, lr_0 = 4.0024e-04
Validation rmse = 0.774717
Epoch 13
Loss = 1.1794e-01, PNorm = 44.7075, GNorm = 7.9232, lr_0 = 3.9057e-04
Loss = 2.7480e-01, PNorm = 44.7246, GNorm = 3.4279, lr_0 = 3.8199e-04
Loss = 3.4389e-01, PNorm = 44.7343, GNorm = 11.2227, lr_0 = 3.7359e-04
Loss = 1.8228e-01, PNorm = 44.7501, GNorm = 4.5225, lr_0 = 3.6538e-04
Validation rmse = 0.772976
Epoch 14
Loss = 3.1248e-01, PNorm = 44.7602, GNorm = 8.2371, lr_0 = 3.5735e-04
Loss = 3.1496e-01, PNorm = 44.7688, GNorm = 8.4364, lr_0 = 3.4949e-04
Loss = 3.1036e-01, PNorm = 44.7832, GNorm = 4.3534, lr_0 = 3.4181e-04
Loss = 2.2024e-01, PNorm = 44.7992, GNorm = 10.1025, lr_0 = 3.3430e-04
Validation rmse = 0.784136
Epoch 15
Loss = 2.3047e-01, PNorm = 44.8076, GNorm = 6.1036, lr_0 = 3.2695e-04
Loss = 3.0079e-01, PNorm = 44.8177, GNorm = 4.9930, lr_0 = 3.1976e-04
Loss = 2.1539e-01, PNorm = 44.8330, GNorm = 12.1906, lr_0 = 3.1273e-04
Loss = 2.1510e-01, PNorm = 44.8415, GNorm = 8.7787, lr_0 = 3.0586e-04
Validation rmse = 0.738180
Epoch 16
Loss = 2.8601e-01, PNorm = 44.8558, GNorm = 3.6359, lr_0 = 2.9847e-04
Loss = 1.7786e-01, PNorm = 44.8704, GNorm = 3.6028, lr_0 = 2.9191e-04
Loss = 1.5489e-01, PNorm = 44.8830, GNorm = 10.1924, lr_0 = 2.8549e-04
Validation rmse = 0.764870
Epoch 17
Loss = 1.3407e-01, PNorm = 44.8942, GNorm = 16.5264, lr_0 = 2.7922e-04
Loss = 1.7601e-01, PNorm = 44.9060, GNorm = 12.8295, lr_0 = 2.7308e-04
Loss = 2.6052e-01, PNorm = 44.9144, GNorm = 11.5852, lr_0 = 2.6708e-04
Loss = 2.1106e-01, PNorm = 44.9265, GNorm = 4.1671, lr_0 = 2.6121e-04
Validation rmse = 0.732924
Epoch 18
Loss = 1.1682e-01, PNorm = 44.9391, GNorm = 7.9455, lr_0 = 2.5490e-04
Loss = 1.7856e-01, PNorm = 44.9530, GNorm = 15.1761, lr_0 = 2.4930e-04
Loss = 1.3298e-01, PNorm = 44.9612, GNorm = 6.2853, lr_0 = 2.4382e-04
Loss = 1.5995e-01, PNorm = 44.9701, GNorm = 4.9208, lr_0 = 2.3846e-04
Validation rmse = 0.756273
Epoch 19
Loss = 8.3142e-02, PNorm = 44.9774, GNorm = 5.5280, lr_0 = 2.3322e-04
Loss = 1.5933e-01, PNorm = 44.9866, GNorm = 9.5607, lr_0 = 2.2809e-04
Loss = 1.6235e-01, PNorm = 44.9957, GNorm = 5.9316, lr_0 = 2.2308e-04
Loss = 1.8483e-01, PNorm = 45.0038, GNorm = 7.7774, lr_0 = 2.1817e-04
Validation rmse = 0.756751
Epoch 20
Loss = 2.0323e-01, PNorm = 45.0107, GNorm = 4.5525, lr_0 = 2.1338e-04
Loss = 1.1170e-01, PNorm = 45.0228, GNorm = 7.9793, lr_0 = 2.0869e-04
Loss = 8.5688e-02, PNorm = 45.0326, GNorm = 7.1128, lr_0 = 2.0410e-04
Validation rmse = 0.736306
Epoch 21
Loss = 6.1362e-02, PNorm = 45.0400, GNorm = 5.6628, lr_0 = 1.9917e-04
Loss = 4.1873e-02, PNorm = 45.0491, GNorm = 6.4117, lr_0 = 1.9479e-04
Loss = 8.4737e-02, PNorm = 45.0578, GNorm = 6.3600, lr_0 = 1.9051e-04
Loss = 1.9773e-01, PNorm = 45.0607, GNorm = 3.6896, lr_0 = 1.8632e-04
Validation rmse = 0.741018
Epoch 22
Loss = -3.5257e-02, PNorm = 45.0664, GNorm = 10.7029, lr_0 = 1.8223e-04
Loss = 8.8937e-02, PNorm = 45.0751, GNorm = 6.0239, lr_0 = 1.7822e-04
Loss = 2.3487e-01, PNorm = 45.0831, GNorm = 20.6046, lr_0 = 1.7431e-04
Loss = 2.0686e-01, PNorm = 45.0870, GNorm = 5.3741, lr_0 = 1.7047e-04
Validation rmse = 0.758625
Epoch 23
Loss = 2.1651e-01, PNorm = 45.0941, GNorm = 14.6346, lr_0 = 1.6636e-04
Loss = 1.4546e-01, PNorm = 45.1014, GNorm = 15.1164, lr_0 = 1.6270e-04
Loss = 8.3069e-02, PNorm = 45.1102, GNorm = 6.5998, lr_0 = 1.5912e-04
Loss = 1.1185e-01, PNorm = 45.1152, GNorm = 11.3319, lr_0 = 1.5563e-04
Validation rmse = 0.727701
Epoch 24
Loss = 1.2940e-01, PNorm = 45.1213, GNorm = 10.0347, lr_0 = 1.5221e-04
Loss = 1.4450e-01, PNorm = 45.1268, GNorm = 5.9861, lr_0 = 1.4886e-04
Loss = 1.2602e-01, PNorm = 45.1303, GNorm = 8.7815, lr_0 = 1.4559e-04
Loss = 1.0489e-02, PNorm = 45.1378, GNorm = 11.7070, lr_0 = 1.4239e-04
Validation rmse = 0.736063
Epoch 25
Loss = 2.0864e-02, PNorm = 45.1454, GNorm = 9.2665, lr_0 = 1.3926e-04
Loss = -3.5871e-02, PNorm = 45.1503, GNorm = 6.7524, lr_0 = 1.3620e-04
Loss = 1.8271e-01, PNorm = 45.1518, GNorm = 9.8478, lr_0 = 1.3320e-04
Validation rmse = 0.738160
Epoch 26
Loss = -2.4863e-02, PNorm = 45.1576, GNorm = 6.1012, lr_0 = 1.2999e-04
Loss = 9.4597e-02, PNorm = 45.1632, GNorm = 4.2104, lr_0 = 1.2713e-04
Loss = 2.7362e-02, PNorm = 45.1692, GNorm = 3.5256, lr_0 = 1.2434e-04
Loss = 2.7498e-02, PNorm = 45.1758, GNorm = 7.8182, lr_0 = 1.2160e-04
Validation rmse = 0.736772
Epoch 27
Loss = -7.3265e-02, PNorm = 45.1818, GNorm = 5.1520, lr_0 = 1.1893e-04
Loss = 8.6167e-02, PNorm = 45.1854, GNorm = 4.8790, lr_0 = 1.1632e-04
Loss = -9.5994e-03, PNorm = 45.1907, GNorm = 4.0197, lr_0 = 1.1376e-04
Loss = 3.9619e-02, PNorm = 45.1944, GNorm = 6.3649, lr_0 = 1.1126e-04
Validation rmse = 0.725130
Epoch 28
Loss = 2.0984e-02, PNorm = 45.1996, GNorm = 8.3744, lr_0 = 1.0857e-04
Loss = 6.5511e-02, PNorm = 45.2054, GNorm = 10.1143, lr_0 = 1.0618e-04
Loss = -1.5557e-02, PNorm = 45.2096, GNorm = 5.4807, lr_0 = 1.0385e-04
Loss = 2.2228e-02, PNorm = 45.2130, GNorm = 6.0622, lr_0 = 1.0157e-04
Validation rmse = 0.729212
Epoch 29
Loss = -3.1636e-02, PNorm = 45.2160, GNorm = 5.6406, lr_0 = 1.0000e-04
Loss = 1.6145e-02, PNorm = 45.2203, GNorm = 5.8456, lr_0 = 1.0000e-04
Loss = 8.3718e-02, PNorm = 45.2246, GNorm = 8.9396, lr_0 = 1.0000e-04
Validation rmse = 0.725528
Model 0 best validation rmse = 0.725130 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.630086
Ensemble test rmse = 0.630086
1-fold cross validation
	Seed 0 ==> test rmse = 0.630086
Overall test rmse = 0.630086 +/- 0.000000
Elapsed time = 0:01:33
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7801e+00, PNorm = 43.3139, GNorm = 3.7098, lr_0 = 2.3026e-04
Loss = 1.5065e+00, PNorm = 43.3169, GNorm = 1.2881, lr_0 = 3.4868e-04
Loss = 1.3869e+00, PNorm = 43.3237, GNorm = 1.4550, lr_0 = 4.6711e-04
Validation rmse = 1.477856
Epoch 1
Loss = 1.3107e+00, PNorm = 43.3412, GNorm = 1.5539, lr_0 = 5.9737e-04
Loss = 1.2594e+00, PNorm = 43.3682, GNorm = 2.4855, lr_0 = 7.1579e-04
Loss = 1.1785e+00, PNorm = 43.4091, GNorm = 5.9589, lr_0 = 8.3421e-04
Loss = 1.1891e+00, PNorm = 43.4494, GNorm = 1.0013, lr_0 = 9.5263e-04
Validation rmse = 1.105582
Epoch 2
Loss = 1.0192e+00, PNorm = 43.5136, GNorm = 2.0454, lr_0 = 9.8497e-04
Loss = 9.2430e-01, PNorm = 43.5903, GNorm = 6.7977, lr_0 = 9.6388e-04
Loss = 8.6722e-01, PNorm = 43.6521, GNorm = 8.3123, lr_0 = 9.4324e-04
Loss = 8.3315e-01, PNorm = 43.6959, GNorm = 3.0339, lr_0 = 9.2305e-04
Validation rmse = 1.129799
Epoch 3
Loss = 8.3655e-01, PNorm = 43.7480, GNorm = 8.0857, lr_0 = 9.0329e-04
Loss = 7.8173e-01, PNorm = 43.8043, GNorm = 6.6651, lr_0 = 8.8395e-04
Loss = 6.9704e-01, PNorm = 43.8594, GNorm = 4.5259, lr_0 = 8.6503e-04
Loss = 6.9460e-01, PNorm = 43.8810, GNorm = 2.1827, lr_0 = 8.4651e-04
Validation rmse = 0.818728
Epoch 4
Loss = 6.1479e-01, PNorm = 43.9322, GNorm = 4.7376, lr_0 = 8.2660e-04
Loss = 6.1149e-01, PNorm = 43.9604, GNorm = 3.0226, lr_0 = 8.0890e-04
Loss = 7.2645e-01, PNorm = 43.9996, GNorm = 1.8406, lr_0 = 7.9158e-04
Loss = 6.5736e-01, PNorm = 44.0291, GNorm = 4.4404, lr_0 = 7.7464e-04
Validation rmse = 0.776766
Epoch 5
Loss = 4.8851e-01, PNorm = 44.0642, GNorm = 10.0988, lr_0 = 7.5805e-04
Loss = 6.3867e-01, PNorm = 44.0903, GNorm = 5.9030, lr_0 = 7.4182e-04
Loss = 5.7187e-01, PNorm = 44.1116, GNorm = 5.1648, lr_0 = 7.2594e-04
Loss = 5.2298e-01, PNorm = 44.1423, GNorm = 12.5028, lr_0 = 7.1040e-04
Loss = 4.9374e-01, PNorm = 44.1453, GNorm = 8.4258, lr_0 = 7.0887e-04
Validation rmse = 0.734003
Epoch 6
Loss = 4.9292e-01, PNorm = 44.1688, GNorm = 6.8031, lr_0 = 6.9369e-04
Loss = 4.7626e-01, PNorm = 44.1899, GNorm = 4.6044, lr_0 = 6.7884e-04
Loss = 5.0855e-01, PNorm = 44.2216, GNorm = 7.7243, lr_0 = 6.6431e-04
Validation rmse = 0.811850
Epoch 7
Loss = 3.7208e-01, PNorm = 44.2475, GNorm = 5.4659, lr_0 = 6.4868e-04
Loss = 4.7829e-01, PNorm = 44.2782, GNorm = 5.4956, lr_0 = 6.3479e-04
Loss = 4.8253e-01, PNorm = 44.3013, GNorm = 8.4407, lr_0 = 6.2120e-04
Loss = 5.1522e-01, PNorm = 44.3250, GNorm = 3.7748, lr_0 = 6.0790e-04
Validation rmse = 0.742367
Epoch 8
Loss = 4.2231e-01, PNorm = 44.3422, GNorm = 2.0992, lr_0 = 5.9489e-04
Loss = 3.8691e-01, PNorm = 44.3733, GNorm = 3.1491, lr_0 = 5.8215e-04
Loss = 3.8895e-01, PNorm = 44.3994, GNorm = 2.6141, lr_0 = 5.6969e-04
Loss = 4.0280e-01, PNorm = 44.4103, GNorm = 3.1129, lr_0 = 5.5749e-04
Validation rmse = 0.824462
Epoch 9
Loss = 3.5354e-01, PNorm = 44.4277, GNorm = 5.3340, lr_0 = 5.4438e-04
Loss = 3.8806e-01, PNorm = 44.4534, GNorm = 6.9065, lr_0 = 5.3273e-04
Loss = 4.0237e-01, PNorm = 44.4729, GNorm = 7.8167, lr_0 = 5.2132e-04
Loss = 3.8389e-01, PNorm = 44.4872, GNorm = 3.3965, lr_0 = 5.1016e-04
Validation rmse = 0.732254
Epoch 10
Loss = 3.5204e-01, PNorm = 44.5018, GNorm = 7.6639, lr_0 = 4.9924e-04
Loss = 2.9243e-01, PNorm = 44.5215, GNorm = 4.4382, lr_0 = 4.8855e-04
Loss = 3.4472e-01, PNorm = 44.5425, GNorm = 5.0143, lr_0 = 4.7809e-04
Loss = 3.3741e-01, PNorm = 44.5530, GNorm = 4.9201, lr_0 = 4.6786e-04
Validation rmse = 0.697143
Epoch 11
Loss = 2.3718e-01, PNorm = 44.5775, GNorm = 3.6777, lr_0 = 4.5685e-04
Loss = 3.1158e-01, PNorm = 44.5981, GNorm = 3.4971, lr_0 = 4.4707e-04
Loss = 3.3077e-01, PNorm = 44.6150, GNorm = 5.6400, lr_0 = 4.3750e-04
Loss = 3.8594e-01, PNorm = 44.6274, GNorm = 3.1822, lr_0 = 4.2813e-04
Loss = 8.1336e-01, PNorm = 44.6276, GNorm = 9.6866, lr_0 = 4.2721e-04
Validation rmse = 0.734763
Epoch 12
Loss = 2.4395e-01, PNorm = 44.6417, GNorm = 3.1279, lr_0 = 4.1806e-04
Loss = 3.3946e-01, PNorm = 44.6623, GNorm = 8.3098, lr_0 = 4.0911e-04
Loss = 3.4465e-01, PNorm = 44.6720, GNorm = 2.9806, lr_0 = 4.0035e-04
Validation rmse = 0.706464
Epoch 13
Loss = 2.0180e-01, PNorm = 44.6853, GNorm = 4.5382, lr_0 = 3.9178e-04
Loss = 2.5294e-01, PNorm = 44.6986, GNorm = 4.4404, lr_0 = 3.8340e-04
Loss = 2.6489e-01, PNorm = 44.7198, GNorm = 8.8791, lr_0 = 3.7519e-04
Loss = 3.3893e-01, PNorm = 44.7300, GNorm = 3.2492, lr_0 = 3.6716e-04
Validation rmse = 0.694669
Epoch 14
Loss = 1.6671e-01, PNorm = 44.7442, GNorm = 4.1991, lr_0 = 3.5852e-04
Loss = 3.0170e-01, PNorm = 44.7581, GNorm = 5.7640, lr_0 = 3.5084e-04
Loss = 2.5604e-01, PNorm = 44.7762, GNorm = 6.6676, lr_0 = 3.4333e-04
Loss = 1.4277e-01, PNorm = 44.7871, GNorm = 10.4767, lr_0 = 3.3598e-04
Validation rmse = 0.691908
Epoch 15
Loss = 1.7951e-01, PNorm = 44.7928, GNorm = 6.8478, lr_0 = 3.2879e-04
Loss = 2.7676e-01, PNorm = 44.8054, GNorm = 6.2357, lr_0 = 3.2175e-04
Loss = 2.9355e-01, PNorm = 44.8184, GNorm = 15.9040, lr_0 = 3.1486e-04
Loss = 3.4171e-01, PNorm = 44.8294, GNorm = 3.6495, lr_0 = 3.0812e-04
Validation rmse = 0.723060
Epoch 16
Loss = 3.4235e-01, PNorm = 44.8466, GNorm = 16.4758, lr_0 = 3.0087e-04
Loss = 2.6737e-01, PNorm = 44.8611, GNorm = 4.6408, lr_0 = 2.9443e-04
Loss = 3.6429e-01, PNorm = 44.8644, GNorm = 4.3560, lr_0 = 2.8813e-04
Loss = 2.0381e-01, PNorm = 44.8787, GNorm = 5.4297, lr_0 = 2.8196e-04
Validation rmse = 0.683808
Epoch 17
Loss = 1.4627e-01, PNorm = 44.8920, GNorm = 6.2925, lr_0 = 2.7533e-04
Loss = 1.9316e-01, PNorm = 44.8996, GNorm = 5.3578, lr_0 = 2.6943e-04
Loss = 1.8771e-01, PNorm = 44.9026, GNorm = 3.7434, lr_0 = 2.6367e-04
Loss = 2.4768e-01, PNorm = 44.9130, GNorm = 3.2557, lr_0 = 2.5802e-04
Validation rmse = 0.697073
Epoch 18
Loss = 2.0739e-01, PNorm = 44.9220, GNorm = 3.5757, lr_0 = 2.5250e-04
Loss = 1.8456e-01, PNorm = 44.9332, GNorm = 7.9704, lr_0 = 2.4709e-04
Loss = 1.2928e-01, PNorm = 44.9468, GNorm = 24.3915, lr_0 = 2.4180e-04
Validation rmse = 0.725192
Epoch 19
Loss = 2.6436e-01, PNorm = 44.9507, GNorm = 14.0632, lr_0 = 2.3611e-04
Loss = 2.7424e-01, PNorm = 44.9571, GNorm = 3.9724, lr_0 = 2.3106e-04
Loss = 1.4851e-01, PNorm = 44.9667, GNorm = 5.0437, lr_0 = 2.2611e-04
Loss = 2.0462e-01, PNorm = 44.9748, GNorm = 5.4292, lr_0 = 2.2127e-04
Validation rmse = 0.689139
Epoch 20
Loss = 1.8432e-02, PNorm = 44.9868, GNorm = 4.9271, lr_0 = 2.1653e-04
Loss = 1.4105e-01, PNorm = 44.9962, GNorm = 5.1101, lr_0 = 2.1190e-04
Loss = 1.0511e-01, PNorm = 45.0054, GNorm = 4.0262, lr_0 = 2.0736e-04
Loss = 1.3208e-01, PNorm = 45.0118, GNorm = 5.0690, lr_0 = 2.0292e-04
Validation rmse = 0.673383
Epoch 21
Loss = 1.0611e-02, PNorm = 45.0193, GNorm = 4.5202, lr_0 = 1.9815e-04
Loss = 9.3887e-02, PNorm = 45.0290, GNorm = 7.7572, lr_0 = 1.9391e-04
Loss = 1.9000e-01, PNorm = 45.0366, GNorm = 12.8951, lr_0 = 1.8976e-04
Loss = 1.4146e-01, PNorm = 45.0413, GNorm = 10.9816, lr_0 = 1.8569e-04
Validation rmse = 0.689994
Epoch 22
Loss = 2.4198e-01, PNorm = 45.0475, GNorm = 6.7278, lr_0 = 1.8133e-04
Loss = 1.0476e-01, PNorm = 45.0573, GNorm = 4.0578, lr_0 = 1.7744e-04
Loss = 9.0391e-02, PNorm = 45.0665, GNorm = 7.9172, lr_0 = 1.7364e-04
Loss = 7.3144e-02, PNorm = 45.0720, GNorm = 4.4659, lr_0 = 1.6993e-04
Validation rmse = 0.675772
Epoch 23
Loss = 1.4687e-01, PNorm = 45.0784, GNorm = 5.7693, lr_0 = 1.6629e-04
Loss = 1.0666e-01, PNorm = 45.0856, GNorm = 4.3607, lr_0 = 1.6273e-04
Loss = 5.3303e-02, PNorm = 45.0901, GNorm = 5.0154, lr_0 = 1.5925e-04
Loss = 1.3794e-01, PNorm = 45.0959, GNorm = 5.4515, lr_0 = 1.5584e-04
Validation rmse = 0.669987
Epoch 24
Loss = 1.2345e-01, PNorm = 45.1025, GNorm = 3.7516, lr_0 = 1.5217e-04
Loss = 8.2063e-02, PNorm = 45.1090, GNorm = 8.9952, lr_0 = 1.4891e-04
Loss = 5.3847e-02, PNorm = 45.1136, GNorm = 4.7253, lr_0 = 1.4572e-04
Loss = 2.1080e-01, PNorm = 45.1177, GNorm = 6.3897, lr_0 = 1.4261e-04
Validation rmse = 0.673379
Epoch 25
Loss = 9.6678e-03, PNorm = 45.1233, GNorm = 5.8548, lr_0 = 1.3955e-04
Loss = 1.3303e-01, PNorm = 45.1293, GNorm = 9.4644, lr_0 = 1.3656e-04
Loss = 1.2553e-01, PNorm = 45.1339, GNorm = 4.0073, lr_0 = 1.3364e-04
Validation rmse = 0.664696
Epoch 26
Loss = 1.7920e-01, PNorm = 45.1395, GNorm = 5.6777, lr_0 = 1.3050e-04
Loss = 4.8843e-02, PNorm = 45.1440, GNorm = 3.5537, lr_0 = 1.2770e-04
Loss = 7.0289e-02, PNorm = 45.1505, GNorm = 5.7687, lr_0 = 1.2497e-04
Loss = 5.3364e-02, PNorm = 45.1553, GNorm = 9.3063, lr_0 = 1.2229e-04
Validation rmse = 0.675559
Epoch 27
Loss = 8.5108e-02, PNorm = 45.1596, GNorm = 12.1637, lr_0 = 1.1942e-04
Loss = 4.3436e-02, PNorm = 45.1638, GNorm = 7.2240, lr_0 = 1.1686e-04
Loss = -3.4121e-02, PNorm = 45.1692, GNorm = 4.1550, lr_0 = 1.1436e-04
Loss = 6.6464e-02, PNorm = 45.1739, GNorm = 13.5694, lr_0 = 1.1191e-04
Validation rmse = 0.674590
Epoch 28
Loss = 8.2127e-02, PNorm = 45.1762, GNorm = 9.8534, lr_0 = 1.0952e-04
Loss = 6.5133e-02, PNorm = 45.1802, GNorm = 5.2411, lr_0 = 1.0717e-04
Loss = -5.5960e-03, PNorm = 45.1855, GNorm = 5.9269, lr_0 = 1.0488e-04
Loss = 8.1884e-02, PNorm = 45.1899, GNorm = 5.8683, lr_0 = 1.0263e-04
Validation rmse = 0.663866
Epoch 29
Loss = -2.6601e-02, PNorm = 45.1966, GNorm = 16.6546, lr_0 = 1.0022e-04
Loss = -3.9590e-03, PNorm = 45.2014, GNorm = 3.8021, lr_0 = 1.0000e-04
Loss = 6.3744e-02, PNorm = 45.2041, GNorm = 11.5897, lr_0 = 1.0000e-04
Loss = 6.6235e-02, PNorm = 45.2070, GNorm = 7.7690, lr_0 = 1.0000e-04
Validation rmse = 0.673435
Model 0 best validation rmse = 0.663866 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.653418
Ensemble test rmse = 0.653418
1-fold cross validation
	Seed 0 ==> test rmse = 0.653418
Overall test rmse = 0.653418 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,225 | train size = 980 | val size = 122 | test size = 123
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0185e+00, PNorm = 43.3128, GNorm = 2.6153, lr_0 = 2.2692e-04
Loss = 1.5024e+00, PNorm = 43.3136, GNorm = 2.2382, lr_0 = 3.4231e-04
Loss = 1.4282e+00, PNorm = 43.3187, GNorm = 1.4207, lr_0 = 4.5769e-04
Validation rmse = 1.428241
Epoch 1
Loss = 1.1376e+00, PNorm = 43.3325, GNorm = 1.1746, lr_0 = 5.8462e-04
Loss = 1.3576e+00, PNorm = 43.3537, GNorm = 2.4032, lr_0 = 7.0000e-04
Loss = 1.0822e+00, PNorm = 43.3857, GNorm = 1.7363, lr_0 = 8.1538e-04
Loss = 1.0585e+00, PNorm = 43.4365, GNorm = 4.0467, lr_0 = 9.3077e-04
Validation rmse = 1.078588
Epoch 2
Loss = 1.0249e+00, PNorm = 43.5086, GNorm = 3.3008, lr_0 = 9.8951e-04
Loss = 9.9473e-01, PNorm = 43.5713, GNorm = 3.2323, lr_0 = 9.6887e-04
Loss = 8.8912e-01, PNorm = 43.6313, GNorm = 5.9687, lr_0 = 9.4865e-04
Loss = 8.0734e-01, PNorm = 43.6807, GNorm = 2.9913, lr_0 = 9.2886e-04
Validation rmse = 0.887246
Epoch 3
Loss = 7.1265e-01, PNorm = 43.7382, GNorm = 3.3270, lr_0 = 9.0756e-04
Loss = 5.8881e-01, PNorm = 43.7853, GNorm = 7.0526, lr_0 = 8.8862e-04
Loss = 6.7482e-01, PNorm = 43.8113, GNorm = 2.6466, lr_0 = 8.7008e-04
Loss = 6.6932e-01, PNorm = 43.8429, GNorm = 4.1008, lr_0 = 8.5193e-04
Validation rmse = 0.968693
Epoch 4
Loss = 7.0442e-01, PNorm = 43.8770, GNorm = 3.4297, lr_0 = 8.3240e-04
Loss = 5.9416e-01, PNorm = 43.9165, GNorm = 5.0002, lr_0 = 8.1503e-04
Loss = 5.6140e-01, PNorm = 43.9488, GNorm = 3.2456, lr_0 = 7.9802e-04
Loss = 5.3114e-01, PNorm = 43.9892, GNorm = 6.9253, lr_0 = 7.8137e-04
Validation rmse = 0.839879
Epoch 5
Loss = 5.7636e-01, PNorm = 44.0111, GNorm = 5.3343, lr_0 = 7.6507e-04
Loss = 5.4484e-01, PNorm = 44.0382, GNorm = 8.2417, lr_0 = 7.4910e-04
Loss = 5.2177e-01, PNorm = 44.0590, GNorm = 5.6201, lr_0 = 7.3347e-04
Loss = 5.0335e-01, PNorm = 44.0805, GNorm = 3.2219, lr_0 = 7.1817e-04
Validation rmse = 0.917592
Epoch 6
Loss = 5.2578e-01, PNorm = 44.1151, GNorm = 12.0126, lr_0 = 7.0170e-04
Loss = 4.5330e-01, PNorm = 44.1448, GNorm = 4.1827, lr_0 = 6.8706e-04
Loss = 4.9585e-01, PNorm = 44.1672, GNorm = 3.0292, lr_0 = 6.7273e-04
Loss = 5.4821e-01, PNorm = 44.1822, GNorm = 4.3107, lr_0 = 6.5869e-04
Validation rmse = 0.875988
Epoch 7
Loss = 3.9093e-01, PNorm = 44.2081, GNorm = 1.8766, lr_0 = 6.4359e-04
Loss = 4.4394e-01, PNorm = 44.2362, GNorm = 5.3254, lr_0 = 6.3016e-04
Loss = 4.4016e-01, PNorm = 44.2543, GNorm = 3.0534, lr_0 = 6.1701e-04
Loss = 4.7398e-01, PNorm = 44.2679, GNorm = 3.3043, lr_0 = 6.0414e-04
Validation rmse = 0.791823
Epoch 8
Loss = 4.0296e-01, PNorm = 44.2878, GNorm = 5.4456, lr_0 = 5.9029e-04
Loss = 5.0587e-01, PNorm = 44.3099, GNorm = 4.7909, lr_0 = 5.7797e-04
Loss = 4.2994e-01, PNorm = 44.3355, GNorm = 2.2673, lr_0 = 5.6591e-04
Loss = 3.9743e-01, PNorm = 44.3534, GNorm = 7.8284, lr_0 = 5.5410e-04
Validation rmse = 0.824068
Epoch 9
Loss = 3.1339e-01, PNorm = 44.3748, GNorm = 5.7770, lr_0 = 5.4140e-04
Loss = 4.4359e-01, PNorm = 44.3908, GNorm = 3.9030, lr_0 = 5.3010e-04
Loss = 3.8303e-01, PNorm = 44.4036, GNorm = 3.2412, lr_0 = 5.1904e-04
Loss = 3.6560e-01, PNorm = 44.4184, GNorm = 5.9815, lr_0 = 5.0821e-04
Validation rmse = 0.815368
Epoch 10
Loss = 3.9746e-01, PNorm = 44.4294, GNorm = 5.3752, lr_0 = 4.9761e-04
Loss = 3.1155e-01, PNorm = 44.4495, GNorm = 6.7037, lr_0 = 4.8722e-04
Loss = 4.6602e-01, PNorm = 44.4659, GNorm = 10.3923, lr_0 = 4.7706e-04
Loss = 3.7555e-01, PNorm = 44.4831, GNorm = 3.9009, lr_0 = 4.6710e-04
Validation rmse = 0.823847
Epoch 11
Loss = 3.3054e-01, PNorm = 44.5031, GNorm = 5.3348, lr_0 = 4.5639e-04
Loss = 3.4267e-01, PNorm = 44.5135, GNorm = 7.4228, lr_0 = 4.4687e-04
Loss = 3.3287e-01, PNorm = 44.5260, GNorm = 9.0412, lr_0 = 4.3755e-04
Loss = 2.7761e-01, PNorm = 44.5379, GNorm = 3.3911, lr_0 = 4.2842e-04
Loss = 8.4859e-01, PNorm = 44.5386, GNorm = 12.0217, lr_0 = 4.2752e-04
Validation rmse = 0.799640
Epoch 12
Loss = 2.8543e-01, PNorm = 44.5499, GNorm = 13.1265, lr_0 = 4.1860e-04
Loss = 3.1073e-01, PNorm = 44.5626, GNorm = 4.7333, lr_0 = 4.0986e-04
Loss = 3.4177e-01, PNorm = 44.5728, GNorm = 7.4504, lr_0 = 4.0131e-04
Validation rmse = 0.813457
Epoch 13
Loss = 3.2360e-01, PNorm = 44.5881, GNorm = 8.7707, lr_0 = 3.9211e-04
Loss = 3.3386e-01, PNorm = 44.6025, GNorm = 4.5529, lr_0 = 3.8393e-04
Loss = 2.8342e-01, PNorm = 44.6173, GNorm = 5.5115, lr_0 = 3.7592e-04
Loss = 2.1928e-01, PNorm = 44.6268, GNorm = 8.8499, lr_0 = 3.6807e-04
Validation rmse = 0.800927
Epoch 14
Loss = 1.7577e-01, PNorm = 44.6334, GNorm = 2.6449, lr_0 = 3.5963e-04
Loss = 3.1847e-01, PNorm = 44.6487, GNorm = 3.1410, lr_0 = 3.5213e-04
Loss = 2.9675e-01, PNorm = 44.6616, GNorm = 5.9108, lr_0 = 3.4478e-04
Loss = 1.9100e-01, PNorm = 44.6742, GNorm = 3.5057, lr_0 = 3.3759e-04
Validation rmse = 0.782581
Epoch 15
Loss = 1.6746e-01, PNorm = 44.6805, GNorm = 3.7605, lr_0 = 3.3055e-04
Loss = 2.0244e-01, PNorm = 44.6936, GNorm = 3.6192, lr_0 = 3.2365e-04
Loss = 1.9773e-01, PNorm = 44.7063, GNorm = 4.2708, lr_0 = 3.1690e-04
Loss = 2.8586e-01, PNorm = 44.7147, GNorm = 11.8873, lr_0 = 3.1028e-04
Validation rmse = 0.795195
Epoch 16
Loss = 2.0637e-01, PNorm = 44.7231, GNorm = 5.9070, lr_0 = 3.0317e-04
Loss = 1.7231e-01, PNorm = 44.7341, GNorm = 8.6743, lr_0 = 2.9684e-04
Loss = 1.8818e-01, PNorm = 44.7429, GNorm = 16.5358, lr_0 = 2.9065e-04
Loss = 2.9607e-01, PNorm = 44.7523, GNorm = 2.5489, lr_0 = 2.8459e-04
Validation rmse = 0.809574
Epoch 17
Loss = 1.3778e-01, PNorm = 44.7606, GNorm = 3.2568, lr_0 = 2.7806e-04
Loss = 1.8141e-01, PNorm = 44.7726, GNorm = 6.6225, lr_0 = 2.7226e-04
Loss = 1.5534e-01, PNorm = 44.7820, GNorm = 3.8675, lr_0 = 2.6658e-04
Loss = 2.0261e-01, PNorm = 44.7878, GNorm = 4.1354, lr_0 = 2.6102e-04
Validation rmse = 0.770218
Epoch 18
Loss = 2.1740e-01, PNorm = 44.8000, GNorm = 3.2981, lr_0 = 2.5503e-04
Loss = 2.2792e-01, PNorm = 44.8075, GNorm = 5.2927, lr_0 = 2.4971e-04
Loss = 2.1889e-01, PNorm = 44.8154, GNorm = 15.3022, lr_0 = 2.4450e-04
Loss = 2.3158e-01, PNorm = 44.8236, GNorm = 5.3990, lr_0 = 2.3940e-04
Validation rmse = 0.754147
Epoch 19
Loss = 1.5669e-01, PNorm = 44.8336, GNorm = 3.9768, lr_0 = 2.3391e-04
Loss = 2.6605e-01, PNorm = 44.8391, GNorm = 3.9406, lr_0 = 2.2903e-04
Loss = 1.1670e-01, PNorm = 44.8470, GNorm = 3.2301, lr_0 = 2.2425e-04
Loss = 1.7122e-01, PNorm = 44.8538, GNorm = 3.5147, lr_0 = 2.1957e-04
Validation rmse = 0.768359
Epoch 20
Loss = 1.2475e-01, PNorm = 44.8613, GNorm = 6.6742, lr_0 = 2.1499e-04
Loss = 2.3526e-01, PNorm = 44.8658, GNorm = 10.0521, lr_0 = 2.1050e-04
Loss = 1.2462e-01, PNorm = 44.8719, GNorm = 3.5089, lr_0 = 2.0611e-04
Loss = 2.4558e-01, PNorm = 44.8789, GNorm = 14.1916, lr_0 = 2.0181e-04
Validation rmse = 0.755645
Epoch 21
Loss = 8.9600e-02, PNorm = 44.8887, GNorm = 2.8689, lr_0 = 1.9718e-04
Loss = 1.6821e-01, PNorm = 44.8993, GNorm = 10.8123, lr_0 = 1.9307e-04
Loss = 2.2618e-01, PNorm = 44.9044, GNorm = 4.6209, lr_0 = 1.8904e-04
Loss = 9.3433e-02, PNorm = 44.9119, GNorm = 7.3738, lr_0 = 1.8510e-04
Validation rmse = 0.738175
Epoch 22
Loss = 2.2068e-02, PNorm = 44.9202, GNorm = 12.0689, lr_0 = 1.8085e-04
Loss = 1.9942e-01, PNorm = 44.9278, GNorm = 5.7952, lr_0 = 1.7708e-04
Loss = 7.4261e-02, PNorm = 44.9336, GNorm = 4.2555, lr_0 = 1.7338e-04
Loss = 1.6763e-01, PNorm = 44.9407, GNorm = 5.2222, lr_0 = 1.6977e-04
Validation rmse = 0.776336
Epoch 23
Loss = 1.4809e-01, PNorm = 44.9462, GNorm = 11.3976, lr_0 = 1.6587e-04
Loss = 1.2481e-01, PNorm = 44.9496, GNorm = 10.1441, lr_0 = 1.6241e-04
Loss = 1.2912e-01, PNorm = 44.9560, GNorm = 7.8870, lr_0 = 1.5902e-04
Loss = 1.5276e-01, PNorm = 44.9627, GNorm = 6.3000, lr_0 = 1.5571e-04
Loss = 1.0286e+00, PNorm = 44.9632, GNorm = 11.7416, lr_0 = 1.5538e-04
Validation rmse = 0.737924
Epoch 24
Loss = 1.2355e-01, PNorm = 44.9682, GNorm = 6.1797, lr_0 = 1.5214e-04
Loss = 1.4153e-01, PNorm = 44.9728, GNorm = 4.4546, lr_0 = 1.4896e-04
Loss = 5.1839e-02, PNorm = 44.9797, GNorm = 4.7534, lr_0 = 1.4585e-04
Loss = 4.6452e-02, PNorm = 44.9854, GNorm = 8.3918, lr_0 = 1.4281e-04
Validation rmse = 0.739452
Epoch 25
Loss = 1.0270e-01, PNorm = 44.9908, GNorm = 5.4217, lr_0 = 1.3983e-04
Loss = 6.0295e-02, PNorm = 44.9960, GNorm = 3.6360, lr_0 = 1.3691e-04
Loss = 6.7806e-02, PNorm = 45.0018, GNorm = 11.7469, lr_0 = 1.3406e-04
Validation rmse = 0.734277
Epoch 26
Loss = 3.4684e-02, PNorm = 45.0055, GNorm = 3.9266, lr_0 = 1.3098e-04
Loss = 5.9207e-02, PNorm = 45.0084, GNorm = 4.8196, lr_0 = 1.2825e-04
Loss = 1.2598e-01, PNorm = 45.0146, GNorm = 6.6060, lr_0 = 1.2557e-04
Loss = 6.1483e-02, PNorm = 45.0190, GNorm = 6.4630, lr_0 = 1.2295e-04
Validation rmse = 0.736216
Epoch 27
Loss = 2.1806e-02, PNorm = 45.0221, GNorm = 7.7213, lr_0 = 1.2014e-04
Loss = 1.5877e-01, PNorm = 45.0258, GNorm = 4.1730, lr_0 = 1.1763e-04
Loss = -8.2901e-03, PNorm = 45.0307, GNorm = 3.3658, lr_0 = 1.1517e-04
Loss = 3.8703e-02, PNorm = 45.0352, GNorm = 9.4452, lr_0 = 1.1277e-04
Validation rmse = 0.743442
Epoch 28
Loss = 9.8121e-03, PNorm = 45.0389, GNorm = 14.5890, lr_0 = 1.1019e-04
Loss = 5.6880e-02, PNorm = 45.0429, GNorm = 5.7082, lr_0 = 1.0789e-04
Loss = 9.4569e-02, PNorm = 45.0453, GNorm = 3.0843, lr_0 = 1.0564e-04
Loss = 4.5276e-02, PNorm = 45.0503, GNorm = 3.7106, lr_0 = 1.0343e-04
Validation rmse = 0.718462
Epoch 29
Loss = 1.4410e-01, PNorm = 45.0552, GNorm = 16.4697, lr_0 = 1.0106e-04
Loss = 2.2025e-02, PNorm = 45.0580, GNorm = 4.1445, lr_0 = 1.0000e-04
Loss = 5.0351e-02, PNorm = 45.0619, GNorm = 8.6297, lr_0 = 1.0000e-04
Loss = 6.4817e-02, PNorm = 45.0655, GNorm = 7.3142, lr_0 = 1.0000e-04
Validation rmse = 0.728150
Model 0 best validation rmse = 0.718462 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.629270
Ensemble test rmse = 0.629270
1-fold cross validation
	Seed 0 ==> test rmse = 0.629270
Overall test rmse = 0.629270 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0171e+00, PNorm = 43.3123, GNorm = 1.8813, lr_0 = 2.2375e-04
Loss = 1.4996e+00, PNorm = 43.3149, GNorm = 1.6901, lr_0 = 3.3625e-04
Loss = 1.4461e+00, PNorm = 43.3194, GNorm = 1.8596, lr_0 = 4.4875e-04
Loss = 1.3367e+00, PNorm = 43.3323, GNorm = 1.6672, lr_0 = 5.6125e-04
Validation rmse = 1.542752
Epoch 1
Loss = 1.2480e+00, PNorm = 43.3554, GNorm = 3.2006, lr_0 = 6.7375e-04
Loss = 1.1405e+00, PNorm = 43.3931, GNorm = 2.2358, lr_0 = 7.8625e-04
Loss = 1.0695e+00, PNorm = 43.4400, GNorm = 3.4592, lr_0 = 8.9875e-04
Loss = 9.3261e-01, PNorm = 43.5122, GNorm = 3.7935, lr_0 = 9.9795e-04
Validation rmse = 1.158322
Epoch 2
Loss = 8.6822e-01, PNorm = 43.5682, GNorm = 3.2384, lr_0 = 9.7764e-04
Loss = 8.1125e-01, PNorm = 43.6257, GNorm = 3.2442, lr_0 = 9.5775e-04
Loss = 7.6767e-01, PNorm = 43.6734, GNorm = 15.0916, lr_0 = 9.3826e-04
Loss = 8.2373e-01, PNorm = 43.7200, GNorm = 7.1750, lr_0 = 9.1916e-04
Validation rmse = 1.242697
Epoch 3
Loss = 7.7497e-01, PNorm = 43.7667, GNorm = 3.1613, lr_0 = 9.0046e-04
Loss = 6.4889e-01, PNorm = 43.8153, GNorm = 5.1858, lr_0 = 8.8214e-04
Loss = 6.3591e-01, PNorm = 43.8360, GNorm = 2.6020, lr_0 = 8.6419e-04
Loss = 6.2355e-01, PNorm = 43.8780, GNorm = 8.7386, lr_0 = 8.4660e-04
Validation rmse = 0.880730
Epoch 4
Loss = 6.3074e-01, PNorm = 43.9166, GNorm = 4.7035, lr_0 = 8.2937e-04
Loss = 6.0437e-01, PNorm = 43.9373, GNorm = 5.9548, lr_0 = 8.1250e-04
Loss = 6.1494e-01, PNorm = 43.9678, GNorm = 2.0967, lr_0 = 7.9596e-04
Loss = 5.6363e-01, PNorm = 44.0053, GNorm = 8.4850, lr_0 = 7.7977e-04
Validation rmse = 0.879986
Epoch 5
Loss = 5.6227e-01, PNorm = 44.0350, GNorm = 1.9275, lr_0 = 7.6390e-04
Loss = 4.8155e-01, PNorm = 44.0702, GNorm = 3.0882, lr_0 = 7.4835e-04
Loss = 4.5284e-01, PNorm = 44.0894, GNorm = 9.2835, lr_0 = 7.3313e-04
Loss = 4.6516e-01, PNorm = 44.1147, GNorm = 4.8480, lr_0 = 7.1821e-04
Validation rmse = 0.875833
Epoch 6
Loss = 4.7550e-01, PNorm = 44.1483, GNorm = 5.2877, lr_0 = 7.0359e-04
Loss = 4.5966e-01, PNorm = 44.1764, GNorm = 11.4357, lr_0 = 6.8928e-04
Loss = 5.1020e-01, PNorm = 44.1998, GNorm = 2.5177, lr_0 = 6.7525e-04
Loss = 4.3407e-01, PNorm = 44.2214, GNorm = 6.4600, lr_0 = 6.6151e-04
Validation rmse = 0.850170
Epoch 7
Loss = 4.1457e-01, PNorm = 44.2464, GNorm = 8.9938, lr_0 = 6.4805e-04
Loss = 4.8250e-01, PNorm = 44.2772, GNorm = 12.4284, lr_0 = 6.3486e-04
Loss = 3.6914e-01, PNorm = 44.2972, GNorm = 3.3039, lr_0 = 6.2194e-04
Loss = 4.3301e-01, PNorm = 44.3186, GNorm = 5.5384, lr_0 = 6.0929e-04
Validation rmse = 0.866763
Epoch 8
Loss = 3.0487e-01, PNorm = 44.3436, GNorm = 8.2530, lr_0 = 5.9689e-04
Loss = 5.5952e-01, PNorm = 44.3602, GNorm = 6.5544, lr_0 = 5.8474e-04
Loss = 5.1744e-01, PNorm = 44.3758, GNorm = 1.9600, lr_0 = 5.7284e-04
Loss = 4.2089e-01, PNorm = 44.4019, GNorm = 3.2595, lr_0 = 5.6119e-04
Validation rmse = 0.852513
Epoch 9
Loss = 2.9937e-01, PNorm = 44.4290, GNorm = 2.9069, lr_0 = 5.4977e-04
Loss = 4.7913e-01, PNorm = 44.4374, GNorm = 8.0198, lr_0 = 5.3858e-04
Loss = 3.3581e-01, PNorm = 44.4617, GNorm = 3.4589, lr_0 = 5.2762e-04
Loss = 3.7088e-01, PNorm = 44.4833, GNorm = 3.8645, lr_0 = 5.1688e-04
Validation rmse = 0.823323
Epoch 10
Loss = 2.5778e-01, PNorm = 44.5006, GNorm = 12.3220, lr_0 = 5.0637e-04
Loss = 3.5596e-01, PNorm = 44.5186, GNorm = 9.3823, lr_0 = 4.9606e-04
Loss = 4.6295e-01, PNorm = 44.5304, GNorm = 14.6516, lr_0 = 4.8597e-04
Loss = 3.9006e-01, PNorm = 44.5394, GNorm = 2.7786, lr_0 = 4.7608e-04
Validation rmse = 0.828006
Epoch 11
Loss = 3.1689e-01, PNorm = 44.5660, GNorm = 4.0416, lr_0 = 4.6639e-04
Loss = 2.8635e-01, PNorm = 44.5834, GNorm = 3.5046, lr_0 = 4.5690e-04
Loss = 3.6551e-01, PNorm = 44.6013, GNorm = 7.5961, lr_0 = 4.4760e-04
Loss = 3.0361e-01, PNorm = 44.6186, GNorm = 7.2581, lr_0 = 4.3849e-04
Validation rmse = 0.833343
Epoch 12
Loss = 1.8044e-01, PNorm = 44.6379, GNorm = 4.6968, lr_0 = 4.2957e-04
Loss = 3.5586e-01, PNorm = 44.6514, GNorm = 9.8336, lr_0 = 4.2083e-04
Loss = 4.2684e-01, PNorm = 44.6661, GNorm = 1.9259, lr_0 = 4.1227e-04
Loss = 3.2155e-01, PNorm = 44.6826, GNorm = 6.7487, lr_0 = 4.0388e-04
Validation rmse = 0.813434
Epoch 13
Loss = 2.3966e-01, PNorm = 44.7011, GNorm = 5.6323, lr_0 = 3.9566e-04
Loss = 1.5232e-01, PNorm = 44.7141, GNorm = 6.2489, lr_0 = 3.8761e-04
Loss = 3.0306e-01, PNorm = 44.7284, GNorm = 5.6161, lr_0 = 3.7972e-04
Loss = 3.6598e-01, PNorm = 44.7346, GNorm = 6.9873, lr_0 = 3.7199e-04
Validation rmse = 0.828923
Epoch 14
Loss = 2.7953e-01, PNorm = 44.7484, GNorm = 3.2777, lr_0 = 3.6442e-04
Loss = 2.0975e-01, PNorm = 44.7658, GNorm = 5.0778, lr_0 = 3.5701e-04
Loss = 1.5779e-01, PNorm = 44.7778, GNorm = 5.8668, lr_0 = 3.4974e-04
Loss = 2.8352e-01, PNorm = 44.7889, GNorm = 4.5284, lr_0 = 3.4263e-04
Validation rmse = 0.845847
Epoch 15
Loss = 1.9562e-01, PNorm = 44.8036, GNorm = 4.7550, lr_0 = 3.3565e-04
Loss = 1.6058e-01, PNorm = 44.8187, GNorm = 6.1885, lr_0 = 3.2882e-04
Loss = 2.6089e-01, PNorm = 44.8285, GNorm = 9.3330, lr_0 = 3.2213e-04
Loss = 2.4605e-01, PNorm = 44.8363, GNorm = 4.4646, lr_0 = 3.1558e-04
Validation rmse = 0.797882
Epoch 16
Loss = 2.5267e-01, PNorm = 44.8453, GNorm = 8.8231, lr_0 = 3.0916e-04
Loss = 1.9069e-01, PNorm = 44.8544, GNorm = 7.5310, lr_0 = 3.0287e-04
Loss = 1.5999e-01, PNorm = 44.8688, GNorm = 4.1335, lr_0 = 2.9670e-04
Loss = 1.8400e-01, PNorm = 44.8781, GNorm = 3.8253, lr_0 = 2.9067e-04
Validation rmse = 0.798129
Epoch 17
Loss = 1.9156e-01, PNorm = 44.8916, GNorm = 4.8060, lr_0 = 2.8475e-04
Loss = 1.9327e-01, PNorm = 44.8997, GNorm = 4.9915, lr_0 = 2.7896e-04
Loss = 1.4881e-01, PNorm = 44.9113, GNorm = 7.0911, lr_0 = 2.7328e-04
Loss = 1.2992e-01, PNorm = 44.9232, GNorm = 3.8189, lr_0 = 2.6772e-04
Validation rmse = 0.820591
Epoch 18
Loss = 1.2274e-01, PNorm = 44.9338, GNorm = 5.6094, lr_0 = 2.6227e-04
Loss = 1.1682e-01, PNorm = 44.9451, GNorm = 8.6212, lr_0 = 2.5693e-04
Loss = 1.8499e-01, PNorm = 44.9519, GNorm = 11.5821, lr_0 = 2.5171e-04
Loss = 2.2014e-01, PNorm = 44.9579, GNorm = 6.8362, lr_0 = 2.4658e-04
Validation rmse = 0.802141
Epoch 19
Loss = 1.9324e-01, PNorm = 44.9700, GNorm = 7.2591, lr_0 = 2.4157e-04
Loss = 1.0681e-01, PNorm = 44.9821, GNorm = 6.2331, lr_0 = 2.3665e-04
Loss = 1.3812e-01, PNorm = 44.9943, GNorm = 17.3837, lr_0 = 2.3183e-04
Loss = 1.3731e-01, PNorm = 45.0008, GNorm = 12.7589, lr_0 = 2.2712e-04
Validation rmse = 0.815745
Epoch 20
Loss = 1.1890e-01, PNorm = 45.0083, GNorm = 4.4683, lr_0 = 2.2250e-04
Loss = 1.3340e-01, PNorm = 45.0175, GNorm = 7.5693, lr_0 = 2.1797e-04
Loss = 4.7909e-02, PNorm = 45.0294, GNorm = 5.7183, lr_0 = 2.1353e-04
Loss = 1.3756e-01, PNorm = 45.0358, GNorm = 12.8091, lr_0 = 2.0919e-04
Validation rmse = 0.801693
Epoch 21
Loss = 5.9492e-02, PNorm = 45.0410, GNorm = 4.0962, lr_0 = 2.0493e-04
Loss = 1.6957e-01, PNorm = 45.0489, GNorm = 3.8699, lr_0 = 2.0076e-04
Loss = 1.4909e-01, PNorm = 45.0589, GNorm = 6.7261, lr_0 = 1.9668e-04
Loss = 7.9237e-02, PNorm = 45.0655, GNorm = 3.4389, lr_0 = 1.9267e-04
Validation rmse = 0.810022
Epoch 22
Loss = 9.1876e-02, PNorm = 45.0739, GNorm = 9.9612, lr_0 = 1.8875e-04
Loss = 7.3411e-03, PNorm = 45.0836, GNorm = 6.1175, lr_0 = 1.8491e-04
Loss = 2.5962e-01, PNorm = 45.0838, GNorm = 7.1139, lr_0 = 1.8115e-04
Loss = 1.3984e-01, PNorm = 45.0899, GNorm = 3.6045, lr_0 = 1.7746e-04
Validation rmse = 0.812946
Epoch 23
Loss = 1.7485e-01, PNorm = 45.0992, GNorm = 7.5173, lr_0 = 1.7385e-04
Loss = 4.7294e-02, PNorm = 45.1096, GNorm = 4.2303, lr_0 = 1.7031e-04
Loss = 8.5933e-03, PNorm = 45.1180, GNorm = 11.3112, lr_0 = 1.6685e-04
Loss = 1.2054e-01, PNorm = 45.1209, GNorm = 4.5358, lr_0 = 1.6345e-04
Validation rmse = 0.797948
Epoch 24
Loss = 6.0417e-02, PNorm = 45.1268, GNorm = 4.9241, lr_0 = 1.6013e-04
Loss = 9.9589e-02, PNorm = 45.1344, GNorm = 12.0931, lr_0 = 1.5687e-04
Loss = 6.3184e-02, PNorm = 45.1401, GNorm = 3.5154, lr_0 = 1.5368e-04
Loss = 1.1072e-01, PNorm = 45.1448, GNorm = 5.8729, lr_0 = 1.5055e-04
Validation rmse = 0.785691
Epoch 25
Loss = 1.2031e-01, PNorm = 45.1519, GNorm = 5.8966, lr_0 = 1.4749e-04
Loss = 6.0664e-02, PNorm = 45.1585, GNorm = 4.2922, lr_0 = 1.4448e-04
Loss = 7.1234e-02, PNorm = 45.1616, GNorm = 3.4656, lr_0 = 1.4154e-04
Loss = 3.4650e-02, PNorm = 45.1673, GNorm = 7.3489, lr_0 = 1.3866e-04
Validation rmse = 0.791138
Epoch 26
Loss = 4.2566e-02, PNorm = 45.1745, GNorm = 5.2449, lr_0 = 1.3584e-04
Loss = 2.5714e-02, PNorm = 45.1823, GNorm = 6.9833, lr_0 = 1.3308e-04
Loss = 6.9170e-02, PNorm = 45.1857, GNorm = 7.7104, lr_0 = 1.3037e-04
Loss = 3.6232e-03, PNorm = 45.1890, GNorm = 5.8507, lr_0 = 1.2772e-04
Validation rmse = 0.770990
Epoch 27
Loss = 1.0883e-02, PNorm = 45.1958, GNorm = 5.2077, lr_0 = 1.2512e-04
Loss = -6.1512e-03, PNorm = 45.2027, GNorm = 10.3002, lr_0 = 1.2257e-04
Loss = 7.4272e-02, PNorm = 45.2071, GNorm = 12.0834, lr_0 = 1.2008e-04
Loss = 1.0941e-01, PNorm = 45.2089, GNorm = 6.0616, lr_0 = 1.1763e-04
Validation rmse = 0.770909
Epoch 28
Loss = -4.5254e-03, PNorm = 45.2146, GNorm = 5.5005, lr_0 = 1.1524e-04
Loss = 4.4293e-02, PNorm = 45.2223, GNorm = 7.1478, lr_0 = 1.1290e-04
Loss = 5.6058e-02, PNorm = 45.2266, GNorm = 4.0389, lr_0 = 1.1060e-04
Loss = 7.2217e-02, PNorm = 45.2306, GNorm = 12.9998, lr_0 = 1.0835e-04
Validation rmse = 0.784742
Epoch 29
Loss = -4.9469e-03, PNorm = 45.2354, GNorm = 4.2962, lr_0 = 1.0614e-04
Loss = 5.7429e-02, PNorm = 45.2397, GNorm = 7.7834, lr_0 = 1.0398e-04
Loss = 1.8723e-02, PNorm = 45.2436, GNorm = 4.9899, lr_0 = 1.0187e-04
Loss = -1.9798e-02, PNorm = 45.2473, GNorm = 9.4800, lr_0 = 1.0000e-04
Validation rmse = 0.773317
Model 0 best validation rmse = 0.770909 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.602340
Ensemble test rmse = 0.602340
1-fold cross validation
	Seed 0 ==> test rmse = 0.602340
Overall test rmse = 0.602340 +/- 0.000000
Elapsed time = 0:01:39
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,275 | train size = 1,020 | val size = 127 | test size = 128
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1226e+00, PNorm = 43.3114, GNorm = 1.7230, lr_0 = 2.2375e-04
Loss = 1.5042e+00, PNorm = 43.3119, GNorm = 1.3416, lr_0 = 3.3625e-04
Loss = 1.4343e+00, PNorm = 43.3166, GNorm = 1.1847, lr_0 = 4.4875e-04
Loss = 1.3662e+00, PNorm = 43.3263, GNorm = 1.0300, lr_0 = 5.6125e-04
Loss = 1.2330e+00, PNorm = 43.3279, GNorm = 1.9955, lr_0 = 5.7250e-04
Validation rmse = 1.575168
Epoch 1
Loss = 1.1902e+00, PNorm = 43.3471, GNorm = 1.3448, lr_0 = 6.8500e-04
Loss = 1.2142e+00, PNorm = 43.3804, GNorm = 4.0856, lr_0 = 7.9750e-04
Loss = 1.1520e+00, PNorm = 43.4177, GNorm = 2.5196, lr_0 = 9.1000e-04
Loss = 1.0383e+00, PNorm = 43.4747, GNorm = 6.4826, lr_0 = 9.9590e-04
Validation rmse = 1.155538
Epoch 2
Loss = 1.0411e+00, PNorm = 43.5354, GNorm = 5.4576, lr_0 = 9.7563e-04
Loss = 9.4035e-01, PNorm = 43.5985, GNorm = 3.5604, lr_0 = 9.5578e-04
Loss = 7.9772e-01, PNorm = 43.6686, GNorm = 6.6832, lr_0 = 9.3633e-04
Loss = 6.7801e-01, PNorm = 43.7097, GNorm = 2.8455, lr_0 = 9.1728e-04
Validation rmse = 0.980012
Epoch 3
Loss = 8.3159e-01, PNorm = 43.7504, GNorm = 5.4529, lr_0 = 8.9861e-04
Loss = 7.3354e-01, PNorm = 43.8023, GNorm = 4.6393, lr_0 = 8.8032e-04
Loss = 6.9697e-01, PNorm = 43.8543, GNorm = 2.3238, lr_0 = 8.6241e-04
Loss = 6.5732e-01, PNorm = 43.9046, GNorm = 3.8500, lr_0 = 8.4486e-04
Validation rmse = 0.954338
Epoch 4
Loss = 4.9923e-01, PNorm = 43.9382, GNorm = 2.5157, lr_0 = 8.2767e-04
Loss = 4.8589e-01, PNorm = 43.9735, GNorm = 8.6110, lr_0 = 8.1083e-04
Loss = 6.7030e-01, PNorm = 44.0022, GNorm = 3.8734, lr_0 = 7.9433e-04
Loss = 6.1540e-01, PNorm = 44.0366, GNorm = 3.3598, lr_0 = 7.7816e-04
Validation rmse = 0.851835
Epoch 5
Loss = 5.2188e-01, PNorm = 44.0834, GNorm = 4.9036, lr_0 = 7.6233e-04
Loss = 4.8456e-01, PNorm = 44.1144, GNorm = 7.3583, lr_0 = 7.4682e-04
Loss = 4.8229e-01, PNorm = 44.1371, GNorm = 9.6267, lr_0 = 7.3162e-04
Loss = 5.0969e-01, PNorm = 44.1666, GNorm = 3.2987, lr_0 = 7.1673e-04
Validation rmse = 0.900868
Epoch 6
Loss = 4.5078e-01, PNorm = 44.2007, GNorm = 5.7367, lr_0 = 7.0071e-04
Loss = 4.6363e-01, PNorm = 44.2349, GNorm = 4.9301, lr_0 = 6.8645e-04
Loss = 4.9122e-01, PNorm = 44.2486, GNorm = 2.6904, lr_0 = 6.7248e-04
Loss = 4.0513e-01, PNorm = 44.2756, GNorm = 4.8600, lr_0 = 6.5879e-04
Validation rmse = 0.888917
Epoch 7
Loss = 3.4763e-01, PNorm = 44.3032, GNorm = 3.4632, lr_0 = 6.4539e-04
Loss = 4.3180e-01, PNorm = 44.3294, GNorm = 12.3173, lr_0 = 6.3226e-04
Loss = 3.8638e-01, PNorm = 44.3545, GNorm = 11.9181, lr_0 = 6.1939e-04
Loss = 5.7365e-01, PNorm = 44.3733, GNorm = 7.0783, lr_0 = 6.0679e-04
Validation rmse = 0.858609
Epoch 8
Loss = 2.9799e-01, PNorm = 44.4032, GNorm = 1.9217, lr_0 = 5.9444e-04
Loss = 4.3173e-01, PNorm = 44.4247, GNorm = 3.3504, lr_0 = 5.8234e-04
Loss = 3.5263e-01, PNorm = 44.4425, GNorm = 4.6389, lr_0 = 5.7049e-04
Loss = 3.7858e-01, PNorm = 44.4655, GNorm = 8.0371, lr_0 = 5.5888e-04
Validation rmse = 0.846872
Epoch 9
Loss = 3.5743e-01, PNorm = 44.4721, GNorm = 5.2074, lr_0 = 5.4751e-04
Loss = 2.5663e-01, PNorm = 44.5024, GNorm = 7.4655, lr_0 = 5.3637e-04
Loss = 3.8244e-01, PNorm = 44.5214, GNorm = 5.1002, lr_0 = 5.2546e-04
Loss = 4.1311e-01, PNorm = 44.5345, GNorm = 1.9251, lr_0 = 5.1476e-04
Validation rmse = 0.819405
Epoch 10
Loss = 2.4198e-01, PNorm = 44.5509, GNorm = 2.7257, lr_0 = 5.0429e-04
Loss = 2.7635e-01, PNorm = 44.5758, GNorm = 8.3218, lr_0 = 4.9403e-04
Loss = 3.0949e-01, PNorm = 44.5953, GNorm = 8.0020, lr_0 = 4.8397e-04
Loss = 3.3495e-01, PNorm = 44.6017, GNorm = 2.4434, lr_0 = 4.7413e-04
Validation rmse = 0.819258
Epoch 11
Loss = 2.8186e-01, PNorm = 44.6224, GNorm = 3.7038, lr_0 = 4.6352e-04
Loss = 1.7546e-01, PNorm = 44.6335, GNorm = 3.8801, lr_0 = 4.5409e-04
Loss = 3.2010e-01, PNorm = 44.6564, GNorm = 3.6975, lr_0 = 4.4485e-04
Loss = 3.3068e-01, PNorm = 44.6766, GNorm = 6.9901, lr_0 = 4.3580e-04
Validation rmse = 0.813962
Epoch 12
Loss = 2.8926e-01, PNorm = 44.6807, GNorm = 6.5932, lr_0 = 4.2693e-04
Loss = 2.3262e-01, PNorm = 44.6961, GNorm = 2.2780, lr_0 = 4.1824e-04
Loss = 1.7627e-01, PNorm = 44.7146, GNorm = 5.8725, lr_0 = 4.0973e-04
Loss = 4.1419e-01, PNorm = 44.7243, GNorm = 4.0300, lr_0 = 4.0139e-04
Loss = 3.3851e-01, PNorm = 44.7360, GNorm = 3.7899, lr_0 = 3.9323e-04
Validation rmse = 0.839744
Epoch 13
Loss = 2.9690e-01, PNorm = 44.7521, GNorm = 6.3882, lr_0 = 3.8522e-04
Loss = 1.5739e-01, PNorm = 44.7718, GNorm = 9.0657, lr_0 = 3.7739e-04
Loss = 2.5691e-01, PNorm = 44.7797, GNorm = 4.2078, lr_0 = 3.6971e-04
Loss = 2.9277e-01, PNorm = 44.7883, GNorm = 5.7706, lr_0 = 3.6218e-04
Validation rmse = 0.852020
Epoch 14
Loss = 1.3738e-01, PNorm = 44.8015, GNorm = 3.5054, lr_0 = 3.5481e-04
Loss = 2.6447e-01, PNorm = 44.8150, GNorm = 2.8307, lr_0 = 3.4759e-04
Loss = 2.8214e-01, PNorm = 44.8274, GNorm = 7.9317, lr_0 = 3.4052e-04
Loss = 2.9980e-01, PNorm = 44.8387, GNorm = 7.8872, lr_0 = 3.3359e-04
Validation rmse = 0.789088
Epoch 15
Loss = 2.5197e-01, PNorm = 44.8469, GNorm = 2.5017, lr_0 = 3.2680e-04
Loss = 1.2502e-01, PNorm = 44.8606, GNorm = 10.0622, lr_0 = 3.2015e-04
Loss = 2.0226e-01, PNorm = 44.8715, GNorm = 8.7881, lr_0 = 3.1364e-04
Loss = 2.2321e-01, PNorm = 44.8777, GNorm = 7.3897, lr_0 = 3.0726e-04
Validation rmse = 0.843600
Epoch 16
Loss = 2.2772e-01, PNorm = 44.8892, GNorm = 9.1350, lr_0 = 3.0039e-04
Loss = 1.6359e-01, PNorm = 44.9034, GNorm = 8.7462, lr_0 = 2.9427e-04
Loss = 1.7602e-01, PNorm = 44.9127, GNorm = 4.0289, lr_0 = 2.8828e-04
Loss = 1.8258e-01, PNorm = 44.9209, GNorm = 8.0819, lr_0 = 2.8242e-04
Validation rmse = 0.798142
Epoch 17
Loss = 1.6081e-01, PNorm = 44.9303, GNorm = 2.7026, lr_0 = 2.7667e-04
Loss = 7.8118e-02, PNorm = 44.9436, GNorm = 13.6028, lr_0 = 2.7104e-04
Loss = 1.6033e-01, PNorm = 44.9552, GNorm = 4.1129, lr_0 = 2.6553e-04
Loss = 3.0491e-01, PNorm = 44.9572, GNorm = 3.8223, lr_0 = 2.6012e-04
Validation rmse = 0.783367
Epoch 18
Loss = 7.3724e-02, PNorm = 44.9661, GNorm = 3.7627, lr_0 = 2.5483e-04
Loss = 1.1702e-01, PNorm = 44.9787, GNorm = 9.9689, lr_0 = 2.4964e-04
Loss = 1.0412e-01, PNorm = 44.9898, GNorm = 3.9611, lr_0 = 2.4456e-04
Loss = 1.8924e-01, PNorm = 44.9935, GNorm = 4.3645, lr_0 = 2.3959e-04
Validation rmse = 0.801857
Epoch 19
Loss = 1.1710e-01, PNorm = 45.0006, GNorm = 4.2545, lr_0 = 2.3471e-04
Loss = 1.3162e-01, PNorm = 45.0108, GNorm = 4.0831, lr_0 = 2.2994e-04
Loss = 8.6819e-02, PNorm = 45.0167, GNorm = 4.2581, lr_0 = 2.2526e-04
Loss = 1.7118e-01, PNorm = 45.0237, GNorm = 10.1302, lr_0 = 2.2067e-04
Validation rmse = 0.784140
Epoch 20
Loss = 1.9552e-01, PNorm = 45.0299, GNorm = 4.6735, lr_0 = 2.1618e-04
Loss = 1.3025e-01, PNorm = 45.0371, GNorm = 6.7441, lr_0 = 2.1178e-04
Loss = 7.2943e-02, PNorm = 45.0482, GNorm = 9.1408, lr_0 = 2.0747e-04
Loss = 1.4823e-01, PNorm = 45.0574, GNorm = 4.3234, lr_0 = 2.0325e-04
Validation rmse = 0.795310
Epoch 21
Loss = 1.5161e-01, PNorm = 45.0634, GNorm = 9.0992, lr_0 = 1.9871e-04
Loss = 5.6298e-02, PNorm = 45.0707, GNorm = 3.3186, lr_0 = 1.9466e-04
Loss = 1.4618e-01, PNorm = 45.0763, GNorm = 9.9007, lr_0 = 1.9070e-04
Loss = 1.2132e-01, PNorm = 45.0810, GNorm = 6.2302, lr_0 = 1.8682e-04
Validation rmse = 0.773766
Epoch 22
Loss = 1.5538e-01, PNorm = 45.0888, GNorm = 4.2131, lr_0 = 1.8302e-04
Loss = 3.3761e-02, PNorm = 45.0966, GNorm = 6.7661, lr_0 = 1.7930e-04
Loss = 1.4492e-01, PNorm = 45.1004, GNorm = 8.0864, lr_0 = 1.7565e-04
Loss = 1.4898e-01, PNorm = 45.1079, GNorm = 12.9461, lr_0 = 1.7207e-04
Validation rmse = 0.777642
Epoch 23
Loss = -5.3413e-03, PNorm = 45.1110, GNorm = 6.7528, lr_0 = 1.6857e-04
Loss = 7.8280e-02, PNorm = 45.1173, GNorm = 9.2905, lr_0 = 1.6514e-04
Loss = 6.0961e-02, PNorm = 45.1244, GNorm = 3.7887, lr_0 = 1.6178e-04
Loss = 1.4871e-01, PNorm = 45.1289, GNorm = 8.5441, lr_0 = 1.5849e-04
Validation rmse = 0.792317
Epoch 24
Loss = 3.8070e-02, PNorm = 45.1344, GNorm = 4.0862, lr_0 = 1.5526e-04
Loss = 5.5307e-02, PNorm = 45.1397, GNorm = 10.6738, lr_0 = 1.5210e-04
Loss = 3.1402e-02, PNorm = 45.1450, GNorm = 5.9943, lr_0 = 1.4901e-04
Loss = 8.9227e-02, PNorm = 45.1508, GNorm = 4.5321, lr_0 = 1.4598e-04
Loss = 8.9234e-02, PNorm = 45.1585, GNorm = 10.2978, lr_0 = 1.4301e-04
Validation rmse = 0.799979
Epoch 25
Loss = 6.5947e-02, PNorm = 45.1628, GNorm = 3.2673, lr_0 = 1.4010e-04
Loss = 3.5621e-02, PNorm = 45.1683, GNorm = 3.8938, lr_0 = 1.3725e-04
Loss = 2.9955e-02, PNorm = 45.1724, GNorm = 4.3692, lr_0 = 1.3445e-04
Loss = 1.1188e-01, PNorm = 45.1758, GNorm = 4.4850, lr_0 = 1.3172e-04
Loss = -2.6973e-02, PNorm = 45.1760, GNorm = 10.7515, lr_0 = 1.3145e-04
Validation rmse = 0.792949
Epoch 26
Loss = 1.3492e-02, PNorm = 45.1812, GNorm = 3.8326, lr_0 = 1.2877e-04
Loss = 8.3049e-02, PNorm = 45.1876, GNorm = 12.5750, lr_0 = 1.2615e-04
Loss = 3.8303e-03, PNorm = 45.1924, GNorm = 5.6905, lr_0 = 1.2358e-04
Loss = 1.0762e-01, PNorm = 45.1963, GNorm = 6.8515, lr_0 = 1.2107e-04
Validation rmse = 0.777461
Epoch 27
Loss = 5.5888e-02, PNorm = 45.2002, GNorm = 4.4063, lr_0 = 1.1861e-04
Loss = 4.9890e-02, PNorm = 45.2068, GNorm = 5.6315, lr_0 = 1.1619e-04
Loss = 5.1214e-02, PNorm = 45.2118, GNorm = 5.9168, lr_0 = 1.1383e-04
Loss = 3.6628e-02, PNorm = 45.2145, GNorm = 9.8159, lr_0 = 1.1151e-04
Validation rmse = 0.784650
Epoch 28
Loss = 5.3982e-02, PNorm = 45.2181, GNorm = 6.3023, lr_0 = 1.0924e-04
Loss = -1.3742e-02, PNorm = 45.2224, GNorm = 7.5765, lr_0 = 1.0702e-04
Loss = -4.3461e-02, PNorm = 45.2258, GNorm = 4.4011, lr_0 = 1.0484e-04
Loss = 6.6161e-02, PNorm = 45.2300, GNorm = 6.1448, lr_0 = 1.0271e-04
Validation rmse = 0.771297
Epoch 29
Loss = 1.1087e-01, PNorm = 45.2331, GNorm = 7.8892, lr_0 = 1.0062e-04
Loss = -1.8579e-02, PNorm = 45.2365, GNorm = 6.2355, lr_0 = 1.0000e-04
Loss = 1.5763e-03, PNorm = 45.2419, GNorm = 17.4365, lr_0 = 1.0000e-04
Loss = -2.7748e-02, PNorm = 45.2440, GNorm = 5.9949, lr_0 = 1.0000e-04
Validation rmse = 0.765037
Model 0 best validation rmse = 0.765037 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.608501
Ensemble test rmse = 0.608501
1-fold cross validation
	Seed 0 ==> test rmse = 0.608501
Overall test rmse = 0.608501 +/- 0.000000
Elapsed time = 0:01:41
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1840e+00, PNorm = 43.3111, GNorm = 4.4652, lr_0 = 2.2073e-04
Loss = 1.4109e+00, PNorm = 43.3124, GNorm = 1.2981, lr_0 = 3.3049e-04
Loss = 1.4545e+00, PNorm = 43.3175, GNorm = 0.9069, lr_0 = 4.4024e-04
Loss = 1.2963e+00, PNorm = 43.3285, GNorm = 1.4150, lr_0 = 5.5000e-04
Validation rmse = 1.512043
Epoch 1
Loss = 1.2244e+00, PNorm = 43.3552, GNorm = 1.1951, lr_0 = 6.7073e-04
Loss = 1.2451e+00, PNorm = 43.3802, GNorm = 2.4667, lr_0 = 7.8049e-04
Loss = 1.0958e+00, PNorm = 43.4237, GNorm = 4.4721, lr_0 = 8.9024e-04
Loss = 9.9825e-01, PNorm = 43.4834, GNorm = 3.3342, lr_0 = 1.0000e-03
Validation rmse = 1.194262
Epoch 2
Loss = 9.5725e-01, PNorm = 43.5490, GNorm = 6.4483, lr_0 = 9.8014e-04
Loss = 7.9067e-01, PNorm = 43.6152, GNorm = 3.7918, lr_0 = 9.6068e-04
Loss = 7.8629e-01, PNorm = 43.6667, GNorm = 4.6609, lr_0 = 9.4160e-04
Loss = 6.1934e-01, PNorm = 43.7296, GNorm = 7.0123, lr_0 = 9.2290e-04
Validation rmse = 0.942010
Epoch 3
Loss = 7.8721e-01, PNorm = 43.7755, GNorm = 3.2638, lr_0 = 9.0277e-04
Loss = 7.4082e-01, PNorm = 43.8203, GNorm = 2.5352, lr_0 = 8.8484e-04
Loss = 5.1976e-01, PNorm = 43.8604, GNorm = 3.3900, lr_0 = 8.6727e-04
Loss = 6.9753e-01, PNorm = 43.8998, GNorm = 3.4322, lr_0 = 8.5005e-04
Validation rmse = 1.046717
Epoch 4
Loss = 5.8427e-01, PNorm = 43.9385, GNorm = 2.8597, lr_0 = 8.3317e-04
Loss = 5.2411e-01, PNorm = 43.9620, GNorm = 5.5470, lr_0 = 8.1662e-04
Loss = 5.9897e-01, PNorm = 43.9994, GNorm = 6.4234, lr_0 = 8.0041e-04
Loss = 5.3387e-01, PNorm = 44.0191, GNorm = 5.3478, lr_0 = 7.8451e-04
Validation rmse = 0.892177
Epoch 5
Loss = 4.3379e-01, PNorm = 44.0496, GNorm = 5.6827, lr_0 = 7.6893e-04
Loss = 5.0631e-01, PNorm = 44.0801, GNorm = 7.1396, lr_0 = 7.5366e-04
Loss = 4.9049e-01, PNorm = 44.1029, GNorm = 2.4481, lr_0 = 7.3870e-04
Loss = 5.1630e-01, PNorm = 44.1250, GNorm = 6.8081, lr_0 = 7.2403e-04
Validation rmse = 0.945140
Epoch 6
Loss = 4.7672e-01, PNorm = 44.1516, GNorm = 5.9441, lr_0 = 7.0823e-04
Loss = 4.1292e-01, PNorm = 44.1791, GNorm = 4.7347, lr_0 = 6.9417e-04
Loss = 4.2808e-01, PNorm = 44.2089, GNorm = 10.0701, lr_0 = 6.8038e-04
Loss = 4.3826e-01, PNorm = 44.2304, GNorm = 4.0082, lr_0 = 6.6687e-04
Loss = 5.5054e-01, PNorm = 44.2463, GNorm = 2.8766, lr_0 = 6.5363e-04
Validation rmse = 0.825283
Epoch 7
Loss = 4.8832e-01, PNorm = 44.2641, GNorm = 5.7960, lr_0 = 6.4065e-04
Loss = 4.3703e-01, PNorm = 44.2907, GNorm = 2.9986, lr_0 = 6.2793e-04
Loss = 3.4376e-01, PNorm = 44.3214, GNorm = 9.3268, lr_0 = 6.1546e-04
Loss = 4.2415e-01, PNorm = 44.3382, GNorm = 11.5397, lr_0 = 6.0324e-04
Validation rmse = 0.840840
Epoch 8
Loss = 3.3588e-01, PNorm = 44.3613, GNorm = 2.8820, lr_0 = 5.9007e-04
Loss = 3.7934e-01, PNorm = 44.3818, GNorm = 7.3645, lr_0 = 5.7836e-04
Loss = 3.5560e-01, PNorm = 44.4007, GNorm = 2.5053, lr_0 = 5.6687e-04
Loss = 3.1583e-01, PNorm = 44.4199, GNorm = 6.7022, lr_0 = 5.5561e-04
Validation rmse = 0.805996
Epoch 9
Loss = 3.5102e-01, PNorm = 44.4344, GNorm = 2.1708, lr_0 = 5.4458e-04
Loss = 3.6306e-01, PNorm = 44.4589, GNorm = 3.6374, lr_0 = 5.3377e-04
Loss = 3.0570e-01, PNorm = 44.4760, GNorm = 3.9854, lr_0 = 5.2317e-04
Loss = 4.2213e-01, PNorm = 44.4919, GNorm = 2.7637, lr_0 = 5.1278e-04
Validation rmse = 0.852796
Epoch 10
Loss = 3.9913e-01, PNorm = 44.5084, GNorm = 3.9141, lr_0 = 5.0260e-04
Loss = 3.1488e-01, PNorm = 44.5293, GNorm = 5.0783, lr_0 = 4.9262e-04
Loss = 2.0720e-01, PNorm = 44.5434, GNorm = 6.2156, lr_0 = 4.8283e-04
Loss = 3.8552e-01, PNorm = 44.5529, GNorm = 4.6007, lr_0 = 4.7325e-04
Validation rmse = 0.799453
Epoch 11
Loss = 3.1756e-01, PNorm = 44.5738, GNorm = 4.8597, lr_0 = 4.6292e-04
Loss = 3.3424e-01, PNorm = 44.5898, GNorm = 2.8790, lr_0 = 4.5373e-04
Loss = 2.8655e-01, PNorm = 44.6108, GNorm = 2.3645, lr_0 = 4.4472e-04
Loss = 3.1583e-01, PNorm = 44.6303, GNorm = 9.0684, lr_0 = 4.3589e-04
Validation rmse = 0.784587
Epoch 12
Loss = 3.3397e-01, PNorm = 44.6384, GNorm = 3.0635, lr_0 = 4.2723e-04
Loss = 2.0073e-01, PNorm = 44.6587, GNorm = 2.8267, lr_0 = 4.1875e-04
Loss = 2.8355e-01, PNorm = 44.6749, GNorm = 7.4706, lr_0 = 4.1043e-04
Loss = 2.7997e-01, PNorm = 44.6894, GNorm = 5.2864, lr_0 = 4.0228e-04
Loss = 3.2277e-01, PNorm = 44.7004, GNorm = 6.8850, lr_0 = 3.9429e-04
Loss = 1.2062e-02, PNorm = 44.7017, GNorm = 7.9099, lr_0 = 3.9350e-04
Validation rmse = 0.807900
Epoch 13
Loss = 3.3384e-01, PNorm = 44.7174, GNorm = 2.7364, lr_0 = 3.8569e-04
Loss = 2.8707e-01, PNorm = 44.7311, GNorm = 6.4435, lr_0 = 3.7803e-04
Loss = 2.7733e-01, PNorm = 44.7454, GNorm = 9.6199, lr_0 = 3.7052e-04
Loss = 1.7410e-01, PNorm = 44.7602, GNorm = 4.0481, lr_0 = 3.6317e-04
Validation rmse = 0.751838
Epoch 14
Loss = 1.9032e-01, PNorm = 44.7682, GNorm = 4.2926, lr_0 = 3.5595e-04
Loss = 9.7030e-02, PNorm = 44.7857, GNorm = 4.4367, lr_0 = 3.4889e-04
Loss = 2.4524e-01, PNorm = 44.7935, GNorm = 5.1063, lr_0 = 3.4196e-04
Loss = 2.7907e-01, PNorm = 44.8040, GNorm = 8.9015, lr_0 = 3.3517e-04
Validation rmse = 0.774904
Epoch 15
Loss = 1.0081e-01, PNorm = 44.8188, GNorm = 3.7111, lr_0 = 3.2851e-04
Loss = 1.5004e-01, PNorm = 44.8316, GNorm = 13.0255, lr_0 = 3.2199e-04
Loss = 2.8147e-01, PNorm = 44.8416, GNorm = 5.4170, lr_0 = 3.1559e-04
Loss = 2.5166e-01, PNorm = 44.8545, GNorm = 4.1560, lr_0 = 3.0933e-04
Validation rmse = 0.758630
Epoch 16
Loss = 1.5254e-01, PNorm = 44.8678, GNorm = 8.4128, lr_0 = 3.0258e-04
Loss = 1.3021e-01, PNorm = 44.8829, GNorm = 6.7860, lr_0 = 2.9657e-04
Loss = 1.8758e-01, PNorm = 44.8917, GNorm = 4.7120, lr_0 = 2.9068e-04
Loss = 1.1170e-01, PNorm = 44.8981, GNorm = 5.9659, lr_0 = 2.8491e-04
Validation rmse = 0.752613
Epoch 17
Loss = 1.1763e-01, PNorm = 44.9053, GNorm = 10.7877, lr_0 = 2.7925e-04
Loss = 1.0011e-01, PNorm = 44.9129, GNorm = 4.4097, lr_0 = 2.7370e-04
Loss = 1.7456e-01, PNorm = 44.9235, GNorm = 4.2707, lr_0 = 2.6827e-04
Loss = 1.5438e-01, PNorm = 44.9305, GNorm = 5.3110, lr_0 = 2.6294e-04
Validation rmse = 0.744891
Epoch 18
Loss = 4.0399e-02, PNorm = 44.9427, GNorm = 6.1568, lr_0 = 2.5720e-04
Loss = 6.9143e-02, PNorm = 44.9554, GNorm = 4.5916, lr_0 = 2.5210e-04
Loss = 1.9862e-01, PNorm = 44.9616, GNorm = 11.5346, lr_0 = 2.4709e-04
Loss = 1.3863e-01, PNorm = 44.9704, GNorm = 6.2102, lr_0 = 2.4218e-04
Loss = 1.6549e-01, PNorm = 44.9786, GNorm = 3.5645, lr_0 = 2.3738e-04
Validation rmse = 0.771132
Epoch 19
Loss = 1.2341e-01, PNorm = 44.9878, GNorm = 3.3233, lr_0 = 2.3266e-04
Loss = 1.6370e-01, PNorm = 44.9963, GNorm = 4.0495, lr_0 = 2.2804e-04
Loss = 9.4196e-02, PNorm = 45.0051, GNorm = 8.4289, lr_0 = 2.2351e-04
Loss = 7.6334e-02, PNorm = 45.0137, GNorm = 10.2096, lr_0 = 2.1907e-04
Validation rmse = 0.768027
Epoch 20
Loss = 6.4221e-02, PNorm = 45.0168, GNorm = 4.7835, lr_0 = 2.1472e-04
Loss = 1.8607e-01, PNorm = 45.0237, GNorm = 9.7527, lr_0 = 2.1046e-04
Loss = 1.5203e-01, PNorm = 45.0311, GNorm = 3.6904, lr_0 = 2.0628e-04
Loss = 4.5759e-02, PNorm = 45.0420, GNorm = 5.0446, lr_0 = 2.0219e-04
Validation rmse = 0.735892
Epoch 21
Loss = 4.8230e-02, PNorm = 45.0526, GNorm = 3.6039, lr_0 = 1.9777e-04
Loss = 3.2785e-02, PNorm = 45.0609, GNorm = 8.1318, lr_0 = 1.9385e-04
Loss = 3.2745e-02, PNorm = 45.0675, GNorm = 3.6277, lr_0 = 1.9000e-04
Loss = 9.5455e-02, PNorm = 45.0736, GNorm = 6.2431, lr_0 = 1.8622e-04
Validation rmse = 0.728202
Epoch 22
Loss = 2.2076e-02, PNorm = 45.0780, GNorm = 7.5233, lr_0 = 1.8253e-04
Loss = 1.2486e-01, PNorm = 45.0833, GNorm = 2.5421, lr_0 = 1.7890e-04
Loss = 7.8156e-02, PNorm = 45.0903, GNorm = 5.8567, lr_0 = 1.7535e-04
Loss = 2.3436e-02, PNorm = 45.0993, GNorm = 6.8823, lr_0 = 1.7187e-04
Validation rmse = 0.732933
Epoch 23
Loss = -1.3369e-02, PNorm = 45.1062, GNorm = 5.2027, lr_0 = 1.6812e-04
Loss = 3.8860e-02, PNorm = 45.1123, GNorm = 4.8748, lr_0 = 1.6478e-04
Loss = 1.9338e-01, PNorm = 45.1177, GNorm = 10.4473, lr_0 = 1.6151e-04
Loss = 4.1121e-02, PNorm = 45.1210, GNorm = 6.2852, lr_0 = 1.5830e-04
Validation rmse = 0.743876
Epoch 24
Loss = 2.6613e-01, PNorm = 45.1280, GNorm = 4.0358, lr_0 = 1.5516e-04
Loss = -7.0993e-03, PNorm = 45.1336, GNorm = 12.7073, lr_0 = 1.5207e-04
Loss = 1.1759e-01, PNorm = 45.1377, GNorm = 4.8783, lr_0 = 1.4905e-04
Loss = 2.4262e-03, PNorm = 45.1434, GNorm = 3.6962, lr_0 = 1.4609e-04
Loss = 2.2242e-02, PNorm = 45.1506, GNorm = 7.4798, lr_0 = 1.4319e-04
Validation rmse = 0.722651
Epoch 25
Loss = 3.0422e-02, PNorm = 45.1563, GNorm = 5.6144, lr_0 = 1.4035e-04
Loss = 5.2486e-02, PNorm = 45.1611, GNorm = 7.8892, lr_0 = 1.3756e-04
Loss = 2.0244e-02, PNorm = 45.1652, GNorm = 4.4185, lr_0 = 1.3483e-04
Loss = 7.9391e-03, PNorm = 45.1703, GNorm = 7.3819, lr_0 = 1.3215e-04
Validation rmse = 0.721204
Epoch 26
Loss = -5.5064e-02, PNorm = 45.1774, GNorm = 8.6505, lr_0 = 1.2927e-04
Loss = 6.9232e-02, PNorm = 45.1816, GNorm = 12.1743, lr_0 = 1.2670e-04
Loss = 4.6669e-02, PNorm = 45.1855, GNorm = 3.5763, lr_0 = 1.2419e-04
Loss = 3.3036e-02, PNorm = 45.1900, GNorm = 8.7517, lr_0 = 1.2172e-04
Validation rmse = 0.737094
Epoch 27
Loss = -5.6470e-02, PNorm = 45.1952, GNorm = 7.0364, lr_0 = 1.1930e-04
Loss = 1.6298e-02, PNorm = 45.2022, GNorm = 9.7319, lr_0 = 1.1693e-04
Loss = 7.5879e-03, PNorm = 45.2081, GNorm = 10.1447, lr_0 = 1.1461e-04
Loss = -1.7980e-02, PNorm = 45.2109, GNorm = 7.4535, lr_0 = 1.1234e-04
Validation rmse = 0.755687
Epoch 28
Loss = -1.4881e-01, PNorm = 45.2140, GNorm = 9.2007, lr_0 = 1.0989e-04
Loss = 3.0399e-02, PNorm = 45.2182, GNorm = 10.3402, lr_0 = 1.0770e-04
Loss = -2.2097e-02, PNorm = 45.2221, GNorm = 5.0974, lr_0 = 1.0556e-04
Loss = 1.7950e-02, PNorm = 45.2261, GNorm = 4.6135, lr_0 = 1.0347e-04
Validation rmse = 0.725767
Epoch 29
Loss = -7.0498e-03, PNorm = 45.2295, GNorm = 4.0424, lr_0 = 1.0141e-04
Loss = 6.4314e-03, PNorm = 45.2345, GNorm = 5.3271, lr_0 = 1.0000e-04
Loss = -7.6703e-02, PNorm = 45.2360, GNorm = 5.9083, lr_0 = 1.0000e-04
Loss = 1.9351e-04, PNorm = 45.2409, GNorm = 6.4408, lr_0 = 1.0000e-04
Validation rmse = 0.730403
Model 0 best validation rmse = 0.721204 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.653152
Ensemble test rmse = 0.653152
1-fold cross validation
	Seed 0 ==> test rmse = 0.653152
Overall test rmse = 0.653152 +/- 0.000000
Elapsed time = 0:01:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,325 | train size = 1,060 | val size = 132 | test size = 133
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0997e+00, PNorm = 43.3136, GNorm = 4.9333, lr_0 = 2.1786e-04
Loss = 1.4515e+00, PNorm = 43.3159, GNorm = 2.4877, lr_0 = 3.2500e-04
Loss = 1.4739e+00, PNorm = 43.3198, GNorm = 1.1026, lr_0 = 4.3214e-04
Loss = 1.3302e+00, PNorm = 43.3304, GNorm = 0.7930, lr_0 = 5.3929e-04
Validation rmse = 1.490010
Epoch 1
Loss = 1.2071e+00, PNorm = 43.3563, GNorm = 1.1692, lr_0 = 6.5714e-04
Loss = 1.1592e+00, PNorm = 43.3837, GNorm = 1.1000, lr_0 = 7.6429e-04
Loss = 1.0572e+00, PNorm = 43.4264, GNorm = 2.1325, lr_0 = 8.7143e-04
Loss = 1.0110e+00, PNorm = 43.4865, GNorm = 1.9308, lr_0 = 9.7857e-04
Validation rmse = 1.258095
Epoch 2
Loss = 8.7422e-01, PNorm = 43.5559, GNorm = 3.9789, lr_0 = 9.8253e-04
Loss = 8.2700e-01, PNorm = 43.6128, GNorm = 3.1212, lr_0 = 9.6348e-04
Loss = 7.5248e-01, PNorm = 43.6629, GNorm = 2.2450, lr_0 = 9.4480e-04
Loss = 6.5254e-01, PNorm = 43.7126, GNorm = 6.2663, lr_0 = 9.2648e-04
Validation rmse = 1.036239
Epoch 3
Loss = 8.2528e-01, PNorm = 43.7469, GNorm = 1.9793, lr_0 = 9.0852e-04
Loss = 6.8269e-01, PNorm = 43.7829, GNorm = 6.2670, lr_0 = 8.9090e-04
Loss = 5.8604e-01, PNorm = 43.8204, GNorm = 2.4012, lr_0 = 8.7363e-04
Loss = 5.8680e-01, PNorm = 43.8553, GNorm = 2.8271, lr_0 = 8.5669e-04
Validation rmse = 0.885472
Epoch 4
Loss = 5.4255e-01, PNorm = 43.8777, GNorm = 2.2162, lr_0 = 8.3843e-04
Loss = 4.8720e-01, PNorm = 43.9171, GNorm = 3.1406, lr_0 = 8.2218e-04
Loss = 5.6009e-01, PNorm = 43.9385, GNorm = 6.4902, lr_0 = 8.0624e-04
Loss = 5.8074e-01, PNorm = 43.9678, GNorm = 2.0618, lr_0 = 7.9060e-04
Loss = 7.1868e-01, PNorm = 43.9904, GNorm = 8.5011, lr_0 = 7.7528e-04
Validation rmse = 0.875415
Epoch 5
Loss = 5.6304e-01, PNorm = 44.0162, GNorm = 2.6308, lr_0 = 7.6024e-04
Loss = 4.2908e-01, PNorm = 44.0615, GNorm = 3.6048, lr_0 = 7.4550e-04
Loss = 5.1288e-01, PNorm = 44.0941, GNorm = 5.1293, lr_0 = 7.3105e-04
Loss = 4.6899e-01, PNorm = 44.1121, GNorm = 2.7252, lr_0 = 7.1687e-04
Validation rmse = 0.849554
Epoch 6
Loss = 4.2094e-01, PNorm = 44.1320, GNorm = 2.1420, lr_0 = 7.0160e-04
Loss = 4.1973e-01, PNorm = 44.1563, GNorm = 2.9635, lr_0 = 6.8799e-04
Loss = 4.6771e-01, PNorm = 44.1771, GNorm = 4.5136, lr_0 = 6.7465e-04
Loss = 4.4566e-01, PNorm = 44.1949, GNorm = 5.3710, lr_0 = 6.6157e-04
Validation rmse = 0.867866
Epoch 7
Loss = 5.9991e-01, PNorm = 44.2145, GNorm = 7.5060, lr_0 = 6.4748e-04
Loss = 4.6639e-01, PNorm = 44.2442, GNorm = 5.4743, lr_0 = 6.3492e-04
Loss = 3.8522e-01, PNorm = 44.2654, GNorm = 6.1286, lr_0 = 6.2261e-04
Loss = 4.2775e-01, PNorm = 44.2846, GNorm = 5.0085, lr_0 = 6.1054e-04
Validation rmse = 0.881675
Epoch 8
Loss = 8.3922e-01, PNorm = 44.3067, GNorm = 10.1005, lr_0 = 5.9870e-04
Loss = 3.1552e-01, PNorm = 44.3335, GNorm = 5.3678, lr_0 = 5.8709e-04
Loss = 3.3251e-01, PNorm = 44.3538, GNorm = 5.8646, lr_0 = 5.7571e-04
Loss = 4.1891e-01, PNorm = 44.3656, GNorm = 2.2238, lr_0 = 5.6455e-04
Loss = 4.1396e-01, PNorm = 44.3850, GNorm = 6.0647, lr_0 = 5.5360e-04
Validation rmse = 0.862579
Epoch 9
Loss = 4.1769e-01, PNorm = 44.4034, GNorm = 8.3724, lr_0 = 5.4181e-04
Loss = 3.9383e-01, PNorm = 44.4260, GNorm = 3.9431, lr_0 = 5.3130e-04
Loss = 2.7542e-01, PNorm = 44.4465, GNorm = 5.7875, lr_0 = 5.2100e-04
Loss = 3.1886e-01, PNorm = 44.4521, GNorm = 6.0437, lr_0 = 5.1090e-04
Validation rmse = 0.773894
Epoch 10
Loss = 3.1663e-01, PNorm = 44.4651, GNorm = 4.7340, lr_0 = 5.0099e-04
Loss = 3.4402e-01, PNorm = 44.4846, GNorm = 4.3742, lr_0 = 4.9128e-04
Loss = 3.7042e-01, PNorm = 44.4995, GNorm = 5.6055, lr_0 = 4.8175e-04
Loss = 2.8816e-01, PNorm = 44.5212, GNorm = 2.9108, lr_0 = 4.7241e-04
Validation rmse = 0.750838
Epoch 11
Loss = 2.4729e-01, PNorm = 44.5326, GNorm = 5.7306, lr_0 = 4.6234e-04
Loss = 4.3392e-01, PNorm = 44.5472, GNorm = 8.5560, lr_0 = 4.5338e-04
Loss = 3.5311e-01, PNorm = 44.5674, GNorm = 6.2998, lr_0 = 4.4459e-04
Loss = 3.0790e-01, PNorm = 44.5837, GNorm = 7.2475, lr_0 = 4.3597e-04
Validation rmse = 0.762603
Epoch 12
Loss = 1.4940e-01, PNorm = 44.5974, GNorm = 5.5462, lr_0 = 4.2668e-04
Loss = 2.6903e-01, PNorm = 44.6125, GNorm = 6.5605, lr_0 = 4.1841e-04
Loss = 2.4935e-01, PNorm = 44.6295, GNorm = 5.9064, lr_0 = 4.1029e-04
Loss = 3.6812e-01, PNorm = 44.6377, GNorm = 5.1482, lr_0 = 4.0234e-04
Loss = 4.4989e-01, PNorm = 44.6500, GNorm = 11.3336, lr_0 = 3.9454e-04
Validation rmse = 0.837537
Epoch 13
Loss = 2.9148e-01, PNorm = 44.6675, GNorm = 2.9953, lr_0 = 3.8689e-04
Loss = 2.1013e-01, PNorm = 44.6870, GNorm = 3.9369, lr_0 = 3.7939e-04
Loss = 3.4787e-01, PNorm = 44.6953, GNorm = 7.2732, lr_0 = 3.7203e-04
Loss = 2.4022e-01, PNorm = 44.7042, GNorm = 2.6454, lr_0 = 3.6482e-04
Validation rmse = 0.773665
Epoch 14
Loss = 2.7377e-01, PNorm = 44.7218, GNorm = 2.6127, lr_0 = 3.5704e-04
Loss = 2.7511e-01, PNorm = 44.7336, GNorm = 15.4772, lr_0 = 3.5012e-04
Loss = 1.1499e-01, PNorm = 44.7444, GNorm = 3.9177, lr_0 = 3.4333e-04
Loss = 2.4595e-01, PNorm = 44.7577, GNorm = 10.0443, lr_0 = 3.3668e-04
Validation rmse = 0.777790
Epoch 15
Loss = 3.0763e-01, PNorm = 44.7639, GNorm = 3.2183, lr_0 = 3.3015e-04
Loss = 2.3831e-01, PNorm = 44.7757, GNorm = 3.2189, lr_0 = 3.2375e-04
Loss = 1.5818e-01, PNorm = 44.7895, GNorm = 2.7281, lr_0 = 3.1747e-04
Loss = 2.4252e-01, PNorm = 44.7963, GNorm = 3.3295, lr_0 = 3.1131e-04
Validation rmse = 0.745569
Epoch 16
Loss = 5.3438e-02, PNorm = 44.8055, GNorm = 9.3257, lr_0 = 3.0468e-04
Loss = 1.3654e-01, PNorm = 44.8213, GNorm = 3.7124, lr_0 = 2.9877e-04
Loss = 2.0817e-01, PNorm = 44.8350, GNorm = 6.0347, lr_0 = 2.9298e-04
Loss = 2.5878e-01, PNorm = 44.8393, GNorm = 7.8986, lr_0 = 2.8730e-04
Loss = 2.6488e-01, PNorm = 44.8460, GNorm = 6.1852, lr_0 = 2.8173e-04
Loss = 7.8366e-02, PNorm = 44.8470, GNorm = 3.5973, lr_0 = 2.8118e-04
Validation rmse = 0.752825
Epoch 17
Loss = 1.6720e-01, PNorm = 44.8588, GNorm = 8.8487, lr_0 = 2.7573e-04
Loss = 1.0028e-01, PNorm = 44.8687, GNorm = 3.0889, lr_0 = 2.7038e-04
Loss = 2.1081e-01, PNorm = 44.8754, GNorm = 5.3843, lr_0 = 2.6514e-04
Loss = 2.3363e-01, PNorm = 44.8863, GNorm = 6.5013, lr_0 = 2.6000e-04
Validation rmse = 0.827021
Epoch 18
Loss = 2.4988e-01, PNorm = 44.8951, GNorm = 3.7769, lr_0 = 2.5495e-04
Loss = 1.5792e-01, PNorm = 44.9042, GNorm = 7.4354, lr_0 = 2.5001e-04
Loss = 1.8477e-01, PNorm = 44.9132, GNorm = 3.2214, lr_0 = 2.4516e-04
Loss = 1.0244e-01, PNorm = 44.9235, GNorm = 3.2671, lr_0 = 2.4041e-04
Validation rmse = 0.748120
Epoch 19
Loss = 4.8761e-02, PNorm = 44.9301, GNorm = 6.8907, lr_0 = 2.3529e-04
Loss = 1.3289e-01, PNorm = 44.9367, GNorm = 6.7616, lr_0 = 2.3073e-04
Loss = 1.0112e-01, PNorm = 44.9433, GNorm = 11.3936, lr_0 = 2.2625e-04
Loss = 1.7365e-01, PNorm = 44.9526, GNorm = 4.7698, lr_0 = 2.2186e-04
Validation rmse = 0.793117
Epoch 20
Loss = 1.7383e-01, PNorm = 44.9612, GNorm = 6.7489, lr_0 = 2.1756e-04
Loss = 1.4035e-01, PNorm = 44.9670, GNorm = 2.8264, lr_0 = 2.1334e-04
Loss = 1.4825e-01, PNorm = 44.9742, GNorm = 4.7591, lr_0 = 2.0921e-04
Loss = 1.1331e-01, PNorm = 44.9828, GNorm = 6.6609, lr_0 = 2.0515e-04
Loss = 9.6091e-02, PNorm = 44.9880, GNorm = 6.9597, lr_0 = 2.0117e-04
Loss = 1.8584e-02, PNorm = 44.9888, GNorm = 10.1180, lr_0 = 2.0078e-04
Validation rmse = 0.735208
Epoch 21
Loss = 5.2207e-02, PNorm = 44.9973, GNorm = 8.8716, lr_0 = 1.9689e-04
Loss = 7.7784e-02, PNorm = 45.0072, GNorm = 10.8854, lr_0 = 1.9307e-04
Loss = 1.5121e-01, PNorm = 45.0131, GNorm = 5.2135, lr_0 = 1.8933e-04
Loss = 1.7982e-01, PNorm = 45.0168, GNorm = 9.6807, lr_0 = 1.8566e-04
Validation rmse = 0.785461
Epoch 22
Loss = 1.4750e-01, PNorm = 45.0211, GNorm = 4.6114, lr_0 = 1.8170e-04
Loss = 6.4174e-02, PNorm = 45.0286, GNorm = 4.6824, lr_0 = 1.7818e-04
Loss = 1.0051e-01, PNorm = 45.0383, GNorm = 6.0807, lr_0 = 1.7472e-04
Loss = 1.3823e-01, PNorm = 45.0449, GNorm = 10.0385, lr_0 = 1.7133e-04
Validation rmse = 0.739318
Epoch 23
Loss = -7.0462e-02, PNorm = 45.0485, GNorm = 4.2563, lr_0 = 1.6801e-04
Loss = 7.9798e-02, PNorm = 45.0549, GNorm = 5.0221, lr_0 = 1.6475e-04
Loss = 1.3610e-01, PNorm = 45.0598, GNorm = 8.4661, lr_0 = 1.6156e-04
Loss = 1.5644e-01, PNorm = 45.0635, GNorm = 7.0673, lr_0 = 1.5843e-04
Validation rmse = 0.745062
Epoch 24
Loss = 1.0172e-01, PNorm = 45.0691, GNorm = 13.6570, lr_0 = 1.5505e-04
Loss = 4.0231e-02, PNorm = 45.0758, GNorm = 6.8789, lr_0 = 1.5205e-04
Loss = 1.1743e-01, PNorm = 45.0831, GNorm = 6.3432, lr_0 = 1.4910e-04
Loss = 7.2225e-02, PNorm = 45.0872, GNorm = 9.8216, lr_0 = 1.4621e-04
Loss = 3.6216e-02, PNorm = 45.0901, GNorm = 9.0049, lr_0 = 1.4337e-04
Validation rmse = 0.745575
Epoch 25
Loss = 7.1055e-02, PNorm = 45.0963, GNorm = 5.1278, lr_0 = 1.4059e-04
Loss = 8.5735e-02, PNorm = 45.1011, GNorm = 3.4754, lr_0 = 1.3787e-04
Loss = 4.5258e-02, PNorm = 45.1065, GNorm = 5.3078, lr_0 = 1.3519e-04
Loss = 2.0207e-02, PNorm = 45.1120, GNorm = 5.4638, lr_0 = 1.3257e-04
Validation rmse = 0.733238
Epoch 26
Loss = 2.8693e-02, PNorm = 45.1162, GNorm = 6.2305, lr_0 = 1.2975e-04
Loss = 2.1485e-02, PNorm = 45.1207, GNorm = 12.5047, lr_0 = 1.2723e-04
Loss = 3.2341e-02, PNorm = 45.1247, GNorm = 5.2842, lr_0 = 1.2476e-04
Loss = 1.1703e-01, PNorm = 45.1278, GNorm = 6.1448, lr_0 = 1.2234e-04
Validation rmse = 0.733762
Epoch 27
Loss = 1.3075e-01, PNorm = 45.1313, GNorm = 4.1960, lr_0 = 1.1974e-04
Loss = -3.7517e-02, PNorm = 45.1359, GNorm = 11.1513, lr_0 = 1.1742e-04
Loss = -1.9382e-03, PNorm = 45.1410, GNorm = 10.4130, lr_0 = 1.1514e-04
Loss = 6.3709e-02, PNorm = 45.1446, GNorm = 4.9573, lr_0 = 1.1291e-04
Validation rmse = 0.761092
Epoch 28
Loss = 5.1751e-02, PNorm = 45.1487, GNorm = 16.8979, lr_0 = 1.1072e-04
Loss = 3.8033e-02, PNorm = 45.1523, GNorm = 7.9161, lr_0 = 1.0857e-04
Loss = 4.9451e-02, PNorm = 45.1558, GNorm = 13.2623, lr_0 = 1.0647e-04
Loss = 5.8882e-02, PNorm = 45.1575, GNorm = 4.1424, lr_0 = 1.0440e-04
Validation rmse = 0.728517
Epoch 29
Loss = 1.3178e-01, PNorm = 45.1591, GNorm = 9.5094, lr_0 = 1.0218e-04
Loss = 9.3878e-02, PNorm = 45.1648, GNorm = 4.8181, lr_0 = 1.0020e-04
Loss = -1.3580e-02, PNorm = 45.1695, GNorm = 3.9265, lr_0 = 1.0000e-04
Loss = 3.3735e-02, PNorm = 45.1728, GNorm = 5.8713, lr_0 = 1.0000e-04
Loss = 1.3879e-02, PNorm = 45.1747, GNorm = 7.2461, lr_0 = 1.0000e-04
Validation rmse = 0.720906
Model 0 best validation rmse = 0.720906 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.593627
Ensemble test rmse = 0.593627
1-fold cross validation
	Seed 0 ==> test rmse = 0.593627
Overall test rmse = 0.593627 +/- 0.000000
Elapsed time = 0:01:48
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8366e+00, PNorm = 43.3126, GNorm = 2.9988, lr_0 = 2.1512e-04
Loss = 1.5203e+00, PNorm = 43.3136, GNorm = 1.4030, lr_0 = 3.1977e-04
Loss = 1.4764e+00, PNorm = 43.3181, GNorm = 1.2170, lr_0 = 4.2442e-04
Loss = 1.3236e+00, PNorm = 43.3289, GNorm = 0.9438, lr_0 = 5.2907e-04
Validation rmse = 1.505449
Epoch 1
Loss = 1.0993e+00, PNorm = 43.3519, GNorm = 1.6715, lr_0 = 6.4419e-04
Loss = 1.1318e+00, PNorm = 43.3799, GNorm = 4.4789, lr_0 = 7.4884e-04
Loss = 1.0622e+00, PNorm = 43.4252, GNorm = 3.0012, lr_0 = 8.5349e-04
Loss = 1.0230e+00, PNorm = 43.4857, GNorm = 3.4562, lr_0 = 9.5814e-04
Validation rmse = 1.063583
Epoch 2
Loss = 7.2644e-01, PNorm = 43.5620, GNorm = 2.1565, lr_0 = 9.8670e-04
Loss = 7.7048e-01, PNorm = 43.6324, GNorm = 2.6444, lr_0 = 9.6801e-04
Loss = 7.1054e-01, PNorm = 43.6746, GNorm = 5.0963, lr_0 = 9.4967e-04
Loss = 7.9714e-01, PNorm = 43.7124, GNorm = 7.5274, lr_0 = 9.3168e-04
Validation rmse = 1.028640
Epoch 3
Loss = 9.8749e-01, PNorm = 43.7553, GNorm = 13.7746, lr_0 = 9.1229e-04
Loss = 6.8986e-01, PNorm = 43.7810, GNorm = 2.8730, lr_0 = 8.9501e-04
Loss = 6.5855e-01, PNorm = 43.8236, GNorm = 2.0113, lr_0 = 8.7805e-04
Loss = 6.1217e-01, PNorm = 43.8601, GNorm = 3.1308, lr_0 = 8.6142e-04
Loss = 6.3662e-01, PNorm = 43.8955, GNorm = 3.7076, lr_0 = 8.4510e-04
Validation rmse = 0.897219
Epoch 4
Loss = 7.6062e-01, PNorm = 43.9353, GNorm = 4.7886, lr_0 = 8.2751e-04
Loss = 6.7512e-01, PNorm = 43.9726, GNorm = 7.3338, lr_0 = 8.1184e-04
Loss = 5.7436e-01, PNorm = 44.0156, GNorm = 2.4605, lr_0 = 7.9646e-04
Loss = 5.5151e-01, PNorm = 44.0446, GNorm = 4.0653, lr_0 = 7.8137e-04
Validation rmse = 0.823284
Epoch 5
Loss = 4.3523e-01, PNorm = 44.0667, GNorm = 5.1620, lr_0 = 7.6657e-04
Loss = 4.1405e-01, PNorm = 44.0985, GNorm = 4.8039, lr_0 = 7.5205e-04
Loss = 4.3241e-01, PNorm = 44.1299, GNorm = 3.1133, lr_0 = 7.3780e-04
Loss = 5.5652e-01, PNorm = 44.1397, GNorm = 10.3910, lr_0 = 7.2383e-04
Validation rmse = 0.884595
Epoch 6
Loss = 5.5456e-01, PNorm = 44.1587, GNorm = 4.6563, lr_0 = 7.0876e-04
Loss = 4.6704e-01, PNorm = 44.1897, GNorm = 4.4064, lr_0 = 6.9533e-04
Loss = 4.3075e-01, PNorm = 44.2136, GNorm = 2.8490, lr_0 = 6.8216e-04
Loss = 4.3609e-01, PNorm = 44.2316, GNorm = 5.7509, lr_0 = 6.6924e-04
Loss = 5.1926e-01, PNorm = 44.2537, GNorm = 6.2237, lr_0 = 6.5656e-04
Validation rmse = 0.836176
Epoch 7
Loss = 4.0747e-01, PNorm = 44.2841, GNorm = 7.6060, lr_0 = 6.4289e-04
Loss = 4.2546e-01, PNorm = 44.2972, GNorm = 2.8010, lr_0 = 6.3072e-04
Loss = 3.7021e-01, PNorm = 44.3134, GNorm = 5.9546, lr_0 = 6.1877e-04
Loss = 4.5437e-01, PNorm = 44.3331, GNorm = 3.4909, lr_0 = 6.0705e-04
Validation rmse = 0.820205
Epoch 8
Loss = 3.4531e-01, PNorm = 44.3551, GNorm = 4.5373, lr_0 = 5.9441e-04
Loss = 4.0313e-01, PNorm = 44.3778, GNorm = 9.5692, lr_0 = 5.8315e-04
Loss = 3.3039e-01, PNorm = 44.4015, GNorm = 9.6310, lr_0 = 5.7210e-04
Loss = 3.7046e-01, PNorm = 44.4203, GNorm = 7.9008, lr_0 = 5.6127e-04
Validation rmse = 0.830232
Epoch 9
Loss = 2.9897e-01, PNorm = 44.4281, GNorm = 2.5860, lr_0 = 5.4958e-04
Loss = 3.4168e-01, PNorm = 44.4488, GNorm = 5.5056, lr_0 = 5.3917e-04
Loss = 4.7268e-01, PNorm = 44.4617, GNorm = 15.0409, lr_0 = 5.2896e-04
Loss = 3.9901e-01, PNorm = 44.4821, GNorm = 2.3550, lr_0 = 5.1894e-04
Loss = 3.5692e-01, PNorm = 44.5021, GNorm = 5.2652, lr_0 = 5.0911e-04
Validation rmse = 0.835009
Epoch 10
Loss = 3.0228e-01, PNorm = 44.5209, GNorm = 5.2798, lr_0 = 4.9946e-04
Loss = 3.6423e-01, PNorm = 44.5376, GNorm = 3.2805, lr_0 = 4.9000e-04
Loss = 3.4313e-01, PNorm = 44.5524, GNorm = 11.0142, lr_0 = 4.8072e-04
Loss = 3.5479e-01, PNorm = 44.5660, GNorm = 3.8760, lr_0 = 4.7162e-04
Validation rmse = 0.834095
Epoch 11
Loss = 2.4613e-01, PNorm = 44.5850, GNorm = 4.6995, lr_0 = 4.6180e-04
Loss = 2.9337e-01, PNorm = 44.6025, GNorm = 5.7167, lr_0 = 4.5305e-04
Loss = 2.6138e-01, PNorm = 44.6195, GNorm = 3.6993, lr_0 = 4.4447e-04
Loss = 2.8645e-01, PNorm = 44.6332, GNorm = 5.5999, lr_0 = 4.3605e-04
Validation rmse = 0.798544
Epoch 12
Loss = 2.8645e-01, PNorm = 44.6540, GNorm = 4.6505, lr_0 = 4.2697e-04
Loss = 1.5927e-01, PNorm = 44.6658, GNorm = 3.4531, lr_0 = 4.1888e-04
Loss = 2.8142e-01, PNorm = 44.6779, GNorm = 2.9043, lr_0 = 4.1095e-04
Loss = 2.5145e-01, PNorm = 44.6961, GNorm = 9.9706, lr_0 = 4.0316e-04
Loss = 3.4902e-01, PNorm = 44.7047, GNorm = 5.3884, lr_0 = 3.9553e-04
Validation rmse = 0.779778
Epoch 13
Loss = 2.3521e-01, PNorm = 44.7227, GNorm = 5.7331, lr_0 = 3.8729e-04
Loss = 1.3973e-01, PNorm = 44.7380, GNorm = 3.6578, lr_0 = 3.7996e-04
Loss = 2.8801e-01, PNorm = 44.7442, GNorm = 2.9463, lr_0 = 3.7276e-04
Loss = 1.3561e-01, PNorm = 44.7597, GNorm = 3.0347, lr_0 = 3.6570e-04
Validation rmse = 0.778640
Epoch 14
Loss = 2.0937e-01, PNorm = 44.7655, GNorm = 5.0350, lr_0 = 3.5809e-04
Loss = 1.5774e-01, PNorm = 44.7836, GNorm = 9.4988, lr_0 = 3.5130e-04
Loss = 2.5067e-01, PNorm = 44.7947, GNorm = 3.5819, lr_0 = 3.4465e-04
Loss = 2.1016e-01, PNorm = 44.8072, GNorm = 4.1889, lr_0 = 3.3812e-04
Validation rmse = 0.786863
Epoch 15
Loss = 3.6820e-01, PNorm = 44.8193, GNorm = 18.2400, lr_0 = 3.3171e-04
Loss = 3.4365e-01, PNorm = 44.8270, GNorm = 9.1019, lr_0 = 3.2543e-04
Loss = 1.6260e-01, PNorm = 44.8424, GNorm = 2.8285, lr_0 = 3.1927e-04
Loss = 2.2271e-01, PNorm = 44.8559, GNorm = 3.4864, lr_0 = 3.1322e-04
Loss = 1.2307e-01, PNorm = 44.8647, GNorm = 5.9651, lr_0 = 3.0729e-04
Validation rmse = 0.788267
Epoch 16
Loss = 3.0005e-01, PNorm = 44.8616, GNorm = 3.9589, lr_0 = 3.0089e-04
Loss = 2.8954e-01, PNorm = 44.8727, GNorm = 6.7097, lr_0 = 2.9519e-04
Loss = 2.4593e-01, PNorm = 44.8842, GNorm = 3.7196, lr_0 = 2.8960e-04
Loss = 1.5152e-01, PNorm = 44.8966, GNorm = 3.7577, lr_0 = 2.8411e-04
Validation rmse = 0.785361
Epoch 17
Loss = 1.6355e-01, PNorm = 44.9038, GNorm = 4.8801, lr_0 = 2.7820e-04
Loss = 1.7437e-01, PNorm = 44.9144, GNorm = 4.5609, lr_0 = 2.7293e-04
Loss = 1.5131e-01, PNorm = 44.9245, GNorm = 2.9120, lr_0 = 2.6776e-04
Loss = 2.0101e-01, PNorm = 44.9338, GNorm = 15.5169, lr_0 = 2.6268e-04
Validation rmse = 0.788308
Epoch 18
Loss = 9.3233e-02, PNorm = 44.9383, GNorm = 8.7451, lr_0 = 2.5722e-04
Loss = 1.7751e-01, PNorm = 44.9486, GNorm = 2.5948, lr_0 = 2.5234e-04
Loss = 1.3171e-01, PNorm = 44.9580, GNorm = 6.3202, lr_0 = 2.4756e-04
Loss = 1.5205e-01, PNorm = 44.9652, GNorm = 6.5719, lr_0 = 2.4287e-04
Loss = 1.6884e-01, PNorm = 44.9730, GNorm = 5.3428, lr_0 = 2.3827e-04
Loss = 3.5501e-01, PNorm = 44.9736, GNorm = 11.7016, lr_0 = 2.3782e-04
Validation rmse = 0.773633
Epoch 19
Loss = 1.1169e-01, PNorm = 44.9821, GNorm = 7.8248, lr_0 = 2.3331e-04
Loss = 1.3157e-01, PNorm = 44.9913, GNorm = 8.6400, lr_0 = 2.2889e-04
Loss = 1.4338e-01, PNorm = 44.9984, GNorm = 4.1458, lr_0 = 2.2456e-04
Loss = 1.2713e-01, PNorm = 45.0034, GNorm = 6.8097, lr_0 = 2.2030e-04
Validation rmse = 0.769925
Epoch 20
Loss = 5.4441e-02, PNorm = 45.0117, GNorm = 3.2192, lr_0 = 2.1613e-04
Loss = 8.0172e-02, PNorm = 45.0206, GNorm = 3.4799, lr_0 = 2.1204e-04
Loss = 1.6335e-01, PNorm = 45.0280, GNorm = 8.5686, lr_0 = 2.0802e-04
Loss = 1.5602e-01, PNorm = 45.0340, GNorm = 3.7222, lr_0 = 2.0408e-04
Validation rmse = 0.762272
Epoch 21
Loss = 2.8097e-01, PNorm = 45.0415, GNorm = 16.9868, lr_0 = 1.9983e-04
Loss = 3.6623e-02, PNorm = 45.0479, GNorm = 6.3471, lr_0 = 1.9605e-04
Loss = 7.2840e-02, PNorm = 45.0575, GNorm = 11.3265, lr_0 = 1.9233e-04
Loss = 1.8614e-01, PNorm = 45.0591, GNorm = 8.7981, lr_0 = 1.8869e-04
Loss = 1.7690e-01, PNorm = 45.0624, GNorm = 4.0371, lr_0 = 1.8512e-04
Loss = 1.8480e-01, PNorm = 45.0631, GNorm = 7.7292, lr_0 = 1.8476e-04
Validation rmse = 0.741452
Epoch 22
Loss = 1.5306e-01, PNorm = 45.0708, GNorm = 10.5303, lr_0 = 1.8126e-04
Loss = 3.9353e-02, PNorm = 45.0781, GNorm = 3.6475, lr_0 = 1.7783e-04
Loss = 6.9781e-02, PNorm = 45.0853, GNorm = 5.1962, lr_0 = 1.7446e-04
Loss = 9.8313e-02, PNorm = 45.0905, GNorm = 10.7677, lr_0 = 1.7115e-04
Validation rmse = 0.738017
Epoch 23
Loss = -6.4672e-03, PNorm = 45.0973, GNorm = 8.0148, lr_0 = 1.6759e-04
Loss = 4.8262e-02, PNorm = 45.1031, GNorm = 5.6675, lr_0 = 1.6442e-04
Loss = 6.1469e-02, PNorm = 45.1085, GNorm = 7.4894, lr_0 = 1.6130e-04
Loss = 1.0734e-01, PNorm = 45.1121, GNorm = 3.2493, lr_0 = 1.5825e-04
Validation rmse = 0.762172
Epoch 24
Loss = 2.2939e-02, PNorm = 45.1182, GNorm = 4.3275, lr_0 = 1.5495e-04
Loss = 3.4763e-02, PNorm = 45.1255, GNorm = 4.3602, lr_0 = 1.5202e-04
Loss = 1.2140e-01, PNorm = 45.1302, GNorm = 7.0968, lr_0 = 1.4914e-04
Loss = 1.0491e-02, PNorm = 45.1356, GNorm = 3.1640, lr_0 = 1.4631e-04
Loss = 6.0446e-02, PNorm = 45.1390, GNorm = 13.7991, lr_0 = 1.4354e-04
Validation rmse = 0.748670
Epoch 25
Loss = 1.7703e-02, PNorm = 45.1428, GNorm = 6.8302, lr_0 = 1.4082e-04
Loss = 7.6105e-02, PNorm = 45.1485, GNorm = 6.4178, lr_0 = 1.3815e-04
Loss = -6.1294e-03, PNorm = 45.1524, GNorm = 9.1852, lr_0 = 1.3554e-04
Loss = 3.2456e-02, PNorm = 45.1569, GNorm = 6.0373, lr_0 = 1.3297e-04
Validation rmse = 0.762058
Epoch 26
Loss = 7.0142e-02, PNorm = 45.1608, GNorm = 4.3221, lr_0 = 1.3020e-04
Loss = 1.8009e-02, PNorm = 45.1672, GNorm = 5.4389, lr_0 = 1.2774e-04
Loss = 7.6723e-03, PNorm = 45.1735, GNorm = 4.0800, lr_0 = 1.2532e-04
Loss = 1.4286e-01, PNorm = 45.1770, GNorm = 11.5725, lr_0 = 1.2294e-04
Validation rmse = 0.749121
Epoch 27
Loss = 8.0607e-02, PNorm = 45.1801, GNorm = 8.4067, lr_0 = 1.2038e-04
Loss = -1.9396e-02, PNorm = 45.1846, GNorm = 8.3608, lr_0 = 1.1810e-04
Loss = 2.5904e-02, PNorm = 45.1891, GNorm = 9.0276, lr_0 = 1.1587e-04
Loss = 8.4305e-02, PNorm = 45.1919, GNorm = 6.5113, lr_0 = 1.1367e-04
Validation rmse = 0.747107
Epoch 28
Loss = -8.3482e-02, PNorm = 45.1955, GNorm = 4.3004, lr_0 = 1.1130e-04
Loss = -1.2189e-02, PNorm = 45.2007, GNorm = 6.9192, lr_0 = 1.0920e-04
Loss = 3.6330e-02, PNorm = 45.2060, GNorm = 6.7542, lr_0 = 1.0713e-04
Loss = 3.5069e-02, PNorm = 45.2085, GNorm = 3.8524, lr_0 = 1.0510e-04
Loss = 2.1601e-02, PNorm = 45.2127, GNorm = 6.2095, lr_0 = 1.0311e-04
Validation rmse = 0.752772
Epoch 29
Loss = 6.3308e-03, PNorm = 45.2153, GNorm = 6.7600, lr_0 = 1.0096e-04
Loss = -2.1652e-02, PNorm = 45.2177, GNorm = 7.9349, lr_0 = 1.0000e-04
Loss = -1.8281e-02, PNorm = 45.2216, GNorm = 10.3870, lr_0 = 1.0000e-04
Loss = 5.7768e-02, PNorm = 45.2254, GNorm = 4.5220, lr_0 = 1.0000e-04
Validation rmse = 0.740016
Model 0 best validation rmse = 0.738017 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.650119
Ensemble test rmse = 0.650119
1-fold cross validation
	Seed 0 ==> test rmse = 0.650119
Overall test rmse = 0.650119 +/- 0.000000
Elapsed time = 0:01:49
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,375 | train size = 1,100 | val size = 137 | test size = 138
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9010e+00, PNorm = 43.3128, GNorm = 2.0951, lr_0 = 2.1250e-04
Loss = 1.4495e+00, PNorm = 43.3153, GNorm = 2.2352, lr_0 = 3.1477e-04
Loss = 1.3715e+00, PNorm = 43.3209, GNorm = 2.3270, lr_0 = 4.1705e-04
Loss = 1.3456e+00, PNorm = 43.3336, GNorm = 0.9378, lr_0 = 5.1932e-04
Validation rmse = 1.490408
Epoch 1
Loss = 1.0897e+00, PNorm = 43.3534, GNorm = 1.2250, lr_0 = 6.2159e-04
Loss = 1.0844e+00, PNorm = 43.3880, GNorm = 4.1195, lr_0 = 7.2386e-04
Loss = 1.0484e+00, PNorm = 43.4375, GNorm = 1.3100, lr_0 = 8.2614e-04
Loss = 1.0212e+00, PNorm = 43.5029, GNorm = 6.4705, lr_0 = 9.2841e-04
Validation rmse = 0.998388
Epoch 2
Loss = 7.8847e-01, PNorm = 43.5773, GNorm = 4.1196, lr_0 = 9.9441e-04
Loss = 9.0965e-01, PNorm = 43.6422, GNorm = 3.0566, lr_0 = 9.7600e-04
Loss = 7.1581e-01, PNorm = 43.7013, GNorm = 3.0351, lr_0 = 9.5792e-04
Loss = 8.1860e-01, PNorm = 43.7498, GNorm = 3.3154, lr_0 = 9.4019e-04
Loss = 6.7869e-01, PNorm = 43.7980, GNorm = 4.9580, lr_0 = 9.2278e-04
Validation rmse = 0.933783
Epoch 3
Loss = 6.1753e-01, PNorm = 43.8317, GNorm = 3.9431, lr_0 = 9.0569e-04
Loss = 7.2625e-01, PNorm = 43.8737, GNorm = 7.1648, lr_0 = 8.8892e-04
Loss = 5.9320e-01, PNorm = 43.9170, GNorm = 3.3865, lr_0 = 8.7246e-04
Loss = 5.6632e-01, PNorm = 43.9536, GNorm = 3.4236, lr_0 = 8.5631e-04
Validation rmse = 0.929232
Epoch 4
Loss = 5.2455e-01, PNorm = 43.9966, GNorm = 4.8835, lr_0 = 8.4045e-04
Loss = 6.1439e-01, PNorm = 44.0302, GNorm = 2.3059, lr_0 = 8.2489e-04
Loss = 6.2206e-01, PNorm = 44.0639, GNorm = 3.2477, lr_0 = 8.0962e-04
Loss = 4.8915e-01, PNorm = 44.0983, GNorm = 2.4302, lr_0 = 7.9463e-04
Loss = 5.1542e-01, PNorm = 44.1332, GNorm = 7.2650, lr_0 = 7.7991e-04
Validation rmse = 0.856124
Epoch 5
Loss = 4.7613e-01, PNorm = 44.1695, GNorm = 2.1539, lr_0 = 7.6547e-04
Loss = 4.7929e-01, PNorm = 44.1904, GNorm = 2.1149, lr_0 = 7.5130e-04
Loss = 4.4397e-01, PNorm = 44.2260, GNorm = 8.8649, lr_0 = 7.3739e-04
Loss = 5.3061e-01, PNorm = 44.2448, GNorm = 2.5733, lr_0 = 7.2373e-04
Validation rmse = 0.879517
Epoch 6
Loss = 4.1856e-01, PNorm = 44.2701, GNorm = 2.0402, lr_0 = 7.1033e-04
Loss = 5.0000e-01, PNorm = 44.3008, GNorm = 2.8785, lr_0 = 6.9718e-04
Loss = 4.3252e-01, PNorm = 44.3305, GNorm = 3.8699, lr_0 = 6.8427e-04
Loss = 3.3060e-01, PNorm = 44.3622, GNorm = 4.2344, lr_0 = 6.7160e-04
Validation rmse = 0.782668
Epoch 7
Loss = 3.4683e-01, PNorm = 44.3695, GNorm = 3.8327, lr_0 = 6.5916e-04
Loss = 4.0586e-01, PNorm = 44.3976, GNorm = 7.3549, lr_0 = 6.4696e-04
Loss = 4.6509e-01, PNorm = 44.4195, GNorm = 2.3758, lr_0 = 6.3498e-04
Loss = 3.6910e-01, PNorm = 44.4431, GNorm = 7.0910, lr_0 = 6.2322e-04
Loss = 3.5873e-01, PNorm = 44.4617, GNorm = 5.8193, lr_0 = 6.1168e-04
Validation rmse = 0.818206
Epoch 8
Loss = 3.5092e-01, PNorm = 44.4756, GNorm = 3.8376, lr_0 = 6.0036e-04
Loss = 3.3711e-01, PNorm = 44.5024, GNorm = 3.6792, lr_0 = 5.8924e-04
Loss = 2.9494e-01, PNorm = 44.5160, GNorm = 4.6916, lr_0 = 5.7833e-04
Loss = 3.2160e-01, PNorm = 44.5337, GNorm = 3.6179, lr_0 = 5.6762e-04
Validation rmse = 0.806369
Epoch 9
Loss = 3.2305e-01, PNorm = 44.5493, GNorm = 3.2852, lr_0 = 5.5711e-04
Loss = 2.7053e-01, PNorm = 44.5709, GNorm = 7.1459, lr_0 = 5.4680e-04
Loss = 2.5131e-01, PNorm = 44.5949, GNorm = 6.2037, lr_0 = 5.3667e-04
Loss = 3.9711e-01, PNorm = 44.6074, GNorm = 9.0728, lr_0 = 5.2673e-04
Loss = 3.6121e-01, PNorm = 44.6247, GNorm = 4.3807, lr_0 = 5.1698e-04
Validation rmse = 0.804656
Epoch 10
Loss = 3.4378e-01, PNorm = 44.6463, GNorm = 14.1586, lr_0 = 5.0741e-04
Loss = 2.5663e-01, PNorm = 44.6681, GNorm = 3.9594, lr_0 = 4.9801e-04
Loss = 4.0358e-01, PNorm = 44.6802, GNorm = 10.6160, lr_0 = 4.8879e-04
Loss = 5.5964e-01, PNorm = 44.6930, GNorm = 6.4750, lr_0 = 4.7974e-04
Validation rmse = 0.992690
Epoch 11
Loss = 4.9807e-01, PNorm = 44.7141, GNorm = 3.1380, lr_0 = 4.7086e-04
Loss = 3.3944e-01, PNorm = 44.7441, GNorm = 3.6242, lr_0 = 4.6214e-04
Loss = 2.9863e-01, PNorm = 44.7661, GNorm = 6.1005, lr_0 = 4.5358e-04
Loss = 3.8744e-01, PNorm = 44.7815, GNorm = 7.7080, lr_0 = 4.4518e-04
Validation rmse = 0.788960
Epoch 12
Loss = 1.1113e-01, PNorm = 44.7994, GNorm = 2.3986, lr_0 = 4.3694e-04
Loss = 2.0101e-01, PNorm = 44.8247, GNorm = 2.6433, lr_0 = 4.2885e-04
Loss = 2.9544e-01, PNorm = 44.8445, GNorm = 7.5039, lr_0 = 4.2091e-04
Loss = 4.4576e-01, PNorm = 44.8544, GNorm = 10.2871, lr_0 = 4.1312e-04
Loss = 3.7046e-01, PNorm = 44.8620, GNorm = 3.0895, lr_0 = 4.0547e-04
Validation rmse = 0.757798
Epoch 13
Loss = 3.0882e-01, PNorm = 44.8832, GNorm = 2.7626, lr_0 = 3.9796e-04
Loss = 3.0235e-01, PNorm = 44.8993, GNorm = 9.0634, lr_0 = 3.9059e-04
Loss = 1.7955e-01, PNorm = 44.9146, GNorm = 5.9900, lr_0 = 3.8336e-04
Loss = 2.2290e-01, PNorm = 44.9257, GNorm = 3.5080, lr_0 = 3.7626e-04
Validation rmse = 0.752609
Epoch 14
Loss = 1.9077e-01, PNorm = 44.9405, GNorm = 4.1664, lr_0 = 3.6929e-04
Loss = 1.7061e-01, PNorm = 44.9529, GNorm = 3.8195, lr_0 = 3.6245e-04
Loss = 1.9936e-01, PNorm = 44.9603, GNorm = 4.8365, lr_0 = 3.5574e-04
Loss = 2.3269e-01, PNorm = 44.9726, GNorm = 2.5145, lr_0 = 3.4916e-04
Loss = 2.3387e-01, PNorm = 44.9854, GNorm = 3.4615, lr_0 = 3.4269e-04
Validation rmse = 0.768177
Epoch 15
Loss = 2.2413e-01, PNorm = 44.9986, GNorm = 4.1307, lr_0 = 3.3635e-04
Loss = 1.5859e-01, PNorm = 45.0130, GNorm = 6.9256, lr_0 = 3.3012e-04
Loss = 2.5533e-01, PNorm = 45.0173, GNorm = 3.8295, lr_0 = 3.2401e-04
Loss = 1.9873e-01, PNorm = 45.0318, GNorm = 3.3428, lr_0 = 3.1801e-04
Validation rmse = 0.742024
Epoch 16
Loss = 8.0147e-02, PNorm = 45.0498, GNorm = 3.8796, lr_0 = 3.1212e-04
Loss = 1.6733e-01, PNorm = 45.0635, GNorm = 3.1544, lr_0 = 3.0634e-04
Loss = 1.6772e-01, PNorm = 45.0739, GNorm = 7.4156, lr_0 = 3.0067e-04
Loss = 1.5724e-01, PNorm = 45.0791, GNorm = 8.0834, lr_0 = 2.9510e-04
Validation rmse = 0.747250
Epoch 17
Loss = 8.8869e-02, PNorm = 45.0881, GNorm = 5.3392, lr_0 = 2.8963e-04
Loss = 1.4946e-01, PNorm = 45.1021, GNorm = 4.7118, lr_0 = 2.8427e-04
Loss = 1.1869e-01, PNorm = 45.1177, GNorm = 4.4648, lr_0 = 2.7901e-04
Loss = 2.3359e-01, PNorm = 45.1259, GNorm = 7.4814, lr_0 = 2.7384e-04
Loss = 1.6871e-01, PNorm = 45.1348, GNorm = 8.6189, lr_0 = 2.6877e-04
Validation rmse = 0.727848
Epoch 18
Loss = 1.3437e-01, PNorm = 45.1456, GNorm = 3.0878, lr_0 = 2.6379e-04
Loss = 1.7870e-01, PNorm = 45.1566, GNorm = 8.2717, lr_0 = 2.5891e-04
Loss = 7.9263e-02, PNorm = 45.1675, GNorm = 7.8844, lr_0 = 2.5412e-04
Loss = 1.6476e-01, PNorm = 45.1754, GNorm = 7.1701, lr_0 = 2.4941e-04
Validation rmse = 0.763999
Epoch 19
Loss = -1.0588e-02, PNorm = 45.1862, GNorm = 6.0100, lr_0 = 2.4479e-04
Loss = 1.7106e-01, PNorm = 45.1969, GNorm = 9.9181, lr_0 = 2.4026e-04
Loss = 2.0611e-01, PNorm = 45.2034, GNorm = 7.4415, lr_0 = 2.3581e-04
Loss = 1.2802e-01, PNorm = 45.2099, GNorm = 4.0711, lr_0 = 2.3145e-04
Loss = 5.1880e-02, PNorm = 45.2228, GNorm = 3.9411, lr_0 = 2.2716e-04
Validation rmse = 0.744613
Epoch 20
Loss = 1.4850e-01, PNorm = 45.2331, GNorm = 5.2634, lr_0 = 2.2295e-04
Loss = 3.1290e-02, PNorm = 45.2430, GNorm = 5.3776, lr_0 = 2.1883e-04
Loss = 1.9865e-02, PNorm = 45.2506, GNorm = 7.4135, lr_0 = 2.1477e-04
Loss = 1.2931e-01, PNorm = 45.2565, GNorm = 5.3793, lr_0 = 2.1080e-04
Validation rmse = 0.777487
Epoch 21
Loss = 6.4564e-02, PNorm = 45.2609, GNorm = 5.9718, lr_0 = 2.0689e-04
Loss = 1.2068e-01, PNorm = 45.2731, GNorm = 7.3584, lr_0 = 2.0306e-04
Loss = 1.4253e-01, PNorm = 45.2814, GNorm = 4.9901, lr_0 = 1.9930e-04
Loss = 9.3647e-02, PNorm = 45.2850, GNorm = 4.1456, lr_0 = 1.9561e-04
Validation rmse = 0.734045
Epoch 22
Loss = 1.1442e-01, PNorm = 45.2929, GNorm = 3.5277, lr_0 = 1.9199e-04
Loss = 4.8377e-02, PNorm = 45.3027, GNorm = 5.4175, lr_0 = 1.8844e-04
Loss = 5.3487e-02, PNorm = 45.3097, GNorm = 5.1657, lr_0 = 1.8495e-04
Loss = 5.2787e-02, PNorm = 45.3170, GNorm = 11.6937, lr_0 = 1.8152e-04
Loss = 4.9774e-02, PNorm = 45.3245, GNorm = 6.2092, lr_0 = 1.7816e-04
Validation rmse = 0.737502
Epoch 23
Loss = 1.0386e-01, PNorm = 45.3315, GNorm = 4.2717, lr_0 = 1.7486e-04
Loss = 5.6252e-02, PNorm = 45.3363, GNorm = 6.5038, lr_0 = 1.7162e-04
Loss = 2.0975e-02, PNorm = 45.3427, GNorm = 6.3426, lr_0 = 1.6845e-04
Loss = 4.1660e-02, PNorm = 45.3502, GNorm = 4.9992, lr_0 = 1.6533e-04
Validation rmse = 0.742185
Epoch 24
Loss = -5.1968e-02, PNorm = 45.3568, GNorm = 5.3453, lr_0 = 1.6227e-04
Loss = 1.7306e-02, PNorm = 45.3635, GNorm = 7.1785, lr_0 = 1.5926e-04
Loss = -4.4899e-03, PNorm = 45.3657, GNorm = 6.3669, lr_0 = 1.5631e-04
Loss = 8.2670e-02, PNorm = 45.3722, GNorm = 5.0266, lr_0 = 1.5342e-04
Loss = 8.0315e-02, PNorm = 45.3778, GNorm = 5.6786, lr_0 = 1.5058e-04
Validation rmse = 0.725964
Epoch 25
Loss = 1.5291e-02, PNorm = 45.3854, GNorm = 7.0113, lr_0 = 1.4779e-04
Loss = -2.4131e-02, PNorm = 45.3951, GNorm = 6.3516, lr_0 = 1.4505e-04
Loss = 7.3712e-03, PNorm = 45.3981, GNorm = 6.0223, lr_0 = 1.4237e-04
Loss = 4.3866e-02, PNorm = 45.4014, GNorm = 7.3308, lr_0 = 1.3973e-04
Validation rmse = 0.705676
Epoch 26
Loss = -1.9499e-01, PNorm = 45.4068, GNorm = 7.8318, lr_0 = 1.3714e-04
Loss = 1.1329e-02, PNorm = 45.4126, GNorm = 11.3035, lr_0 = 1.3460e-04
Loss = 3.7621e-02, PNorm = 45.4186, GNorm = 3.5471, lr_0 = 1.3211e-04
Loss = 6.7442e-02, PNorm = 45.4225, GNorm = 4.0388, lr_0 = 1.2967e-04
Validation rmse = 0.708699
Epoch 27
Loss = -8.5803e-02, PNorm = 45.4275, GNorm = 3.3849, lr_0 = 1.2726e-04
Loss = 1.7766e-02, PNorm = 45.4334, GNorm = 4.4792, lr_0 = 1.2491e-04
Loss = -2.2809e-02, PNorm = 45.4377, GNorm = 4.1871, lr_0 = 1.2260e-04
Loss = -5.4840e-03, PNorm = 45.4422, GNorm = 13.3659, lr_0 = 1.2033e-04
Loss = -4.5860e-02, PNorm = 45.4479, GNorm = 7.3426, lr_0 = 1.1810e-04
Validation rmse = 0.704359
Epoch 28
Loss = -3.8648e-02, PNorm = 45.4543, GNorm = 6.6924, lr_0 = 1.1591e-04
Loss = 1.2033e-02, PNorm = 45.4576, GNorm = 5.1868, lr_0 = 1.1376e-04
Loss = -7.5557e-02, PNorm = 45.4618, GNorm = 5.9716, lr_0 = 1.1166e-04
Loss = -6.0375e-02, PNorm = 45.4666, GNorm = 9.3933, lr_0 = 1.0959e-04
Validation rmse = 0.710551
Epoch 29
Loss = -1.1627e-01, PNorm = 45.4715, GNorm = 5.4964, lr_0 = 1.0756e-04
Loss = -6.8693e-02, PNorm = 45.4748, GNorm = 5.1166, lr_0 = 1.0557e-04
Loss = 1.5025e-02, PNorm = 45.4784, GNorm = 11.2483, lr_0 = 1.0361e-04
Loss = -2.4149e-02, PNorm = 45.4812, GNorm = 3.3901, lr_0 = 1.0170e-04
Loss = -2.8415e-02, PNorm = 45.4849, GNorm = 6.9226, lr_0 = 1.0000e-04
Validation rmse = 0.710108
Model 0 best validation rmse = 0.704359 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.614141
Ensemble test rmse = 0.614141
1-fold cross validation
	Seed 0 ==> test rmse = 0.614141
Overall test rmse = 0.614141 +/- 0.000000
Elapsed time = 0:17:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9385e+00, PNorm = 43.3116, GNorm = 1.3769, lr_0 = 2.1250e-04
Loss = 1.4849e+00, PNorm = 43.3132, GNorm = 2.6830, lr_0 = 3.1477e-04
Loss = 1.4420e+00, PNorm = 43.3187, GNorm = 1.1289, lr_0 = 4.1705e-04
Loss = 1.2924e+00, PNorm = 43.3311, GNorm = 1.3446, lr_0 = 5.1932e-04
Validation rmse = 1.535623
Epoch 1
Loss = 1.2172e+00, PNorm = 43.3532, GNorm = 1.5906, lr_0 = 6.3182e-04
Loss = 1.1911e+00, PNorm = 43.3835, GNorm = 2.3770, lr_0 = 7.3409e-04
Loss = 1.0716e+00, PNorm = 43.4249, GNorm = 1.4623, lr_0 = 8.3636e-04
Loss = 9.2500e-01, PNorm = 43.4854, GNorm = 5.6120, lr_0 = 9.3864e-04
Validation rmse = 1.053409
Epoch 2
Loss = 8.1392e-01, PNorm = 43.5434, GNorm = 4.0855, lr_0 = 9.9255e-04
Loss = 7.2674e-01, PNorm = 43.6116, GNorm = 3.6865, lr_0 = 9.7417e-04
Loss = 7.8901e-01, PNorm = 43.6637, GNorm = 2.7259, lr_0 = 9.5614e-04
Loss = 7.5639e-01, PNorm = 43.7328, GNorm = 18.3419, lr_0 = 9.3843e-04
Loss = 8.0702e-01, PNorm = 43.7684, GNorm = 3.9280, lr_0 = 9.2106e-04
Validation rmse = 1.021462
Epoch 3
Loss = 7.1174e-01, PNorm = 43.8151, GNorm = 3.1663, lr_0 = 9.0400e-04
Loss = 5.5564e-01, PNorm = 43.8659, GNorm = 4.1940, lr_0 = 8.8726e-04
Loss = 7.0920e-01, PNorm = 43.9110, GNorm = 7.4909, lr_0 = 8.7083e-04
Loss = 6.7836e-01, PNorm = 43.9446, GNorm = 8.6463, lr_0 = 8.5471e-04
Validation rmse = 0.851676
Epoch 4
Loss = 7.4986e-01, PNorm = 43.9804, GNorm = 3.3083, lr_0 = 8.3888e-04
Loss = 4.7696e-01, PNorm = 44.0126, GNorm = 5.2594, lr_0 = 8.2335e-04
Loss = 5.6181e-01, PNorm = 44.0484, GNorm = 4.2104, lr_0 = 8.0810e-04
Loss = 6.2561e-01, PNorm = 44.0805, GNorm = 5.5647, lr_0 = 7.9314e-04
Loss = 5.9325e-01, PNorm = 44.1138, GNorm = 2.1512, lr_0 = 7.7846e-04
Validation rmse = 0.863261
Epoch 5
Loss = 4.5872e-01, PNorm = 44.1555, GNorm = 2.4233, lr_0 = 7.6404e-04
Loss = 4.0766e-01, PNorm = 44.1819, GNorm = 6.8671, lr_0 = 7.4989e-04
Loss = 4.2001e-01, PNorm = 44.2065, GNorm = 4.8660, lr_0 = 7.3601e-04
Loss = 5.7434e-01, PNorm = 44.2301, GNorm = 3.1088, lr_0 = 7.2238e-04
Validation rmse = 0.875427
Epoch 6
Loss = 4.7077e-01, PNorm = 44.2666, GNorm = 10.3298, lr_0 = 7.0768e-04
Loss = 4.2147e-01, PNorm = 44.2999, GNorm = 5.7650, lr_0 = 6.9458e-04
Loss = 3.8119e-01, PNorm = 44.3251, GNorm = 8.6799, lr_0 = 6.8172e-04
Loss = 4.9708e-01, PNorm = 44.3493, GNorm = 7.4402, lr_0 = 6.6909e-04
Loss = 4.5045e-01, PNorm = 44.3702, GNorm = 2.1722, lr_0 = 6.5670e-04
Validation rmse = 0.814324
Epoch 7
Loss = 3.9005e-01, PNorm = 44.3935, GNorm = 4.4081, lr_0 = 6.4455e-04
Loss = 2.9412e-01, PNorm = 44.4219, GNorm = 3.9038, lr_0 = 6.3261e-04
Loss = 4.0318e-01, PNorm = 44.4434, GNorm = 3.9054, lr_0 = 6.2090e-04
Loss = 3.1037e-01, PNorm = 44.4630, GNorm = 5.3949, lr_0 = 6.0940e-04
Validation rmse = 0.792927
Epoch 8
Loss = 1.3791e-01, PNorm = 44.4841, GNorm = 2.9874, lr_0 = 5.9812e-04
Loss = 3.1008e-01, PNorm = 44.5022, GNorm = 6.9783, lr_0 = 5.8704e-04
Loss = 4.6640e-01, PNorm = 44.5188, GNorm = 5.0125, lr_0 = 5.7617e-04
Loss = 3.8863e-01, PNorm = 44.5420, GNorm = 8.3208, lr_0 = 5.6550e-04
Loss = 3.0618e-01, PNorm = 44.5666, GNorm = 5.8859, lr_0 = 5.5503e-04
Validation rmse = 0.773420
Epoch 9
Loss = 2.2563e-01, PNorm = 44.5904, GNorm = 4.5775, lr_0 = 5.4476e-04
Loss = 2.7357e-01, PNorm = 44.6079, GNorm = 6.7397, lr_0 = 5.3467e-04
Loss = 3.5433e-01, PNorm = 44.6237, GNorm = 4.2619, lr_0 = 5.2477e-04
Loss = 3.2977e-01, PNorm = 44.6467, GNorm = 3.0365, lr_0 = 5.1505e-04
Validation rmse = 0.778270
Epoch 10
Loss = 2.9293e-01, PNorm = 44.6630, GNorm = 9.4252, lr_0 = 5.0551e-04
Loss = 2.0642e-01, PNorm = 44.6806, GNorm = 9.7063, lr_0 = 4.9615e-04
Loss = 2.8373e-01, PNorm = 44.6973, GNorm = 3.3540, lr_0 = 4.8697e-04
Loss = 2.7700e-01, PNorm = 44.7152, GNorm = 3.2451, lr_0 = 4.7795e-04
Loss = 3.1153e-01, PNorm = 44.7291, GNorm = 3.0484, lr_0 = 4.6910e-04
Validation rmse = 0.823303
Epoch 11
Loss = 2.4414e-01, PNorm = 44.7470, GNorm = 4.0729, lr_0 = 4.5956e-04
Loss = 1.5041e-01, PNorm = 44.7685, GNorm = 2.9308, lr_0 = 4.5105e-04
Loss = 2.0588e-01, PNorm = 44.7843, GNorm = 3.9224, lr_0 = 4.4269e-04
Loss = 2.5643e-01, PNorm = 44.7971, GNorm = 6.5750, lr_0 = 4.3450e-04
Validation rmse = 0.761333
Epoch 12
Loss = 2.9737e-01, PNorm = 44.8090, GNorm = 3.4485, lr_0 = 4.2645e-04
Loss = 2.6363e-01, PNorm = 44.8311, GNorm = 5.2412, lr_0 = 4.1856e-04
Loss = 2.0942e-01, PNorm = 44.8557, GNorm = 9.0486, lr_0 = 4.1081e-04
Loss = 2.6304e-01, PNorm = 44.8735, GNorm = 5.8361, lr_0 = 4.0320e-04
Loss = 1.2893e-01, PNorm = 44.8858, GNorm = 5.0687, lr_0 = 3.9573e-04
Validation rmse = 0.739892
Epoch 13
Loss = 1.7152e-01, PNorm = 44.8983, GNorm = 4.9097, lr_0 = 3.8841e-04
Loss = 2.3480e-01, PNorm = 44.9158, GNorm = 10.2913, lr_0 = 3.8121e-04
Loss = 1.3297e-01, PNorm = 44.9334, GNorm = 4.5254, lr_0 = 3.7416e-04
Loss = 1.5835e-01, PNorm = 44.9456, GNorm = 7.8675, lr_0 = 3.6723e-04
Validation rmse = 0.756485
Epoch 14
Loss = 3.0270e-01, PNorm = 44.9580, GNorm = 7.0581, lr_0 = 3.6043e-04
Loss = 9.8174e-02, PNorm = 44.9734, GNorm = 5.9785, lr_0 = 3.5375e-04
Loss = 1.4358e-01, PNorm = 44.9876, GNorm = 7.8754, lr_0 = 3.4720e-04
Loss = 1.7127e-01, PNorm = 44.9990, GNorm = 3.8333, lr_0 = 3.4077e-04
Loss = 1.4933e-01, PNorm = 45.0074, GNorm = 4.0808, lr_0 = 3.3446e-04
Validation rmse = 0.725973
Epoch 15
Loss = 8.2122e-02, PNorm = 45.0206, GNorm = 4.9905, lr_0 = 3.2827e-04
Loss = 9.5518e-02, PNorm = 45.0368, GNorm = 6.6529, lr_0 = 3.2219e-04
Loss = 1.2691e-01, PNorm = 45.0461, GNorm = 9.7346, lr_0 = 3.1623e-04
Loss = 2.4203e-01, PNorm = 45.0521, GNorm = 5.6980, lr_0 = 3.1037e-04
Validation rmse = 0.725215
Epoch 16
Loss = 9.5588e-02, PNorm = 45.0675, GNorm = 11.8426, lr_0 = 3.0406e-04
Loss = 1.3412e-01, PNorm = 45.0814, GNorm = 13.7850, lr_0 = 2.9843e-04
Loss = 1.7158e-01, PNorm = 45.0957, GNorm = 6.1701, lr_0 = 2.9290e-04
Loss = 1.2131e-01, PNorm = 45.1047, GNorm = 4.5620, lr_0 = 2.8748e-04
Loss = 1.6439e-01, PNorm = 45.1153, GNorm = 5.8133, lr_0 = 2.8215e-04
Validation rmse = 0.782093
Epoch 17
Loss = 3.8118e-02, PNorm = 45.1241, GNorm = 8.2216, lr_0 = 2.7693e-04
Loss = 1.2434e-01, PNorm = 45.1288, GNorm = 5.0454, lr_0 = 2.7180e-04
Loss = 1.8571e-01, PNorm = 45.1374, GNorm = 3.5987, lr_0 = 2.6677e-04
Loss = 2.0297e-01, PNorm = 45.1475, GNorm = 8.5731, lr_0 = 2.6183e-04
Validation rmse = 0.727454
Epoch 18
Loss = 1.4440e-02, PNorm = 45.1562, GNorm = 4.2691, lr_0 = 2.5698e-04
Loss = 9.1829e-02, PNorm = 45.1672, GNorm = 11.3962, lr_0 = 2.5222e-04
Loss = 1.3564e-01, PNorm = 45.1734, GNorm = 6.3056, lr_0 = 2.4755e-04
Loss = 9.7010e-02, PNorm = 45.1819, GNorm = 3.4542, lr_0 = 2.4297e-04
Loss = 1.4747e-01, PNorm = 45.1919, GNorm = 14.5028, lr_0 = 2.3847e-04
Validation rmse = 0.755868
Epoch 19
Loss = 4.5980e-02, PNorm = 45.1981, GNorm = 6.1934, lr_0 = 2.3406e-04
Loss = 1.1656e-01, PNorm = 45.2089, GNorm = 5.9189, lr_0 = 2.2972e-04
Loss = 5.4268e-02, PNorm = 45.2183, GNorm = 3.4173, lr_0 = 2.2547e-04
Loss = 2.4293e-02, PNorm = 45.2280, GNorm = 4.9792, lr_0 = 2.2129e-04
Validation rmse = 0.720043
Epoch 20
Loss = 1.5809e-02, PNorm = 45.2342, GNorm = 5.4521, lr_0 = 2.1720e-04
Loss = 7.0087e-02, PNorm = 45.2422, GNorm = 4.4953, lr_0 = 2.1317e-04
Loss = 5.9014e-02, PNorm = 45.2492, GNorm = 3.3569, lr_0 = 2.0923e-04
Loss = -4.6171e-03, PNorm = 45.2595, GNorm = 6.6691, lr_0 = 2.0535e-04
Loss = 8.3129e-02, PNorm = 45.2652, GNorm = 3.9811, lr_0 = 2.0155e-04
Loss = -2.4393e-01, PNorm = 45.2655, GNorm = 5.0120, lr_0 = 2.0117e-04
Validation rmse = 0.700181
Epoch 21
Loss = -5.4832e-02, PNorm = 45.2731, GNorm = 4.8913, lr_0 = 1.9745e-04
Loss = -1.5552e-02, PNorm = 45.2838, GNorm = 10.9412, lr_0 = 1.9379e-04
Loss = 5.2001e-02, PNorm = 45.2881, GNorm = 13.8000, lr_0 = 1.9020e-04
Loss = 1.2132e-01, PNorm = 45.2930, GNorm = 7.1900, lr_0 = 1.8668e-04
Validation rmse = 0.720551
Epoch 22
Loss = -1.9031e-03, PNorm = 45.2988, GNorm = 3.1560, lr_0 = 1.8323e-04
Loss = -4.0851e-02, PNorm = 45.3081, GNorm = 3.4044, lr_0 = 1.7983e-04
Loss = 3.5555e-02, PNorm = 45.3156, GNorm = 6.6181, lr_0 = 1.7650e-04
Loss = -6.5295e-03, PNorm = 45.3217, GNorm = 3.3063, lr_0 = 1.7324e-04
Loss = 1.0096e-01, PNorm = 45.3262, GNorm = 10.2851, lr_0 = 1.7003e-04
Validation rmse = 0.700375
Epoch 23
Loss = -2.0996e-02, PNorm = 45.3325, GNorm = 3.2774, lr_0 = 1.6688e-04
Loss = 2.7878e-03, PNorm = 45.3393, GNorm = 6.0470, lr_0 = 1.6379e-04
Loss = 1.5919e-02, PNorm = 45.3457, GNorm = 6.4647, lr_0 = 1.6076e-04
Loss = 5.1532e-03, PNorm = 45.3526, GNorm = 5.4278, lr_0 = 1.5778e-04
Validation rmse = 0.706333
Epoch 24
Loss = -8.2469e-02, PNorm = 45.3586, GNorm = 3.1627, lr_0 = 1.5486e-04
Loss = -7.8232e-02, PNorm = 45.3628, GNorm = 4.7824, lr_0 = 1.5199e-04
Loss = -6.9425e-03, PNorm = 45.3690, GNorm = 5.7290, lr_0 = 1.4918e-04
Loss = -1.1448e-02, PNorm = 45.3740, GNorm = 12.5207, lr_0 = 1.4641e-04
Loss = 9.8379e-02, PNorm = 45.3771, GNorm = 5.7940, lr_0 = 1.4370e-04
Validation rmse = 0.711351
Epoch 25
Loss = -1.3810e-02, PNorm = 45.3833, GNorm = 3.0533, lr_0 = 1.4104e-04
Loss = -2.1694e-02, PNorm = 45.3887, GNorm = 6.5647, lr_0 = 1.3843e-04
Loss = -4.9855e-03, PNorm = 45.3943, GNorm = 9.4091, lr_0 = 1.3587e-04
Loss = -3.6193e-03, PNorm = 45.4002, GNorm = 6.2688, lr_0 = 1.3335e-04
Validation rmse = 0.711674
Epoch 26
Loss = 1.0727e-02, PNorm = 45.4048, GNorm = 4.1454, lr_0 = 1.3064e-04
Loss = -4.4929e-02, PNorm = 45.4116, GNorm = 6.0039, lr_0 = 1.2822e-04
Loss = -1.0700e-01, PNorm = 45.4160, GNorm = 6.1939, lr_0 = 1.2585e-04
Loss = 4.4974e-02, PNorm = 45.4200, GNorm = 6.9045, lr_0 = 1.2352e-04
Validation rmse = 0.714078
Epoch 27
Loss = 1.7169e-01, PNorm = 45.4228, GNorm = 7.2172, lr_0 = 1.2123e-04
Loss = -3.1158e-02, PNorm = 45.4279, GNorm = 11.0507, lr_0 = 1.1898e-04
Loss = -8.5429e-02, PNorm = 45.4325, GNorm = 3.5423, lr_0 = 1.1678e-04
Loss = 4.4978e-02, PNorm = 45.4360, GNorm = 6.2278, lr_0 = 1.1462e-04
Loss = -7.5097e-02, PNorm = 45.4388, GNorm = 10.5694, lr_0 = 1.1250e-04
Validation rmse = 0.729143
Epoch 28
Loss = -4.3670e-03, PNorm = 45.4429, GNorm = 5.9007, lr_0 = 1.1041e-04
Loss = -5.0121e-02, PNorm = 45.4480, GNorm = 9.5614, lr_0 = 1.0837e-04
Loss = -7.6948e-02, PNorm = 45.4532, GNorm = 7.3181, lr_0 = 1.0636e-04
Loss = -8.5236e-03, PNorm = 45.4547, GNorm = 6.4568, lr_0 = 1.0439e-04
Validation rmse = 0.729187
Epoch 29
Loss = 3.0034e-02, PNorm = 45.4567, GNorm = 9.1803, lr_0 = 1.0246e-04
Loss = -1.0675e-01, PNorm = 45.4599, GNorm = 5.5725, lr_0 = 1.0056e-04
Loss = -1.0618e-01, PNorm = 45.4648, GNorm = 5.5736, lr_0 = 1.0000e-04
Loss = -2.3709e-02, PNorm = 45.4679, GNorm = 4.8131, lr_0 = 1.0000e-04
Loss = 1.5688e-02, PNorm = 45.4717, GNorm = 8.2800, lr_0 = 1.0000e-04
Validation rmse = 0.722390
Model 0 best validation rmse = 0.700181 on epoch 20
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.617408
Ensemble test rmse = 0.617408
1-fold cross validation
	Seed 0 ==> test rmse = 0.617408
Overall test rmse = 0.617408 +/- 0.000000
Elapsed time = 0:32:19
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,425 | train size = 1,140 | val size = 142 | test size = 143
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9387e+00, PNorm = 43.3132, GNorm = 1.9670, lr_0 = 2.1000e-04
Loss = 1.4709e+00, PNorm = 43.3144, GNorm = 1.6131, lr_0 = 3.1000e-04
Loss = 1.4201e+00, PNorm = 43.3192, GNorm = 1.8441, lr_0 = 4.1000e-04
Loss = 1.2998e+00, PNorm = 43.3312, GNorm = 1.0739, lr_0 = 5.1000e-04
Validation rmse = 1.449569
Epoch 1
Loss = 1.2510e+00, PNorm = 43.3514, GNorm = 1.3616, lr_0 = 6.2000e-04
Loss = 1.0640e+00, PNorm = 43.3840, GNorm = 1.7450, lr_0 = 7.2000e-04
Loss = 1.0432e+00, PNorm = 43.4266, GNorm = 4.4903, lr_0 = 8.2000e-04
Loss = 9.4071e-01, PNorm = 43.4869, GNorm = 5.4967, lr_0 = 9.2000e-04
Loss = 9.2032e-01, PNorm = 43.5471, GNorm = 4.8192, lr_0 = 9.9635e-04
Validation rmse = 0.973737
Epoch 2
Loss = 7.7525e-01, PNorm = 43.6061, GNorm = 3.2774, lr_0 = 9.7831e-04
Loss = 7.4089e-01, PNorm = 43.6569, GNorm = 7.4334, lr_0 = 9.6059e-04
Loss = 7.4359e-01, PNorm = 43.7090, GNorm = 6.9580, lr_0 = 9.4320e-04
Loss = 6.3910e-01, PNorm = 43.7532, GNorm = 3.2855, lr_0 = 9.2612e-04
Validation rmse = 0.924489
Epoch 3
Loss = 6.6510e-01, PNorm = 43.7987, GNorm = 2.7858, lr_0 = 9.0769e-04
Loss = 6.2047e-01, PNorm = 43.8372, GNorm = 3.5263, lr_0 = 8.9125e-04
Loss = 5.7729e-01, PNorm = 43.8855, GNorm = 2.2495, lr_0 = 8.7511e-04
Loss = 6.8777e-01, PNorm = 43.9124, GNorm = 4.0772, lr_0 = 8.5926e-04
Loss = 5.9719e-01, PNorm = 43.9486, GNorm = 4.0305, lr_0 = 8.4370e-04
Validation rmse = 0.827210
Epoch 4
Loss = 4.3571e-01, PNorm = 43.9833, GNorm = 6.9200, lr_0 = 8.2843e-04
Loss = 3.8384e-01, PNorm = 44.0190, GNorm = 4.7202, lr_0 = 8.1342e-04
Loss = 6.3564e-01, PNorm = 44.0438, GNorm = 7.3807, lr_0 = 7.9869e-04
Loss = 6.1890e-01, PNorm = 44.0590, GNorm = 3.5436, lr_0 = 7.8423e-04
Validation rmse = 0.856896
Epoch 5
Loss = 4.2872e-01, PNorm = 44.0822, GNorm = 7.0073, lr_0 = 7.7003e-04
Loss = 4.3899e-01, PNorm = 44.1122, GNorm = 10.7340, lr_0 = 7.5609e-04
Loss = 5.3018e-01, PNorm = 44.1391, GNorm = 2.4172, lr_0 = 7.4239e-04
Loss = 5.0699e-01, PNorm = 44.1645, GNorm = 4.9764, lr_0 = 7.2895e-04
Loss = 5.0762e-01, PNorm = 44.1781, GNorm = 2.1045, lr_0 = 7.1575e-04
Validation rmse = 0.800086
Epoch 6
Loss = 3.3718e-01, PNorm = 44.2224, GNorm = 2.9045, lr_0 = 7.0151e-04
Loss = 4.3702e-01, PNorm = 44.2418, GNorm = 11.4300, lr_0 = 6.8880e-04
Loss = 4.3872e-01, PNorm = 44.2627, GNorm = 8.0350, lr_0 = 6.7633e-04
Loss = 5.3201e-01, PNorm = 44.2805, GNorm = 6.4071, lr_0 = 6.6408e-04
Validation rmse = 0.796401
Epoch 7
Loss = 3.7252e-01, PNorm = 44.3031, GNorm = 4.0206, lr_0 = 6.5206e-04
Loss = 4.1754e-01, PNorm = 44.3294, GNorm = 9.8568, lr_0 = 6.4025e-04
Loss = 2.5031e-01, PNorm = 44.3630, GNorm = 11.7378, lr_0 = 6.2866e-04
Loss = 4.6325e-01, PNorm = 44.3842, GNorm = 9.1361, lr_0 = 6.1727e-04
Loss = 4.2089e-01, PNorm = 44.3966, GNorm = 4.7860, lr_0 = 6.0609e-04
Validation rmse = 0.794795
Epoch 8
Loss = 3.6426e-01, PNorm = 44.4225, GNorm = 8.3369, lr_0 = 5.9403e-04
Loss = 3.2666e-01, PNorm = 44.4551, GNorm = 4.3028, lr_0 = 5.8327e-04
Loss = 3.4585e-01, PNorm = 44.4762, GNorm = 8.0481, lr_0 = 5.7271e-04
Loss = 3.4641e-01, PNorm = 44.4930, GNorm = 4.1407, lr_0 = 5.6234e-04
Loss = 3.9331e-01, PNorm = 44.5073, GNorm = 9.0553, lr_0 = 5.5216e-04
Validation rmse = 0.798101
Epoch 9
Loss = 3.2831e-01, PNorm = 44.5282, GNorm = 13.9127, lr_0 = 5.4216e-04
Loss = 3.1460e-01, PNorm = 44.5501, GNorm = 2.9586, lr_0 = 5.3234e-04
Loss = 3.1546e-01, PNorm = 44.5782, GNorm = 3.6333, lr_0 = 5.2270e-04
Loss = 3.2943e-01, PNorm = 44.5958, GNorm = 4.1375, lr_0 = 5.1324e-04
Validation rmse = 0.793708
Epoch 10
Loss = 2.3592e-01, PNorm = 44.6118, GNorm = 5.0451, lr_0 = 5.0394e-04
Loss = 2.6871e-01, PNorm = 44.6383, GNorm = 11.9928, lr_0 = 4.9482e-04
Loss = 2.2597e-01, PNorm = 44.6548, GNorm = 2.8624, lr_0 = 4.8586e-04
Loss = 3.1971e-01, PNorm = 44.6693, GNorm = 3.7605, lr_0 = 4.7706e-04
Loss = 3.6763e-01, PNorm = 44.6728, GNorm = 3.3191, lr_0 = 4.6842e-04
Validation rmse = 0.772150
Epoch 11
Loss = 3.1132e-01, PNorm = 44.6924, GNorm = 9.1232, lr_0 = 4.5910e-04
Loss = 2.6469e-01, PNorm = 44.7123, GNorm = 5.3159, lr_0 = 4.5078e-04
Loss = 2.3607e-01, PNorm = 44.7329, GNorm = 8.3865, lr_0 = 4.4262e-04
Loss = 2.4183e-01, PNorm = 44.7438, GNorm = 6.7486, lr_0 = 4.3461e-04
Validation rmse = 0.769961
Epoch 12
Loss = 2.5200e-01, PNorm = 44.7591, GNorm = 4.3491, lr_0 = 4.2674e-04
Loss = 1.7963e-01, PNorm = 44.7776, GNorm = 11.8144, lr_0 = 4.1901e-04
Loss = 2.1533e-01, PNorm = 44.7901, GNorm = 7.6385, lr_0 = 4.1142e-04
Loss = 1.9972e-01, PNorm = 44.7996, GNorm = 9.8734, lr_0 = 4.0397e-04
Loss = 3.1874e-01, PNorm = 44.8103, GNorm = 3.6947, lr_0 = 3.9665e-04
Validation rmse = 0.747207
Epoch 13
Loss = 2.7909e-01, PNorm = 44.8225, GNorm = 2.8876, lr_0 = 3.8876e-04
Loss = 2.7633e-01, PNorm = 44.8400, GNorm = 8.8827, lr_0 = 3.8172e-04
Loss = 1.6788e-01, PNorm = 44.8542, GNorm = 4.5269, lr_0 = 3.7481e-04
Loss = 1.9836e-01, PNorm = 44.8660, GNorm = 12.8003, lr_0 = 3.6802e-04
Validation rmse = 0.755095
Epoch 14
Loss = 9.5070e-02, PNorm = 44.8773, GNorm = 2.5106, lr_0 = 3.6136e-04
Loss = 2.5295e-01, PNorm = 44.8938, GNorm = 8.2246, lr_0 = 3.5481e-04
Loss = 2.5361e-01, PNorm = 44.9101, GNorm = 8.3297, lr_0 = 3.4839e-04
Loss = 2.2948e-01, PNorm = 44.9212, GNorm = 4.6983, lr_0 = 3.4208e-04
Loss = 1.5855e-01, PNorm = 44.9368, GNorm = 6.1329, lr_0 = 3.3588e-04
Validation rmse = 0.744043
Epoch 15
Loss = 1.0270e-01, PNorm = 44.9476, GNorm = 3.4870, lr_0 = 3.2980e-04
Loss = 2.2762e-01, PNorm = 44.9608, GNorm = 3.9905, lr_0 = 3.2383e-04
Loss = 1.0096e-01, PNorm = 44.9737, GNorm = 3.6096, lr_0 = 3.1797e-04
Loss = 2.4611e-01, PNorm = 44.9763, GNorm = 9.0781, lr_0 = 3.1221e-04
Validation rmse = 0.730118
Epoch 16
Loss = 5.8683e-02, PNorm = 44.9865, GNorm = 6.2189, lr_0 = 3.0599e-04
Loss = 1.6947e-01, PNorm = 45.0008, GNorm = 5.8411, lr_0 = 3.0045e-04
Loss = 1.3755e-01, PNorm = 45.0119, GNorm = 15.2103, lr_0 = 2.9501e-04
Loss = 2.5359e-01, PNorm = 45.0218, GNorm = 4.4479, lr_0 = 2.8967e-04
Loss = 2.0694e-01, PNorm = 45.0318, GNorm = 6.3314, lr_0 = 2.8443e-04
Validation rmse = 0.746999
Epoch 17
Loss = 1.2878e-01, PNorm = 45.0482, GNorm = 5.9176, lr_0 = 2.7927e-04
Loss = 1.3638e-01, PNorm = 45.0616, GNorm = 5.8502, lr_0 = 2.7422e-04
Loss = 1.2019e-01, PNorm = 45.0697, GNorm = 4.9386, lr_0 = 2.6925e-04
Loss = 1.7475e-01, PNorm = 45.0793, GNorm = 2.8960, lr_0 = 2.6438e-04
Loss = 1.7673e-01, PNorm = 45.0850, GNorm = 2.9675, lr_0 = 2.5959e-04
Loss = 1.6780e-01, PNorm = 45.0858, GNorm = 12.0422, lr_0 = 2.5911e-04
Validation rmse = 0.753197
Epoch 18
Loss = 3.6142e-02, PNorm = 45.0987, GNorm = 5.4050, lr_0 = 2.5442e-04
Loss = 9.0924e-02, PNorm = 45.1106, GNorm = 4.8767, lr_0 = 2.4982e-04
Loss = 1.4202e-01, PNorm = 45.1165, GNorm = 9.3819, lr_0 = 2.4529e-04
Loss = 2.1925e-01, PNorm = 45.1214, GNorm = 6.1598, lr_0 = 2.4085e-04
Validation rmse = 0.735910
Epoch 19
Loss = -4.0844e-02, PNorm = 45.1278, GNorm = 3.8951, lr_0 = 2.3649e-04
Loss = 1.0177e-01, PNorm = 45.1385, GNorm = 8.9092, lr_0 = 2.3221e-04
Loss = 4.8766e-02, PNorm = 45.1461, GNorm = 5.5332, lr_0 = 2.2800e-04
Loss = 1.5134e-01, PNorm = 45.1512, GNorm = 3.0773, lr_0 = 2.2387e-04
Loss = 1.0207e-01, PNorm = 45.1595, GNorm = 3.0877, lr_0 = 2.1982e-04
Validation rmse = 0.732515
Epoch 20
Loss = 7.2033e-02, PNorm = 45.1713, GNorm = 6.7963, lr_0 = 2.1584e-04
Loss = 3.1063e-02, PNorm = 45.1822, GNorm = 7.9105, lr_0 = 2.1193e-04
Loss = 4.1653e-02, PNorm = 45.1923, GNorm = 5.3288, lr_0 = 2.0809e-04
Loss = 1.0084e-01, PNorm = 45.1987, GNorm = 6.9153, lr_0 = 2.0432e-04
Validation rmse = 0.727539
Epoch 21
Loss = 5.9458e-02, PNorm = 45.2049, GNorm = 9.7260, lr_0 = 2.0026e-04
Loss = 4.2193e-02, PNorm = 45.2141, GNorm = 3.8575, lr_0 = 1.9663e-04
Loss = 2.8857e-02, PNorm = 45.2230, GNorm = 4.0515, lr_0 = 1.9307e-04
Loss = 1.4401e-01, PNorm = 45.2293, GNorm = 3.7448, lr_0 = 1.8957e-04
Loss = 6.9990e-02, PNorm = 45.2365, GNorm = 2.6640, lr_0 = 1.8614e-04
Validation rmse = 0.729590
Epoch 22
Loss = 7.1172e-02, PNorm = 45.2432, GNorm = 7.8296, lr_0 = 1.8277e-04
Loss = 7.5195e-02, PNorm = 45.2518, GNorm = 9.3435, lr_0 = 1.7946e-04
Loss = 3.6585e-02, PNorm = 45.2600, GNorm = 5.1243, lr_0 = 1.7621e-04
Loss = -6.9046e-03, PNorm = 45.2640, GNorm = 4.0097, lr_0 = 1.7302e-04
Validation rmse = 0.726425
Epoch 23
Loss = 1.9828e-01, PNorm = 45.2725, GNorm = 4.3284, lr_0 = 1.6958e-04
Loss = -1.4849e-02, PNorm = 45.2793, GNorm = 8.5178, lr_0 = 1.6651e-04
Loss = 8.6745e-02, PNorm = 45.2850, GNorm = 7.6893, lr_0 = 1.6349e-04
Loss = 2.2991e-02, PNorm = 45.2917, GNorm = 7.3399, lr_0 = 1.6053e-04
Loss = -8.7325e-03, PNorm = 45.2974, GNorm = 3.7402, lr_0 = 1.5762e-04
Validation rmse = 0.714032
Epoch 24
Loss = 1.4337e-02, PNorm = 45.3051, GNorm = 13.2251, lr_0 = 1.5477e-04
Loss = -1.2532e-02, PNorm = 45.3144, GNorm = 7.3841, lr_0 = 1.5197e-04
Loss = 9.4901e-02, PNorm = 45.3173, GNorm = 5.2297, lr_0 = 1.4921e-04
Loss = -4.4586e-02, PNorm = 45.3223, GNorm = 5.2213, lr_0 = 1.4651e-04
Loss = 6.8306e-02, PNorm = 45.3279, GNorm = 5.9471, lr_0 = 1.4386e-04
Validation rmse = 0.711429
Epoch 25
Loss = -6.7026e-02, PNorm = 45.3327, GNorm = 5.6698, lr_0 = 1.4125e-04
Loss = -1.8101e-02, PNorm = 45.3397, GNorm = 3.8168, lr_0 = 1.3870e-04
Loss = 2.5787e-02, PNorm = 45.3461, GNorm = 10.1939, lr_0 = 1.3618e-04
Loss = 4.1398e-02, PNorm = 45.3493, GNorm = 3.3390, lr_0 = 1.3372e-04
Validation rmse = 0.718955
Epoch 26
Loss = -7.5850e-03, PNorm = 45.3541, GNorm = 5.6064, lr_0 = 1.3106e-04
Loss = -4.1684e-02, PNorm = 45.3610, GNorm = 11.4374, lr_0 = 1.2868e-04
Loss = -6.5012e-03, PNorm = 45.3662, GNorm = 5.6377, lr_0 = 1.2635e-04
Loss = -3.5246e-02, PNorm = 45.3690, GNorm = 5.7805, lr_0 = 1.2407e-04
Loss = 5.2180e-02, PNorm = 45.3734, GNorm = 5.5595, lr_0 = 1.2182e-04
Validation rmse = 0.708893
Epoch 27
Loss = -1.3582e-01, PNorm = 45.3772, GNorm = 3.6053, lr_0 = 1.1961e-04
Loss = 3.6690e-02, PNorm = 45.3817, GNorm = 5.2822, lr_0 = 1.1745e-04
Loss = 1.3213e-02, PNorm = 45.3856, GNorm = 7.1027, lr_0 = 1.1532e-04
Loss = -2.8895e-02, PNorm = 45.3900, GNorm = 8.6680, lr_0 = 1.1323e-04
Validation rmse = 0.716954
Epoch 28
Loss = 2.3924e-02, PNorm = 45.3947, GNorm = 6.5830, lr_0 = 1.1098e-04
Loss = -1.3419e-01, PNorm = 45.4003, GNorm = 4.3108, lr_0 = 1.0897e-04
Loss = 2.3620e-02, PNorm = 45.4052, GNorm = 9.5117, lr_0 = 1.0700e-04
Loss = -3.5091e-02, PNorm = 45.4087, GNorm = 4.0920, lr_0 = 1.0506e-04
Loss = -1.7004e-02, PNorm = 45.4121, GNorm = 7.5883, lr_0 = 1.0316e-04
Validation rmse = 0.720246
Epoch 29
Loss = 6.3361e-02, PNorm = 45.4153, GNorm = 7.9967, lr_0 = 1.0129e-04
Loss = 9.0202e-03, PNorm = 45.4189, GNorm = 3.9380, lr_0 = 1.0000e-04
Loss = -5.3923e-02, PNorm = 45.4236, GNorm = 11.2677, lr_0 = 1.0000e-04
Loss = -1.5536e-01, PNorm = 45.4283, GNorm = 8.6242, lr_0 = 1.0000e-04
Validation rmse = 0.737203
Model 0 best validation rmse = 0.708893 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.582704
Ensemble test rmse = 0.582704
1-fold cross validation
	Seed 0 ==> test rmse = 0.582704
Overall test rmse = 0.582704 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1755e+00, PNorm = 43.3125, GNorm = 2.5430, lr_0 = 2.0761e-04
Loss = 1.5385e+00, PNorm = 43.3143, GNorm = 2.2276, lr_0 = 3.0543e-04
Loss = 1.4217e+00, PNorm = 43.3186, GNorm = 1.5326, lr_0 = 4.0326e-04
Loss = 1.3303e+00, PNorm = 43.3277, GNorm = 1.4819, lr_0 = 5.0109e-04
Validation rmse = 1.477261
Epoch 1
Loss = 1.1717e+00, PNorm = 43.3449, GNorm = 1.2940, lr_0 = 6.0870e-04
Loss = 1.1408e+00, PNorm = 43.3709, GNorm = 2.4111, lr_0 = 7.0652e-04
Loss = 1.1164e+00, PNorm = 43.4126, GNorm = 1.8228, lr_0 = 8.0435e-04
Loss = 9.3549e-01, PNorm = 43.4646, GNorm = 6.6412, lr_0 = 9.0217e-04
Loss = 9.8197e-01, PNorm = 43.5157, GNorm = 2.1517, lr_0 = 1.0000e-03
Validation rmse = 1.028992
Epoch 2
Loss = 7.2415e-01, PNorm = 43.5880, GNorm = 4.7472, lr_0 = 9.8053e-04
Loss = 7.7098e-01, PNorm = 43.6374, GNorm = 5.1930, lr_0 = 9.6315e-04
Loss = 7.2602e-01, PNorm = 43.6893, GNorm = 5.6702, lr_0 = 9.4609e-04
Loss = 6.9833e-01, PNorm = 43.7274, GNorm = 2.6348, lr_0 = 9.2933e-04
Validation rmse = 0.978799
Epoch 3
Loss = 4.9076e-01, PNorm = 43.7699, GNorm = 5.6957, lr_0 = 9.1286e-04
Loss = 6.5590e-01, PNorm = 43.8030, GNorm = 7.6792, lr_0 = 8.9668e-04
Loss = 5.3120e-01, PNorm = 43.8454, GNorm = 7.3801, lr_0 = 8.8080e-04
Loss = 6.8215e-01, PNorm = 43.8777, GNorm = 4.9250, lr_0 = 8.6519e-04
Loss = 6.4903e-01, PNorm = 43.9163, GNorm = 2.9464, lr_0 = 8.4986e-04
Validation rmse = 0.816242
Epoch 4
Loss = 3.4098e-01, PNorm = 43.9487, GNorm = 3.0545, lr_0 = 8.3331e-04
Loss = 4.8374e-01, PNorm = 43.9808, GNorm = 2.5087, lr_0 = 8.1855e-04
Loss = 5.9052e-01, PNorm = 43.9926, GNorm = 5.4979, lr_0 = 8.0404e-04
Loss = 4.4933e-01, PNorm = 44.0144, GNorm = 6.0325, lr_0 = 7.8980e-04
Loss = 4.4265e-01, PNorm = 44.0501, GNorm = 3.4054, lr_0 = 7.7580e-04
Validation rmse = 0.861494
Epoch 5
Loss = 4.1034e-01, PNorm = 44.0806, GNorm = 9.2431, lr_0 = 7.6206e-04
Loss = 6.2551e-01, PNorm = 44.0993, GNorm = 8.0011, lr_0 = 7.4855e-04
Loss = 5.6771e-01, PNorm = 44.1241, GNorm = 6.5958, lr_0 = 7.3529e-04
Loss = 4.5824e-01, PNorm = 44.1567, GNorm = 3.0789, lr_0 = 7.2226e-04
Validation rmse = 0.755747
Epoch 6
Loss = 4.4489e-01, PNorm = 44.1829, GNorm = 4.5620, lr_0 = 7.0820e-04
Loss = 4.1399e-01, PNorm = 44.2038, GNorm = 4.8397, lr_0 = 6.9565e-04
Loss = 4.1008e-01, PNorm = 44.2267, GNorm = 12.2722, lr_0 = 6.8333e-04
Loss = 5.0839e-01, PNorm = 44.2486, GNorm = 4.6939, lr_0 = 6.7122e-04
Loss = 5.7997e-01, PNorm = 44.2645, GNorm = 2.2354, lr_0 = 6.5932e-04
Validation rmse = 0.812997
Epoch 7
Loss = 4.4765e-01, PNorm = 44.2869, GNorm = 2.3607, lr_0 = 6.4649e-04
Loss = 4.2118e-01, PNorm = 44.3109, GNorm = 6.8933, lr_0 = 6.3503e-04
Loss = 2.9152e-01, PNorm = 44.3413, GNorm = 2.6388, lr_0 = 6.2378e-04
Loss = 4.0746e-01, PNorm = 44.3584, GNorm = 2.5542, lr_0 = 6.1273e-04
Loss = 3.7061e-01, PNorm = 44.3671, GNorm = 9.9060, lr_0 = 6.0187e-04
Validation rmse = 0.771448
Epoch 8
Loss = 3.7744e-01, PNorm = 44.3859, GNorm = 7.6461, lr_0 = 5.9121e-04
Loss = 3.5541e-01, PNorm = 44.4067, GNorm = 8.3439, lr_0 = 5.8073e-04
Loss = 4.5736e-01, PNorm = 44.4235, GNorm = 5.4516, lr_0 = 5.7044e-04
Loss = 4.6774e-01, PNorm = 44.4459, GNorm = 6.0212, lr_0 = 5.6033e-04
Validation rmse = 0.901000
Epoch 9
Loss = 5.0173e-01, PNorm = 44.4664, GNorm = 10.1848, lr_0 = 5.4942e-04
Loss = 3.3666e-01, PNorm = 44.4858, GNorm = 2.3624, lr_0 = 5.3969e-04
Loss = 2.8859e-01, PNorm = 44.5054, GNorm = 4.3162, lr_0 = 5.3013e-04
Loss = 3.9058e-01, PNorm = 44.5177, GNorm = 2.6519, lr_0 = 5.2073e-04
Loss = 3.4971e-01, PNorm = 44.5274, GNorm = 3.2018, lr_0 = 5.1151e-04
Validation rmse = 0.754068
Epoch 10
Loss = 3.0403e-01, PNorm = 44.5439, GNorm = 2.9602, lr_0 = 5.0244e-04
Loss = 2.8752e-01, PNorm = 44.5671, GNorm = 3.3284, lr_0 = 4.9354e-04
Loss = 3.1177e-01, PNorm = 44.5769, GNorm = 4.4023, lr_0 = 4.8480e-04
Loss = 3.1854e-01, PNorm = 44.5944, GNorm = 8.5712, lr_0 = 4.7621e-04
Loss = 2.9589e-01, PNorm = 44.6135, GNorm = 2.1183, lr_0 = 4.6777e-04
Loss = 1.3363e-02, PNorm = 44.6157, GNorm = 3.7736, lr_0 = 4.6693e-04
Validation rmse = 0.770385
Epoch 11
Loss = 1.3956e-01, PNorm = 44.6429, GNorm = 8.6988, lr_0 = 4.5866e-04
Loss = 3.1940e-01, PNorm = 44.6480, GNorm = 3.8158, lr_0 = 4.5053e-04
Loss = 2.6865e-01, PNorm = 44.6547, GNorm = 6.2861, lr_0 = 4.4255e-04
Loss = 2.9031e-01, PNorm = 44.6660, GNorm = 6.1087, lr_0 = 4.3471e-04
Validation rmse = 0.798195
Epoch 12
Loss = 2.3870e-01, PNorm = 44.6810, GNorm = 5.3196, lr_0 = 4.2624e-04
Loss = 2.2155e-01, PNorm = 44.7004, GNorm = 3.1467, lr_0 = 4.1869e-04
Loss = 1.9127e-01, PNorm = 44.7180, GNorm = 11.2754, lr_0 = 4.1127e-04
Loss = 3.3265e-01, PNorm = 44.7241, GNorm = 3.4188, lr_0 = 4.0399e-04
Loss = 2.8055e-01, PNorm = 44.7409, GNorm = 2.9999, lr_0 = 3.9683e-04
Validation rmse = 0.757947
Epoch 13
Loss = 2.3185e-01, PNorm = 44.7557, GNorm = 3.6227, lr_0 = 3.8980e-04
Loss = 2.3089e-01, PNorm = 44.7680, GNorm = 6.6939, lr_0 = 3.8289e-04
Loss = 2.0921e-01, PNorm = 44.7841, GNorm = 9.5330, lr_0 = 3.7611e-04
Loss = 1.4121e-01, PNorm = 44.7958, GNorm = 7.4975, lr_0 = 3.6944e-04
Validation rmse = 0.748479
Epoch 14
Loss = 1.0209e-01, PNorm = 44.8071, GNorm = 3.5511, lr_0 = 3.6225e-04
Loss = 1.5972e-01, PNorm = 44.8218, GNorm = 6.3694, lr_0 = 3.5583e-04
Loss = 2.2260e-01, PNorm = 44.8382, GNorm = 4.8902, lr_0 = 3.4953e-04
Loss = 2.7925e-01, PNorm = 44.8454, GNorm = 9.8781, lr_0 = 3.4333e-04
Loss = 2.0212e-01, PNorm = 44.8544, GNorm = 8.4289, lr_0 = 3.3725e-04
Validation rmse = 0.729692
Epoch 15
Loss = 4.8564e-02, PNorm = 44.8689, GNorm = 3.6610, lr_0 = 3.3127e-04
Loss = 1.2357e-01, PNorm = 44.8842, GNorm = 3.8043, lr_0 = 3.2540e-04
Loss = 2.0558e-01, PNorm = 44.8951, GNorm = 4.9582, lr_0 = 3.1964e-04
Loss = 2.2978e-01, PNorm = 44.9031, GNorm = 5.0290, lr_0 = 3.1397e-04
Loss = 7.9500e-02, PNorm = 44.9150, GNorm = 2.5350, lr_0 = 3.0841e-04
Validation rmse = 0.748695
Epoch 16
Loss = 1.5245e-01, PNorm = 44.9261, GNorm = 12.2155, lr_0 = 3.0241e-04
Loss = 1.1001e-01, PNorm = 44.9314, GNorm = 5.0169, lr_0 = 2.9705e-04
Loss = 1.6927e-01, PNorm = 44.9396, GNorm = 3.6579, lr_0 = 2.9178e-04
Loss = 1.7395e-01, PNorm = 44.9512, GNorm = 3.7129, lr_0 = 2.8661e-04
Validation rmse = 0.721193
Epoch 17
Loss = 2.0508e-01, PNorm = 44.9591, GNorm = 4.9790, lr_0 = 2.8103e-04
Loss = 7.0008e-02, PNorm = 44.9707, GNorm = 6.3130, lr_0 = 2.7605e-04
Loss = 1.9303e-01, PNorm = 44.9788, GNorm = 13.6757, lr_0 = 2.7116e-04
Loss = 1.8191e-01, PNorm = 44.9864, GNorm = 6.1702, lr_0 = 2.6636e-04
Loss = 1.6864e-01, PNorm = 44.9952, GNorm = 9.4885, lr_0 = 2.6164e-04
Validation rmse = 0.764615
Epoch 18
Loss = 1.5018e-01, PNorm = 45.0043, GNorm = 4.2395, lr_0 = 2.5700e-04
Loss = 7.1154e-02, PNorm = 45.0149, GNorm = 3.8053, lr_0 = 2.5245e-04
Loss = 1.0623e-01, PNorm = 45.0265, GNorm = 7.1804, lr_0 = 2.4798e-04
Loss = 1.9231e-01, PNorm = 45.0242, GNorm = 3.0100, lr_0 = 2.4358e-04
Loss = 1.6443e-01, PNorm = 45.0342, GNorm = 4.4503, lr_0 = 2.3927e-04
Validation rmse = 0.738341
Epoch 19
Loss = 7.1781e-02, PNorm = 45.0487, GNorm = 8.0229, lr_0 = 2.3461e-04
Loss = 1.0863e-01, PNorm = 45.0536, GNorm = 7.9692, lr_0 = 2.3045e-04
Loss = 1.6731e-01, PNorm = 45.0620, GNorm = 9.9255, lr_0 = 2.2637e-04
Loss = 5.8032e-02, PNorm = 45.0683, GNorm = 8.4421, lr_0 = 2.2236e-04
Validation rmse = 0.718129
Epoch 20
Loss = 1.5454e-01, PNorm = 45.0778, GNorm = 5.6144, lr_0 = 2.1842e-04
Loss = 1.2302e-01, PNorm = 45.0850, GNorm = 7.6106, lr_0 = 2.1455e-04
Loss = 8.7438e-02, PNorm = 45.0925, GNorm = 6.1669, lr_0 = 2.1075e-04
Loss = 6.8309e-02, PNorm = 45.0996, GNorm = 3.8303, lr_0 = 2.0701e-04
Loss = 1.3062e-01, PNorm = 45.1057, GNorm = 6.9786, lr_0 = 2.0334e-04
Validation rmse = 0.692466
Epoch 21
Loss = 1.0299e-01, PNorm = 45.1147, GNorm = 6.3278, lr_0 = 1.9938e-04
Loss = 6.7003e-02, PNorm = 45.1210, GNorm = 11.6948, lr_0 = 1.9585e-04
Loss = 1.1582e-01, PNorm = 45.1291, GNorm = 5.5372, lr_0 = 1.9238e-04
Loss = 5.3722e-02, PNorm = 45.1340, GNorm = 4.0287, lr_0 = 1.8897e-04
Loss = 6.5341e-02, PNorm = 45.1418, GNorm = 8.1884, lr_0 = 1.8562e-04
Loss = 3.2400e-01, PNorm = 45.1429, GNorm = 14.9232, lr_0 = 1.8529e-04
Validation rmse = 0.726323
Epoch 22
Loss = -1.6522e-02, PNorm = 45.1544, GNorm = 7.9712, lr_0 = 1.8201e-04
Loss = 1.3752e-01, PNorm = 45.1610, GNorm = 7.1702, lr_0 = 1.7878e-04
Loss = 5.1240e-02, PNorm = 45.1650, GNorm = 5.3092, lr_0 = 1.7562e-04
Loss = 7.6386e-02, PNorm = 45.1740, GNorm = 7.6499, lr_0 = 1.7250e-04
Validation rmse = 0.725222
Epoch 23
Loss = 8.3664e-02, PNorm = 45.1793, GNorm = 5.1975, lr_0 = 1.6945e-04
Loss = 3.4551e-02, PNorm = 45.1851, GNorm = 5.7571, lr_0 = 1.6645e-04
Loss = 1.5592e-02, PNorm = 45.1915, GNorm = 5.6305, lr_0 = 1.6350e-04
Loss = 1.7787e-02, PNorm = 45.1987, GNorm = 4.6926, lr_0 = 1.6060e-04
Loss = 6.6553e-02, PNorm = 45.2054, GNorm = 8.7900, lr_0 = 1.5775e-04
Validation rmse = 0.699782
Epoch 24
Loss = 1.8736e-02, PNorm = 45.2073, GNorm = 3.7392, lr_0 = 1.5468e-04
Loss = 7.3340e-02, PNorm = 45.2116, GNorm = 12.1383, lr_0 = 1.5194e-04
Loss = 5.0532e-02, PNorm = 45.2191, GNorm = 7.2213, lr_0 = 1.4925e-04
Loss = -1.9664e-02, PNorm = 45.2260, GNorm = 4.8875, lr_0 = 1.4661e-04
Loss = 1.2882e-01, PNorm = 45.2309, GNorm = 7.5860, lr_0 = 1.4401e-04
Validation rmse = 0.711041
Epoch 25
Loss = 1.1762e-02, PNorm = 45.2358, GNorm = 2.8339, lr_0 = 1.4146e-04
Loss = -5.4045e-04, PNorm = 45.2407, GNorm = 4.6221, lr_0 = 1.3895e-04
Loss = 7.4161e-02, PNorm = 45.2459, GNorm = 4.7660, lr_0 = 1.3649e-04
Loss = 2.9818e-02, PNorm = 45.2500, GNorm = 4.0653, lr_0 = 1.3407e-04
Validation rmse = 0.691020
Epoch 26
Loss = -4.1106e-03, PNorm = 45.2576, GNorm = 3.5071, lr_0 = 1.3146e-04
Loss = -7.7936e-04, PNorm = 45.2632, GNorm = 20.2176, lr_0 = 1.2913e-04
Loss = 5.4773e-02, PNorm = 45.2645, GNorm = 7.4508, lr_0 = 1.2684e-04
Loss = 2.0223e-02, PNorm = 45.2676, GNorm = 8.4722, lr_0 = 1.2459e-04
Loss = 2.5846e-02, PNorm = 45.2726, GNorm = 6.7692, lr_0 = 1.2239e-04
Validation rmse = 0.695526
Epoch 27
Loss = -1.3204e-02, PNorm = 45.2788, GNorm = 8.4093, lr_0 = 1.2000e-04
Loss = -2.8378e-03, PNorm = 45.2851, GNorm = 4.8811, lr_0 = 1.1788e-04
Loss = -1.4574e-02, PNorm = 45.2899, GNorm = 6.6796, lr_0 = 1.1579e-04
Loss = 6.7241e-02, PNorm = 45.2903, GNorm = 6.8720, lr_0 = 1.1374e-04
Validation rmse = 0.716637
Epoch 28
Loss = -1.0980e-01, PNorm = 45.2934, GNorm = 3.5148, lr_0 = 1.1172e-04
Loss = 3.6167e-02, PNorm = 45.2973, GNorm = 6.4465, lr_0 = 1.0974e-04
Loss = -5.9888e-02, PNorm = 45.3023, GNorm = 4.8371, lr_0 = 1.0780e-04
Loss = 1.0713e-02, PNorm = 45.3074, GNorm = 13.6513, lr_0 = 1.0589e-04
Loss = 2.8006e-02, PNorm = 45.3104, GNorm = 4.4903, lr_0 = 1.0401e-04
Validation rmse = 0.687377
Epoch 29
Loss = -2.6773e-02, PNorm = 45.3134, GNorm = 7.7610, lr_0 = 1.0199e-04
Loss = -6.9618e-02, PNorm = 45.3186, GNorm = 4.6512, lr_0 = 1.0018e-04
Loss = 6.6844e-02, PNorm = 45.3218, GNorm = 11.5486, lr_0 = 1.0000e-04
Loss = -3.1721e-02, PNorm = 45.3259, GNorm = 7.3402, lr_0 = 1.0000e-04
Loss = -1.5274e-02, PNorm = 45.3309, GNorm = 19.3802, lr_0 = 1.0000e-04
Validation rmse = 0.696182
Model 0 best validation rmse = 0.687377 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.611681
Ensemble test rmse = 0.611681
1-fold cross validation
	Seed 0 ==> test rmse = 0.611681
Overall test rmse = 0.611681 +/- 0.000000
Elapsed time = 0:01:55
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,475 | train size = 1,180 | val size = 147 | test size = 148
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1512e+00, PNorm = 43.3118, GNorm = 3.5690, lr_0 = 2.0532e-04
Loss = 1.4624e+00, PNorm = 43.3130, GNorm = 2.1900, lr_0 = 3.0106e-04
Loss = 1.4268e+00, PNorm = 43.3170, GNorm = 1.3897, lr_0 = 3.9681e-04
Loss = 1.3563e+00, PNorm = 43.3251, GNorm = 2.2247, lr_0 = 4.9255e-04
Validation rmse = 1.503894
Epoch 1
Loss = 1.3651e+00, PNorm = 43.3441, GNorm = 4.4452, lr_0 = 5.9787e-04
Loss = 1.1261e+00, PNorm = 43.3725, GNorm = 1.8690, lr_0 = 6.9362e-04
Loss = 1.0303e+00, PNorm = 43.4073, GNorm = 3.1688, lr_0 = 7.8936e-04
Loss = 8.5519e-01, PNorm = 43.4585, GNorm = 3.9029, lr_0 = 8.8511e-04
Loss = 1.0218e+00, PNorm = 43.5156, GNorm = 4.5812, lr_0 = 9.8085e-04
Validation rmse = 1.042251
Epoch 2
Loss = 8.8459e-01, PNorm = 43.5684, GNorm = 5.8670, lr_0 = 9.8438e-04
Loss = 8.3069e-01, PNorm = 43.6168, GNorm = 6.3077, lr_0 = 9.6730e-04
Loss = 8.0571e-01, PNorm = 43.6718, GNorm = 5.2020, lr_0 = 9.5052e-04
Loss = 7.4134e-01, PNorm = 43.7277, GNorm = 2.1309, lr_0 = 9.3404e-04
Loss = 6.0077e-01, PNorm = 43.7641, GNorm = 9.0071, lr_0 = 9.1784e-04
Validation rmse = 0.969366
Epoch 3
Loss = 6.1511e-01, PNorm = 43.8070, GNorm = 2.3926, lr_0 = 9.0034e-04
Loss = 5.5645e-01, PNorm = 43.8448, GNorm = 7.8657, lr_0 = 8.8473e-04
Loss = 5.9031e-01, PNorm = 43.8661, GNorm = 4.1687, lr_0 = 8.6938e-04
Loss = 5.9456e-01, PNorm = 43.8924, GNorm = 5.3544, lr_0 = 8.5430e-04
Validation rmse = 0.898597
Epoch 4
Loss = 6.0150e-01, PNorm = 43.9293, GNorm = 4.4442, lr_0 = 8.3802e-04
Loss = 5.2461e-01, PNorm = 43.9691, GNorm = 3.9884, lr_0 = 8.2348e-04
Loss = 5.2719e-01, PNorm = 44.0008, GNorm = 6.0594, lr_0 = 8.0920e-04
Loss = 4.7008e-01, PNorm = 44.0266, GNorm = 5.0907, lr_0 = 7.9516e-04
Loss = 5.5270e-01, PNorm = 44.0563, GNorm = 2.9013, lr_0 = 7.8137e-04
Validation rmse = 0.995753
Epoch 5
Loss = 4.9514e-01, PNorm = 44.0759, GNorm = 5.8217, lr_0 = 7.6782e-04
Loss = 5.2751e-01, PNorm = 44.1030, GNorm = 6.0968, lr_0 = 7.5450e-04
Loss = 5.1351e-01, PNorm = 44.1282, GNorm = 5.7391, lr_0 = 7.4141e-04
Loss = 3.7842e-01, PNorm = 44.1500, GNorm = 3.5584, lr_0 = 7.2855e-04
Loss = 4.6053e-01, PNorm = 44.1750, GNorm = 7.5511, lr_0 = 7.1592e-04
Validation rmse = 0.846782
Epoch 6
Loss = 4.8194e-01, PNorm = 44.2044, GNorm = 5.0096, lr_0 = 7.0227e-04
Loss = 5.3723e-01, PNorm = 44.2316, GNorm = 3.0740, lr_0 = 6.9009e-04
Loss = 4.0626e-01, PNorm = 44.2587, GNorm = 3.0101, lr_0 = 6.7812e-04
Loss = 3.5018e-01, PNorm = 44.2816, GNorm = 16.7524, lr_0 = 6.6636e-04
Loss = 4.8990e-01, PNorm = 44.2991, GNorm = 2.0427, lr_0 = 6.5480e-04
Loss = 2.3332e-01, PNorm = 44.3013, GNorm = 7.4607, lr_0 = 6.5366e-04
Validation rmse = 0.817404
Epoch 7
Loss = 3.9713e-01, PNorm = 44.3246, GNorm = 3.4013, lr_0 = 6.4232e-04
Loss = 3.0788e-01, PNorm = 44.3435, GNorm = 10.5973, lr_0 = 6.3118e-04
Loss = 3.5710e-01, PNorm = 44.3628, GNorm = 3.2597, lr_0 = 6.2023e-04
Loss = 3.9193e-01, PNorm = 44.3822, GNorm = 3.2353, lr_0 = 6.0947e-04
Validation rmse = 0.798488
Epoch 8
Loss = 2.5823e-01, PNorm = 44.4072, GNorm = 4.7102, lr_0 = 5.9785e-04
Loss = 3.2561e-01, PNorm = 44.4187, GNorm = 7.4418, lr_0 = 5.8749e-04
Loss = 3.3419e-01, PNorm = 44.4295, GNorm = 3.5594, lr_0 = 5.7730e-04
Loss = 2.8127e-01, PNorm = 44.4498, GNorm = 4.0737, lr_0 = 5.6728e-04
Loss = 5.4621e-01, PNorm = 44.4654, GNorm = 2.7877, lr_0 = 5.5744e-04
Validation rmse = 0.887092
Epoch 9
Loss = 4.3361e-01, PNorm = 44.4932, GNorm = 9.8430, lr_0 = 5.4682e-04
Loss = 3.6733e-01, PNorm = 44.5181, GNorm = 6.7953, lr_0 = 5.3733e-04
Loss = 3.9533e-01, PNorm = 44.5425, GNorm = 8.8609, lr_0 = 5.2801e-04
Loss = 3.9969e-01, PNorm = 44.5569, GNorm = 7.3649, lr_0 = 5.1885e-04
Loss = 3.0657e-01, PNorm = 44.5679, GNorm = 7.9484, lr_0 = 5.0986e-04
Validation rmse = 0.790212
Epoch 10
Loss = 3.5064e-01, PNorm = 44.5766, GNorm = 5.0668, lr_0 = 5.0101e-04
Loss = 5.3307e-01, PNorm = 44.5961, GNorm = 2.5762, lr_0 = 4.9232e-04
Loss = 2.9860e-01, PNorm = 44.6163, GNorm = 5.7702, lr_0 = 4.8378e-04
Loss = 2.9316e-01, PNorm = 44.6351, GNorm = 7.3740, lr_0 = 4.7539e-04
Validation rmse = 0.780312
Epoch 11
Loss = 1.3553e-01, PNorm = 44.6532, GNorm = 2.4746, lr_0 = 4.6633e-04
Loss = 2.4909e-01, PNorm = 44.6677, GNorm = 5.1192, lr_0 = 4.5824e-04
Loss = 2.5487e-01, PNorm = 44.6848, GNorm = 15.3148, lr_0 = 4.5029e-04
Loss = 3.4521e-01, PNorm = 44.6924, GNorm = 2.9349, lr_0 = 4.4248e-04
Loss = 3.2417e-01, PNorm = 44.7040, GNorm = 3.5459, lr_0 = 4.3481e-04
Validation rmse = 0.759094
Epoch 12
Loss = 3.7314e-01, PNorm = 44.7190, GNorm = 2.1032, lr_0 = 4.2652e-04
Loss = 2.6438e-01, PNorm = 44.7346, GNorm = 2.8947, lr_0 = 4.1912e-04
Loss = 1.8304e-01, PNorm = 44.7472, GNorm = 5.1275, lr_0 = 4.1185e-04
Loss = 2.5423e-01, PNorm = 44.7579, GNorm = 6.0376, lr_0 = 4.0471e-04
Loss = 2.8578e-01, PNorm = 44.7708, GNorm = 4.5353, lr_0 = 3.9769e-04
Validation rmse = 0.806052
Epoch 13
Loss = 2.7750e-01, PNorm = 44.7867, GNorm = 11.5540, lr_0 = 3.9011e-04
Loss = 2.4487e-01, PNorm = 44.8038, GNorm = 3.1476, lr_0 = 3.8334e-04
Loss = 1.8708e-01, PNorm = 44.8184, GNorm = 5.3174, lr_0 = 3.7669e-04
Loss = 2.4042e-01, PNorm = 44.8275, GNorm = 3.9843, lr_0 = 3.7016e-04
Loss = 2.6700e-01, PNorm = 44.8304, GNorm = 3.0766, lr_0 = 3.6374e-04
Loss = 2.7873e-01, PNorm = 44.8313, GNorm = 6.4486, lr_0 = 3.6310e-04
Validation rmse = 0.758488
Epoch 14
Loss = 2.2744e-01, PNorm = 44.8443, GNorm = 6.5042, lr_0 = 3.5681e-04
Loss = 1.2764e-01, PNorm = 44.8609, GNorm = 3.3782, lr_0 = 3.5062e-04
Loss = 2.3768e-01, PNorm = 44.8708, GNorm = 5.7585, lr_0 = 3.4454e-04
Loss = 1.7119e-01, PNorm = 44.8782, GNorm = 7.2544, lr_0 = 3.3856e-04
Validation rmse = 0.738597
Epoch 15
Loss = 2.3593e-01, PNorm = 44.8854, GNorm = 8.2973, lr_0 = 3.3269e-04
Loss = 1.7369e-01, PNorm = 44.9043, GNorm = 3.5044, lr_0 = 3.2692e-04
Loss = 1.7232e-01, PNorm = 44.9153, GNorm = 2.5724, lr_0 = 3.2125e-04
Loss = 1.2459e-01, PNorm = 44.9290, GNorm = 4.0114, lr_0 = 3.1567e-04
Loss = 9.6582e-02, PNorm = 44.9403, GNorm = 3.6150, lr_0 = 3.1020e-04
Validation rmse = 0.791566
Epoch 16
Loss = 2.0080e-01, PNorm = 44.9432, GNorm = 3.4531, lr_0 = 3.0429e-04
Loss = 2.8327e-01, PNorm = 44.9540, GNorm = 4.0598, lr_0 = 2.9901e-04
Loss = 1.3743e-01, PNorm = 44.9641, GNorm = 3.1397, lr_0 = 2.9382e-04
Loss = 3.5827e-02, PNorm = 44.9796, GNorm = 3.5568, lr_0 = 2.8873e-04
Loss = 1.8881e-01, PNorm = 44.9885, GNorm = 9.4650, lr_0 = 2.8372e-04
Validation rmse = 0.739237
Epoch 17
Loss = 1.0941e-01, PNorm = 44.9967, GNorm = 4.9411, lr_0 = 2.7831e-04
Loss = 1.1059e-01, PNorm = 45.0055, GNorm = 3.1352, lr_0 = 2.7348e-04
Loss = 1.3537e-01, PNorm = 45.0164, GNorm = 3.5040, lr_0 = 2.6874e-04
Loss = 1.0881e-01, PNorm = 45.0238, GNorm = 4.1002, lr_0 = 2.6408e-04
Validation rmse = 0.777399
Epoch 18
Loss = 2.6780e-01, PNorm = 45.0315, GNorm = 10.1122, lr_0 = 2.5904e-04
Loss = 1.2295e-01, PNorm = 45.0421, GNorm = 2.9831, lr_0 = 2.5455e-04
Loss = 1.4021e-01, PNorm = 45.0531, GNorm = 4.2499, lr_0 = 2.5014e-04
Loss = 1.0030e-01, PNorm = 45.0577, GNorm = 13.2408, lr_0 = 2.4580e-04
Loss = 1.4119e-01, PNorm = 45.0608, GNorm = 4.6568, lr_0 = 2.4153e-04
Validation rmse = 0.740033
Epoch 19
Loss = -6.7144e-02, PNorm = 45.0727, GNorm = 3.4725, lr_0 = 2.3693e-04
Loss = 4.7832e-02, PNorm = 45.0836, GNorm = 8.8502, lr_0 = 2.3282e-04
Loss = 1.3856e-01, PNorm = 45.0879, GNorm = 4.5464, lr_0 = 2.2878e-04
Loss = 1.9506e-01, PNorm = 45.0941, GNorm = 7.2038, lr_0 = 2.2481e-04
Loss = 1.2290e-01, PNorm = 45.1024, GNorm = 8.3127, lr_0 = 2.2091e-04
Validation rmse = 0.730738
Epoch 20
Loss = 5.8267e-02, PNorm = 45.1146, GNorm = 6.8134, lr_0 = 2.1708e-04
Loss = 1.1326e-01, PNorm = 45.1173, GNorm = 8.5982, lr_0 = 2.1332e-04
Loss = 5.6157e-02, PNorm = 45.1249, GNorm = 4.1150, lr_0 = 2.0962e-04
Loss = 1.5698e-01, PNorm = 45.1327, GNorm = 3.1028, lr_0 = 2.0598e-04
Loss = 1.2209e-01, PNorm = 45.1410, GNorm = 5.6151, lr_0 = 2.0241e-04
Validation rmse = 0.761570
Epoch 21
Loss = 1.1017e-01, PNorm = 45.1497, GNorm = 5.7411, lr_0 = 1.9855e-04
Loss = 4.1909e-02, PNorm = 45.1566, GNorm = 4.5604, lr_0 = 1.9511e-04
Loss = 6.7421e-03, PNorm = 45.1637, GNorm = 3.7158, lr_0 = 1.9172e-04
Loss = 1.2935e-01, PNorm = 45.1670, GNorm = 7.2906, lr_0 = 1.8840e-04
Validation rmse = 0.723529
Epoch 22
Loss = 3.5086e-02, PNorm = 45.1699, GNorm = 10.0034, lr_0 = 1.8481e-04
Loss = 2.3084e-01, PNorm = 45.1746, GNorm = 10.5465, lr_0 = 1.8160e-04
Loss = 1.1961e-01, PNorm = 45.1822, GNorm = 3.9579, lr_0 = 1.7845e-04
Loss = 3.0724e-02, PNorm = 45.1909, GNorm = 6.7925, lr_0 = 1.7536e-04
Loss = 2.8836e-02, PNorm = 45.1944, GNorm = 5.2506, lr_0 = 1.7231e-04
Validation rmse = 0.755562
Epoch 23
Loss = 6.9263e-02, PNorm = 45.2006, GNorm = 7.9678, lr_0 = 1.6903e-04
Loss = 4.4107e-02, PNorm = 45.2085, GNorm = 3.8988, lr_0 = 1.6610e-04
Loss = 4.0735e-02, PNorm = 45.2115, GNorm = 5.4629, lr_0 = 1.6322e-04
Loss = 2.8234e-03, PNorm = 45.2173, GNorm = 3.9057, lr_0 = 1.6039e-04
Loss = 1.2648e-01, PNorm = 45.2242, GNorm = 5.3231, lr_0 = 1.5760e-04
Validation rmse = 0.717423
Epoch 24
Loss = -5.4818e-02, PNorm = 45.2313, GNorm = 4.0502, lr_0 = 1.5460e-04
Loss = 6.7192e-02, PNorm = 45.2371, GNorm = 9.8503, lr_0 = 1.5192e-04
Loss = 4.6952e-02, PNorm = 45.2435, GNorm = 7.7767, lr_0 = 1.4928e-04
Loss = 2.3034e-02, PNorm = 45.2487, GNorm = 6.4802, lr_0 = 1.4669e-04
Loss = 8.0417e-02, PNorm = 45.2515, GNorm = 14.2455, lr_0 = 1.4415e-04
Validation rmse = 0.718708
Epoch 25
Loss = 5.2825e-02, PNorm = 45.2572, GNorm = 3.6860, lr_0 = 1.4165e-04
Loss = 3.1069e-02, PNorm = 45.2617, GNorm = 7.8777, lr_0 = 1.3919e-04
Loss = -1.4607e-02, PNorm = 45.2670, GNorm = 6.7241, lr_0 = 1.3678e-04
Loss = 1.0456e-01, PNorm = 45.2697, GNorm = 5.8075, lr_0 = 1.3441e-04
Validation rmse = 0.710939
Epoch 26
Loss = -8.2346e-02, PNorm = 45.2751, GNorm = 6.5358, lr_0 = 1.3184e-04
Loss = 3.2978e-04, PNorm = 45.2801, GNorm = 4.4769, lr_0 = 1.2956e-04
Loss = 3.6182e-02, PNorm = 45.2837, GNorm = 4.9299, lr_0 = 1.2731e-04
Loss = 1.4303e-02, PNorm = 45.2891, GNorm = 3.7918, lr_0 = 1.2510e-04
Loss = -2.5087e-02, PNorm = 45.2929, GNorm = 5.5672, lr_0 = 1.2293e-04
Validation rmse = 0.702942
Epoch 27
Loss = -1.9171e-02, PNorm = 45.2990, GNorm = 4.4376, lr_0 = 1.2059e-04
Loss = -1.3651e-01, PNorm = 45.3039, GNorm = 6.4578, lr_0 = 1.1850e-04
Loss = 6.8408e-02, PNorm = 45.3079, GNorm = 10.4365, lr_0 = 1.1644e-04
Loss = 3.3669e-02, PNorm = 45.3118, GNorm = 6.4657, lr_0 = 1.1442e-04
Loss = 5.1754e-02, PNorm = 45.3142, GNorm = 4.7356, lr_0 = 1.1244e-04
Validation rmse = 0.711911
Epoch 28
Loss = 4.6115e-02, PNorm = 45.3183, GNorm = 5.5581, lr_0 = 1.1029e-04
Loss = 2.6297e-02, PNorm = 45.3220, GNorm = 7.2296, lr_0 = 1.0838e-04
Loss = 2.2590e-02, PNorm = 45.3268, GNorm = 5.2830, lr_0 = 1.0650e-04
Loss = -6.5644e-02, PNorm = 45.3316, GNorm = 3.4354, lr_0 = 1.0465e-04
Validation rmse = 0.727009
Epoch 29
Loss = -1.8013e-01, PNorm = 45.3350, GNorm = 3.5161, lr_0 = 1.0266e-04
Loss = -2.5683e-02, PNorm = 45.3366, GNorm = 11.6007, lr_0 = 1.0088e-04
Loss = 1.3391e-03, PNorm = 45.3414, GNorm = 7.5996, lr_0 = 1.0000e-04
Loss = -2.2357e-03, PNorm = 45.3455, GNorm = 6.7256, lr_0 = 1.0000e-04
Loss = -1.4944e-02, PNorm = 45.3493, GNorm = 10.2766, lr_0 = 1.0000e-04
Validation rmse = 0.706230
Model 0 best validation rmse = 0.702942 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.597418
Ensemble test rmse = 0.597418
1-fold cross validation
	Seed 0 ==> test rmse = 0.597418
Overall test rmse = 0.597418 +/- 0.000000
Elapsed time = 0:01:58
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1012e+00, PNorm = 43.3116, GNorm = 5.6105, lr_0 = 2.0312e-04
Loss = 1.4312e+00, PNorm = 43.3124, GNorm = 2.0843, lr_0 = 2.9687e-04
Loss = 1.4428e+00, PNorm = 43.3174, GNorm = 2.0689, lr_0 = 3.9062e-04
Loss = 1.3417e+00, PNorm = 43.3272, GNorm = 1.3149, lr_0 = 4.8437e-04
Validation rmse = 1.559192
Epoch 1
Loss = 1.2753e+00, PNorm = 43.3453, GNorm = 1.3712, lr_0 = 5.7812e-04
Loss = 1.1198e+00, PNorm = 43.3732, GNorm = 2.9473, lr_0 = 6.7187e-04
Loss = 1.1430e+00, PNorm = 43.4133, GNorm = 1.6047, lr_0 = 7.6563e-04
Loss = 9.2169e-01, PNorm = 43.4744, GNorm = 12.3733, lr_0 = 8.5938e-04
Loss = 8.8590e-01, PNorm = 43.5286, GNorm = 5.0637, lr_0 = 9.5312e-04
Validation rmse = 1.017539
Epoch 2
Loss = 7.6415e-01, PNorm = 43.5810, GNorm = 3.6770, lr_0 = 9.9147e-04
Loss = 7.6210e-01, PNorm = 43.6283, GNorm = 4.1862, lr_0 = 9.7463e-04
Loss = 7.9568e-01, PNorm = 43.6868, GNorm = 8.2680, lr_0 = 9.5807e-04
Loss = 7.4951e-01, PNorm = 43.7268, GNorm = 2.5013, lr_0 = 9.4180e-04
Loss = 5.5534e-01, PNorm = 43.7856, GNorm = 4.3649, lr_0 = 9.2580e-04
Validation rmse = 1.141927
Epoch 3
Loss = 8.1724e-01, PNorm = 43.8108, GNorm = 4.4757, lr_0 = 9.1008e-04
Loss = 7.7181e-01, PNorm = 43.8540, GNorm = 4.3481, lr_0 = 8.9462e-04
Loss = 5.3328e-01, PNorm = 43.9060, GNorm = 5.6286, lr_0 = 8.7942e-04
Loss = 7.2836e-01, PNorm = 43.9454, GNorm = 2.9168, lr_0 = 8.6448e-04
Loss = 7.0254e-01, PNorm = 43.9766, GNorm = 3.6620, lr_0 = 8.4980e-04
Validation rmse = 0.891314
Epoch 4
Loss = 5.4090e-01, PNorm = 44.0130, GNorm = 2.9260, lr_0 = 8.3536e-04
Loss = 5.3688e-01, PNorm = 44.0520, GNorm = 3.4313, lr_0 = 8.2117e-04
Loss = 5.5518e-01, PNorm = 44.0681, GNorm = 5.9519, lr_0 = 8.0722e-04
Loss = 5.0278e-01, PNorm = 44.1019, GNorm = 6.1792, lr_0 = 7.9351e-04
Loss = 6.0135e-01, PNorm = 44.1229, GNorm = 4.4745, lr_0 = 7.8003e-04
Validation rmse = 0.903645
Epoch 5
Loss = 4.7884e-01, PNorm = 44.1571, GNorm = 2.9454, lr_0 = 7.6678e-04
Loss = 5.4802e-01, PNorm = 44.1856, GNorm = 8.4114, lr_0 = 7.5376e-04
Loss = 5.4684e-01, PNorm = 44.2090, GNorm = 6.6575, lr_0 = 7.4095e-04
Loss = 4.8932e-01, PNorm = 44.2339, GNorm = 8.3936, lr_0 = 7.2837e-04
Validation rmse = 0.980801
Epoch 6
Loss = 5.4277e-01, PNorm = 44.2612, GNorm = 8.7264, lr_0 = 7.1600e-04
Loss = 4.2428e-01, PNorm = 44.2882, GNorm = 2.3484, lr_0 = 7.0383e-04
Loss = 3.9802e-01, PNorm = 44.3187, GNorm = 2.3242, lr_0 = 6.9188e-04
Loss = 4.2124e-01, PNorm = 44.3306, GNorm = 5.9780, lr_0 = 6.8013e-04
Loss = 5.3870e-01, PNorm = 44.3440, GNorm = 3.4971, lr_0 = 6.6857e-04
Validation rmse = 0.846367
Epoch 7
Loss = 4.1107e-01, PNorm = 44.3630, GNorm = 2.1433, lr_0 = 6.5722e-04
Loss = 3.3918e-01, PNorm = 44.3918, GNorm = 7.0813, lr_0 = 6.4605e-04
Loss = 4.4525e-01, PNorm = 44.4131, GNorm = 2.7416, lr_0 = 6.3508e-04
Loss = 4.8834e-01, PNorm = 44.4336, GNorm = 2.8213, lr_0 = 6.2429e-04
Loss = 3.2941e-01, PNorm = 44.4572, GNorm = 4.2209, lr_0 = 6.1369e-04
Validation rmse = 0.774646
Epoch 8
Loss = 3.7306e-01, PNorm = 44.4817, GNorm = 4.1597, lr_0 = 6.0326e-04
Loss = 3.0307e-01, PNorm = 44.5056, GNorm = 4.9170, lr_0 = 5.9301e-04
Loss = 3.5271e-01, PNorm = 44.5202, GNorm = 5.8459, lr_0 = 5.8294e-04
Loss = 3.5815e-01, PNorm = 44.5354, GNorm = 3.1496, lr_0 = 5.7304e-04
Loss = 4.3768e-01, PNorm = 44.5536, GNorm = 7.6392, lr_0 = 5.6331e-04
Validation rmse = 0.776473
Epoch 9
Loss = 3.4391e-01, PNorm = 44.5668, GNorm = 7.6086, lr_0 = 5.5374e-04
Loss = 2.5041e-01, PNorm = 44.5863, GNorm = 9.9173, lr_0 = 5.4433e-04
Loss = 3.3372e-01, PNorm = 44.6049, GNorm = 3.1751, lr_0 = 5.3508e-04
Loss = 3.1149e-01, PNorm = 44.6173, GNorm = 2.5865, lr_0 = 5.2600e-04
Loss = 3.3362e-01, PNorm = 44.6322, GNorm = 8.5029, lr_0 = 5.1706e-04
Validation rmse = 0.767817
Epoch 10
Loss = 2.3806e-01, PNorm = 44.6519, GNorm = 2.7312, lr_0 = 5.0828e-04
Loss = 2.4849e-01, PNorm = 44.6679, GNorm = 12.1544, lr_0 = 4.9964e-04
Loss = 4.0120e-01, PNorm = 44.6794, GNorm = 2.1749, lr_0 = 4.9116e-04
Loss = 2.9974e-01, PNorm = 44.6964, GNorm = 2.3350, lr_0 = 4.8281e-04
Validation rmse = 0.782649
Epoch 11
Loss = 2.5265e-01, PNorm = 44.7126, GNorm = 7.0067, lr_0 = 4.7461e-04
Loss = 2.4910e-01, PNorm = 44.7304, GNorm = 3.5067, lr_0 = 4.6655e-04
Loss = 1.9960e-01, PNorm = 44.7535, GNorm = 3.7281, lr_0 = 4.5863e-04
Loss = 2.5979e-01, PNorm = 44.7692, GNorm = 3.0269, lr_0 = 4.5084e-04
Loss = 3.1884e-01, PNorm = 44.7801, GNorm = 3.2298, lr_0 = 4.4318e-04
Validation rmse = 0.782633
Epoch 12
Loss = 2.0573e-01, PNorm = 44.7891, GNorm = 4.8066, lr_0 = 4.3565e-04
Loss = 1.5953e-01, PNorm = 44.8075, GNorm = 4.7712, lr_0 = 4.2825e-04
Loss = 2.7091e-01, PNorm = 44.8226, GNorm = 9.1888, lr_0 = 4.2097e-04
Loss = 2.9230e-01, PNorm = 44.8352, GNorm = 7.3261, lr_0 = 4.1382e-04
Loss = 2.3519e-01, PNorm = 44.8486, GNorm = 2.5884, lr_0 = 4.0679e-04
Validation rmse = 0.746316
Epoch 13
Loss = 1.8189e-01, PNorm = 44.8649, GNorm = 4.9123, lr_0 = 3.9988e-04
Loss = 1.5668e-01, PNorm = 44.8741, GNorm = 4.3296, lr_0 = 3.9309e-04
Loss = 2.0356e-01, PNorm = 44.8863, GNorm = 4.7021, lr_0 = 3.8641e-04
Loss = 1.7085e-01, PNorm = 44.8970, GNorm = 3.0063, lr_0 = 3.7985e-04
Loss = 3.1832e-01, PNorm = 44.9112, GNorm = 9.0172, lr_0 = 3.7340e-04
Validation rmse = 0.762533
Epoch 14
Loss = 1.5735e-01, PNorm = 44.9227, GNorm = 3.7064, lr_0 = 3.6706e-04
Loss = 1.5359e-01, PNorm = 44.9393, GNorm = 3.6286, lr_0 = 3.6082e-04
Loss = 1.8326e-01, PNorm = 44.9540, GNorm = 7.5435, lr_0 = 3.5469e-04
Loss = 1.9804e-01, PNorm = 44.9660, GNorm = 6.0205, lr_0 = 3.4867e-04
Loss = 2.6704e-01, PNorm = 44.9721, GNorm = 2.7268, lr_0 = 3.4274e-04
Validation rmse = 0.734804
Epoch 15
Loss = 1.9365e-01, PNorm = 44.9859, GNorm = 3.3476, lr_0 = 3.3692e-04
Loss = 1.3375e-01, PNorm = 44.9996, GNorm = 5.3234, lr_0 = 3.3120e-04
Loss = 1.3423e-01, PNorm = 45.0151, GNorm = 11.9107, lr_0 = 3.2557e-04
Loss = 1.9281e-01, PNorm = 45.0235, GNorm = 3.9930, lr_0 = 3.2004e-04
Validation rmse = 0.734927
Epoch 16
Loss = -4.4990e-02, PNorm = 45.0304, GNorm = 2.4309, lr_0 = 3.1461e-04
Loss = 7.7105e-02, PNorm = 45.0460, GNorm = 4.1248, lr_0 = 3.0926e-04
Loss = 1.6282e-01, PNorm = 45.0566, GNorm = 21.4076, lr_0 = 3.0401e-04
Loss = 1.5687e-01, PNorm = 45.0592, GNorm = 7.2875, lr_0 = 2.9885e-04
Loss = 1.8733e-01, PNorm = 45.0686, GNorm = 4.6415, lr_0 = 2.9377e-04
Validation rmse = 0.719825
Epoch 17
Loss = 1.9887e-01, PNorm = 45.0792, GNorm = 8.6779, lr_0 = 2.8878e-04
Loss = 1.4320e-01, PNorm = 45.0932, GNorm = 4.2875, lr_0 = 2.8387e-04
Loss = 1.0195e-01, PNorm = 45.1042, GNorm = 3.8616, lr_0 = 2.7905e-04
Loss = 7.1677e-02, PNorm = 45.1128, GNorm = 6.6377, lr_0 = 2.7431e-04
Loss = 1.4464e-01, PNorm = 45.1166, GNorm = 6.8024, lr_0 = 2.6965e-04
Validation rmse = 0.741301
Epoch 18
Loss = 2.1122e-02, PNorm = 45.1235, GNorm = 4.1199, lr_0 = 2.6507e-04
Loss = 1.0108e-01, PNorm = 45.1331, GNorm = 5.6871, lr_0 = 2.6057e-04
Loss = 1.2964e-01, PNorm = 45.1401, GNorm = 6.1716, lr_0 = 2.5614e-04
Loss = 1.1126e-01, PNorm = 45.1506, GNorm = 3.6777, lr_0 = 2.5179e-04
Loss = 1.9189e-01, PNorm = 45.1590, GNorm = 6.5867, lr_0 = 2.4751e-04
Validation rmse = 0.760419
Epoch 19
Loss = 6.7631e-02, PNorm = 45.1695, GNorm = 3.7198, lr_0 = 2.4331e-04
Loss = 2.8343e-02, PNorm = 45.1803, GNorm = 7.1287, lr_0 = 2.3918e-04
Loss = 1.7751e-01, PNorm = 45.1851, GNorm = 5.4805, lr_0 = 2.3511e-04
Loss = 1.9381e-02, PNorm = 45.1892, GNorm = 3.9727, lr_0 = 2.3112e-04
Loss = 2.0932e-01, PNorm = 45.1925, GNorm = 3.5512, lr_0 = 2.2720e-04
Validation rmse = 0.723015
Epoch 20
Loss = 3.2097e-02, PNorm = 45.2037, GNorm = 3.5970, lr_0 = 2.2334e-04
Loss = 4.5475e-02, PNorm = 45.2143, GNorm = 3.1284, lr_0 = 2.1954e-04
Loss = 1.2148e-01, PNorm = 45.2163, GNorm = 6.1208, lr_0 = 2.1581e-04
Loss = 1.3224e-01, PNorm = 45.2237, GNorm = 7.9322, lr_0 = 2.1215e-04
Validation rmse = 0.734711
Epoch 21
Loss = 1.5196e-01, PNorm = 45.2312, GNorm = 7.7976, lr_0 = 2.0854e-04
Loss = 1.3858e-01, PNorm = 45.2372, GNorm = 4.0188, lr_0 = 2.0500e-04
Loss = 3.6119e-02, PNorm = 45.2459, GNorm = 10.7048, lr_0 = 2.0152e-04
Loss = -1.2380e-02, PNorm = 45.2550, GNorm = 14.3060, lr_0 = 1.9810e-04
Loss = 1.2790e-01, PNorm = 45.2594, GNorm = 3.9220, lr_0 = 1.9473e-04
Validation rmse = 0.722244
Epoch 22
Loss = 5.3129e-02, PNorm = 45.2646, GNorm = 5.6528, lr_0 = 1.9142e-04
Loss = 1.2519e-01, PNorm = 45.2729, GNorm = 6.2231, lr_0 = 1.8817e-04
Loss = -1.0067e-02, PNorm = 45.2795, GNorm = 4.8864, lr_0 = 1.8498e-04
Loss = 6.8067e-02, PNorm = 45.2848, GNorm = 4.0540, lr_0 = 1.8183e-04
Loss = 4.2314e-02, PNorm = 45.2921, GNorm = 7.4985, lr_0 = 1.7874e-04
Validation rmse = 0.715217
Epoch 23
Loss = 2.1706e-02, PNorm = 45.3000, GNorm = 4.3330, lr_0 = 1.7571e-04
Loss = -2.8010e-02, PNorm = 45.3061, GNorm = 11.5095, lr_0 = 1.7272e-04
Loss = 9.2584e-02, PNorm = 45.3085, GNorm = 6.4658, lr_0 = 1.6979e-04
Loss = 1.0991e-01, PNorm = 45.3158, GNorm = 4.4813, lr_0 = 1.6691e-04
Loss = 8.8618e-03, PNorm = 45.3211, GNorm = 4.7724, lr_0 = 1.6407e-04
Validation rmse = 0.702986
Epoch 24
Loss = -8.0297e-02, PNorm = 45.3273, GNorm = 6.7256, lr_0 = 1.6128e-04
Loss = -3.8609e-02, PNorm = 45.3351, GNorm = 7.0652, lr_0 = 1.5854e-04
Loss = 1.4327e-01, PNorm = 45.3370, GNorm = 20.0653, lr_0 = 1.5585e-04
Loss = 2.7979e-02, PNorm = 45.3430, GNorm = 11.2819, lr_0 = 1.5320e-04
Loss = 6.2456e-02, PNorm = 45.3480, GNorm = 3.5316, lr_0 = 1.5060e-04
Validation rmse = 0.701925
Epoch 25
Loss = 1.8800e-02, PNorm = 45.3529, GNorm = 6.9572, lr_0 = 1.4804e-04
Loss = -6.0789e-02, PNorm = 45.3593, GNorm = 10.0539, lr_0 = 1.4553e-04
Loss = 6.3015e-02, PNorm = 45.3638, GNorm = 11.2561, lr_0 = 1.4306e-04
Loss = 7.9753e-02, PNorm = 45.3668, GNorm = 4.6365, lr_0 = 1.4063e-04
Validation rmse = 0.704319
Epoch 26
Loss = 3.0390e-02, PNorm = 45.3727, GNorm = 3.3061, lr_0 = 1.3824e-04
Loss = 1.1930e-02, PNorm = 45.3793, GNorm = 13.6239, lr_0 = 1.3589e-04
Loss = -1.3670e-01, PNorm = 45.3858, GNorm = 8.8026, lr_0 = 1.3358e-04
Loss = 6.7884e-02, PNorm = 45.3889, GNorm = 3.9331, lr_0 = 1.3131e-04
Loss = 2.8371e-03, PNorm = 45.3920, GNorm = 4.4296, lr_0 = 1.2908e-04
Validation rmse = 0.711705
Epoch 27
Loss = -8.6303e-02, PNorm = 45.3946, GNorm = 7.1903, lr_0 = 1.2689e-04
Loss = 2.5273e-02, PNorm = 45.4014, GNorm = 7.1501, lr_0 = 1.2473e-04
Loss = -4.4088e-02, PNorm = 45.4051, GNorm = 10.4770, lr_0 = 1.2261e-04
Loss = -6.1554e-02, PNorm = 45.4097, GNorm = 4.0743, lr_0 = 1.2053e-04
Loss = -5.8037e-03, PNorm = 45.4142, GNorm = 11.9755, lr_0 = 1.1848e-04
Validation rmse = 0.692322
Epoch 28
Loss = 2.8967e-02, PNorm = 45.4150, GNorm = 13.2709, lr_0 = 1.1647e-04
Loss = 3.0663e-02, PNorm = 45.4182, GNorm = 3.5804, lr_0 = 1.1449e-04
Loss = -1.6165e-02, PNorm = 45.4239, GNorm = 4.3698, lr_0 = 1.1255e-04
Loss = -8.3205e-02, PNorm = 45.4290, GNorm = 5.6827, lr_0 = 1.1064e-04
Loss = 9.3644e-03, PNorm = 45.4330, GNorm = 10.3903, lr_0 = 1.0876e-04
Validation rmse = 0.688762
Epoch 29
Loss = -2.4558e-02, PNorm = 45.4374, GNorm = 8.0480, lr_0 = 1.0691e-04
Loss = -5.3463e-03, PNorm = 45.4425, GNorm = 9.5617, lr_0 = 1.0509e-04
Loss = 8.6446e-03, PNorm = 45.4459, GNorm = 4.4221, lr_0 = 1.0331e-04
Loss = -7.4413e-02, PNorm = 45.4490, GNorm = 6.2176, lr_0 = 1.0155e-04
Loss = -4.7989e-02, PNorm = 45.4532, GNorm = 9.4391, lr_0 = 1.0000e-04
Validation rmse = 0.682003
Model 0 best validation rmse = 0.682003 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.603131
Ensemble test rmse = 0.603131
1-fold cross validation
	Seed 0 ==> test rmse = 0.603131
Overall test rmse = 0.603131 +/- 0.000000
Elapsed time = 0:01:59
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6782e+00, PNorm = 43.3109, GNorm = 3.1329, lr_0 = 2.5469e-04
Loss = 1.5197e+00, PNorm = 43.3113, GNorm = 1.6780, lr_0 = 3.9531e-04
Loss = 1.4327e+00, PNorm = 43.3165, GNorm = 0.9825, lr_0 = 5.3594e-04
Validation rmse = 1.331564
Epoch 1
Loss = 1.3036e+00, PNorm = 43.3276, GNorm = 2.7904, lr_0 = 6.7656e-04
Loss = 1.4208e+00, PNorm = 43.3467, GNorm = 1.0540, lr_0 = 8.1719e-04
Loss = 1.2542e+00, PNorm = 43.3797, GNorm = 0.7650, lr_0 = 9.5781e-04
Validation rmse = 1.123993
Epoch 2
Loss = 1.1751e+00, PNorm = 43.4305, GNorm = 2.7851, lr_0 = 9.8217e-04
Loss = 1.2065e+00, PNorm = 43.4811, GNorm = 1.4766, lr_0 = 9.5725e-04
Loss = 1.1420e+00, PNorm = 43.5412, GNorm = 3.4413, lr_0 = 9.3297e-04
Validation rmse = 1.038159
Epoch 3
Loss = 1.0054e+00, PNorm = 43.5983, GNorm = 1.1890, lr_0 = 9.0930e-04
Loss = 9.5838e-01, PNorm = 43.6510, GNorm = 3.7347, lr_0 = 8.8623e-04
Loss = 9.0440e-01, PNorm = 43.7011, GNorm = 2.8549, lr_0 = 8.6374e-04
Validation rmse = 0.969518
Epoch 4
Loss = 8.4110e-01, PNorm = 43.7520, GNorm = 2.7887, lr_0 = 8.4183e-04
Loss = 8.7339e-01, PNorm = 43.7951, GNorm = 10.7740, lr_0 = 8.2047e-04
Loss = 8.6420e-01, PNorm = 43.8332, GNorm = 6.1645, lr_0 = 7.9965e-04
Loss = 7.8718e-01, PNorm = 43.8795, GNorm = 4.9492, lr_0 = 7.7937e-04
Validation rmse = 0.914465
Epoch 5
Loss = 7.0136e-01, PNorm = 43.9181, GNorm = 2.0944, lr_0 = 7.5959e-04
Loss = 7.5847e-01, PNorm = 43.9452, GNorm = 2.4513, lr_0 = 7.4032e-04
Loss = 7.5458e-01, PNorm = 43.9812, GNorm = 6.5364, lr_0 = 7.2154e-04
Validation rmse = 0.909270
Epoch 6
Loss = 6.9659e-01, PNorm = 44.0225, GNorm = 2.8922, lr_0 = 7.0323e-04
Loss = 6.9486e-01, PNorm = 44.0601, GNorm = 8.8148, lr_0 = 6.8539e-04
Loss = 8.3713e-01, PNorm = 44.0884, GNorm = 4.1122, lr_0 = 6.6800e-04
Validation rmse = 0.859970
Epoch 7
Loss = 8.1894e-01, PNorm = 44.1125, GNorm = 1.9268, lr_0 = 6.5105e-04
Loss = 7.8960e-01, PNorm = 44.1448, GNorm = 6.9240, lr_0 = 6.3453e-04
Loss = 6.0544e-01, PNorm = 44.1785, GNorm = 2.3845, lr_0 = 6.1844e-04
Validation rmse = 0.879540
Epoch 8
Loss = 5.9013e-01, PNorm = 44.2038, GNorm = 9.5504, lr_0 = 6.0275e-04
Loss = 6.5773e-01, PNorm = 44.2215, GNorm = 2.6752, lr_0 = 5.8745e-04
Loss = 6.2741e-01, PNorm = 44.2464, GNorm = 8.1527, lr_0 = 5.7255e-04
Validation rmse = 0.947457
Epoch 9
Loss = 4.4505e-01, PNorm = 44.2771, GNorm = 6.2599, lr_0 = 5.5802e-04
Loss = 6.8142e-01, PNorm = 44.2898, GNorm = 2.3919, lr_0 = 5.4386e-04
Loss = 7.0948e-01, PNorm = 44.3059, GNorm = 9.4329, lr_0 = 5.3007e-04
Loss = 6.3635e-01, PNorm = 44.3302, GNorm = 6.2047, lr_0 = 5.1662e-04
Validation rmse = 0.885113
Epoch 10
Loss = 5.7376e-01, PNorm = 44.3564, GNorm = 10.7409, lr_0 = 5.0351e-04
Loss = 4.6964e-01, PNorm = 44.3831, GNorm = 6.7700, lr_0 = 4.9074e-04
Loss = 6.0157e-01, PNorm = 44.3969, GNorm = 4.6707, lr_0 = 4.7829e-04
Validation rmse = 0.907597
Epoch 11
Loss = 4.9223e-01, PNorm = 44.4102, GNorm = 3.3136, lr_0 = 4.6615e-04
Loss = 5.6109e-01, PNorm = 44.4359, GNorm = 5.5463, lr_0 = 4.5432e-04
Loss = 5.0915e-01, PNorm = 44.4494, GNorm = 2.8695, lr_0 = 4.4280e-04
Validation rmse = 0.852511
Epoch 12
Loss = 4.2420e-01, PNorm = 44.4647, GNorm = 6.1196, lr_0 = 4.3156e-04
Loss = 4.5197e-01, PNorm = 44.4825, GNorm = 4.8884, lr_0 = 4.2061e-04
Loss = 5.1979e-01, PNorm = 44.5029, GNorm = 5.7204, lr_0 = 4.0994e-04
Validation rmse = 0.821784
Epoch 13
Loss = 4.2952e-01, PNorm = 44.5152, GNorm = 3.2893, lr_0 = 3.9954e-04
Loss = 5.0208e-01, PNorm = 44.5347, GNorm = 6.0688, lr_0 = 3.8941e-04
Loss = 4.1321e-01, PNorm = 44.5544, GNorm = 9.4210, lr_0 = 3.7953e-04
Validation rmse = 0.844541
Epoch 14
Loss = 4.4897e-01, PNorm = 44.5669, GNorm = 4.8739, lr_0 = 3.6990e-04
Loss = 4.9113e-01, PNorm = 44.5747, GNorm = 4.6848, lr_0 = 3.6051e-04
Loss = 3.5110e-01, PNorm = 44.5880, GNorm = 3.5377, lr_0 = 3.5137e-04
Loss = 4.6376e-01, PNorm = 44.6063, GNorm = 11.7889, lr_0 = 3.4245e-04
Validation rmse = 0.838207
Epoch 15
Loss = 3.7716e-01, PNorm = 44.6222, GNorm = 6.9901, lr_0 = 3.3376e-04
Loss = 4.6979e-01, PNorm = 44.6341, GNorm = 5.2823, lr_0 = 3.2529e-04
Loss = 4.4263e-01, PNorm = 44.6457, GNorm = 6.2407, lr_0 = 3.1704e-04
Validation rmse = 0.826655
Epoch 16
Loss = 3.4324e-01, PNorm = 44.6578, GNorm = 5.1360, lr_0 = 3.0900e-04
Loss = 3.7383e-01, PNorm = 44.6708, GNorm = 24.7585, lr_0 = 3.0116e-04
Loss = 4.6927e-01, PNorm = 44.6777, GNorm = 9.3550, lr_0 = 2.9352e-04
Validation rmse = 0.831550
Epoch 17
Loss = 3.8400e-01, PNorm = 44.6854, GNorm = 5.9179, lr_0 = 2.8607e-04
Loss = 3.2448e-01, PNorm = 44.6977, GNorm = 4.8647, lr_0 = 2.7881e-04
Loss = 5.0311e-01, PNorm = 44.7115, GNorm = 14.9219, lr_0 = 2.7174e-04
Validation rmse = 0.834997
Epoch 18
Loss = 3.6345e-01, PNorm = 44.7195, GNorm = 11.1659, lr_0 = 2.6484e-04
Loss = 4.1722e-01, PNorm = 44.7300, GNorm = 7.7481, lr_0 = 2.5813e-04
Loss = 4.1212e-01, PNorm = 44.7417, GNorm = 11.4878, lr_0 = 2.5158e-04
Validation rmse = 0.827398
Epoch 19
Loss = 4.4845e-01, PNorm = 44.7508, GNorm = 7.6833, lr_0 = 2.4519e-04
Loss = 3.5685e-01, PNorm = 44.7618, GNorm = 4.2046, lr_0 = 2.3897e-04
Loss = 3.0664e-01, PNorm = 44.7729, GNorm = 6.3176, lr_0 = 2.3291e-04
Loss = 4.3281e-01, PNorm = 44.7798, GNorm = 5.0695, lr_0 = 2.2700e-04
Validation rmse = 0.855865
Epoch 20
Loss = 3.1507e-01, PNorm = 44.7869, GNorm = 3.9577, lr_0 = 2.2124e-04
Loss = 2.9729e-01, PNorm = 44.7963, GNorm = 6.7005, lr_0 = 2.1563e-04
Loss = 4.0902e-01, PNorm = 44.8061, GNorm = 6.6022, lr_0 = 2.1016e-04
Validation rmse = 0.822200
Epoch 21
Loss = 2.9087e-01, PNorm = 44.8168, GNorm = 6.0704, lr_0 = 2.0483e-04
Loss = 3.1159e-01, PNorm = 44.8225, GNorm = 4.7375, lr_0 = 1.9963e-04
Loss = 3.5570e-01, PNorm = 44.8277, GNorm = 4.1948, lr_0 = 1.9456e-04
Validation rmse = 0.843443
Epoch 22
Loss = 3.3759e-01, PNorm = 44.8337, GNorm = 5.7779, lr_0 = 1.8963e-04
Loss = 3.0940e-01, PNorm = 44.8437, GNorm = 5.8897, lr_0 = 1.8482e-04
Loss = 2.8332e-01, PNorm = 44.8509, GNorm = 10.7844, lr_0 = 1.8013e-04
Validation rmse = 0.821376
Epoch 23
Loss = 2.6785e-01, PNorm = 44.8577, GNorm = 4.8036, lr_0 = 1.7556e-04
Loss = 2.6324e-01, PNorm = 44.8668, GNorm = 17.5890, lr_0 = 1.7110e-04
Loss = 2.7988e-01, PNorm = 44.8718, GNorm = 17.2067, lr_0 = 1.6676e-04
Validation rmse = 0.826803
Epoch 24
Loss = 1.0464e-01, PNorm = 44.8754, GNorm = 3.8367, lr_0 = 1.6253e-04
Loss = 2.7031e-01, PNorm = 44.8830, GNorm = 7.0977, lr_0 = 1.5841e-04
Loss = 2.5676e-01, PNorm = 44.8881, GNorm = 3.7220, lr_0 = 1.5439e-04
Loss = 3.0491e-01, PNorm = 44.8935, GNorm = 5.5925, lr_0 = 1.5047e-04
Validation rmse = 0.827031
Epoch 25
Loss = 2.8441e-01, PNorm = 44.8993, GNorm = 6.8537, lr_0 = 1.4665e-04
Loss = 2.5660e-01, PNorm = 44.9058, GNorm = 5.1378, lr_0 = 1.4293e-04
Loss = 2.1713e-01, PNorm = 44.9111, GNorm = 13.7001, lr_0 = 1.3931e-04
Validation rmse = 0.844168
Epoch 26
Loss = 3.2242e-01, PNorm = 44.9167, GNorm = 5.8735, lr_0 = 1.3577e-04
Loss = 2.7124e-01, PNorm = 44.9202, GNorm = 12.8207, lr_0 = 1.3233e-04
Loss = 2.6544e-01, PNorm = 44.9254, GNorm = 18.4430, lr_0 = 1.2897e-04
Validation rmse = 0.807763
Epoch 27
Loss = 2.9089e-01, PNorm = 44.9322, GNorm = 6.2464, lr_0 = 1.2570e-04
Loss = 2.9366e-01, PNorm = 44.9374, GNorm = 15.0618, lr_0 = 1.2251e-04
Loss = 1.9003e-01, PNorm = 44.9402, GNorm = 5.4202, lr_0 = 1.1940e-04
Validation rmse = 0.817195
Epoch 28
Loss = 3.7617e-01, PNorm = 44.9453, GNorm = 9.2891, lr_0 = 1.1637e-04
Loss = 2.3479e-01, PNorm = 44.9515, GNorm = 5.0130, lr_0 = 1.1342e-04
Loss = 2.1143e-01, PNorm = 44.9557, GNorm = 7.3165, lr_0 = 1.1054e-04
Validation rmse = 0.809075
Epoch 29
Loss = 6.1099e-02, PNorm = 44.9594, GNorm = 5.6039, lr_0 = 1.0774e-04
Loss = 2.1631e-01, PNorm = 44.9631, GNorm = 3.4925, lr_0 = 1.0500e-04
Loss = 2.2174e-01, PNorm = 44.9663, GNorm = 6.4900, lr_0 = 1.0234e-04
Loss = 2.3075e-01, PNorm = 44.9700, GNorm = 6.9996, lr_0 = 1.0000e-04
Validation rmse = 0.811333
Model 0 best validation rmse = 0.807763 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.662219
Ensemble test rmse = 0.662219
1-fold cross validation
	Seed 0 ==> test rmse = 0.662219
Overall test rmse = 0.662219 +/- 0.000000
Elapsed time = 0:01:19
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,025 | train size = 820 | val size = 102 | test size = 103
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7182e+00, PNorm = 43.3108, GNorm = 1.2470, lr_0 = 2.5469e-04
Loss = 1.5007e+00, PNorm = 43.3107, GNorm = 1.6304, lr_0 = 3.9531e-04
Loss = 1.4692e+00, PNorm = 43.3169, GNorm = 1.6862, lr_0 = 5.3594e-04
Validation rmse = 1.307528
Epoch 1
Loss = 1.3441e+00, PNorm = 43.3351, GNorm = 2.4120, lr_0 = 6.9063e-04
Loss = 1.3259e+00, PNorm = 43.3551, GNorm = 1.3097, lr_0 = 8.3125e-04
Loss = 1.2726e+00, PNorm = 43.3880, GNorm = 1.5639, lr_0 = 9.7187e-04
Validation rmse = 1.090384
Epoch 2
Loss = 1.1273e+00, PNorm = 43.4455, GNorm = 3.5000, lr_0 = 9.7965e-04
Loss = 1.0339e+00, PNorm = 43.5050, GNorm = 3.4925, lr_0 = 9.5480e-04
Loss = 1.0428e+00, PNorm = 43.5655, GNorm = 2.3316, lr_0 = 9.3057e-04
Validation rmse = 0.893411
Epoch 3
Loss = 7.7120e-01, PNorm = 43.6208, GNorm = 4.8783, lr_0 = 9.0696e-04
Loss = 9.3866e-01, PNorm = 43.6620, GNorm = 3.3938, lr_0 = 8.8395e-04
Loss = 9.2259e-01, PNorm = 43.7155, GNorm = 6.0997, lr_0 = 8.6152e-04
Loss = 9.2878e-01, PNorm = 43.7580, GNorm = 5.7641, lr_0 = 8.3967e-04
Validation rmse = 0.868781
Epoch 4
Loss = 7.6588e-01, PNorm = 43.7980, GNorm = 7.2955, lr_0 = 8.1836e-04
Loss = 7.6951e-01, PNorm = 43.8343, GNorm = 5.3485, lr_0 = 7.9760e-04
Loss = 8.3617e-01, PNorm = 43.8591, GNorm = 10.1264, lr_0 = 7.7737e-04
Validation rmse = 0.848607
Epoch 5
Loss = 6.7874e-01, PNorm = 43.9011, GNorm = 5.6396, lr_0 = 7.5764e-04
Loss = 6.9678e-01, PNorm = 43.9405, GNorm = 2.4380, lr_0 = 7.3842e-04
Loss = 6.9573e-01, PNorm = 43.9718, GNorm = 2.8730, lr_0 = 7.1969e-04
Validation rmse = 0.903520
Epoch 6
Loss = 6.8308e-01, PNorm = 44.0133, GNorm = 6.1191, lr_0 = 6.9963e-04
Loss = 6.3365e-01, PNorm = 44.0436, GNorm = 2.8894, lr_0 = 6.8188e-04
Loss = 6.1932e-01, PNorm = 44.0646, GNorm = 3.3316, lr_0 = 6.6458e-04
Validation rmse = 0.828509
Epoch 7
Loss = 6.5225e-01, PNorm = 44.0900, GNorm = 5.1333, lr_0 = 6.4771e-04
Loss = 5.9397e-01, PNorm = 44.1071, GNorm = 8.9279, lr_0 = 6.3128e-04
Loss = 5.7590e-01, PNorm = 44.1361, GNorm = 9.3185, lr_0 = 6.1527e-04
Loss = 6.1938e-01, PNorm = 44.1551, GNorm = 3.0454, lr_0 = 5.9966e-04
Validation rmse = 0.816313
Epoch 8
Loss = 6.0623e-01, PNorm = 44.1760, GNorm = 9.8815, lr_0 = 5.8444e-04
Loss = 4.9650e-01, PNorm = 44.1960, GNorm = 3.9191, lr_0 = 5.6961e-04
Loss = 5.4617e-01, PNorm = 44.2165, GNorm = 5.9163, lr_0 = 5.5516e-04
Validation rmse = 0.840254
Epoch 9
Loss = 5.8285e-01, PNorm = 44.2315, GNorm = 10.4013, lr_0 = 5.4108e-04
Loss = 5.3322e-01, PNorm = 44.2478, GNorm = 4.6470, lr_0 = 5.2735e-04
Loss = 4.7093e-01, PNorm = 44.2706, GNorm = 5.7331, lr_0 = 5.1397e-04
Validation rmse = 0.813920
Epoch 10
Loss = 3.1421e-01, PNorm = 44.2901, GNorm = 4.3421, lr_0 = 5.0093e-04
Loss = 5.5638e-01, PNorm = 44.3088, GNorm = 13.7280, lr_0 = 4.8822e-04
Loss = 5.8057e-01, PNorm = 44.3229, GNorm = 11.5141, lr_0 = 4.7583e-04
Loss = 5.0080e-01, PNorm = 44.3406, GNorm = 4.2580, lr_0 = 4.6376e-04
Loss = 5.4490e-01, PNorm = 44.3423, GNorm = 6.8128, lr_0 = 4.6257e-04
Validation rmse = 0.809178
Epoch 11
Loss = 4.9817e-01, PNorm = 44.3623, GNorm = 10.3373, lr_0 = 4.5084e-04
Loss = 4.1616e-01, PNorm = 44.3813, GNorm = 4.0489, lr_0 = 4.3940e-04
Loss = 5.8274e-01, PNorm = 44.3822, GNorm = 3.1032, lr_0 = 4.2825e-04
Validation rmse = 0.848950
Epoch 12
Loss = 5.1677e-01, PNorm = 44.3922, GNorm = 2.2326, lr_0 = 4.1738e-04
Loss = 4.3979e-01, PNorm = 44.4111, GNorm = 4.0647, lr_0 = 4.0679e-04
Loss = 4.9831e-01, PNorm = 44.4213, GNorm = 16.0811, lr_0 = 3.9647e-04
Validation rmse = 0.830773
Epoch 13
Loss = 5.6513e-01, PNorm = 44.4279, GNorm = 5.0677, lr_0 = 3.8641e-04
Loss = 4.9908e-01, PNorm = 44.4449, GNorm = 8.4762, lr_0 = 3.7661e-04
Loss = 4.2662e-01, PNorm = 44.4630, GNorm = 10.4257, lr_0 = 3.6706e-04
Validation rmse = 0.822413
Epoch 14
Loss = 2.1554e-01, PNorm = 44.4772, GNorm = 5.2151, lr_0 = 3.5774e-04
Loss = 4.3955e-01, PNorm = 44.4821, GNorm = 2.2494, lr_0 = 3.4867e-04
Loss = 3.3260e-01, PNorm = 44.4951, GNorm = 5.0272, lr_0 = 3.3982e-04
Loss = 3.7414e-01, PNorm = 44.5058, GNorm = 3.3033, lr_0 = 3.3120e-04
Validation rmse = 0.829129
Epoch 15
Loss = 3.0915e-01, PNorm = 44.5216, GNorm = 17.7772, lr_0 = 3.2280e-04
Loss = 4.6054e-01, PNorm = 44.5277, GNorm = 6.1011, lr_0 = 3.1461e-04
Loss = 3.3723e-01, PNorm = 44.5392, GNorm = 4.6843, lr_0 = 3.0662e-04
Validation rmse = 0.842352
Epoch 16
Loss = 3.4221e-01, PNorm = 44.5527, GNorm = 15.1948, lr_0 = 2.9808e-04
Loss = 3.0463e-01, PNorm = 44.5624, GNorm = 8.7634, lr_0 = 2.9052e-04
Loss = 4.1098e-01, PNorm = 44.5664, GNorm = 4.4922, lr_0 = 2.8315e-04
Validation rmse = 0.811896
Epoch 17
Loss = 3.5678e-01, PNorm = 44.5727, GNorm = 3.9313, lr_0 = 2.7596e-04
Loss = 4.2783e-01, PNorm = 44.5822, GNorm = 5.1384, lr_0 = 2.6896e-04
Loss = 3.5077e-01, PNorm = 44.5930, GNorm = 8.7810, lr_0 = 2.6214e-04
Loss = 3.1134e-01, PNorm = 44.5999, GNorm = 10.1969, lr_0 = 2.5549e-04
Validation rmse = 0.817306
Epoch 18
Loss = 3.1283e-01, PNorm = 44.6081, GNorm = 3.7679, lr_0 = 2.4900e-04
Loss = 2.9200e-01, PNorm = 44.6177, GNorm = 4.9749, lr_0 = 2.4269e-04
Loss = 3.2825e-01, PNorm = 44.6263, GNorm = 4.1498, lr_0 = 2.3653e-04
Validation rmse = 0.819570
Epoch 19
Loss = 2.8371e-01, PNorm = 44.6332, GNorm = 11.8080, lr_0 = 2.3053e-04
Loss = 3.0488e-01, PNorm = 44.6431, GNorm = 5.7521, lr_0 = 2.2468e-04
Loss = 3.1746e-01, PNorm = 44.6506, GNorm = 4.8394, lr_0 = 2.1898e-04
Validation rmse = 0.826237
Epoch 20
Loss = 1.5515e-01, PNorm = 44.6576, GNorm = 7.0509, lr_0 = 2.1342e-04
Loss = 3.0061e-01, PNorm = 44.6638, GNorm = 15.5048, lr_0 = 2.0801e-04
Loss = 2.4904e-01, PNorm = 44.6705, GNorm = 4.8568, lr_0 = 2.0273e-04
Validation rmse = 0.810871
Epoch 21
Loss = 3.2991e-01, PNorm = 44.6777, GNorm = 14.7100, lr_0 = 1.9708e-04
Loss = 2.2871e-01, PNorm = 44.6838, GNorm = 4.3225, lr_0 = 1.9208e-04
Loss = 2.3113e-01, PNorm = 44.6931, GNorm = 8.4545, lr_0 = 1.8721e-04
Loss = 3.2098e-01, PNorm = 44.6992, GNorm = 6.8200, lr_0 = 1.8246e-04
Validation rmse = 0.807280
Epoch 22
Loss = 3.1844e-01, PNorm = 44.7058, GNorm = 6.1973, lr_0 = 1.7783e-04
Loss = 2.4785e-01, PNorm = 44.7110, GNorm = 4.9197, lr_0 = 1.7332e-04
Loss = 2.6711e-01, PNorm = 44.7142, GNorm = 7.2362, lr_0 = 1.6892e-04
Validation rmse = 0.813099
Epoch 23
Loss = 2.8740e-01, PNorm = 44.7207, GNorm = 7.9083, lr_0 = 1.6463e-04
Loss = 1.9650e-01, PNorm = 44.7263, GNorm = 6.6656, lr_0 = 1.6046e-04
Loss = 2.5385e-01, PNorm = 44.7303, GNorm = 15.1790, lr_0 = 1.5639e-04
Validation rmse = 0.862858
Epoch 24
Loss = 3.8974e-01, PNorm = 44.7334, GNorm = 4.7482, lr_0 = 1.5242e-04
Loss = 3.2189e-01, PNorm = 44.7387, GNorm = 3.4108, lr_0 = 1.4855e-04
Loss = 1.7861e-01, PNorm = 44.7452, GNorm = 5.8063, lr_0 = 1.4478e-04
Loss = 3.4101e-01, PNorm = 44.7505, GNorm = 6.3937, lr_0 = 1.4111e-04
Validation rmse = 0.815933
Epoch 25
Loss = 2.6619e-01, PNorm = 44.7551, GNorm = 5.6033, lr_0 = 1.3753e-04
Loss = 1.7800e-01, PNorm = 44.7598, GNorm = 4.5435, lr_0 = 1.3404e-04
Loss = 2.6884e-01, PNorm = 44.7639, GNorm = 8.1473, lr_0 = 1.3064e-04
Validation rmse = 0.822282
Epoch 26
Loss = 1.1200e-01, PNorm = 44.7695, GNorm = 4.7091, lr_0 = 1.2700e-04
Loss = 2.2647e-01, PNorm = 44.7747, GNorm = 7.4316, lr_0 = 1.2378e-04
Loss = 3.0676e-01, PNorm = 44.7786, GNorm = 5.4630, lr_0 = 1.2063e-04
Validation rmse = 0.810553
Epoch 27
Loss = 1.8144e-01, PNorm = 44.7796, GNorm = 9.1113, lr_0 = 1.1757e-04
Loss = 2.5609e-01, PNorm = 44.7825, GNorm = 3.0217, lr_0 = 1.1459e-04
Loss = 2.0319e-01, PNorm = 44.7885, GNorm = 12.2074, lr_0 = 1.1168e-04
Validation rmse = 0.822191
Epoch 28
Loss = 2.7272e-01, PNorm = 44.7920, GNorm = 4.4863, lr_0 = 1.0885e-04
Loss = 1.7013e-01, PNorm = 44.7949, GNorm = 11.0497, lr_0 = 1.0609e-04
Loss = 2.1194e-01, PNorm = 44.7987, GNorm = 4.9497, lr_0 = 1.0340e-04
Loss = 2.1941e-01, PNorm = 44.8025, GNorm = 5.3518, lr_0 = 1.0077e-04
Validation rmse = 0.808669
Epoch 29
Loss = 1.8289e-01, PNorm = 44.8067, GNorm = 7.1767, lr_0 = 1.0000e-04
Loss = 1.9878e-01, PNorm = 44.8104, GNorm = 15.2767, lr_0 = 1.0000e-04
Loss = 1.9058e-01, PNorm = 44.8136, GNorm = 8.8220, lr_0 = 1.0000e-04
Validation rmse = 0.817757
Model 0 best validation rmse = 0.807280 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.609060
Ensemble test rmse = 0.609060
1-fold cross validation
	Seed 0 ==> test rmse = 0.609060
Overall test rmse = 0.609060 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0404e+00, PNorm = 43.3129, GNorm = 2.3823, lr_0 = 2.5000e-04
Loss = 1.4653e+00, PNorm = 43.3162, GNorm = 2.0976, lr_0 = 3.8636e-04
Loss = 1.4047e+00, PNorm = 43.3234, GNorm = 1.4128, lr_0 = 5.2273e-04
Validation rmse = 1.418378
Epoch 1
Loss = 1.3895e+00, PNorm = 43.3378, GNorm = 2.2903, lr_0 = 6.7273e-04
Loss = 1.2993e+00, PNorm = 43.3605, GNorm = 1.3933, lr_0 = 8.0909e-04
Loss = 1.1665e+00, PNorm = 43.3991, GNorm = 2.9032, lr_0 = 9.4545e-04
Validation rmse = 1.244366
Epoch 2
Loss = 1.1731e+00, PNorm = 43.4506, GNorm = 6.2035, lr_0 = 9.8516e-04
Loss = 1.1599e+00, PNorm = 43.5042, GNorm = 2.8997, lr_0 = 9.6091e-04
Loss = 1.0172e+00, PNorm = 43.5637, GNorm = 5.3571, lr_0 = 9.3726e-04
Loss = 9.5879e-01, PNorm = 43.6190, GNorm = 2.1417, lr_0 = 9.1420e-04
Loss = 1.0665e+00, PNorm = 43.6238, GNorm = 2.7113, lr_0 = 9.1192e-04
Validation rmse = 0.941348
Epoch 3
Loss = 8.8165e-01, PNorm = 43.6753, GNorm = 3.4365, lr_0 = 8.8948e-04
Loss = 8.0854e-01, PNorm = 43.7213, GNorm = 3.3337, lr_0 = 8.6758e-04
Loss = 8.2080e-01, PNorm = 43.7600, GNorm = 4.4169, lr_0 = 8.4623e-04
Validation rmse = 0.876932
Epoch 4
Loss = 7.4862e-01, PNorm = 43.7799, GNorm = 7.8510, lr_0 = 8.2540e-04
Loss = 7.8828e-01, PNorm = 43.8257, GNorm = 13.1029, lr_0 = 8.0509e-04
Loss = 7.7604e-01, PNorm = 43.8684, GNorm = 9.3906, lr_0 = 7.8527e-04
Validation rmse = 0.823861
Epoch 5
Loss = 8.4411e-01, PNorm = 43.9163, GNorm = 10.5777, lr_0 = 7.6595e-04
Loss = 6.0680e-01, PNorm = 43.9485, GNorm = 3.8433, lr_0 = 7.4710e-04
Loss = 7.3307e-01, PNorm = 43.9709, GNorm = 6.2493, lr_0 = 7.2871e-04
Loss = 6.7211e-01, PNorm = 44.0018, GNorm = 6.4877, lr_0 = 7.1077e-04
Validation rmse = 0.793599
Epoch 6
Loss = 5.2611e-01, PNorm = 44.0326, GNorm = 9.3288, lr_0 = 6.9156e-04
Loss = 6.7041e-01, PNorm = 44.0684, GNorm = 7.3126, lr_0 = 6.7453e-04
Loss = 6.0253e-01, PNorm = 44.1014, GNorm = 10.4698, lr_0 = 6.5793e-04
Validation rmse = 0.846104
Epoch 7
Loss = 5.9579e-01, PNorm = 44.1238, GNorm = 4.6652, lr_0 = 6.4174e-04
Loss = 6.2003e-01, PNorm = 44.1455, GNorm = 6.1227, lr_0 = 6.2595e-04
Loss = 6.3214e-01, PNorm = 44.1674, GNorm = 9.2998, lr_0 = 6.1054e-04
Validation rmse = 0.769701
Epoch 8
Loss = 4.3286e-01, PNorm = 44.1923, GNorm = 5.1352, lr_0 = 5.9403e-04
Loss = 5.5254e-01, PNorm = 44.2222, GNorm = 3.6183, lr_0 = 5.7941e-04
Loss = 4.5823e-01, PNorm = 44.2424, GNorm = 10.9906, lr_0 = 5.6515e-04
Loss = 8.2996e-01, PNorm = 44.2579, GNorm = 4.2634, lr_0 = 5.5124e-04
Validation rmse = 0.765875
Epoch 9
Loss = 6.8589e-01, PNorm = 44.2842, GNorm = 2.6598, lr_0 = 5.3767e-04
Loss = 5.0324e-01, PNorm = 44.3103, GNorm = 3.7123, lr_0 = 5.2444e-04
Loss = 4.8959e-01, PNorm = 44.3310, GNorm = 8.4309, lr_0 = 5.1153e-04
Validation rmse = 0.765110
Epoch 10
Loss = 5.2388e-01, PNorm = 44.3461, GNorm = 8.9902, lr_0 = 4.9894e-04
Loss = 4.1707e-01, PNorm = 44.3674, GNorm = 5.4712, lr_0 = 4.8666e-04
Loss = 4.6261e-01, PNorm = 44.3900, GNorm = 4.5300, lr_0 = 4.7469e-04
Validation rmse = 0.775459
Epoch 11
Loss = 5.3661e-01, PNorm = 44.4046, GNorm = 3.9018, lr_0 = 4.6185e-04
Loss = 4.8054e-01, PNorm = 44.4251, GNorm = 5.7260, lr_0 = 4.5048e-04
Loss = 4.0814e-01, PNorm = 44.4429, GNorm = 3.8161, lr_0 = 4.3940e-04
Loss = 5.2131e-01, PNorm = 44.4546, GNorm = 7.8287, lr_0 = 4.2858e-04
Validation rmse = 0.810268
Epoch 12
Loss = 4.6060e-01, PNorm = 44.4695, GNorm = 2.4040, lr_0 = 4.1803e-04
Loss = 3.5379e-01, PNorm = 44.4903, GNorm = 19.3363, lr_0 = 4.0775e-04
Loss = 5.1521e-01, PNorm = 44.5002, GNorm = 3.7101, lr_0 = 3.9771e-04
Validation rmse = 0.744490
Epoch 13
Loss = 4.1097e-01, PNorm = 44.5091, GNorm = 3.9962, lr_0 = 3.8696e-04
Loss = 4.2367e-01, PNorm = 44.5263, GNorm = 10.1400, lr_0 = 3.7743e-04
Loss = 3.9265e-01, PNorm = 44.5372, GNorm = 4.8180, lr_0 = 3.6814e-04
Loss = 4.0730e-01, PNorm = 44.5486, GNorm = 7.4798, lr_0 = 3.5908e-04
Validation rmse = 0.743743
Epoch 14
Loss = 3.1570e-01, PNorm = 44.5623, GNorm = 6.5614, lr_0 = 3.5025e-04
Loss = 4.5449e-01, PNorm = 44.5785, GNorm = 11.6837, lr_0 = 3.4163e-04
Loss = 4.4923e-01, PNorm = 44.5894, GNorm = 5.1360, lr_0 = 3.3322e-04
Validation rmse = 0.733008
Epoch 15
Loss = 3.3284e-01, PNorm = 44.5991, GNorm = 4.9283, lr_0 = 3.2502e-04
Loss = 3.6624e-01, PNorm = 44.6108, GNorm = 6.6021, lr_0 = 3.1702e-04
Loss = 3.3697e-01, PNorm = 44.6189, GNorm = 5.9899, lr_0 = 3.0921e-04
Validation rmse = 0.732716
Epoch 16
Loss = 3.5956e-01, PNorm = 44.6342, GNorm = 6.6643, lr_0 = 3.0085e-04
Loss = 3.6520e-01, PNorm = 44.6391, GNorm = 6.5596, lr_0 = 2.9345e-04
Loss = 4.0552e-01, PNorm = 44.6461, GNorm = 4.4834, lr_0 = 2.8623e-04
Loss = 2.9212e-01, PNorm = 44.6573, GNorm = 8.6045, lr_0 = 2.7918e-04
Validation rmse = 0.737528
Epoch 17
Loss = 2.4312e-01, PNorm = 44.6740, GNorm = 7.2960, lr_0 = 2.7231e-04
Loss = 3.8456e-01, PNorm = 44.6825, GNorm = 5.7882, lr_0 = 2.6561e-04
Loss = 2.9171e-01, PNorm = 44.6876, GNorm = 12.1568, lr_0 = 2.5907e-04
Validation rmse = 0.729608
Epoch 18
Loss = 3.0721e-01, PNorm = 44.6985, GNorm = 8.5818, lr_0 = 2.5207e-04
Loss = 2.8292e-01, PNorm = 44.7105, GNorm = 17.4909, lr_0 = 2.4586e-04
Loss = 3.0210e-01, PNorm = 44.7145, GNorm = 4.8597, lr_0 = 2.3981e-04
Validation rmse = 0.755356
Epoch 19
Loss = 3.4432e-01, PNorm = 44.7229, GNorm = 11.9969, lr_0 = 2.3391e-04
Loss = 2.7306e-01, PNorm = 44.7316, GNorm = 5.0558, lr_0 = 2.2815e-04
Loss = 2.8472e-01, PNorm = 44.7391, GNorm = 13.3734, lr_0 = 2.2254e-04
Loss = 2.2031e-01, PNorm = 44.7463, GNorm = 6.6562, lr_0 = 2.1706e-04
Validation rmse = 0.724966
Epoch 20
Loss = 1.7203e-01, PNorm = 44.7553, GNorm = 3.8272, lr_0 = 2.1172e-04
Loss = 3.2588e-01, PNorm = 44.7599, GNorm = 4.1944, lr_0 = 2.0651e-04
Loss = 2.3766e-01, PNorm = 44.7672, GNorm = 6.4020, lr_0 = 2.0142e-04
Validation rmse = 0.738627
Epoch 21
Loss = 3.3343e-01, PNorm = 44.7714, GNorm = 14.4365, lr_0 = 1.9598e-04
Loss = 2.8943e-01, PNorm = 44.7779, GNorm = 9.7899, lr_0 = 1.9115e-04
Loss = 1.8402e-01, PNorm = 44.7854, GNorm = 3.1077, lr_0 = 1.8645e-04
Validation rmse = 0.709060
Epoch 22
Loss = 2.7783e-01, PNorm = 44.7914, GNorm = 7.2629, lr_0 = 1.8186e-04
Loss = 1.9702e-01, PNorm = 44.7974, GNorm = 10.1738, lr_0 = 1.7739e-04
Loss = 2.6235e-01, PNorm = 44.8032, GNorm = 8.2548, lr_0 = 1.7302e-04
Loss = 2.3877e-01, PNorm = 44.8093, GNorm = 5.8044, lr_0 = 1.6876e-04
Validation rmse = 0.710861
Epoch 23
Loss = 2.3202e-01, PNorm = 44.8182, GNorm = 5.0778, lr_0 = 1.6420e-04
Loss = 1.6650e-01, PNorm = 44.8224, GNorm = 8.9535, lr_0 = 1.6016e-04
Loss = 2.4068e-01, PNorm = 44.8285, GNorm = 6.9968, lr_0 = 1.5622e-04
Validation rmse = 0.714001
Epoch 24
Loss = 2.1272e-01, PNorm = 44.8331, GNorm = 3.6829, lr_0 = 1.5237e-04
Loss = 1.4547e-01, PNorm = 44.8389, GNorm = 9.8482, lr_0 = 1.4862e-04
Loss = 2.4892e-01, PNorm = 44.8444, GNorm = 18.0885, lr_0 = 1.4496e-04
Loss = 2.4413e-01, PNorm = 44.8483, GNorm = 10.0333, lr_0 = 1.4139e-04
Validation rmse = 0.725606
Epoch 25
Loss = 2.5185e-01, PNorm = 44.8515, GNorm = 3.4998, lr_0 = 1.3791e-04
Loss = 1.7515e-01, PNorm = 44.8556, GNorm = 11.3535, lr_0 = 1.3452e-04
Loss = 2.4392e-01, PNorm = 44.8604, GNorm = 4.3124, lr_0 = 1.3121e-04
Validation rmse = 0.711610
Epoch 26
Loss = 1.6954e-01, PNorm = 44.8654, GNorm = 7.3021, lr_0 = 1.2766e-04
Loss = 2.0530e-01, PNorm = 44.8698, GNorm = 8.6528, lr_0 = 1.2452e-04
Loss = 2.7588e-01, PNorm = 44.8740, GNorm = 4.1870, lr_0 = 1.2146e-04
Validation rmse = 0.711496
Epoch 27
Loss = 1.0867e-01, PNorm = 44.8778, GNorm = 6.4434, lr_0 = 1.1847e-04
Loss = 9.5484e-02, PNorm = 44.8808, GNorm = 9.2164, lr_0 = 1.1555e-04
Loss = 2.0110e-01, PNorm = 44.8847, GNorm = 3.9422, lr_0 = 1.1271e-04
Loss = 2.1859e-01, PNorm = 44.8902, GNorm = 4.9846, lr_0 = 1.0993e-04
Loss = 6.2087e-01, PNorm = 44.8905, GNorm = 10.0992, lr_0 = 1.0966e-04
Validation rmse = 0.701898
Epoch 28
Loss = 1.5763e-01, PNorm = 44.8932, GNorm = 4.7479, lr_0 = 1.0696e-04
Loss = 1.5122e-01, PNorm = 44.8965, GNorm = 5.1980, lr_0 = 1.0433e-04
Loss = 1.5698e-01, PNorm = 44.8993, GNorm = 8.0500, lr_0 = 1.0176e-04
Validation rmse = 0.706197
Epoch 29
Loss = 2.0984e-01, PNorm = 44.9022, GNorm = 7.4979, lr_0 = 1.0000e-04
Loss = 2.3225e-01, PNorm = 44.9057, GNorm = 6.8575, lr_0 = 1.0000e-04
Loss = 1.3557e-01, PNorm = 44.9086, GNorm = 5.5767, lr_0 = 1.0000e-04
Validation rmse = 0.705585
Model 0 best validation rmse = 0.701898 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.765347
Ensemble test rmse = 0.765347
1-fold cross validation
	Seed 0 ==> test rmse = 0.765347
Overall test rmse = 0.765347 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,075 | train size = 860 | val size = 107 | test size = 108
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9587e+00, PNorm = 43.3124, GNorm = 2.5729, lr_0 = 2.4559e-04
Loss = 1.4773e+00, PNorm = 43.3149, GNorm = 1.9909, lr_0 = 3.7794e-04
Loss = 1.3981e+00, PNorm = 43.3215, GNorm = 1.1479, lr_0 = 5.1029e-04
Validation rmse = 1.454744
Epoch 1
Loss = 1.1613e+00, PNorm = 43.3371, GNorm = 0.9083, lr_0 = 6.5588e-04
Loss = 1.3346e+00, PNorm = 43.3609, GNorm = 1.5370, lr_0 = 7.8824e-04
Loss = 1.2914e+00, PNorm = 43.3980, GNorm = 2.2061, lr_0 = 9.2059e-04
Validation rmse = 1.091779
Epoch 2
Loss = 9.9037e-01, PNorm = 43.4523, GNorm = 1.3902, lr_0 = 9.8798e-04
Loss = 1.0205e+00, PNorm = 43.5150, GNorm = 1.8309, lr_0 = 9.6437e-04
Loss = 9.7175e-01, PNorm = 43.5836, GNorm = 7.9191, lr_0 = 9.4132e-04
Loss = 9.8384e-01, PNorm = 43.6284, GNorm = 3.8633, lr_0 = 9.1883e-04
Validation rmse = 0.996793
Epoch 3
Loss = 8.7273e-01, PNorm = 43.6769, GNorm = 3.5379, lr_0 = 8.9687e-04
Loss = 8.9000e-01, PNorm = 43.7346, GNorm = 7.8087, lr_0 = 8.7544e-04
Loss = 8.8508e-01, PNorm = 43.7699, GNorm = 5.7416, lr_0 = 8.5452e-04
Validation rmse = 0.889584
Epoch 4
Loss = 8.6212e-01, PNorm = 43.8110, GNorm = 4.0853, lr_0 = 8.3209e-04
Loss = 7.1864e-01, PNorm = 43.8589, GNorm = 2.8807, lr_0 = 8.1220e-04
Loss = 7.1780e-01, PNorm = 43.8993, GNorm = 2.6669, lr_0 = 7.9279e-04
Loss = 7.9890e-01, PNorm = 43.9313, GNorm = 4.4753, lr_0 = 7.7385e-04
Validation rmse = 0.819352
Epoch 5
Loss = 7.4264e-01, PNorm = 43.9695, GNorm = 3.2061, lr_0 = 7.5536e-04
Loss = 7.5009e-01, PNorm = 44.0102, GNorm = 10.5570, lr_0 = 7.3730e-04
Loss = 7.7165e-01, PNorm = 44.0463, GNorm = 4.3130, lr_0 = 7.1969e-04
Validation rmse = 0.936928
Epoch 6
Loss = 6.9601e-01, PNorm = 44.0917, GNorm = 2.3361, lr_0 = 7.0079e-04
Loss = 6.2507e-01, PNorm = 44.1307, GNorm = 3.6432, lr_0 = 6.8404e-04
Loss = 6.2642e-01, PNorm = 44.1612, GNorm = 4.1128, lr_0 = 6.6770e-04
Loss = 5.4956e-01, PNorm = 44.1888, GNorm = 5.9863, lr_0 = 6.5174e-04
Loss = 3.5366e-01, PNorm = 44.1920, GNorm = 6.9627, lr_0 = 6.5017e-04
Validation rmse = 0.765351
Epoch 7
Loss = 4.6912e-01, PNorm = 44.2296, GNorm = 3.7287, lr_0 = 6.3463e-04
Loss = 4.8453e-01, PNorm = 44.2447, GNorm = 3.6021, lr_0 = 6.1947e-04
Loss = 6.2878e-01, PNorm = 44.2702, GNorm = 2.4477, lr_0 = 6.0466e-04
Validation rmse = 0.749915
Epoch 8
Loss = 5.2680e-01, PNorm = 44.2984, GNorm = 7.3839, lr_0 = 5.9021e-04
Loss = 4.1791e-01, PNorm = 44.3263, GNorm = 8.1677, lr_0 = 5.7611e-04
Loss = 5.3546e-01, PNorm = 44.3407, GNorm = 3.3611, lr_0 = 5.6234e-04
Validation rmse = 0.743856
Epoch 9
Loss = 5.6558e-01, PNorm = 44.3701, GNorm = 9.1707, lr_0 = 5.4758e-04
Loss = 4.4630e-01, PNorm = 44.3923, GNorm = 3.3968, lr_0 = 5.3449e-04
Loss = 3.6536e-01, PNorm = 44.4169, GNorm = 3.7245, lr_0 = 5.2172e-04
Loss = 5.8239e-01, PNorm = 44.4408, GNorm = 2.1883, lr_0 = 5.0925e-04
Validation rmse = 0.705169
Epoch 10
Loss = 3.5411e-01, PNorm = 44.4582, GNorm = 3.7365, lr_0 = 4.9708e-04
Loss = 4.2228e-01, PNorm = 44.4780, GNorm = 11.3812, lr_0 = 4.8520e-04
Loss = 4.3682e-01, PNorm = 44.4944, GNorm = 9.6602, lr_0 = 4.7361e-04
Validation rmse = 0.803863
Epoch 11
Loss = 5.0531e-01, PNorm = 44.5080, GNorm = 4.3404, lr_0 = 4.6117e-04
Loss = 4.6008e-01, PNorm = 44.5230, GNorm = 6.7980, lr_0 = 4.5015e-04
Loss = 4.5007e-01, PNorm = 44.5492, GNorm = 3.8263, lr_0 = 4.3940e-04
Loss = 4.7246e-01, PNorm = 44.5559, GNorm = 5.8372, lr_0 = 4.2890e-04
Validation rmse = 0.759802
Epoch 12
Loss = 3.8122e-01, PNorm = 44.5750, GNorm = 3.9882, lr_0 = 4.1764e-04
Loss = 4.1330e-01, PNorm = 44.5930, GNorm = 9.1074, lr_0 = 4.0766e-04
Loss = 3.4917e-01, PNorm = 44.6042, GNorm = 8.7586, lr_0 = 3.9791e-04
Validation rmse = 0.734254
Epoch 13
Loss = 3.5218e-01, PNorm = 44.6096, GNorm = 4.6227, lr_0 = 3.8841e-04
Loss = 3.9183e-01, PNorm = 44.6212, GNorm = 2.8228, lr_0 = 3.7912e-04
Loss = 3.3024e-01, PNorm = 44.6421, GNorm = 4.3175, lr_0 = 3.7006e-04
Loss = 4.6032e-01, PNorm = 44.6521, GNorm = 6.7573, lr_0 = 3.6122e-04
Validation rmse = 0.709656
Epoch 14
Loss = 3.4988e-01, PNorm = 44.6689, GNorm = 3.2224, lr_0 = 3.5174e-04
Loss = 3.1591e-01, PNorm = 44.6844, GNorm = 16.0008, lr_0 = 3.4333e-04
Loss = 3.3693e-01, PNorm = 44.6951, GNorm = 3.5667, lr_0 = 3.3513e-04
Validation rmse = 0.687636
Epoch 15
Loss = 4.6770e-01, PNorm = 44.7061, GNorm = 4.3553, lr_0 = 3.2712e-04
Loss = 2.5570e-01, PNorm = 44.7202, GNorm = 8.5768, lr_0 = 3.1930e-04
Loss = 3.0795e-01, PNorm = 44.7349, GNorm = 4.9942, lr_0 = 3.1167e-04
Loss = 2.7961e-01, PNorm = 44.7477, GNorm = 6.2955, lr_0 = 3.0422e-04
Loss = 4.5630e-01, PNorm = 44.7480, GNorm = 5.5434, lr_0 = 3.0349e-04
Validation rmse = 0.686491
Epoch 16
Loss = 3.0634e-01, PNorm = 44.7553, GNorm = 10.4417, lr_0 = 2.9624e-04
Loss = 2.4286e-01, PNorm = 44.7712, GNorm = 10.1867, lr_0 = 2.8916e-04
Loss = 3.1928e-01, PNorm = 44.7776, GNorm = 5.0253, lr_0 = 2.8225e-04
Validation rmse = 0.702152
Epoch 17
Loss = 3.2064e-01, PNorm = 44.7872, GNorm = 8.0213, lr_0 = 2.7484e-04
Loss = 3.3403e-01, PNorm = 44.7951, GNorm = 14.5680, lr_0 = 2.6827e-04
Loss = 2.7463e-01, PNorm = 44.8080, GNorm = 15.4837, lr_0 = 2.6186e-04
Validation rmse = 0.701524
Epoch 18
Loss = 4.8153e-01, PNorm = 44.8188, GNorm = 4.6669, lr_0 = 2.5560e-04
Loss = 3.2323e-01, PNorm = 44.8265, GNorm = 3.9848, lr_0 = 2.4949e-04
Loss = 2.8891e-01, PNorm = 44.8348, GNorm = 3.5543, lr_0 = 2.4353e-04
Loss = 3.2190e-01, PNorm = 44.8430, GNorm = 6.2290, lr_0 = 2.3771e-04
Validation rmse = 0.697057
Epoch 19
Loss = 3.1253e-01, PNorm = 44.8538, GNorm = 4.7346, lr_0 = 2.3147e-04
Loss = 1.5516e-01, PNorm = 44.8664, GNorm = 9.3728, lr_0 = 2.2594e-04
Loss = 3.1207e-01, PNorm = 44.8731, GNorm = 11.4256, lr_0 = 2.2054e-04
Validation rmse = 0.646084
Epoch 20
Loss = 9.8587e-02, PNorm = 44.8781, GNorm = 7.5216, lr_0 = 2.1527e-04
Loss = 1.9731e-01, PNorm = 44.8825, GNorm = 6.0854, lr_0 = 2.1013e-04
Loss = 3.0769e-01, PNorm = 44.8854, GNorm = 8.3624, lr_0 = 2.0510e-04
Loss = 3.2631e-01, PNorm = 44.8936, GNorm = 6.9195, lr_0 = 2.0020e-04
Validation rmse = 0.659266
Epoch 21
Loss = 2.7985e-01, PNorm = 44.9031, GNorm = 6.8902, lr_0 = 1.9495e-04
Loss = 1.7972e-01, PNorm = 44.9107, GNorm = 8.6510, lr_0 = 1.9029e-04
Loss = 1.4349e-01, PNorm = 44.9186, GNorm = 5.2975, lr_0 = 1.8574e-04
Validation rmse = 0.646794
Epoch 22
Loss = 3.8435e-01, PNorm = 44.9256, GNorm = 4.9130, lr_0 = 1.8086e-04
Loss = 2.0347e-01, PNorm = 44.9320, GNorm = 6.8235, lr_0 = 1.7654e-04
Loss = 1.2094e-01, PNorm = 44.9393, GNorm = 9.4952, lr_0 = 1.7232e-04
Loss = 1.9652e-01, PNorm = 44.9415, GNorm = 11.6827, lr_0 = 1.6821e-04
Validation rmse = 0.656280
Epoch 23
Loss = 2.0653e-01, PNorm = 44.9468, GNorm = 6.3015, lr_0 = 1.6419e-04
Loss = 1.5331e-01, PNorm = 44.9530, GNorm = 5.6801, lr_0 = 1.6026e-04
Loss = 2.2880e-01, PNorm = 44.9574, GNorm = 10.0276, lr_0 = 1.5643e-04
Validation rmse = 0.645841
Epoch 24
Loss = 1.3005e-01, PNorm = 44.9653, GNorm = 7.5494, lr_0 = 1.5233e-04
Loss = 1.6364e-01, PNorm = 44.9701, GNorm = 4.6236, lr_0 = 1.4869e-04
Loss = 2.5587e-01, PNorm = 44.9741, GNorm = 6.1528, lr_0 = 1.4513e-04
Loss = 1.7645e-01, PNorm = 44.9782, GNorm = 8.4953, lr_0 = 1.4166e-04
Validation rmse = 0.646803
Epoch 25
Loss = 1.3799e-01, PNorm = 44.9851, GNorm = 8.5088, lr_0 = 1.3828e-04
Loss = 1.7862e-01, PNorm = 44.9916, GNorm = 4.6881, lr_0 = 1.3497e-04
Loss = 1.7289e-01, PNorm = 44.9950, GNorm = 8.3160, lr_0 = 1.3175e-04
Validation rmse = 0.635215
Epoch 26
Loss = 7.0309e-02, PNorm = 44.9996, GNorm = 6.0525, lr_0 = 1.2829e-04
Loss = 1.3684e-01, PNorm = 45.0047, GNorm = 6.4713, lr_0 = 1.2522e-04
Loss = 2.0480e-01, PNorm = 45.0099, GNorm = 10.5553, lr_0 = 1.2223e-04
Validation rmse = 0.635531
Epoch 27
Loss = -7.4653e-02, PNorm = 45.0137, GNorm = 3.2010, lr_0 = 1.1902e-04
Loss = 1.2489e-01, PNorm = 45.0179, GNorm = 4.7989, lr_0 = 1.1618e-04
Loss = 2.5247e-01, PNorm = 45.0214, GNorm = 4.4443, lr_0 = 1.1340e-04
Loss = 9.6843e-02, PNorm = 45.0261, GNorm = 8.1292, lr_0 = 1.1069e-04
Validation rmse = 0.651531
Epoch 28
Loss = 2.3983e-01, PNorm = 45.0299, GNorm = 3.4523, lr_0 = 1.0805e-04
Loss = 1.2590e-01, PNorm = 45.0337, GNorm = 7.1069, lr_0 = 1.0547e-04
Loss = 1.6165e-01, PNorm = 45.0385, GNorm = 16.7272, lr_0 = 1.0294e-04
Validation rmse = 0.639612
Epoch 29
Loss = 1.0179e-01, PNorm = 45.0413, GNorm = 10.0299, lr_0 = 1.0024e-04
Loss = 1.3867e-01, PNorm = 45.0460, GNorm = 18.4975, lr_0 = 1.0000e-04
Loss = 1.5138e-01, PNorm = 45.0494, GNorm = 8.7503, lr_0 = 1.0000e-04
Loss = 9.5082e-02, PNorm = 45.0526, GNorm = 5.9961, lr_0 = 1.0000e-04
Validation rmse = 0.654319
Model 0 best validation rmse = 0.635215 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.785150
Ensemble test rmse = 0.785150
1-fold cross validation
	Seed 0 ==> test rmse = 0.785150
Overall test rmse = 0.785150 +/- 0.000000
Elapsed time = 0:01:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7180e+00, PNorm = 43.3131, GNorm = 1.8112, lr_0 = 2.4143e-04
Loss = 1.5201e+00, PNorm = 43.3149, GNorm = 0.8695, lr_0 = 3.7000e-04
Loss = 1.3976e+00, PNorm = 43.3215, GNorm = 1.4547, lr_0 = 4.9857e-04
Validation rmse = 1.330867
Epoch 1
Loss = 1.2987e+00, PNorm = 43.3378, GNorm = 2.2493, lr_0 = 6.4000e-04
Loss = 1.2228e+00, PNorm = 43.3682, GNorm = 1.9199, lr_0 = 7.6857e-04
Loss = 1.1795e+00, PNorm = 43.4134, GNorm = 3.1958, lr_0 = 8.9714e-04
Loss = 1.0738e+00, PNorm = 43.4579, GNorm = 6.2512, lr_0 = 9.9531e-04
Loss = 1.1470e+00, PNorm = 43.4633, GNorm = 3.8822, lr_0 = 9.9298e-04
Validation rmse = 1.023769
Epoch 2
Loss = 1.0601e+00, PNorm = 43.5233, GNorm = 17.0086, lr_0 = 9.6992e-04
Loss = 9.6561e-01, PNorm = 43.5809, GNorm = 5.4944, lr_0 = 9.4739e-04
Loss = 1.0541e+00, PNorm = 43.6313, GNorm = 4.0934, lr_0 = 9.2539e-04
Validation rmse = 1.022196
Epoch 3
Loss = 9.0196e-01, PNorm = 43.6949, GNorm = 6.4090, lr_0 = 9.0178e-04
Loss = 9.0139e-01, PNorm = 43.7568, GNorm = 1.6838, lr_0 = 8.8084e-04
Loss = 8.2926e-01, PNorm = 43.8112, GNorm = 5.0362, lr_0 = 8.6039e-04
Loss = 8.0874e-01, PNorm = 43.8554, GNorm = 1.9401, lr_0 = 8.4041e-04
Loss = 3.9515e-01, PNorm = 43.8591, GNorm = 2.9568, lr_0 = 8.3843e-04
Validation rmse = 0.836349
Epoch 4
Loss = 6.8199e-01, PNorm = 43.8990, GNorm = 3.3491, lr_0 = 8.1896e-04
Loss = 7.3610e-01, PNorm = 43.9274, GNorm = 5.0192, lr_0 = 7.9995e-04
Loss = 6.9517e-01, PNorm = 43.9636, GNorm = 7.5319, lr_0 = 7.8137e-04
Validation rmse = 0.766279
Epoch 5
Loss = 5.9555e-01, PNorm = 44.0108, GNorm = 10.9012, lr_0 = 7.6323e-04
Loss = 6.8775e-01, PNorm = 44.0528, GNorm = 3.9146, lr_0 = 7.4550e-04
Loss = 6.3111e-01, PNorm = 44.0983, GNorm = 7.2485, lr_0 = 7.2819e-04
Loss = 7.1184e-01, PNorm = 44.1351, GNorm = 8.9481, lr_0 = 7.1128e-04
Validation rmse = 0.770949
Epoch 6
Loss = 5.1698e-01, PNorm = 44.1810, GNorm = 2.5927, lr_0 = 6.9313e-04
Loss = 5.4638e-01, PNorm = 44.2130, GNorm = 6.4398, lr_0 = 6.7704e-04
Loss = 5.9410e-01, PNorm = 44.2326, GNorm = 2.8525, lr_0 = 6.6131e-04
Validation rmse = 0.683419
Epoch 7
Loss = 4.1489e-01, PNorm = 44.2609, GNorm = 2.4470, lr_0 = 6.4444e-04
Loss = 5.2140e-01, PNorm = 44.2940, GNorm = 4.9445, lr_0 = 6.2948e-04
Loss = 4.7090e-01, PNorm = 44.3209, GNorm = 5.5229, lr_0 = 6.1486e-04
Loss = 4.8419e-01, PNorm = 44.3418, GNorm = 7.8795, lr_0 = 6.0058e-04
Validation rmse = 0.719316
Epoch 8
Loss = 5.1791e-01, PNorm = 44.3668, GNorm = 9.0660, lr_0 = 5.8526e-04
Loss = 4.6906e-01, PNorm = 44.3961, GNorm = 6.5077, lr_0 = 5.7167e-04
Loss = 5.7309e-01, PNorm = 44.4254, GNorm = 7.2911, lr_0 = 5.5839e-04
Validation rmse = 0.720127
Epoch 9
Loss = 4.2404e-01, PNorm = 44.4539, GNorm = 13.0289, lr_0 = 5.4414e-04
Loss = 4.0641e-01, PNorm = 44.4704, GNorm = 2.6590, lr_0 = 5.3151e-04
Loss = 4.6323e-01, PNorm = 44.4911, GNorm = 4.8637, lr_0 = 5.1917e-04
Loss = 3.9864e-01, PNorm = 44.5009, GNorm = 4.9113, lr_0 = 5.0711e-04
Validation rmse = 0.683829
Epoch 10
Loss = 3.4526e-01, PNorm = 44.5203, GNorm = 5.2798, lr_0 = 4.9533e-04
Loss = 5.5878e-01, PNorm = 44.5411, GNorm = 9.9474, lr_0 = 4.8383e-04
Loss = 3.8019e-01, PNorm = 44.5605, GNorm = 4.4992, lr_0 = 4.7260e-04
Validation rmse = 0.749086
Epoch 11
Loss = 4.2042e-01, PNorm = 44.5881, GNorm = 4.8440, lr_0 = 4.6054e-04
Loss = 4.0867e-01, PNorm = 44.6041, GNorm = 7.5730, lr_0 = 4.4984e-04
Loss = 3.7214e-01, PNorm = 44.6160, GNorm = 4.5301, lr_0 = 4.3940e-04
Loss = 3.4631e-01, PNorm = 44.6339, GNorm = 7.3471, lr_0 = 4.2919e-04
Validation rmse = 0.679596
Epoch 12
Loss = 3.4376e-01, PNorm = 44.6499, GNorm = 12.0159, lr_0 = 4.1824e-04
Loss = 3.9716e-01, PNorm = 44.6723, GNorm = 10.1322, lr_0 = 4.0853e-04
Loss = 4.1654e-01, PNorm = 44.6852, GNorm = 5.2518, lr_0 = 3.9904e-04
Validation rmse = 0.652540
Epoch 13
Loss = 2.7435e-01, PNorm = 44.6963, GNorm = 2.8957, lr_0 = 3.8886e-04
Loss = 2.5582e-01, PNorm = 44.7138, GNorm = 5.7993, lr_0 = 3.7983e-04
Loss = 4.0881e-01, PNorm = 44.7257, GNorm = 8.5299, lr_0 = 3.7101e-04
Loss = 3.3338e-01, PNorm = 44.7378, GNorm = 3.6053, lr_0 = 3.6240e-04
Validation rmse = 0.654814
Epoch 14
Loss = 2.7941e-01, PNorm = 44.7530, GNorm = 5.8610, lr_0 = 3.5315e-04
Loss = 2.5298e-01, PNorm = 44.7696, GNorm = 6.8831, lr_0 = 3.4495e-04
Loss = 3.4581e-01, PNorm = 44.7849, GNorm = 6.3181, lr_0 = 3.3694e-04
Validation rmse = 0.688196
Epoch 15
Loss = 1.7614e-01, PNorm = 44.7940, GNorm = 3.9088, lr_0 = 3.2911e-04
Loss = 2.3695e-01, PNorm = 44.8059, GNorm = 8.1682, lr_0 = 3.2147e-04
Loss = 2.2814e-01, PNorm = 44.8193, GNorm = 6.0521, lr_0 = 3.1401e-04
Loss = 3.2281e-01, PNorm = 44.8298, GNorm = 7.9251, lr_0 = 3.0671e-04
Validation rmse = 0.660330
Epoch 16
Loss = 1.7130e-01, PNorm = 44.8398, GNorm = 5.2297, lr_0 = 2.9889e-04
Loss = 2.6548e-01, PNorm = 44.8453, GNorm = 9.6147, lr_0 = 2.9195e-04
Loss = 2.5532e-01, PNorm = 44.8529, GNorm = 3.2778, lr_0 = 2.8517e-04
Validation rmse = 0.664815
Epoch 17
Loss = 2.9286e-01, PNorm = 44.8675, GNorm = 4.3000, lr_0 = 2.7789e-04
Loss = 2.0260e-01, PNorm = 44.8787, GNorm = 4.7749, lr_0 = 2.7144e-04
Loss = 1.8440e-01, PNorm = 44.8868, GNorm = 6.3120, lr_0 = 2.6514e-04
Loss = 1.9416e-01, PNorm = 44.8955, GNorm = 4.3629, lr_0 = 2.5898e-04
Validation rmse = 0.661311
Epoch 18
Loss = 2.0065e-01, PNorm = 44.9046, GNorm = 6.5281, lr_0 = 2.5237e-04
Loss = 2.9614e-01, PNorm = 44.9133, GNorm = 6.6106, lr_0 = 2.4651e-04
Loss = 1.8810e-01, PNorm = 44.9234, GNorm = 4.7294, lr_0 = 2.4079e-04
Validation rmse = 0.657700
Epoch 19
Loss = 1.8767e-01, PNorm = 44.9336, GNorm = 11.4071, lr_0 = 2.3464e-04
Loss = 1.7799e-01, PNorm = 44.9428, GNorm = 3.1993, lr_0 = 2.2919e-04
Loss = 1.0943e-01, PNorm = 44.9503, GNorm = 6.2026, lr_0 = 2.2387e-04
Loss = 2.3294e-01, PNorm = 44.9569, GNorm = 6.2631, lr_0 = 2.1867e-04
Validation rmse = 0.662343
Epoch 20
Loss = 1.8999e-01, PNorm = 44.9606, GNorm = 3.8503, lr_0 = 2.1360e-04
Loss = 2.1221e-01, PNorm = 44.9683, GNorm = 3.8851, lr_0 = 2.0864e-04
Loss = 2.3608e-01, PNorm = 44.9779, GNorm = 3.4221, lr_0 = 2.0379e-04
Validation rmse = 0.667959
Epoch 21
Loss = 2.0143e-01, PNorm = 44.9888, GNorm = 10.6641, lr_0 = 1.9859e-04
Loss = 1.3688e-01, PNorm = 44.9935, GNorm = 6.0234, lr_0 = 1.9398e-04
Loss = 1.9210e-01, PNorm = 44.9993, GNorm = 6.5040, lr_0 = 1.8947e-04
Loss = 2.1674e-01, PNorm = 45.0066, GNorm = 8.0111, lr_0 = 1.8507e-04
Validation rmse = 0.643107
Epoch 22
Loss = 2.1336e-01, PNorm = 45.0152, GNorm = 12.0356, lr_0 = 1.8035e-04
Loss = 2.7804e-01, PNorm = 45.0192, GNorm = 13.3425, lr_0 = 1.7616e-04
Loss = 2.6054e-01, PNorm = 45.0247, GNorm = 10.1731, lr_0 = 1.7207e-04
Validation rmse = 0.654492
Epoch 23
Loss = -5.3168e-02, PNorm = 45.0329, GNorm = 4.3243, lr_0 = 1.6768e-04
Loss = 1.1436e-01, PNorm = 45.0419, GNorm = 4.7588, lr_0 = 1.6379e-04
Loss = 1.0718e-01, PNorm = 45.0470, GNorm = 5.0231, lr_0 = 1.5999e-04
Loss = 2.1951e-01, PNorm = 45.0518, GNorm = 5.4307, lr_0 = 1.5627e-04
Validation rmse = 0.646283
Epoch 24
Loss = 9.4467e-02, PNorm = 45.0562, GNorm = 2.9143, lr_0 = 1.5228e-04
Loss = 1.0948e-01, PNorm = 45.0622, GNorm = 7.6344, lr_0 = 1.4875e-04
Loss = 1.0813e-01, PNorm = 45.0676, GNorm = 4.5822, lr_0 = 1.4529e-04
Loss = 2.0050e-01, PNorm = 45.0714, GNorm = 12.4539, lr_0 = 1.4192e-04
Validation rmse = 0.651530
Epoch 25
Loss = 1.0862e-01, PNorm = 45.0765, GNorm = 5.4244, lr_0 = 1.3862e-04
Loss = 1.2601e-01, PNorm = 45.0821, GNorm = 4.8788, lr_0 = 1.3540e-04
Loss = 7.2807e-02, PNorm = 45.0867, GNorm = 3.1240, lr_0 = 1.3226e-04
Validation rmse = 0.650460
Epoch 26
Loss = 1.4162e-01, PNorm = 45.0908, GNorm = 6.0744, lr_0 = 1.2889e-04
Loss = 1.2474e-01, PNorm = 45.0963, GNorm = 5.7324, lr_0 = 1.2589e-04
Loss = 1.3198e-01, PNorm = 45.0998, GNorm = 6.1715, lr_0 = 1.2297e-04
Loss = 1.2660e-01, PNorm = 45.1053, GNorm = 4.6083, lr_0 = 1.2011e-04
Loss = -1.4622e-01, PNorm = 45.1059, GNorm = 8.6708, lr_0 = 1.1983e-04
Validation rmse = 0.648767
Epoch 27
Loss = 1.3440e-01, PNorm = 45.1108, GNorm = 3.8785, lr_0 = 1.1705e-04
Loss = 6.9108e-02, PNorm = 45.1152, GNorm = 4.8973, lr_0 = 1.1433e-04
Loss = 1.3231e-01, PNorm = 45.1195, GNorm = 11.5721, lr_0 = 1.1168e-04
Validation rmse = 0.652216
Epoch 28
Loss = 1.7459e-02, PNorm = 45.1223, GNorm = 7.7839, lr_0 = 1.0883e-04
Loss = 1.2906e-01, PNorm = 45.1246, GNorm = 5.6020, lr_0 = 1.0630e-04
Loss = 1.4203e-01, PNorm = 45.1287, GNorm = 7.2967, lr_0 = 1.0383e-04
Loss = 6.2528e-02, PNorm = 45.1337, GNorm = 9.0611, lr_0 = 1.0142e-04
Loss = -6.7968e-02, PNorm = 45.1342, GNorm = 25.0762, lr_0 = 1.0118e-04
Validation rmse = 0.663725
Epoch 29
Loss = 4.1532e-02, PNorm = 45.1383, GNorm = 12.8861, lr_0 = 1.0000e-04
Loss = 1.1460e-01, PNorm = 45.1415, GNorm = 10.0029, lr_0 = 1.0000e-04
Loss = 1.7402e-01, PNorm = 45.1437, GNorm = 5.6221, lr_0 = 1.0000e-04
Validation rmse = 0.650993
Model 0 best validation rmse = 0.643107 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.708002
Ensemble test rmse = 0.708002
1-fold cross validation
	Seed 0 ==> test rmse = 0.708002
Overall test rmse = 0.708002 +/- 0.000000
Elapsed time = 0:10:03
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,125 | train size = 900 | val size = 112 | test size = 113
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7065e+00, PNorm = 43.3127, GNorm = 2.0549, lr_0 = 2.3750e-04
Loss = 1.5629e+00, PNorm = 43.3139, GNorm = 1.1861, lr_0 = 3.6250e-04
Loss = 1.4121e+00, PNorm = 43.3193, GNorm = 1.5849, lr_0 = 4.8750e-04
Validation rmse = 1.390929
Epoch 1
Loss = 1.2086e+00, PNorm = 43.3334, GNorm = 0.8612, lr_0 = 6.1250e-04
Loss = 1.3329e+00, PNorm = 43.3588, GNorm = 1.8097, lr_0 = 7.3750e-04
Loss = 1.2082e+00, PNorm = 43.3918, GNorm = 0.9666, lr_0 = 8.6250e-04
Loss = 1.0350e+00, PNorm = 43.4443, GNorm = 5.1015, lr_0 = 9.8750e-04
Validation rmse = 1.105226
Epoch 2
Loss = 1.0360e+00, PNorm = 43.5016, GNorm = 2.5940, lr_0 = 9.7965e-04
Loss = 8.6515e-01, PNorm = 43.5707, GNorm = 5.6492, lr_0 = 9.5753e-04
Loss = 8.2667e-01, PNorm = 43.6330, GNorm = 2.8253, lr_0 = 9.3590e-04
Validation rmse = 1.025835
Epoch 3
Loss = 8.6120e-01, PNorm = 43.6757, GNorm = 10.6103, lr_0 = 9.1476e-04
Loss = 7.2826e-01, PNorm = 43.7266, GNorm = 4.1578, lr_0 = 8.9411e-04
Loss = 8.0619e-01, PNorm = 43.7794, GNorm = 8.1570, lr_0 = 8.7391e-04
Loss = 6.6672e-01, PNorm = 43.8168, GNorm = 2.6189, lr_0 = 8.5418e-04
Validation rmse = 0.836040
Epoch 4
Loss = 5.9631e-01, PNorm = 43.8563, GNorm = 3.1386, lr_0 = 8.3489e-04
Loss = 6.5528e-01, PNorm = 43.8919, GNorm = 5.1263, lr_0 = 8.1603e-04
Loss = 7.6733e-01, PNorm = 43.9187, GNorm = 7.7080, lr_0 = 7.9760e-04
Loss = 6.7231e-01, PNorm = 43.9568, GNorm = 2.4345, lr_0 = 7.7959e-04
Validation rmse = 0.832302
Epoch 5
Loss = 6.3126e-01, PNorm = 43.9945, GNorm = 3.6867, lr_0 = 7.6198e-04
Loss = 6.2467e-01, PNorm = 44.0368, GNorm = 12.5752, lr_0 = 7.4477e-04
Loss = 5.9989e-01, PNorm = 44.0627, GNorm = 3.8245, lr_0 = 7.2795e-04
Validation rmse = 0.766722
Epoch 6
Loss = 4.6511e-01, PNorm = 44.0916, GNorm = 2.7189, lr_0 = 7.1151e-04
Loss = 5.0326e-01, PNorm = 44.1158, GNorm = 3.4989, lr_0 = 6.9544e-04
Loss = 5.0094e-01, PNorm = 44.1443, GNorm = 4.0575, lr_0 = 6.7974e-04
Loss = 5.9857e-01, PNorm = 44.1621, GNorm = 3.1502, lr_0 = 6.6439e-04
Validation rmse = 0.814811
Epoch 7
Loss = 6.1955e-01, PNorm = 44.1767, GNorm = 7.8303, lr_0 = 6.4938e-04
Loss = 4.9567e-01, PNorm = 44.2047, GNorm = 4.8986, lr_0 = 6.3472e-04
Loss = 5.7617e-01, PNorm = 44.2366, GNorm = 7.9032, lr_0 = 6.2038e-04
Validation rmse = 0.771459
Epoch 8
Loss = 2.2121e-01, PNorm = 44.2629, GNorm = 3.6796, lr_0 = 6.0637e-04
Loss = 4.0696e-01, PNorm = 44.2837, GNorm = 10.1237, lr_0 = 5.9268e-04
Loss = 4.9464e-01, PNorm = 44.2974, GNorm = 2.8455, lr_0 = 5.7929e-04
Loss = 4.7318e-01, PNorm = 44.3200, GNorm = 2.7565, lr_0 = 5.6621e-04
Validation rmse = 0.757270
Epoch 9
Loss = 4.0600e-01, PNorm = 44.3443, GNorm = 3.8190, lr_0 = 5.5342e-04
Loss = 3.7262e-01, PNorm = 44.3572, GNorm = 13.6430, lr_0 = 5.4092e-04
Loss = 3.5280e-01, PNorm = 44.3655, GNorm = 10.0034, lr_0 = 5.2871e-04
Loss = 4.9207e-01, PNorm = 44.3782, GNorm = 4.9652, lr_0 = 5.1677e-04
Validation rmse = 0.726648
Epoch 10
Loss = 3.7440e-01, PNorm = 44.4005, GNorm = 11.9863, lr_0 = 5.0509e-04
Loss = 3.0104e-01, PNorm = 44.4224, GNorm = 6.3027, lr_0 = 4.9369e-04
Loss = 4.2186e-01, PNorm = 44.4348, GNorm = 2.8733, lr_0 = 4.8254e-04
Validation rmse = 0.725497
Epoch 11
Loss = 2.0902e-01, PNorm = 44.4516, GNorm = 4.0500, lr_0 = 4.7164e-04
Loss = 2.9589e-01, PNorm = 44.4749, GNorm = 5.4975, lr_0 = 4.6099e-04
Loss = 3.4393e-01, PNorm = 44.4871, GNorm = 12.1420, lr_0 = 4.5058e-04
Loss = 4.3568e-01, PNorm = 44.4951, GNorm = 2.7967, lr_0 = 4.4040e-04
Validation rmse = 0.720155
Epoch 12
Loss = 3.0195e-01, PNorm = 44.5186, GNorm = 4.3130, lr_0 = 4.3046e-04
Loss = 3.6269e-01, PNorm = 44.5365, GNorm = 5.5865, lr_0 = 4.2073e-04
Loss = 3.0798e-01, PNorm = 44.5501, GNorm = 11.2071, lr_0 = 4.1123e-04
Validation rmse = 0.751243
Epoch 13
Loss = 7.7717e-02, PNorm = 44.5597, GNorm = 3.7553, lr_0 = 4.0195e-04
Loss = 2.9261e-01, PNorm = 44.5683, GNorm = 2.9018, lr_0 = 3.9287e-04
Loss = 3.5669e-01, PNorm = 44.5790, GNorm = 3.6721, lr_0 = 3.8399e-04
Loss = 2.4949e-01, PNorm = 44.5911, GNorm = 4.5833, lr_0 = 3.7532e-04
Validation rmse = 0.741840
Epoch 14
Loss = 2.0151e-01, PNorm = 44.6089, GNorm = 9.8917, lr_0 = 3.6685e-04
Loss = 3.2889e-01, PNorm = 44.6203, GNorm = 6.9824, lr_0 = 3.5856e-04
Loss = 3.2690e-01, PNorm = 44.6278, GNorm = 5.0370, lr_0 = 3.5046e-04
Loss = 3.1615e-01, PNorm = 44.6407, GNorm = 2.9006, lr_0 = 3.4255e-04
Validation rmse = 0.749684
Epoch 15
Loss = 3.2683e-01, PNorm = 44.6496, GNorm = 6.7048, lr_0 = 3.3481e-04
Loss = 4.3928e-01, PNorm = 44.6565, GNorm = 12.7697, lr_0 = 3.2725e-04
Loss = 3.8157e-01, PNorm = 44.6685, GNorm = 5.6768, lr_0 = 3.1986e-04
Validation rmse = 0.713303
Epoch 16
Loss = 2.5237e-01, PNorm = 44.6841, GNorm = 2.7424, lr_0 = 3.1264e-04
Loss = 3.2959e-01, PNorm = 44.6982, GNorm = 5.0561, lr_0 = 3.0558e-04
Loss = 1.6965e-01, PNorm = 44.7078, GNorm = 4.5079, lr_0 = 2.9867e-04
Loss = 2.7930e-01, PNorm = 44.7127, GNorm = 14.1547, lr_0 = 2.9193e-04
Validation rmse = 0.707643
Epoch 17
Loss = 2.8784e-01, PNorm = 44.7198, GNorm = 5.4173, lr_0 = 2.8534e-04
Loss = 2.1210e-01, PNorm = 44.7328, GNorm = 2.7669, lr_0 = 2.7889e-04
Loss = 2.0429e-01, PNorm = 44.7491, GNorm = 7.7861, lr_0 = 2.7259e-04
Validation rmse = 0.698704
Epoch 18
Loss = 9.2337e-02, PNorm = 44.7581, GNorm = 3.3843, lr_0 = 2.6644e-04
Loss = 2.3262e-01, PNorm = 44.7655, GNorm = 8.0985, lr_0 = 2.6042e-04
Loss = 2.5124e-01, PNorm = 44.7711, GNorm = 3.3445, lr_0 = 2.5454e-04
Loss = 1.7998e-01, PNorm = 44.7816, GNorm = 2.8934, lr_0 = 2.4879e-04
Validation rmse = 0.700719
Epoch 19
Loss = 1.4940e-01, PNorm = 44.7922, GNorm = 6.6903, lr_0 = 2.4317e-04
Loss = 1.5458e-01, PNorm = 44.8000, GNorm = 10.9970, lr_0 = 2.3768e-04
Loss = 1.7277e-01, PNorm = 44.8054, GNorm = 3.3939, lr_0 = 2.3231e-04
Loss = 2.6806e-01, PNorm = 44.8109, GNorm = 3.9378, lr_0 = 2.2707e-04
Validation rmse = 0.692259
Epoch 20
Loss = 2.2558e-01, PNorm = 44.8193, GNorm = 10.7328, lr_0 = 2.2194e-04
Loss = 2.2335e-01, PNorm = 44.8267, GNorm = 5.3403, lr_0 = 2.1692e-04
Loss = 2.3789e-01, PNorm = 44.8370, GNorm = 6.8849, lr_0 = 2.1203e-04
Validation rmse = 0.710280
Epoch 21
Loss = 1.0424e-01, PNorm = 44.8459, GNorm = 7.1747, lr_0 = 2.0724e-04
Loss = 1.0731e-01, PNorm = 44.8570, GNorm = 3.8875, lr_0 = 2.0256e-04
Loss = 2.2175e-01, PNorm = 44.8626, GNorm = 9.0689, lr_0 = 1.9798e-04
Loss = 1.7244e-01, PNorm = 44.8640, GNorm = 5.0605, lr_0 = 1.9351e-04
Validation rmse = 0.688994
Epoch 22
Loss = 6.3797e-02, PNorm = 44.8718, GNorm = 3.1723, lr_0 = 1.8914e-04
Loss = 1.5825e-01, PNorm = 44.8807, GNorm = 3.9759, lr_0 = 1.8487e-04
Loss = 1.9295e-01, PNorm = 44.8891, GNorm = 15.0034, lr_0 = 1.8069e-04
Validation rmse = 0.701643
Epoch 23
Loss = 1.6044e-01, PNorm = 44.8916, GNorm = 6.3421, lr_0 = 1.7661e-04
Loss = 1.4964e-01, PNorm = 44.8969, GNorm = 4.3225, lr_0 = 1.7262e-04
Loss = 1.4948e-01, PNorm = 44.9030, GNorm = 4.4416, lr_0 = 1.6873e-04
Loss = 1.0911e-01, PNorm = 44.9099, GNorm = 9.4152, lr_0 = 1.6492e-04
Validation rmse = 0.688531
Epoch 24
Loss = 1.1600e-01, PNorm = 44.9146, GNorm = 8.0848, lr_0 = 1.6119e-04
Loss = 1.2322e-01, PNorm = 44.9220, GNorm = 11.1342, lr_0 = 1.5755e-04
Loss = 1.6680e-01, PNorm = 44.9271, GNorm = 15.2390, lr_0 = 1.5399e-04
Loss = 1.3182e-01, PNorm = 44.9325, GNorm = 6.2404, lr_0 = 1.5051e-04
Validation rmse = 0.686882
Epoch 25
Loss = -6.4521e-03, PNorm = 44.9398, GNorm = 4.5395, lr_0 = 1.4712e-04
Loss = 1.5185e-01, PNorm = 44.9443, GNorm = 17.2590, lr_0 = 1.4379e-04
Loss = 2.1061e-01, PNorm = 44.9461, GNorm = 8.5624, lr_0 = 1.4055e-04
Validation rmse = 0.694626
Epoch 26
Loss = 6.9314e-02, PNorm = 44.9492, GNorm = 5.3884, lr_0 = 1.3737e-04
Loss = 1.4072e-01, PNorm = 44.9565, GNorm = 5.0814, lr_0 = 1.3427e-04
Loss = 9.7331e-02, PNorm = 44.9639, GNorm = 3.4557, lr_0 = 1.3124e-04
Loss = 9.7586e-02, PNorm = 44.9684, GNorm = 3.9923, lr_0 = 1.2827e-04
Validation rmse = 0.689698
Epoch 27
Loss = 5.1129e-02, PNorm = 44.9721, GNorm = 9.4931, lr_0 = 1.2538e-04
Loss = 1.0388e-02, PNorm = 44.9786, GNorm = 5.0350, lr_0 = 1.2254e-04
Loss = 1.1142e-01, PNorm = 44.9821, GNorm = 5.4137, lr_0 = 1.1978e-04
Validation rmse = 0.682326
Epoch 28
Loss = 2.0522e-01, PNorm = 44.9826, GNorm = 4.4181, lr_0 = 1.1707e-04
Loss = 1.4836e-01, PNorm = 44.9860, GNorm = 3.1227, lr_0 = 1.1443e-04
Loss = 1.2201e-02, PNorm = 44.9924, GNorm = 6.4946, lr_0 = 1.1184e-04
Loss = 6.6917e-02, PNorm = 44.9974, GNorm = 9.4657, lr_0 = 1.0932e-04
Validation rmse = 0.689646
Epoch 29
Loss = 3.8952e-02, PNorm = 45.0001, GNorm = 7.5285, lr_0 = 1.0685e-04
Loss = -2.6247e-02, PNorm = 45.0050, GNorm = 10.2757, lr_0 = 1.0444e-04
Loss = 2.0111e-01, PNorm = 45.0089, GNorm = 28.7482, lr_0 = 1.0208e-04
Loss = 9.7896e-02, PNorm = 45.0107, GNorm = 4.7670, lr_0 = 1.0000e-04
Validation rmse = 0.683896
Model 0 best validation rmse = 0.682326 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.634053
Ensemble test rmse = 0.634053
1-fold cross validation
	Seed 0 ==> test rmse = 0.634053
Overall test rmse = 0.634053 +/- 0.000000
Elapsed time = 0:01:30
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7861e+00, PNorm = 43.3121, GNorm = 2.2104, lr_0 = 2.3750e-04
Loss = 1.4954e+00, PNorm = 43.3136, GNorm = 1.1288, lr_0 = 3.6250e-04
Loss = 1.3876e+00, PNorm = 43.3203, GNorm = 0.7197, lr_0 = 4.8750e-04
Validation rmse = 1.369857
Epoch 1
Loss = 1.2672e+00, PNorm = 43.3355, GNorm = 1.3278, lr_0 = 6.2500e-04
Loss = 1.2309e+00, PNorm = 43.3607, GNorm = 1.6238, lr_0 = 7.5000e-04
Loss = 1.1489e+00, PNorm = 43.4014, GNorm = 4.9609, lr_0 = 8.7500e-04
Loss = 1.0441e+00, PNorm = 43.4535, GNorm = 7.4685, lr_0 = 1.0000e-03
Validation rmse = 1.227709
Epoch 2
Loss = 9.9580e-01, PNorm = 43.5100, GNorm = 5.8149, lr_0 = 9.7742e-04
Loss = 8.5979e-01, PNorm = 43.5714, GNorm = 10.6768, lr_0 = 9.5534e-04
Loss = 9.0821e-01, PNorm = 43.6256, GNorm = 6.4100, lr_0 = 9.3377e-04
Loss = 7.5201e-01, PNorm = 43.6883, GNorm = 11.7640, lr_0 = 9.1268e-04
Validation rmse = 0.995067
Epoch 3
Loss = 8.1379e-01, PNorm = 43.7370, GNorm = 1.8286, lr_0 = 8.9207e-04
Loss = 7.4062e-01, PNorm = 43.7785, GNorm = 11.8889, lr_0 = 8.7192e-04
Loss = 6.2275e-01, PNorm = 43.8269, GNorm = 8.4610, lr_0 = 8.5223e-04
Validation rmse = 0.896073
Epoch 4
Loss = 6.8266e-01, PNorm = 43.8651, GNorm = 5.6727, lr_0 = 8.3298e-04
Loss = 6.3300e-01, PNorm = 43.9049, GNorm = 2.5422, lr_0 = 8.1417e-04
Loss = 6.4941e-01, PNorm = 43.9344, GNorm = 4.5529, lr_0 = 7.9578e-04
Loss = 5.4964e-01, PNorm = 43.9663, GNorm = 3.6404, lr_0 = 7.7781e-04
Validation rmse = 0.898682
Epoch 5
Loss = 4.6227e-01, PNorm = 43.9794, GNorm = 2.9799, lr_0 = 7.6024e-04
Loss = 5.0001e-01, PNorm = 44.0112, GNorm = 4.0287, lr_0 = 7.4307e-04
Loss = 6.0688e-01, PNorm = 44.0364, GNorm = 3.5833, lr_0 = 7.2629e-04
Loss = 4.8797e-01, PNorm = 44.0605, GNorm = 14.3329, lr_0 = 7.0989e-04
Loss = 7.4156e-01, PNorm = 44.0623, GNorm = 6.0333, lr_0 = 7.0827e-04
Validation rmse = 0.788314
Epoch 6
Loss = 4.9836e-01, PNorm = 44.0880, GNorm = 5.6425, lr_0 = 6.9227e-04
Loss = 5.1974e-01, PNorm = 44.1147, GNorm = 5.4484, lr_0 = 6.7664e-04
Loss = 5.5318e-01, PNorm = 44.1391, GNorm = 3.9943, lr_0 = 6.6136e-04
Validation rmse = 0.805474
Epoch 7
Loss = 4.1583e-01, PNorm = 44.1680, GNorm = 6.4682, lr_0 = 6.4642e-04
Loss = 4.4759e-01, PNorm = 44.1801, GNorm = 2.6616, lr_0 = 6.3182e-04
Loss = 4.7931e-01, PNorm = 44.2101, GNorm = 8.3967, lr_0 = 6.1755e-04
Loss = 4.2709e-01, PNorm = 44.2303, GNorm = 2.7097, lr_0 = 6.0361e-04
Validation rmse = 0.749061
Epoch 8
Loss = 3.2997e-01, PNorm = 44.2509, GNorm = 2.7274, lr_0 = 5.8997e-04
Loss = 4.2353e-01, PNorm = 44.2684, GNorm = 6.6154, lr_0 = 5.7665e-04
Loss = 3.6209e-01, PNorm = 44.2837, GNorm = 8.5263, lr_0 = 5.6363e-04
Loss = 3.9350e-01, PNorm = 44.3023, GNorm = 16.6971, lr_0 = 5.5090e-04
Validation rmse = 0.735030
Epoch 9
Loss = 4.4674e-01, PNorm = 44.3219, GNorm = 5.9933, lr_0 = 5.3846e-04
Loss = 4.2761e-01, PNorm = 44.3410, GNorm = 6.5256, lr_0 = 5.2630e-04
Loss = 4.7450e-01, PNorm = 44.3597, GNorm = 6.3759, lr_0 = 5.1441e-04
Validation rmse = 0.739094
Epoch 10
Loss = 2.1083e-01, PNorm = 44.3826, GNorm = 7.4921, lr_0 = 5.0279e-04
Loss = 3.6603e-01, PNorm = 44.4034, GNorm = 7.2571, lr_0 = 4.9144e-04
Loss = 4.1976e-01, PNorm = 44.4169, GNorm = 3.5102, lr_0 = 4.8034e-04
Loss = 3.6042e-01, PNorm = 44.4335, GNorm = 2.6091, lr_0 = 4.6949e-04
Validation rmse = 0.724944
Epoch 11
Loss = 3.1593e-01, PNorm = 44.4544, GNorm = 7.5104, lr_0 = 4.5784e-04
Loss = 2.9734e-01, PNorm = 44.4685, GNorm = 3.6232, lr_0 = 4.4750e-04
Loss = 3.5684e-01, PNorm = 44.4798, GNorm = 6.4252, lr_0 = 4.3739e-04
Loss = 3.9491e-01, PNorm = 44.4921, GNorm = 5.4881, lr_0 = 4.2752e-04
Validation rmse = 0.706130
Epoch 12
Loss = 2.8420e-01, PNorm = 44.5065, GNorm = 4.3212, lr_0 = 4.1786e-04
Loss = 3.9944e-01, PNorm = 44.5199, GNorm = 16.7036, lr_0 = 4.0842e-04
Loss = 4.3392e-01, PNorm = 44.5329, GNorm = 10.2462, lr_0 = 3.9920e-04
Validation rmse = 0.707006
Epoch 13
Loss = 4.6179e-01, PNorm = 44.5483, GNorm = 3.5832, lr_0 = 3.9018e-04
Loss = 2.7995e-01, PNorm = 44.5667, GNorm = 4.1080, lr_0 = 3.8137e-04
Loss = 2.7292e-01, PNorm = 44.5823, GNorm = 9.3672, lr_0 = 3.7276e-04
Loss = 3.4057e-01, PNorm = 44.5906, GNorm = 5.3996, lr_0 = 3.6434e-04
Validation rmse = 0.707086
Epoch 14
Loss = 2.2888e-01, PNorm = 44.6039, GNorm = 3.3284, lr_0 = 3.5611e-04
Loss = 2.4455e-01, PNorm = 44.6216, GNorm = 2.7684, lr_0 = 3.4807e-04
Loss = 2.7106e-01, PNorm = 44.6354, GNorm = 2.7713, lr_0 = 3.4021e-04
Loss = 3.4928e-01, PNorm = 44.6417, GNorm = 10.7710, lr_0 = 3.3253e-04
Validation rmse = 0.701231
Epoch 15
Loss = 2.4115e-01, PNorm = 44.6501, GNorm = 2.9296, lr_0 = 3.2502e-04
Loss = 1.9628e-01, PNorm = 44.6604, GNorm = 6.2517, lr_0 = 3.1768e-04
Loss = 3.0516e-01, PNorm = 44.6727, GNorm = 13.6878, lr_0 = 3.1050e-04
Validation rmse = 0.731266
Epoch 16
Loss = 1.7545e-01, PNorm = 44.6815, GNorm = 6.9929, lr_0 = 3.0280e-04
Loss = 2.7801e-01, PNorm = 44.6902, GNorm = 4.8305, lr_0 = 2.9596e-04
Loss = 1.9426e-01, PNorm = 44.7041, GNorm = 15.9310, lr_0 = 2.8927e-04
Loss = 2.4248e-01, PNorm = 44.7119, GNorm = 8.3711, lr_0 = 2.8274e-04
Validation rmse = 0.679427
Epoch 17
Loss = 1.5987e-01, PNorm = 44.7201, GNorm = 6.3496, lr_0 = 2.7636e-04
Loss = 2.1739e-01, PNorm = 44.7318, GNorm = 13.1221, lr_0 = 2.7011e-04
Loss = 2.4856e-01, PNorm = 44.7395, GNorm = 15.1332, lr_0 = 2.6401e-04
Loss = 2.2043e-01, PNorm = 44.7497, GNorm = 2.8285, lr_0 = 2.5805e-04
Validation rmse = 0.743258
Epoch 18
Loss = 2.3322e-01, PNorm = 44.7580, GNorm = 10.3631, lr_0 = 2.5222e-04
Loss = 2.2367e-01, PNorm = 44.7695, GNorm = 3.3016, lr_0 = 2.4653e-04
Loss = 1.4398e-01, PNorm = 44.7766, GNorm = 5.8814, lr_0 = 2.4096e-04
Validation rmse = 0.741474
Epoch 19
Loss = 1.2242e-02, PNorm = 44.7802, GNorm = 5.6762, lr_0 = 2.3552e-04
Loss = 1.9588e-01, PNorm = 44.7878, GNorm = 6.4264, lr_0 = 2.3020e-04
Loss = 1.8709e-01, PNorm = 44.7976, GNorm = 2.9535, lr_0 = 2.2500e-04
Loss = 1.7726e-01, PNorm = 44.8066, GNorm = 5.9402, lr_0 = 2.1992e-04
Validation rmse = 0.698732
Epoch 20
Loss = 8.5428e-02, PNorm = 44.8145, GNorm = 6.2106, lr_0 = 2.1495e-04
Loss = 1.2346e-01, PNorm = 44.8227, GNorm = 5.5580, lr_0 = 2.1010e-04
Loss = 1.8481e-01, PNorm = 44.8272, GNorm = 10.5702, lr_0 = 2.0535e-04
Loss = 2.6459e-01, PNorm = 44.8324, GNorm = 4.6738, lr_0 = 2.0071e-04
Validation rmse = 0.738011
Epoch 21
Loss = 2.0723e-01, PNorm = 44.8394, GNorm = 4.0519, lr_0 = 1.9573e-04
Loss = 1.2221e-01, PNorm = 44.8485, GNorm = 8.6715, lr_0 = 1.9131e-04
Loss = 2.1588e-01, PNorm = 44.8530, GNorm = 4.1255, lr_0 = 1.8699e-04
Validation rmse = 0.663285
Epoch 22
Loss = 8.8997e-02, PNorm = 44.8587, GNorm = 3.2242, lr_0 = 1.8277e-04
Loss = 2.0461e-01, PNorm = 44.8648, GNorm = 6.8848, lr_0 = 1.7864e-04
Loss = 1.1991e-01, PNorm = 44.8726, GNorm = 5.2074, lr_0 = 1.7461e-04
Loss = 2.7123e-01, PNorm = 44.8772, GNorm = 3.3189, lr_0 = 1.7066e-04
Validation rmse = 0.666791
Epoch 23
Loss = 1.9930e-01, PNorm = 44.8835, GNorm = 4.4326, lr_0 = 1.6681e-04
Loss = 5.7780e-02, PNorm = 44.8926, GNorm = 15.3461, lr_0 = 1.6304e-04
Loss = 1.9304e-01, PNorm = 44.8980, GNorm = 7.4952, lr_0 = 1.5936e-04
Loss = 2.5305e-01, PNorm = 44.9010, GNorm = 15.0077, lr_0 = 1.5576e-04
Validation rmse = 0.658765
Epoch 24
Loss = 8.3853e-02, PNorm = 44.9066, GNorm = 7.3979, lr_0 = 1.5224e-04
Loss = 5.5871e-02, PNorm = 44.9146, GNorm = 6.8471, lr_0 = 1.4881e-04
Loss = 1.5436e-01, PNorm = 44.9208, GNorm = 6.7610, lr_0 = 1.4544e-04
Loss = 2.8111e-01, PNorm = 44.9233, GNorm = 12.8526, lr_0 = 1.4216e-04
Validation rmse = 0.666051
Epoch 25
Loss = 1.9924e-01, PNorm = 44.9235, GNorm = 10.4636, lr_0 = 1.3895e-04
Loss = 1.4363e-01, PNorm = 44.9298, GNorm = 7.4078, lr_0 = 1.3581e-04
Loss = 1.3278e-01, PNorm = 44.9351, GNorm = 5.3480, lr_0 = 1.3274e-04
Validation rmse = 0.663876
Epoch 26
Loss = 4.0783e-02, PNorm = 44.9422, GNorm = 4.8264, lr_0 = 1.2945e-04
Loss = 1.1295e-01, PNorm = 44.9463, GNorm = 4.3241, lr_0 = 1.2653e-04
Loss = 1.2917e-01, PNorm = 44.9496, GNorm = 18.6529, lr_0 = 1.2367e-04
Loss = 1.5990e-01, PNorm = 44.9533, GNorm = 8.5641, lr_0 = 1.2088e-04
Validation rmse = 0.661093
Epoch 27
Loss = 1.6521e-01, PNorm = 44.9570, GNorm = 3.7026, lr_0 = 1.1815e-04
Loss = 5.5620e-02, PNorm = 44.9614, GNorm = 7.0770, lr_0 = 1.1548e-04
Loss = 8.6362e-02, PNorm = 44.9677, GNorm = 9.9888, lr_0 = 1.1287e-04
Loss = 1.3929e-01, PNorm = 44.9712, GNorm = 4.7653, lr_0 = 1.1032e-04
Validation rmse = 0.657086
Epoch 28
Loss = 1.0664e-01, PNorm = 44.9748, GNorm = 8.1843, lr_0 = 1.0783e-04
Loss = 1.1377e-01, PNorm = 44.9785, GNorm = 12.0648, lr_0 = 1.0539e-04
Loss = 1.0071e-01, PNorm = 44.9824, GNorm = 6.0715, lr_0 = 1.0301e-04
Validation rmse = 0.664348
Epoch 29
Loss = 7.8485e-02, PNorm = 44.9856, GNorm = 5.1197, lr_0 = 1.0069e-04
Loss = 5.2202e-02, PNorm = 44.9889, GNorm = 6.8943, lr_0 = 1.0000e-04
Loss = 5.4741e-02, PNorm = 44.9921, GNorm = 4.7136, lr_0 = 1.0000e-04
Loss = 1.5344e-01, PNorm = 44.9944, GNorm = 6.5800, lr_0 = 1.0000e-04
Validation rmse = 0.653350
Model 0 best validation rmse = 0.653350 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.614790
Ensemble test rmse = 0.614790
1-fold cross validation
	Seed 0 ==> test rmse = 0.614790
Overall test rmse = 0.614790 +/- 0.000000
Elapsed time = 0:01:31
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,175 | train size = 940 | val size = 117 | test size = 118
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8415e+00, PNorm = 43.3126, GNorm = 4.4848, lr_0 = 2.3378e-04
Loss = 1.4856e+00, PNorm = 43.3152, GNorm = 1.6995, lr_0 = 3.5541e-04
Loss = 1.4477e+00, PNorm = 43.3212, GNorm = 1.4861, lr_0 = 4.7703e-04
Validation rmse = 1.550632
Epoch 1
Loss = 1.1645e+00, PNorm = 43.3363, GNorm = 1.6382, lr_0 = 6.1081e-04
Loss = 1.2368e+00, PNorm = 43.3602, GNorm = 2.2880, lr_0 = 7.3243e-04
Loss = 1.1834e+00, PNorm = 43.3895, GNorm = 1.5767, lr_0 = 8.5405e-04
Loss = 1.0636e+00, PNorm = 43.4349, GNorm = 2.2632, lr_0 = 9.7568e-04
Validation rmse = 1.415196
Epoch 2
Loss = 1.2084e+00, PNorm = 43.4942, GNorm = 1.8816, lr_0 = 9.8238e-04
Loss = 1.1210e+00, PNorm = 43.5568, GNorm = 1.6415, lr_0 = 9.6078e-04
Loss = 9.7212e-01, PNorm = 43.6260, GNorm = 4.3083, lr_0 = 9.3966e-04
Loss = 7.6624e-01, PNorm = 43.6838, GNorm = 3.0714, lr_0 = 9.1901e-04
Validation rmse = 1.029376
Epoch 3
Loss = 7.9815e-01, PNorm = 43.7415, GNorm = 3.2320, lr_0 = 8.9681e-04
Loss = 7.5549e-01, PNorm = 43.7920, GNorm = 2.3521, lr_0 = 8.7710e-04
Loss = 6.6595e-01, PNorm = 43.8381, GNorm = 6.0023, lr_0 = 8.5782e-04
Loss = 7.1069e-01, PNorm = 43.8758, GNorm = 3.1698, lr_0 = 8.3897e-04
Validation rmse = 0.887988
Epoch 4
Loss = 6.2003e-01, PNorm = 43.9183, GNorm = 4.6356, lr_0 = 8.2053e-04
Loss = 5.4468e-01, PNorm = 43.9550, GNorm = 8.6662, lr_0 = 8.0249e-04
Loss = 6.1839e-01, PNorm = 43.9840, GNorm = 1.6957, lr_0 = 7.8485e-04
Validation rmse = 0.862832
Epoch 5
Loss = 6.0121e-01, PNorm = 44.0294, GNorm = 7.6598, lr_0 = 7.6760e-04
Loss = 6.7509e-01, PNorm = 44.0417, GNorm = 1.8758, lr_0 = 7.5073e-04
Loss = 5.5953e-01, PNorm = 44.0749, GNorm = 3.3805, lr_0 = 7.3423e-04
Loss = 4.5525e-01, PNorm = 44.1102, GNorm = 7.1012, lr_0 = 7.1809e-04
Validation rmse = 0.909548
Epoch 6
Loss = 5.1436e-01, PNorm = 44.1483, GNorm = 6.2388, lr_0 = 7.0074e-04
Loss = 5.2864e-01, PNorm = 44.1739, GNorm = 6.4918, lr_0 = 6.8534e-04
Loss = 4.6178e-01, PNorm = 44.2052, GNorm = 5.7786, lr_0 = 6.7028e-04
Loss = 4.9421e-01, PNorm = 44.2311, GNorm = 7.9947, lr_0 = 6.5554e-04
Validation rmse = 0.798963
Epoch 7
Loss = 3.0549e-01, PNorm = 44.2546, GNorm = 4.1119, lr_0 = 6.4114e-04
Loss = 4.3657e-01, PNorm = 44.2792, GNorm = 9.9038, lr_0 = 6.2704e-04
Loss = 6.1983e-01, PNorm = 44.3052, GNorm = 3.0317, lr_0 = 6.1326e-04
Loss = 5.2454e-01, PNorm = 44.3258, GNorm = 12.3761, lr_0 = 5.9978e-04
Loss = 3.4026e-01, PNorm = 44.3272, GNorm = 10.1721, lr_0 = 5.9845e-04
Validation rmse = 0.762378
Epoch 8
Loss = 4.1766e-01, PNorm = 44.3432, GNorm = 3.5833, lr_0 = 5.8529e-04
Loss = 4.2601e-01, PNorm = 44.3679, GNorm = 13.0091, lr_0 = 5.7243e-04
Loss = 4.2841e-01, PNorm = 44.3739, GNorm = 2.3144, lr_0 = 5.5985e-04
Validation rmse = 0.752444
Epoch 9
Loss = 2.9023e-01, PNorm = 44.3982, GNorm = 2.6073, lr_0 = 5.4754e-04
Loss = 3.7803e-01, PNorm = 44.4155, GNorm = 8.0397, lr_0 = 5.3551e-04
Loss = 5.2710e-01, PNorm = 44.4341, GNorm = 5.9775, lr_0 = 5.2374e-04
Loss = 4.2232e-01, PNorm = 44.4555, GNorm = 5.1595, lr_0 = 5.1222e-04
Validation rmse = 0.766270
Epoch 10
Loss = 4.2138e-01, PNorm = 44.4677, GNorm = 4.5216, lr_0 = 5.0096e-04
Loss = 3.7396e-01, PNorm = 44.4898, GNorm = 4.8412, lr_0 = 4.8995e-04
Loss = 3.0506e-01, PNorm = 44.5106, GNorm = 9.2527, lr_0 = 4.7918e-04
Loss = 3.6192e-01, PNorm = 44.5210, GNorm = 5.4495, lr_0 = 4.6865e-04
Validation rmse = 0.758313
Epoch 11
Loss = 2.5517e-01, PNorm = 44.5366, GNorm = 9.6962, lr_0 = 4.5733e-04
Loss = 4.2540e-01, PNorm = 44.5498, GNorm = 12.4668, lr_0 = 4.4728e-04
Loss = 3.2325e-01, PNorm = 44.5699, GNorm = 2.4818, lr_0 = 4.3745e-04
Loss = 3.4070e-01, PNorm = 44.5851, GNorm = 5.5278, lr_0 = 4.2783e-04
Validation rmse = 0.773093
Epoch 12
Loss = 3.2517e-01, PNorm = 44.5982, GNorm = 30.0060, lr_0 = 4.1843e-04
Loss = 3.8421e-01, PNorm = 44.6125, GNorm = 10.0404, lr_0 = 4.0923e-04
Loss = 4.4656e-01, PNorm = 44.6276, GNorm = 2.6077, lr_0 = 4.0024e-04
Validation rmse = 0.718211
Epoch 13
Loss = 3.5121e-01, PNorm = 44.6460, GNorm = 3.2855, lr_0 = 3.9057e-04
Loss = 2.4437e-01, PNorm = 44.6632, GNorm = 4.5586, lr_0 = 3.8199e-04
Loss = 3.0385e-01, PNorm = 44.6773, GNorm = 6.4073, lr_0 = 3.7359e-04
Loss = 2.3377e-01, PNorm = 44.6865, GNorm = 6.1125, lr_0 = 3.6538e-04
Validation rmse = 0.709760
Epoch 14
Loss = 1.4945e-01, PNorm = 44.6938, GNorm = 4.7789, lr_0 = 3.5735e-04
Loss = 2.6801e-01, PNorm = 44.7085, GNorm = 4.1146, lr_0 = 3.4949e-04
Loss = 2.0948e-01, PNorm = 44.7176, GNorm = 3.4995, lr_0 = 3.4181e-04
Loss = 2.7690e-01, PNorm = 44.7270, GNorm = 4.8488, lr_0 = 3.3430e-04
Validation rmse = 0.732251
Epoch 15
Loss = 2.0730e-01, PNorm = 44.7378, GNorm = 9.2354, lr_0 = 3.2695e-04
Loss = 2.1637e-01, PNorm = 44.7521, GNorm = 4.4870, lr_0 = 3.1976e-04
Loss = 3.3137e-01, PNorm = 44.7650, GNorm = 10.5208, lr_0 = 3.1273e-04
Loss = 3.1876e-01, PNorm = 44.7754, GNorm = 5.4996, lr_0 = 3.0586e-04
Validation rmse = 0.726139
Epoch 16
Loss = 2.1489e-01, PNorm = 44.7890, GNorm = 8.9762, lr_0 = 2.9847e-04
Loss = 2.4690e-01, PNorm = 44.8015, GNorm = 7.4648, lr_0 = 2.9191e-04
Loss = 2.9546e-01, PNorm = 44.8066, GNorm = 4.4497, lr_0 = 2.8549e-04
Validation rmse = 0.737914
Epoch 17
Loss = 7.7902e-02, PNorm = 44.8174, GNorm = 4.6383, lr_0 = 2.7922e-04
Loss = 2.6732e-01, PNorm = 44.8298, GNorm = 7.3068, lr_0 = 2.7308e-04
Loss = 1.6791e-01, PNorm = 44.8398, GNorm = 5.3622, lr_0 = 2.6708e-04
Loss = 1.9108e-01, PNorm = 44.8484, GNorm = 5.4860, lr_0 = 2.6121e-04
Validation rmse = 0.708390
Epoch 18
Loss = 1.8747e-01, PNorm = 44.8595, GNorm = 5.4119, lr_0 = 2.5490e-04
Loss = 1.4716e-01, PNorm = 44.8677, GNorm = 5.6471, lr_0 = 2.4930e-04
Loss = 1.7134e-01, PNorm = 44.8796, GNorm = 5.4400, lr_0 = 2.4382e-04
Loss = 2.1581e-01, PNorm = 44.8864, GNorm = 7.1807, lr_0 = 2.3846e-04
Validation rmse = 0.744601
Epoch 19
Loss = 1.7957e-01, PNorm = 44.8924, GNorm = 10.4402, lr_0 = 2.3322e-04
Loss = 1.3083e-01, PNorm = 44.9003, GNorm = 10.2791, lr_0 = 2.2809e-04
Loss = 1.8977e-01, PNorm = 44.9115, GNorm = 5.1811, lr_0 = 2.2308e-04
Loss = 1.8804e-01, PNorm = 44.9183, GNorm = 3.2263, lr_0 = 2.1817e-04
Validation rmse = 0.708013
Epoch 20
Loss = 1.6914e-01, PNorm = 44.9239, GNorm = 3.6493, lr_0 = 2.1338e-04
Loss = 1.9752e-01, PNorm = 44.9302, GNorm = 14.5482, lr_0 = 2.0869e-04
Loss = 1.0909e-01, PNorm = 44.9391, GNorm = 15.2615, lr_0 = 2.0410e-04
Validation rmse = 0.695472
Epoch 21
Loss = -1.1851e-01, PNorm = 44.9462, GNorm = 3.5175, lr_0 = 1.9917e-04
Loss = 1.4626e-01, PNorm = 44.9560, GNorm = 4.4343, lr_0 = 1.9479e-04
Loss = 1.3797e-01, PNorm = 44.9625, GNorm = 3.9444, lr_0 = 1.9051e-04
Loss = 1.5597e-01, PNorm = 44.9716, GNorm = 9.5287, lr_0 = 1.8632e-04
Validation rmse = 0.686501
Epoch 22
Loss = -5.3122e-02, PNorm = 44.9729, GNorm = 9.6951, lr_0 = 1.8223e-04
Loss = 2.2383e-01, PNorm = 44.9779, GNorm = 13.3775, lr_0 = 1.7822e-04
Loss = 1.5301e-01, PNorm = 44.9838, GNorm = 11.5165, lr_0 = 1.7431e-04
Loss = 1.1127e-01, PNorm = 44.9907, GNorm = 5.6225, lr_0 = 1.7047e-04
Validation rmse = 0.685188
Epoch 23
Loss = 1.8406e-01, PNorm = 44.9974, GNorm = 6.6435, lr_0 = 1.6636e-04
Loss = 1.3543e-01, PNorm = 45.0045, GNorm = 4.0820, lr_0 = 1.6270e-04
Loss = 1.1905e-01, PNorm = 45.0111, GNorm = 5.1788, lr_0 = 1.5912e-04
Loss = 7.6715e-02, PNorm = 45.0174, GNorm = 5.3833, lr_0 = 1.5563e-04
Validation rmse = 0.733230
Epoch 24
Loss = 1.0041e-01, PNorm = 45.0236, GNorm = 5.2114, lr_0 = 1.5221e-04
Loss = 1.0965e-01, PNorm = 45.0288, GNorm = 11.2883, lr_0 = 1.4886e-04
Loss = 1.9579e-01, PNorm = 45.0334, GNorm = 10.9281, lr_0 = 1.4559e-04
Loss = 6.8745e-02, PNorm = 45.0381, GNorm = 9.2850, lr_0 = 1.4239e-04
Validation rmse = 0.693718
Epoch 25
Loss = 8.5529e-02, PNorm = 45.0435, GNorm = 3.6237, lr_0 = 1.3926e-04
Loss = 2.2749e-02, PNorm = 45.0504, GNorm = 4.1465, lr_0 = 1.3620e-04
Loss = 1.4317e-01, PNorm = 45.0548, GNorm = 7.2197, lr_0 = 1.3320e-04
Validation rmse = 0.684403
Epoch 26
Loss = 1.8612e-01, PNorm = 45.0568, GNorm = 6.9039, lr_0 = 1.2999e-04
Loss = 2.0190e-02, PNorm = 45.0630, GNorm = 11.3921, lr_0 = 1.2713e-04
Loss = -8.4217e-03, PNorm = 45.0686, GNorm = 6.2446, lr_0 = 1.2434e-04
Loss = 1.5453e-01, PNorm = 45.0714, GNorm = 4.0335, lr_0 = 1.2160e-04
Validation rmse = 0.688184
Epoch 27
Loss = 4.8324e-03, PNorm = 45.0739, GNorm = 4.2193, lr_0 = 1.1893e-04
Loss = 6.2501e-02, PNorm = 45.0792, GNorm = 3.4572, lr_0 = 1.1632e-04
Loss = 3.6891e-02, PNorm = 45.0852, GNorm = 5.0271, lr_0 = 1.1376e-04
Loss = 1.1994e-01, PNorm = 45.0897, GNorm = 25.0311, lr_0 = 1.1126e-04
Validation rmse = 0.710151
Epoch 28
Loss = 4.8917e-02, PNorm = 45.0929, GNorm = 18.3877, lr_0 = 1.0857e-04
Loss = 1.7188e-01, PNorm = 45.0955, GNorm = 3.7986, lr_0 = 1.0618e-04
Loss = 5.0683e-02, PNorm = 45.1006, GNorm = 9.5878, lr_0 = 1.0385e-04
Loss = -1.2656e-02, PNorm = 45.1055, GNorm = 4.7689, lr_0 = 1.0157e-04
Validation rmse = 0.687005
Epoch 29
Loss = -2.9037e-02, PNorm = 45.1097, GNorm = 6.8149, lr_0 = 1.0000e-04
Loss = 9.5886e-02, PNorm = 45.1121, GNorm = 10.5119, lr_0 = 1.0000e-04
Loss = 1.4281e-01, PNorm = 45.1140, GNorm = 6.5090, lr_0 = 1.0000e-04
Validation rmse = 0.689194
Model 0 best validation rmse = 0.684403 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.648095
Ensemble test rmse = 0.648095
1-fold cross validation
	Seed 0 ==> test rmse = 0.648095
Overall test rmse = 0.648095 +/- 0.000000
Elapsed time = 0:01:33
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7596e+00, PNorm = 43.3132, GNorm = 3.9488, lr_0 = 2.3026e-04
Loss = 1.4076e+00, PNorm = 43.3169, GNorm = 1.7686, lr_0 = 3.4868e-04
Loss = 1.3865e+00, PNorm = 43.3247, GNorm = 1.2697, lr_0 = 4.6711e-04
Validation rmse = 1.536387
Epoch 1
Loss = 1.2645e+00, PNorm = 43.3407, GNorm = 2.2884, lr_0 = 5.9737e-04
Loss = 1.1982e+00, PNorm = 43.3648, GNorm = 1.1303, lr_0 = 7.1579e-04
Loss = 1.0896e+00, PNorm = 43.4062, GNorm = 2.1831, lr_0 = 8.3421e-04
Loss = 1.0417e+00, PNorm = 43.4545, GNorm = 2.2169, lr_0 = 9.5263e-04
Validation rmse = 1.065250
Epoch 2
Loss = 8.5810e-01, PNorm = 43.5293, GNorm = 2.7221, lr_0 = 9.8497e-04
Loss = 1.0084e+00, PNorm = 43.5821, GNorm = 1.8943, lr_0 = 9.6388e-04
Loss = 9.2026e-01, PNorm = 43.6338, GNorm = 1.7116, lr_0 = 9.4324e-04
Loss = 8.0392e-01, PNorm = 43.6908, GNorm = 5.2969, lr_0 = 9.2305e-04
Validation rmse = 0.861340
Epoch 3
Loss = 6.1763e-01, PNorm = 43.7399, GNorm = 3.1331, lr_0 = 9.0329e-04
Loss = 5.8564e-01, PNorm = 43.7842, GNorm = 4.8027, lr_0 = 8.8395e-04
Loss = 8.9199e-01, PNorm = 43.8131, GNorm = 3.3533, lr_0 = 8.6503e-04
Loss = 6.3937e-01, PNorm = 43.8555, GNorm = 2.3231, lr_0 = 8.4651e-04
Validation rmse = 0.817993
Epoch 4
Loss = 7.2780e-01, PNorm = 43.8949, GNorm = 10.5360, lr_0 = 8.2660e-04
Loss = 6.2760e-01, PNorm = 43.9360, GNorm = 3.6605, lr_0 = 8.0890e-04
Loss = 7.1363e-01, PNorm = 43.9678, GNorm = 9.0443, lr_0 = 7.9158e-04
Loss = 5.7475e-01, PNorm = 44.0023, GNorm = 6.4504, lr_0 = 7.7464e-04
Validation rmse = 0.837987
Epoch 5
Loss = 4.7442e-01, PNorm = 44.0374, GNorm = 4.5869, lr_0 = 7.5805e-04
Loss = 4.9944e-01, PNorm = 44.0683, GNorm = 12.3521, lr_0 = 7.4182e-04
Loss = 4.9504e-01, PNorm = 44.0919, GNorm = 4.3508, lr_0 = 7.2594e-04
Loss = 6.2986e-01, PNorm = 44.1072, GNorm = 2.1172, lr_0 = 7.1040e-04
Loss = 3.3082e-01, PNorm = 44.1093, GNorm = 3.4283, lr_0 = 7.0887e-04
Validation rmse = 0.788598
Epoch 6
Loss = 4.4252e-01, PNorm = 44.1450, GNorm = 4.2303, lr_0 = 6.9369e-04
Loss = 5.1457e-01, PNorm = 44.1695, GNorm = 5.9453, lr_0 = 6.7884e-04
Loss = 4.9568e-01, PNorm = 44.1912, GNorm = 4.1604, lr_0 = 6.6431e-04
Validation rmse = 0.903805
Epoch 7
Loss = 5.3787e-01, PNorm = 44.2151, GNorm = 5.6486, lr_0 = 6.4868e-04
Loss = 2.6249e-01, PNorm = 44.2400, GNorm = 4.1776, lr_0 = 6.3479e-04
Loss = 5.7256e-01, PNorm = 44.2634, GNorm = 3.7922, lr_0 = 6.2120e-04
Loss = 5.1996e-01, PNorm = 44.2909, GNorm = 6.2923, lr_0 = 6.0790e-04
Validation rmse = 0.783174
Epoch 8
Loss = 3.6095e-01, PNorm = 44.3106, GNorm = 3.6684, lr_0 = 5.9489e-04
Loss = 3.5800e-01, PNorm = 44.3314, GNorm = 8.0976, lr_0 = 5.8215e-04
Loss = 3.8501e-01, PNorm = 44.3516, GNorm = 8.8666, lr_0 = 5.6969e-04
Loss = 4.7830e-01, PNorm = 44.3664, GNorm = 6.6273, lr_0 = 5.5749e-04
Validation rmse = 0.799653
Epoch 9
Loss = 3.7737e-01, PNorm = 44.3900, GNorm = 3.9778, lr_0 = 5.4438e-04
Loss = 3.6982e-01, PNorm = 44.4123, GNorm = 8.9798, lr_0 = 5.3273e-04
Loss = 4.0199e-01, PNorm = 44.4350, GNorm = 9.6537, lr_0 = 5.2132e-04
Loss = 4.3252e-01, PNorm = 44.4527, GNorm = 11.0253, lr_0 = 5.1016e-04
Validation rmse = 0.846083
Epoch 10
Loss = 4.1521e-01, PNorm = 44.4763, GNorm = 5.4626, lr_0 = 4.9924e-04
Loss = 3.5039e-01, PNorm = 44.4999, GNorm = 3.0063, lr_0 = 4.8855e-04
Loss = 2.4473e-01, PNorm = 44.5178, GNorm = 4.0410, lr_0 = 4.7809e-04
Loss = 4.2467e-01, PNorm = 44.5279, GNorm = 4.2495, lr_0 = 4.6786e-04
Validation rmse = 0.718653
Epoch 11
Loss = 3.3635e-01, PNorm = 44.5455, GNorm = 4.5958, lr_0 = 4.5685e-04
Loss = 2.3029e-01, PNorm = 44.5691, GNorm = 6.2441, lr_0 = 4.4707e-04
Loss = 3.6403e-01, PNorm = 44.5780, GNorm = 3.6838, lr_0 = 4.3750e-04
Loss = 3.2710e-01, PNorm = 44.5874, GNorm = 7.7014, lr_0 = 4.2813e-04
Loss = 3.3388e-01, PNorm = 44.5887, GNorm = 3.6718, lr_0 = 4.2721e-04
Validation rmse = 0.764883
Epoch 12
Loss = 3.1617e-01, PNorm = 44.6035, GNorm = 7.7841, lr_0 = 4.1806e-04
Loss = 2.3472e-01, PNorm = 44.6241, GNorm = 5.3057, lr_0 = 4.0911e-04
Loss = 2.9794e-01, PNorm = 44.6381, GNorm = 5.2813, lr_0 = 4.0035e-04
Validation rmse = 0.766232
Epoch 13
Loss = 2.0728e-01, PNorm = 44.6415, GNorm = 3.6845, lr_0 = 3.9178e-04
Loss = 3.2691e-01, PNorm = 44.6582, GNorm = 2.4136, lr_0 = 3.8340e-04
Loss = 2.5566e-01, PNorm = 44.6687, GNorm = 5.0157, lr_0 = 3.7519e-04
Loss = 2.6573e-01, PNorm = 44.6775, GNorm = 5.2873, lr_0 = 3.6716e-04
Validation rmse = 0.752795
Epoch 14
Loss = 3.4714e-01, PNorm = 44.6933, GNorm = 12.2343, lr_0 = 3.5852e-04
Loss = 3.7144e-01, PNorm = 44.6951, GNorm = 4.4856, lr_0 = 3.5084e-04
Loss = 2.0923e-01, PNorm = 44.7112, GNorm = 3.6959, lr_0 = 3.4333e-04
Loss = 3.1413e-01, PNorm = 44.7196, GNorm = 6.8485, lr_0 = 3.3598e-04
Validation rmse = 0.751377
Epoch 15
Loss = 1.5537e-01, PNorm = 44.7286, GNorm = 8.5713, lr_0 = 3.2879e-04
Loss = 2.6206e-01, PNorm = 44.7375, GNorm = 5.5728, lr_0 = 3.2175e-04
Loss = 2.0993e-01, PNorm = 44.7488, GNorm = 3.8365, lr_0 = 3.1486e-04
Loss = 2.7111e-01, PNorm = 44.7603, GNorm = 3.6165, lr_0 = 3.0812e-04
Validation rmse = 0.713209
Epoch 16
Loss = 1.8328e-01, PNorm = 44.7668, GNorm = 3.5988, lr_0 = 3.0087e-04
Loss = 1.5775e-01, PNorm = 44.7782, GNorm = 7.3121, lr_0 = 2.9443e-04
Loss = 2.3022e-01, PNorm = 44.7867, GNorm = 6.3186, lr_0 = 2.8813e-04
Loss = 1.5643e-01, PNorm = 44.7944, GNorm = 7.5905, lr_0 = 2.8196e-04
Validation rmse = 0.722906
Epoch 17
Loss = 1.7887e-01, PNorm = 44.8075, GNorm = 4.2686, lr_0 = 2.7533e-04
Loss = 1.8104e-01, PNorm = 44.8169, GNorm = 4.9229, lr_0 = 2.6943e-04
Loss = 1.6612e-01, PNorm = 44.8262, GNorm = 6.0660, lr_0 = 2.6367e-04
Loss = 1.5782e-01, PNorm = 44.8326, GNorm = 4.5681, lr_0 = 2.5802e-04
Validation rmse = 0.717565
Epoch 18
Loss = 1.1768e-01, PNorm = 44.8404, GNorm = 6.2944, lr_0 = 2.5250e-04
Loss = 1.8809e-01, PNorm = 44.8501, GNorm = 4.7682, lr_0 = 2.4709e-04
Loss = 1.7819e-01, PNorm = 44.8550, GNorm = 6.7417, lr_0 = 2.4180e-04
Validation rmse = 0.745865
Epoch 19
Loss = 3.6217e-01, PNorm = 44.8646, GNorm = 5.4123, lr_0 = 2.3611e-04
Loss = 1.4761e-01, PNorm = 44.8753, GNorm = 5.6729, lr_0 = 2.3106e-04
Loss = 1.1984e-01, PNorm = 44.8833, GNorm = 5.3813, lr_0 = 2.2611e-04
Loss = 1.6646e-01, PNorm = 44.8918, GNorm = 2.8332, lr_0 = 2.2127e-04
Validation rmse = 0.760949
Epoch 20
Loss = 6.2790e-02, PNorm = 44.8964, GNorm = 13.2617, lr_0 = 2.1653e-04
Loss = 1.0737e-01, PNorm = 44.9040, GNorm = 9.3008, lr_0 = 2.1190e-04
Loss = 1.6038e-01, PNorm = 44.9109, GNorm = 3.8188, lr_0 = 2.0736e-04
Loss = 9.6761e-02, PNorm = 44.9189, GNorm = 3.7318, lr_0 = 2.0292e-04
Validation rmse = 0.705820
Epoch 21
Loss = 1.1278e-01, PNorm = 44.9238, GNorm = 4.8623, lr_0 = 1.9815e-04
Loss = 9.2547e-02, PNorm = 44.9317, GNorm = 12.3326, lr_0 = 1.9391e-04
Loss = 1.6901e-01, PNorm = 44.9389, GNorm = 4.1311, lr_0 = 1.8976e-04
Loss = 1.7851e-01, PNorm = 44.9409, GNorm = 5.2630, lr_0 = 1.8569e-04
Validation rmse = 0.715023
Epoch 22
Loss = 2.3668e-01, PNorm = 44.9458, GNorm = 7.7232, lr_0 = 1.8133e-04
Loss = 5.5576e-02, PNorm = 44.9553, GNorm = 10.1770, lr_0 = 1.7744e-04
Loss = 1.1525e-01, PNorm = 44.9605, GNorm = 5.0832, lr_0 = 1.7364e-04
Loss = 1.2465e-01, PNorm = 44.9648, GNorm = 4.3072, lr_0 = 1.6993e-04
Validation rmse = 0.744325
Epoch 23
Loss = 8.0139e-02, PNorm = 44.9696, GNorm = 3.7756, lr_0 = 1.6629e-04
Loss = 1.0150e-01, PNorm = 44.9759, GNorm = 5.5575, lr_0 = 1.6273e-04
Loss = 1.0751e-01, PNorm = 44.9823, GNorm = 7.2411, lr_0 = 1.5925e-04
Loss = 1.3195e-01, PNorm = 44.9875, GNorm = 6.1447, lr_0 = 1.5584e-04
Validation rmse = 0.711785
Epoch 24
Loss = 8.5297e-02, PNorm = 44.9944, GNorm = 5.1934, lr_0 = 1.5217e-04
Loss = 1.1268e-01, PNorm = 45.0004, GNorm = 8.0023, lr_0 = 1.4891e-04
Loss = -4.6980e-03, PNorm = 45.0054, GNorm = 10.3220, lr_0 = 1.4572e-04
Loss = 1.5043e-01, PNorm = 45.0083, GNorm = 12.6426, lr_0 = 1.4261e-04
Validation rmse = 0.716622
Epoch 25
Loss = -5.8915e-02, PNorm = 45.0137, GNorm = 4.1628, lr_0 = 1.3955e-04
Loss = 8.5410e-02, PNorm = 45.0190, GNorm = 10.7280, lr_0 = 1.3656e-04
Loss = 1.6969e-01, PNorm = 45.0238, GNorm = 8.4076, lr_0 = 1.3364e-04
Validation rmse = 0.729812
Epoch 26
Loss = 2.2574e-01, PNorm = 45.0272, GNorm = 13.3170, lr_0 = 1.3050e-04
Loss = 7.9331e-02, PNorm = 45.0331, GNorm = 5.9240, lr_0 = 1.2770e-04
Loss = 6.3614e-03, PNorm = 45.0389, GNorm = 7.0735, lr_0 = 1.2497e-04
Loss = -1.0712e-02, PNorm = 45.0446, GNorm = 3.3566, lr_0 = 1.2229e-04
Validation rmse = 0.713295
Epoch 27
Loss = 4.1776e-02, PNorm = 45.0462, GNorm = 6.0561, lr_0 = 1.1942e-04
Loss = 4.3123e-03, PNorm = 45.0504, GNorm = 2.8488, lr_0 = 1.1686e-04
Loss = 2.9679e-03, PNorm = 45.0543, GNorm = 13.0485, lr_0 = 1.1436e-04
Loss = 1.6027e-01, PNorm = 45.0561, GNorm = 6.9085, lr_0 = 1.1191e-04
Validation rmse = 0.710220
Epoch 28
Loss = 2.8499e-02, PNorm = 45.0597, GNorm = 4.2087, lr_0 = 1.0952e-04
Loss = 8.8695e-02, PNorm = 45.0629, GNorm = 15.2185, lr_0 = 1.0717e-04
Loss = 8.9409e-02, PNorm = 45.0658, GNorm = 5.8495, lr_0 = 1.0488e-04
Loss = 3.6770e-02, PNorm = 45.0705, GNorm = 7.3239, lr_0 = 1.0263e-04
Validation rmse = 0.708006
Epoch 29
Loss = -6.0888e-04, PNorm = 45.0743, GNorm = 6.9606, lr_0 = 1.0022e-04
Loss = 3.2025e-02, PNorm = 45.0786, GNorm = 6.5725, lr_0 = 1.0000e-04
Loss = -1.9002e-02, PNorm = 45.0823, GNorm = 6.4865, lr_0 = 1.0000e-04
Loss = 1.1364e-01, PNorm = 45.0845, GNorm = 6.5876, lr_0 = 1.0000e-04
Validation rmse = 0.720368
Model 0 best validation rmse = 0.705820 on epoch 20
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.644393
Ensemble test rmse = 0.644393
1-fold cross validation
	Seed 0 ==> test rmse = 0.644393
Overall test rmse = 0.644393 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,225 | train size = 980 | val size = 122 | test size = 123
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9253e+00, PNorm = 43.3143, GNorm = 4.5357, lr_0 = 2.2692e-04
Loss = 1.4562e+00, PNorm = 43.3162, GNorm = 1.8930, lr_0 = 3.4231e-04
Loss = 1.4184e+00, PNorm = 43.3223, GNorm = 1.6396, lr_0 = 4.5769e-04
Validation rmse = 1.722048
Epoch 1
Loss = 1.3193e+00, PNorm = 43.3373, GNorm = 2.7896, lr_0 = 5.8462e-04
Loss = 1.1724e+00, PNorm = 43.3615, GNorm = 2.0570, lr_0 = 7.0000e-04
Loss = 1.1530e+00, PNorm = 43.3949, GNorm = 1.4047, lr_0 = 8.1538e-04
Loss = 1.0519e+00, PNorm = 43.4426, GNorm = 8.6537, lr_0 = 9.3077e-04
Validation rmse = 1.185159
Epoch 2
Loss = 9.0928e-01, PNorm = 43.5004, GNorm = 6.0499, lr_0 = 9.8951e-04
Loss = 9.4644e-01, PNorm = 43.5661, GNorm = 1.4831, lr_0 = 9.6887e-04
Loss = 8.6476e-01, PNorm = 43.6329, GNorm = 4.4267, lr_0 = 9.4865e-04
Loss = 7.8451e-01, PNorm = 43.6812, GNorm = 5.3908, lr_0 = 9.2886e-04
Validation rmse = 1.009979
Epoch 3
Loss = 9.7667e-01, PNorm = 43.7199, GNorm = 5.0863, lr_0 = 9.0756e-04
Loss = 7.7480e-01, PNorm = 43.7690, GNorm = 3.2321, lr_0 = 8.8862e-04
Loss = 7.3053e-01, PNorm = 43.8166, GNorm = 2.6787, lr_0 = 8.7008e-04
Loss = 7.0464e-01, PNorm = 43.8587, GNorm = 3.7732, lr_0 = 8.5193e-04
Validation rmse = 0.825092
Epoch 4
Loss = 6.4393e-01, PNorm = 43.8925, GNorm = 2.1586, lr_0 = 8.3240e-04
Loss = 5.2739e-01, PNorm = 43.9284, GNorm = 4.1310, lr_0 = 8.1503e-04
Loss = 5.7990e-01, PNorm = 43.9717, GNorm = 5.4737, lr_0 = 7.9802e-04
Loss = 6.1628e-01, PNorm = 43.9887, GNorm = 12.4056, lr_0 = 7.8137e-04
Validation rmse = 0.793414
Epoch 5
Loss = 5.6125e-01, PNorm = 44.0244, GNorm = 1.9981, lr_0 = 7.6507e-04
Loss = 6.0937e-01, PNorm = 44.0504, GNorm = 5.5623, lr_0 = 7.4910e-04
Loss = 5.3312e-01, PNorm = 44.0770, GNorm = 2.2274, lr_0 = 7.3347e-04
Loss = 5.0284e-01, PNorm = 44.1122, GNorm = 11.8865, lr_0 = 7.1817e-04
Validation rmse = 0.715375
Epoch 6
Loss = 3.2908e-01, PNorm = 44.1431, GNorm = 3.8627, lr_0 = 7.0170e-04
Loss = 4.2150e-01, PNorm = 44.1651, GNorm = 11.2978, lr_0 = 6.8706e-04
Loss = 5.9978e-01, PNorm = 44.1857, GNorm = 3.9288, lr_0 = 6.7273e-04
Loss = 5.6046e-01, PNorm = 44.2008, GNorm = 6.8964, lr_0 = 6.5869e-04
Validation rmse = 0.731683
Epoch 7
Loss = 4.8542e-01, PNorm = 44.2178, GNorm = 6.7223, lr_0 = 6.4359e-04
Loss = 4.9386e-01, PNorm = 44.2448, GNorm = 6.5764, lr_0 = 6.3016e-04
Loss = 4.7463e-01, PNorm = 44.2715, GNorm = 8.3508, lr_0 = 6.1701e-04
Loss = 4.5166e-01, PNorm = 44.2959, GNorm = 5.7861, lr_0 = 6.0414e-04
Validation rmse = 0.710796
Epoch 8
Loss = 3.6105e-01, PNorm = 44.3144, GNorm = 3.9919, lr_0 = 5.9029e-04
Loss = 3.0789e-01, PNorm = 44.3387, GNorm = 2.8304, lr_0 = 5.7797e-04
Loss = 4.4154e-01, PNorm = 44.3547, GNorm = 16.3083, lr_0 = 5.6591e-04
Loss = 4.3863e-01, PNorm = 44.3646, GNorm = 10.3336, lr_0 = 5.5410e-04
Validation rmse = 0.770566
Epoch 9
Loss = 4.3168e-01, PNorm = 44.3861, GNorm = 4.5081, lr_0 = 5.4140e-04
Loss = 2.8188e-01, PNorm = 44.4074, GNorm = 5.4196, lr_0 = 5.3010e-04
Loss = 3.4171e-01, PNorm = 44.4255, GNorm = 8.5098, lr_0 = 5.1904e-04
Loss = 3.9103e-01, PNorm = 44.4388, GNorm = 3.7016, lr_0 = 5.0821e-04
Validation rmse = 0.686740
Epoch 10
Loss = 2.9740e-01, PNorm = 44.4516, GNorm = 5.5972, lr_0 = 4.9761e-04
Loss = 3.0873e-01, PNorm = 44.4665, GNorm = 4.9712, lr_0 = 4.8722e-04
Loss = 4.4095e-01, PNorm = 44.4710, GNorm = 2.8592, lr_0 = 4.7706e-04
Loss = 3.4121e-01, PNorm = 44.4873, GNorm = 3.9718, lr_0 = 4.6710e-04
Validation rmse = 0.843087
Epoch 11
Loss = 4.1794e-01, PNorm = 44.5026, GNorm = 8.4105, lr_0 = 4.5639e-04
Loss = 4.0593e-01, PNorm = 44.5231, GNorm = 8.9538, lr_0 = 4.4687e-04
Loss = 2.7377e-01, PNorm = 44.5435, GNorm = 8.8373, lr_0 = 4.3755e-04
Loss = 2.6102e-01, PNorm = 44.5575, GNorm = 14.3087, lr_0 = 4.2842e-04
Loss = 1.0915e+00, PNorm = 44.5568, GNorm = 15.0450, lr_0 = 4.2752e-04
Validation rmse = 0.714526
Epoch 12
Loss = 2.8014e-01, PNorm = 44.5648, GNorm = 10.2065, lr_0 = 4.1860e-04
Loss = 3.6457e-01, PNorm = 44.5765, GNorm = 5.5423, lr_0 = 4.0986e-04
Loss = 2.2906e-01, PNorm = 44.5898, GNorm = 8.9308, lr_0 = 4.0131e-04
Validation rmse = 0.806770
Epoch 13
Loss = 3.7848e-01, PNorm = 44.5972, GNorm = 10.7563, lr_0 = 3.9211e-04
Loss = 3.5280e-01, PNorm = 44.6111, GNorm = 7.6524, lr_0 = 3.8393e-04
Loss = 2.1630e-01, PNorm = 44.6246, GNorm = 5.6405, lr_0 = 3.7592e-04
Loss = 2.7896e-01, PNorm = 44.6340, GNorm = 16.3643, lr_0 = 3.6807e-04
Validation rmse = 0.691861
Epoch 14
Loss = 3.9619e-01, PNorm = 44.6443, GNorm = 2.1733, lr_0 = 3.5963e-04
Loss = 2.4180e-01, PNorm = 44.6588, GNorm = 5.0065, lr_0 = 3.5213e-04
Loss = 1.2945e-01, PNorm = 44.6784, GNorm = 9.2875, lr_0 = 3.4478e-04
Loss = 3.4735e-01, PNorm = 44.6804, GNorm = 12.2098, lr_0 = 3.3759e-04
Validation rmse = 0.704924
Epoch 15
Loss = 2.6836e-01, PNorm = 44.6861, GNorm = 2.9748, lr_0 = 3.3055e-04
Loss = 3.1242e-01, PNorm = 44.7000, GNorm = 13.7174, lr_0 = 3.2365e-04
Loss = 1.9069e-01, PNorm = 44.7192, GNorm = 3.3784, lr_0 = 3.1690e-04
Loss = 2.7496e-01, PNorm = 44.7314, GNorm = 6.0005, lr_0 = 3.1028e-04
Validation rmse = 0.689037
Epoch 16
Loss = 1.7745e-01, PNorm = 44.7373, GNorm = 5.0301, lr_0 = 3.0317e-04
Loss = 2.7202e-01, PNorm = 44.7447, GNorm = 10.1997, lr_0 = 2.9684e-04
Loss = 2.1462e-01, PNorm = 44.7555, GNorm = 7.3072, lr_0 = 2.9065e-04
Loss = 2.1793e-01, PNorm = 44.7618, GNorm = 3.9422, lr_0 = 2.8459e-04
Validation rmse = 0.684891
Epoch 17
Loss = 1.1536e-01, PNorm = 44.7710, GNorm = 6.0324, lr_0 = 2.7806e-04
Loss = 1.1331e-01, PNorm = 44.7803, GNorm = 4.0696, lr_0 = 2.7226e-04
Loss = 3.3776e-01, PNorm = 44.7841, GNorm = 6.0662, lr_0 = 2.6658e-04
Loss = 2.6295e-01, PNorm = 44.7910, GNorm = 5.7317, lr_0 = 2.6102e-04
Validation rmse = 0.698564
Epoch 18
Loss = 2.3855e-01, PNorm = 44.8007, GNorm = 4.2229, lr_0 = 2.5503e-04
Loss = 1.3831e-01, PNorm = 44.8119, GNorm = 3.4761, lr_0 = 2.4971e-04
Loss = 1.7535e-01, PNorm = 44.8225, GNorm = 6.3324, lr_0 = 2.4450e-04
Loss = 2.1404e-01, PNorm = 44.8232, GNorm = 5.4447, lr_0 = 2.3940e-04
Validation rmse = 0.690668
Epoch 19
Loss = 1.5225e-01, PNorm = 44.8329, GNorm = 7.7493, lr_0 = 2.3391e-04
Loss = 1.5590e-01, PNorm = 44.8413, GNorm = 6.0126, lr_0 = 2.2903e-04
Loss = 1.3716e-01, PNorm = 44.8482, GNorm = 7.6673, lr_0 = 2.2425e-04
Loss = 1.6476e-01, PNorm = 44.8535, GNorm = 4.1487, lr_0 = 2.1957e-04
Validation rmse = 0.684096
Epoch 20
Loss = 8.7260e-02, PNorm = 44.8601, GNorm = 15.5395, lr_0 = 2.1499e-04
Loss = 2.7945e-01, PNorm = 44.8625, GNorm = 3.0664, lr_0 = 2.1050e-04
Loss = 1.5931e-01, PNorm = 44.8699, GNorm = 4.6498, lr_0 = 2.0611e-04
Loss = 1.5416e-01, PNorm = 44.8752, GNorm = 5.3364, lr_0 = 2.0181e-04
Validation rmse = 0.716575
Epoch 21
Loss = 1.0609e-01, PNorm = 44.8846, GNorm = 6.7386, lr_0 = 1.9718e-04
Loss = 1.3786e-01, PNorm = 44.8909, GNorm = 8.2613, lr_0 = 1.9307e-04
Loss = 1.6034e-01, PNorm = 44.8965, GNorm = 4.4172, lr_0 = 1.8904e-04
Loss = 8.8893e-02, PNorm = 44.9024, GNorm = 10.6640, lr_0 = 1.8510e-04
Validation rmse = 0.672978
Epoch 22
Loss = 4.3058e-02, PNorm = 44.9073, GNorm = 6.0760, lr_0 = 1.8085e-04
Loss = 1.5438e-01, PNorm = 44.9116, GNorm = 12.8187, lr_0 = 1.7708e-04
Loss = 1.0142e-01, PNorm = 44.9148, GNorm = 3.3244, lr_0 = 1.7338e-04
Loss = 2.1329e-01, PNorm = 44.9200, GNorm = 7.2802, lr_0 = 1.6977e-04
Validation rmse = 0.705465
Epoch 23
Loss = 1.2273e-01, PNorm = 44.9277, GNorm = 6.5142, lr_0 = 1.6587e-04
Loss = 2.3757e-01, PNorm = 44.9327, GNorm = 5.3051, lr_0 = 1.6241e-04
Loss = 8.2986e-02, PNorm = 44.9371, GNorm = 8.1996, lr_0 = 1.5902e-04
Loss = 6.7172e-02, PNorm = 44.9416, GNorm = 3.4021, lr_0 = 1.5571e-04
Loss = -3.9582e-01, PNorm = 44.9425, GNorm = 6.8132, lr_0 = 1.5538e-04
Validation rmse = 0.685261
Epoch 24
Loss = 5.8635e-02, PNorm = 44.9494, GNorm = 4.6305, lr_0 = 1.5214e-04
Loss = 1.0500e-01, PNorm = 44.9533, GNorm = 5.9485, lr_0 = 1.4896e-04
Loss = 1.2949e-01, PNorm = 44.9562, GNorm = 4.8012, lr_0 = 1.4585e-04
Loss = 1.4116e-01, PNorm = 44.9591, GNorm = 18.1029, lr_0 = 1.4281e-04
Validation rmse = 0.680017
Epoch 25
Loss = 2.8189e-02, PNorm = 44.9633, GNorm = 3.8479, lr_0 = 1.3983e-04
Loss = 1.1404e-01, PNorm = 44.9688, GNorm = 3.2979, lr_0 = 1.3691e-04
Loss = 1.2720e-01, PNorm = 44.9740, GNorm = 5.9223, lr_0 = 1.3406e-04
Validation rmse = 0.677447
Epoch 26
Loss = -1.9179e-03, PNorm = 44.9785, GNorm = 5.2977, lr_0 = 1.3098e-04
Loss = 9.1855e-02, PNorm = 44.9826, GNorm = 6.5480, lr_0 = 1.2825e-04
Loss = -4.9908e-03, PNorm = 44.9873, GNorm = 7.5504, lr_0 = 1.2557e-04
Loss = 1.6253e-01, PNorm = 44.9912, GNorm = 7.2358, lr_0 = 1.2295e-04
Validation rmse = 0.685377
Epoch 27
Loss = 1.5342e-01, PNorm = 44.9938, GNorm = 9.1648, lr_0 = 1.2014e-04
Loss = 5.5487e-02, PNorm = 44.9971, GNorm = 4.8979, lr_0 = 1.1763e-04
Loss = 1.1499e-01, PNorm = 45.0007, GNorm = 5.2051, lr_0 = 1.1517e-04
Loss = 2.2042e-02, PNorm = 45.0040, GNorm = 4.2385, lr_0 = 1.1277e-04
Validation rmse = 0.697271
Epoch 28
Loss = 9.7549e-02, PNorm = 45.0087, GNorm = 11.0565, lr_0 = 1.1019e-04
Loss = 1.5121e-01, PNorm = 45.0101, GNorm = 3.1609, lr_0 = 1.0789e-04
Loss = 7.4451e-02, PNorm = 45.0116, GNorm = 4.4868, lr_0 = 1.0564e-04
Loss = 6.1591e-02, PNorm = 45.0166, GNorm = 8.4834, lr_0 = 1.0343e-04
Validation rmse = 0.680086
Epoch 29
Loss = 1.0445e-01, PNorm = 45.0189, GNorm = 9.7973, lr_0 = 1.0106e-04
Loss = 1.3137e-01, PNorm = 45.0209, GNorm = 9.1773, lr_0 = 1.0000e-04
Loss = 2.7281e-02, PNorm = 45.0243, GNorm = 5.5763, lr_0 = 1.0000e-04
Loss = -3.0076e-04, PNorm = 45.0281, GNorm = 6.7398, lr_0 = 1.0000e-04
Validation rmse = 0.701918
Model 0 best validation rmse = 0.672978 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.611547
Ensemble test rmse = 0.611547
1-fold cross validation
	Seed 0 ==> test rmse = 0.611547
Overall test rmse = 0.611547 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7212e+00, PNorm = 43.3121, GNorm = 2.8123, lr_0 = 2.2375e-04
Loss = 1.5066e+00, PNorm = 43.3133, GNorm = 1.4148, lr_0 = 3.3625e-04
Loss = 1.4094e+00, PNorm = 43.3185, GNorm = 1.5854, lr_0 = 4.4875e-04
Loss = 1.2610e+00, PNorm = 43.3314, GNorm = 1.1602, lr_0 = 5.6125e-04
Validation rmse = 1.462160
Epoch 1
Loss = 1.1501e+00, PNorm = 43.3551, GNorm = 2.3487, lr_0 = 6.7375e-04
Loss = 1.0855e+00, PNorm = 43.3883, GNorm = 2.0980, lr_0 = 7.8625e-04
Loss = 1.0510e+00, PNorm = 43.4295, GNorm = 7.3964, lr_0 = 8.9875e-04
Loss = 9.8712e-01, PNorm = 43.4875, GNorm = 7.0141, lr_0 = 9.9795e-04
Validation rmse = 1.131660
Epoch 2
Loss = 8.7855e-01, PNorm = 43.5469, GNorm = 7.3869, lr_0 = 9.7764e-04
Loss = 8.4525e-01, PNorm = 43.6044, GNorm = 4.8564, lr_0 = 9.5775e-04
Loss = 7.3180e-01, PNorm = 43.6608, GNorm = 3.0308, lr_0 = 9.3826e-04
Loss = 7.2061e-01, PNorm = 43.7019, GNorm = 3.8180, lr_0 = 9.1916e-04
Validation rmse = 0.787826
Epoch 3
Loss = 6.9898e-01, PNorm = 43.7518, GNorm = 17.8641, lr_0 = 9.0046e-04
Loss = 7.2667e-01, PNorm = 43.7788, GNorm = 5.3516, lr_0 = 8.8214e-04
Loss = 6.4153e-01, PNorm = 43.8237, GNorm = 11.2646, lr_0 = 8.6419e-04
Loss = 7.0259e-01, PNorm = 43.8669, GNorm = 2.3022, lr_0 = 8.4660e-04
Validation rmse = 0.817747
Epoch 4
Loss = 6.5319e-01, PNorm = 43.9050, GNorm = 12.5124, lr_0 = 8.2937e-04
Loss = 6.5032e-01, PNorm = 43.9386, GNorm = 4.5520, lr_0 = 8.1250e-04
Loss = 5.3320e-01, PNorm = 43.9792, GNorm = 9.0417, lr_0 = 7.9596e-04
Loss = 5.5224e-01, PNorm = 44.0062, GNorm = 4.2258, lr_0 = 7.7977e-04
Validation rmse = 0.720271
Epoch 5
Loss = 4.9095e-01, PNorm = 44.0316, GNorm = 9.5742, lr_0 = 7.6390e-04
Loss = 5.2471e-01, PNorm = 44.0671, GNorm = 8.9299, lr_0 = 7.4835e-04
Loss = 6.4230e-01, PNorm = 44.0965, GNorm = 1.8873, lr_0 = 7.3313e-04
Loss = 5.7413e-01, PNorm = 44.1291, GNorm = 8.3666, lr_0 = 7.1821e-04
Validation rmse = 0.706299
Epoch 6
Loss = 5.2214e-01, PNorm = 44.1554, GNorm = 3.0690, lr_0 = 7.0359e-04
Loss = 4.5226e-01, PNorm = 44.1860, GNorm = 4.5141, lr_0 = 6.8928e-04
Loss = 4.5518e-01, PNorm = 44.2122, GNorm = 6.9205, lr_0 = 6.7525e-04
Loss = 5.4166e-01, PNorm = 44.2229, GNorm = 4.6624, lr_0 = 6.6151e-04
Validation rmse = 0.783943
Epoch 7
Loss = 4.9519e-01, PNorm = 44.2503, GNorm = 2.3578, lr_0 = 6.4805e-04
Loss = 4.3161e-01, PNorm = 44.2766, GNorm = 14.3758, lr_0 = 6.3486e-04
Loss = 4.5280e-01, PNorm = 44.3001, GNorm = 2.7038, lr_0 = 6.2194e-04
Loss = 4.0682e-01, PNorm = 44.3198, GNorm = 3.8965, lr_0 = 6.0929e-04
Validation rmse = 0.688552
Epoch 8
Loss = 2.9602e-01, PNorm = 44.3397, GNorm = 6.7364, lr_0 = 5.9689e-04
Loss = 3.7487e-01, PNorm = 44.3634, GNorm = 3.8921, lr_0 = 5.8474e-04
Loss = 4.9522e-01, PNorm = 44.3854, GNorm = 13.8268, lr_0 = 5.7284e-04
Loss = 3.4366e-01, PNorm = 44.4039, GNorm = 5.8351, lr_0 = 5.6119e-04
Validation rmse = 0.754782
Epoch 9
Loss = 2.7618e-01, PNorm = 44.4274, GNorm = 7.8810, lr_0 = 5.4977e-04
Loss = 4.0271e-01, PNorm = 44.4484, GNorm = 8.1957, lr_0 = 5.3858e-04
Loss = 3.2552e-01, PNorm = 44.4706, GNorm = 3.4569, lr_0 = 5.2762e-04
Loss = 4.4268e-01, PNorm = 44.4855, GNorm = 2.3194, lr_0 = 5.1688e-04
Validation rmse = 0.705971
Epoch 10
Loss = 2.5279e-01, PNorm = 44.5102, GNorm = 4.6027, lr_0 = 5.0637e-04
Loss = 2.8527e-01, PNorm = 44.5272, GNorm = 6.5947, lr_0 = 4.9606e-04
Loss = 3.7593e-01, PNorm = 44.5404, GNorm = 3.5580, lr_0 = 4.8597e-04
Loss = 3.2729e-01, PNorm = 44.5551, GNorm = 4.6895, lr_0 = 4.7608e-04
Validation rmse = 0.695877
Epoch 11
Loss = 1.8809e-01, PNorm = 44.5836, GNorm = 5.1037, lr_0 = 4.6639e-04
Loss = 3.2457e-01, PNorm = 44.6038, GNorm = 11.0153, lr_0 = 4.5690e-04
Loss = 3.1050e-01, PNorm = 44.6176, GNorm = 3.8544, lr_0 = 4.4760e-04
Loss = 3.4740e-01, PNorm = 44.6359, GNorm = 11.8860, lr_0 = 4.3849e-04
Validation rmse = 0.692903
Epoch 12
Loss = 2.1228e-01, PNorm = 44.6470, GNorm = 5.3733, lr_0 = 4.2957e-04
Loss = 3.4280e-01, PNorm = 44.6606, GNorm = 14.0948, lr_0 = 4.2083e-04
Loss = 2.6964e-01, PNorm = 44.6763, GNorm = 3.5152, lr_0 = 4.1227e-04
Loss = 3.6741e-01, PNorm = 44.6972, GNorm = 6.6919, lr_0 = 4.0388e-04
Validation rmse = 0.708441
Epoch 13
Loss = 2.5239e-01, PNorm = 44.7055, GNorm = 5.2831, lr_0 = 3.9566e-04
Loss = 2.1327e-01, PNorm = 44.7212, GNorm = 3.6652, lr_0 = 3.8761e-04
Loss = 2.9978e-01, PNorm = 44.7340, GNorm = 9.8394, lr_0 = 3.7972e-04
Loss = 2.8776e-01, PNorm = 44.7435, GNorm = 3.9903, lr_0 = 3.7199e-04
Validation rmse = 0.699524
Epoch 14
Loss = 3.0571e-01, PNorm = 44.7612, GNorm = 10.8133, lr_0 = 3.6442e-04
Loss = 2.8392e-01, PNorm = 44.7800, GNorm = 14.4301, lr_0 = 3.5701e-04
Loss = 2.8370e-01, PNorm = 44.7921, GNorm = 5.0476, lr_0 = 3.4974e-04
Loss = 1.7847e-01, PNorm = 44.8052, GNorm = 6.7872, lr_0 = 3.4263e-04
Validation rmse = 0.676206
Epoch 15
Loss = 1.0684e-01, PNorm = 44.8188, GNorm = 6.3303, lr_0 = 3.3565e-04
Loss = 1.1070e-01, PNorm = 44.8305, GNorm = 6.5520, lr_0 = 3.2882e-04
Loss = 2.3728e-01, PNorm = 44.8377, GNorm = 6.0493, lr_0 = 3.2213e-04
Loss = 2.9217e-01, PNorm = 44.8477, GNorm = 4.5160, lr_0 = 3.1558e-04
Validation rmse = 0.684570
Epoch 16
Loss = 2.2578e-01, PNorm = 44.8620, GNorm = 11.1100, lr_0 = 3.0916e-04
Loss = 1.2769e-01, PNorm = 44.8791, GNorm = 4.9352, lr_0 = 3.0287e-04
Loss = 1.8744e-01, PNorm = 44.8914, GNorm = 12.4811, lr_0 = 2.9670e-04
Loss = 1.7826e-01, PNorm = 44.8971, GNorm = 8.2513, lr_0 = 2.9067e-04
Validation rmse = 0.668829
Epoch 17
Loss = 1.8384e-01, PNorm = 44.9063, GNorm = 9.8349, lr_0 = 2.8475e-04
Loss = 1.9212e-01, PNorm = 44.9196, GNorm = 4.2087, lr_0 = 2.7896e-04
Loss = 6.6200e-02, PNorm = 44.9282, GNorm = 8.9476, lr_0 = 2.7328e-04
Loss = 2.1427e-01, PNorm = 44.9368, GNorm = 5.3373, lr_0 = 2.6772e-04
Validation rmse = 0.673547
Epoch 18
Loss = 6.7699e-02, PNorm = 44.9472, GNorm = 8.8302, lr_0 = 2.6227e-04
Loss = 1.3630e-01, PNorm = 44.9577, GNorm = 9.1793, lr_0 = 2.5693e-04
Loss = 1.7137e-01, PNorm = 44.9665, GNorm = 11.7137, lr_0 = 2.5171e-04
Loss = 2.4751e-01, PNorm = 44.9730, GNorm = 17.9093, lr_0 = 2.4658e-04
Validation rmse = 0.751580
Epoch 19
Loss = 2.6631e-01, PNorm = 44.9775, GNorm = 10.4883, lr_0 = 2.4157e-04
Loss = 1.8416e-01, PNorm = 44.9881, GNorm = 5.8102, lr_0 = 2.3665e-04
Loss = 8.5332e-02, PNorm = 44.9996, GNorm = 3.8932, lr_0 = 2.3183e-04
Loss = 7.2601e-02, PNorm = 45.0113, GNorm = 11.0011, lr_0 = 2.2712e-04
Validation rmse = 0.691125
Epoch 20
Loss = 4.2401e-02, PNorm = 45.0215, GNorm = 15.7666, lr_0 = 2.2250e-04
Loss = 8.2356e-02, PNorm = 45.0283, GNorm = 7.3375, lr_0 = 2.1797e-04
Loss = 9.7717e-02, PNorm = 45.0369, GNorm = 5.0110, lr_0 = 2.1353e-04
Loss = 1.4327e-01, PNorm = 45.0388, GNorm = 4.2774, lr_0 = 2.0919e-04
Validation rmse = 0.681324
Epoch 21
Loss = 1.1298e-01, PNorm = 45.0469, GNorm = 12.4938, lr_0 = 2.0493e-04
Loss = 9.1346e-02, PNorm = 45.0556, GNorm = 8.3633, lr_0 = 2.0076e-04
Loss = 1.9854e-02, PNorm = 45.0643, GNorm = 8.1126, lr_0 = 1.9668e-04
Loss = 1.5701e-01, PNorm = 45.0671, GNorm = 5.5174, lr_0 = 1.9267e-04
Validation rmse = 0.672798
Epoch 22
Loss = -4.6579e-03, PNorm = 45.0733, GNorm = 5.1191, lr_0 = 1.8875e-04
Loss = 1.4564e-01, PNorm = 45.0816, GNorm = 7.5691, lr_0 = 1.8491e-04
Loss = 1.5702e-01, PNorm = 45.0846, GNorm = 8.7563, lr_0 = 1.8115e-04
Loss = 3.4998e-02, PNorm = 45.0907, GNorm = 5.0179, lr_0 = 1.7746e-04
Validation rmse = 0.692024
Epoch 23
Loss = 1.2097e-01, PNorm = 45.0978, GNorm = 5.0567, lr_0 = 1.7385e-04
Loss = -2.3024e-03, PNorm = 45.1024, GNorm = 13.7397, lr_0 = 1.7031e-04
Loss = 9.6353e-02, PNorm = 45.1078, GNorm = 6.7205, lr_0 = 1.6685e-04
Loss = 6.2754e-02, PNorm = 45.1155, GNorm = 6.5313, lr_0 = 1.6345e-04
Validation rmse = 0.679430
Epoch 24
Loss = 8.0669e-02, PNorm = 45.1225, GNorm = 5.7819, lr_0 = 1.6013e-04
Loss = -2.6945e-04, PNorm = 45.1298, GNorm = 6.6411, lr_0 = 1.5687e-04
Loss = 8.6690e-02, PNorm = 45.1338, GNorm = 6.2388, lr_0 = 1.5368e-04
Loss = 8.6892e-02, PNorm = 45.1373, GNorm = 10.5332, lr_0 = 1.5055e-04
Validation rmse = 0.684059
Epoch 25
Loss = 3.1836e-02, PNorm = 45.1411, GNorm = 3.5632, lr_0 = 1.4749e-04
Loss = 1.1747e-02, PNorm = 45.1475, GNorm = 5.5101, lr_0 = 1.4448e-04
Loss = 1.1803e-01, PNorm = 45.1541, GNorm = 3.5638, lr_0 = 1.4154e-04
Loss = 6.0920e-02, PNorm = 45.1589, GNorm = 6.0279, lr_0 = 1.3866e-04
Validation rmse = 0.673949
Epoch 26
Loss = -5.9440e-03, PNorm = 45.1657, GNorm = 9.4388, lr_0 = 1.3584e-04
Loss = 1.8555e-02, PNorm = 45.1699, GNorm = 8.1569, lr_0 = 1.3308e-04
Loss = 8.1694e-02, PNorm = 45.1745, GNorm = 5.2680, lr_0 = 1.3037e-04
Loss = 4.4436e-03, PNorm = 45.1792, GNorm = 6.5998, lr_0 = 1.2772e-04
Validation rmse = 0.674456
Epoch 27
Loss = -3.2524e-02, PNorm = 45.1852, GNorm = 5.9176, lr_0 = 1.2512e-04
Loss = 2.2943e-03, PNorm = 45.1901, GNorm = 7.9288, lr_0 = 1.2257e-04
Loss = 3.8520e-02, PNorm = 45.1935, GNorm = 5.2722, lr_0 = 1.2008e-04
Loss = 3.0996e-02, PNorm = 45.1967, GNorm = 9.3049, lr_0 = 1.1763e-04
Validation rmse = 0.684531
Epoch 28
Loss = -6.0135e-02, PNorm = 45.2015, GNorm = 4.6521, lr_0 = 1.1524e-04
Loss = 4.3422e-02, PNorm = 45.2064, GNorm = 5.4785, lr_0 = 1.1290e-04
Loss = -4.6065e-02, PNorm = 45.2111, GNorm = 4.5534, lr_0 = 1.1060e-04
Loss = 7.0441e-02, PNorm = 45.2124, GNorm = 3.7867, lr_0 = 1.0835e-04
Validation rmse = 0.674390
Epoch 29
Loss = -8.6591e-02, PNorm = 45.2158, GNorm = 10.2206, lr_0 = 1.0614e-04
Loss = 5.4794e-02, PNorm = 45.2192, GNorm = 11.4175, lr_0 = 1.0398e-04
Loss = 8.3372e-02, PNorm = 45.2222, GNorm = 7.1731, lr_0 = 1.0187e-04
Loss = 2.4095e-02, PNorm = 45.2263, GNorm = 5.7108, lr_0 = 1.0000e-04
Validation rmse = 0.679843
Model 0 best validation rmse = 0.668829 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.628391
Ensemble test rmse = 0.628391
1-fold cross validation
	Seed 0 ==> test rmse = 0.628391
Overall test rmse = 0.628391 +/- 0.000000
Elapsed time = 0:01:38
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,275 | train size = 1,020 | val size = 127 | test size = 128
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8740e+00, PNorm = 43.3126, GNorm = 2.7693, lr_0 = 2.2375e-04
Loss = 1.4513e+00, PNorm = 43.3141, GNorm = 1.3663, lr_0 = 3.3625e-04
Loss = 1.4307e+00, PNorm = 43.3194, GNorm = 1.3425, lr_0 = 4.4875e-04
Loss = 1.2493e+00, PNorm = 43.3321, GNorm = 2.2256, lr_0 = 5.6125e-04
Loss = 1.4186e+00, PNorm = 43.3337, GNorm = 1.7650, lr_0 = 5.7250e-04
Validation rmse = 1.577215
Epoch 1
Loss = 1.2618e+00, PNorm = 43.3509, GNorm = 3.4491, lr_0 = 6.8500e-04
Loss = 1.1628e+00, PNorm = 43.3833, GNorm = 6.3315, lr_0 = 7.9750e-04
Loss = 9.8173e-01, PNorm = 43.4299, GNorm = 4.7427, lr_0 = 9.1000e-04
Loss = 9.8143e-01, PNorm = 43.4683, GNorm = 6.2156, lr_0 = 9.9590e-04
Validation rmse = 1.135395
Epoch 2
Loss = 9.1192e-01, PNorm = 43.5249, GNorm = 2.1887, lr_0 = 9.7563e-04
Loss = 8.0542e-01, PNorm = 43.5881, GNorm = 3.4869, lr_0 = 9.5578e-04
Loss = 7.4470e-01, PNorm = 43.6423, GNorm = 5.6251, lr_0 = 9.3633e-04
Loss = 6.5379e-01, PNorm = 43.6888, GNorm = 7.6009, lr_0 = 9.1728e-04
Validation rmse = 0.818166
Epoch 3
Loss = 6.8417e-01, PNorm = 43.7372, GNorm = 2.8017, lr_0 = 8.9861e-04
Loss = 6.7160e-01, PNorm = 43.7750, GNorm = 9.5892, lr_0 = 8.8032e-04
Loss = 5.7527e-01, PNorm = 43.8136, GNorm = 4.6135, lr_0 = 8.6241e-04
Loss = 5.6865e-01, PNorm = 43.8505, GNorm = 2.7099, lr_0 = 8.4486e-04
Validation rmse = 0.729977
Epoch 4
Loss = 4.3995e-01, PNorm = 43.8833, GNorm = 11.1595, lr_0 = 8.2767e-04
Loss = 5.3445e-01, PNorm = 43.9204, GNorm = 3.5112, lr_0 = 8.1083e-04
Loss = 6.1232e-01, PNorm = 43.9371, GNorm = 6.8376, lr_0 = 7.9433e-04
Loss = 5.8630e-01, PNorm = 43.9690, GNorm = 3.9951, lr_0 = 7.7816e-04
Validation rmse = 0.652199
Epoch 5
Loss = 5.6705e-01, PNorm = 44.0037, GNorm = 3.1971, lr_0 = 7.6233e-04
Loss = 5.0984e-01, PNorm = 44.0387, GNorm = 24.8177, lr_0 = 7.4682e-04
Loss = 5.9757e-01, PNorm = 44.0614, GNorm = 8.8338, lr_0 = 7.3162e-04
Loss = 6.7606e-01, PNorm = 44.0928, GNorm = 7.3962, lr_0 = 7.1673e-04
Validation rmse = 0.769160
Epoch 6
Loss = 5.1744e-01, PNorm = 44.1304, GNorm = 7.0477, lr_0 = 7.0071e-04
Loss = 5.0859e-01, PNorm = 44.1638, GNorm = 4.4652, lr_0 = 6.8645e-04
Loss = 4.2879e-01, PNorm = 44.1805, GNorm = 4.1724, lr_0 = 6.7248e-04
Loss = 4.8322e-01, PNorm = 44.1885, GNorm = 6.1790, lr_0 = 6.5879e-04
Validation rmse = 0.649510
Epoch 7
Loss = 4.7066e-01, PNorm = 44.2030, GNorm = 4.1813, lr_0 = 6.4539e-04
Loss = 4.3777e-01, PNorm = 44.2261, GNorm = 3.4765, lr_0 = 6.3226e-04
Loss = 4.9544e-01, PNorm = 44.2469, GNorm = 8.3127, lr_0 = 6.1939e-04
Loss = 3.9369e-01, PNorm = 44.2715, GNorm = 6.7069, lr_0 = 6.0679e-04
Validation rmse = 0.668471
Epoch 8
Loss = 4.7639e-01, PNorm = 44.2951, GNorm = 18.2221, lr_0 = 5.9444e-04
Loss = 4.0530e-01, PNorm = 44.3123, GNorm = 7.0502, lr_0 = 5.8234e-04
Loss = 4.4896e-01, PNorm = 44.3361, GNorm = 3.8515, lr_0 = 5.7049e-04
Loss = 4.1416e-01, PNorm = 44.3615, GNorm = 9.5748, lr_0 = 5.5888e-04
Validation rmse = 0.641368
Epoch 9
Loss = 4.6853e-01, PNorm = 44.3800, GNorm = 3.7041, lr_0 = 5.4751e-04
Loss = 3.5894e-01, PNorm = 44.3964, GNorm = 5.1955, lr_0 = 5.3637e-04
Loss = 2.9434e-01, PNorm = 44.4106, GNorm = 3.6252, lr_0 = 5.2546e-04
Loss = 3.7077e-01, PNorm = 44.4253, GNorm = 3.7889, lr_0 = 5.1476e-04
Validation rmse = 0.656518
Epoch 10
Loss = 1.6778e-01, PNorm = 44.4430, GNorm = 6.6658, lr_0 = 5.0429e-04
Loss = 3.3525e-01, PNorm = 44.4607, GNorm = 7.2999, lr_0 = 4.9403e-04
Loss = 3.0733e-01, PNorm = 44.4778, GNorm = 5.6340, lr_0 = 4.8397e-04
Loss = 3.7620e-01, PNorm = 44.4944, GNorm = 14.8678, lr_0 = 4.7413e-04
Validation rmse = 0.686776
Epoch 11
Loss = 2.9292e-01, PNorm = 44.5126, GNorm = 9.0360, lr_0 = 4.6352e-04
Loss = 2.0897e-01, PNorm = 44.5255, GNorm = 13.1198, lr_0 = 4.5409e-04
Loss = 3.2321e-01, PNorm = 44.5426, GNorm = 3.7847, lr_0 = 4.4485e-04
Loss = 3.3032e-01, PNorm = 44.5529, GNorm = 5.6348, lr_0 = 4.3580e-04
Validation rmse = 0.602473
Epoch 12
Loss = 3.8949e-01, PNorm = 44.5680, GNorm = 3.3242, lr_0 = 4.2693e-04
Loss = 2.1244e-01, PNorm = 44.5817, GNorm = 10.7946, lr_0 = 4.1824e-04
Loss = 1.8942e-01, PNorm = 44.5954, GNorm = 3.1778, lr_0 = 4.0973e-04
Loss = 2.9519e-01, PNorm = 44.6048, GNorm = 5.8110, lr_0 = 4.0139e-04
Loss = 3.2613e-01, PNorm = 44.6143, GNorm = 6.0228, lr_0 = 3.9323e-04
Validation rmse = 0.645007
Epoch 13
Loss = 1.6182e-01, PNorm = 44.6306, GNorm = 8.6731, lr_0 = 3.8522e-04
Loss = 2.7380e-01, PNorm = 44.6462, GNorm = 5.9396, lr_0 = 3.7739e-04
Loss = 2.2052e-01, PNorm = 44.6560, GNorm = 3.6455, lr_0 = 3.6971e-04
Loss = 2.5064e-01, PNorm = 44.6659, GNorm = 5.5217, lr_0 = 3.6218e-04
Validation rmse = 0.652038
Epoch 14
Loss = 2.7758e-01, PNorm = 44.6768, GNorm = 4.7258, lr_0 = 3.5481e-04
Loss = 1.9605e-01, PNorm = 44.6922, GNorm = 6.4373, lr_0 = 3.4759e-04
Loss = 1.9873e-01, PNorm = 44.7014, GNorm = 3.6961, lr_0 = 3.4052e-04
Loss = 1.4054e-01, PNorm = 44.7080, GNorm = 11.4949, lr_0 = 3.3359e-04
Validation rmse = 0.619804
Epoch 15
Loss = 2.2977e-01, PNorm = 44.7167, GNorm = 4.0668, lr_0 = 3.2680e-04
Loss = 1.8661e-01, PNorm = 44.7325, GNorm = 4.8486, lr_0 = 3.2015e-04
Loss = 1.2720e-01, PNorm = 44.7439, GNorm = 8.6434, lr_0 = 3.1364e-04
Loss = 1.7525e-01, PNorm = 44.7516, GNorm = 3.8824, lr_0 = 3.0726e-04
Validation rmse = 0.655282
Epoch 16
Loss = 2.9096e-01, PNorm = 44.7581, GNorm = 5.9413, lr_0 = 3.0039e-04
Loss = 1.6243e-01, PNorm = 44.7697, GNorm = 4.6810, lr_0 = 2.9427e-04
Loss = 2.3091e-01, PNorm = 44.7833, GNorm = 5.2424, lr_0 = 2.8828e-04
Loss = 1.3168e-01, PNorm = 44.7951, GNorm = 6.7784, lr_0 = 2.8242e-04
Validation rmse = 0.612754
Epoch 17
Loss = 1.4696e-01, PNorm = 44.8014, GNorm = 10.6226, lr_0 = 2.7667e-04
Loss = 2.3580e-01, PNorm = 44.8088, GNorm = 4.0137, lr_0 = 2.7104e-04
Loss = 9.3240e-02, PNorm = 44.8210, GNorm = 4.2652, lr_0 = 2.6553e-04
Loss = 1.9006e-01, PNorm = 44.8291, GNorm = 8.6131, lr_0 = 2.6012e-04
Validation rmse = 0.607271
Epoch 18
Loss = 7.9177e-02, PNorm = 44.8333, GNorm = 4.4122, lr_0 = 2.5483e-04
Loss = 1.4479e-01, PNorm = 44.8413, GNorm = 5.4396, lr_0 = 2.4964e-04
Loss = 1.6246e-01, PNorm = 44.8502, GNorm = 3.7965, lr_0 = 2.4456e-04
Loss = 1.5091e-01, PNorm = 44.8591, GNorm = 8.2095, lr_0 = 2.3959e-04
Validation rmse = 0.647146
Epoch 19
Loss = 2.5891e-01, PNorm = 44.8693, GNorm = 4.9795, lr_0 = 2.3471e-04
Loss = 2.1064e-01, PNorm = 44.8758, GNorm = 7.1985, lr_0 = 2.2994e-04
Loss = 1.6792e-01, PNorm = 44.8857, GNorm = 5.2043, lr_0 = 2.2526e-04
Loss = 7.2855e-03, PNorm = 44.8959, GNorm = 4.6534, lr_0 = 2.2067e-04
Validation rmse = 0.628523
Epoch 20
Loss = 1.1589e-01, PNorm = 44.9041, GNorm = 4.6591, lr_0 = 2.1618e-04
Loss = 1.0050e-01, PNorm = 44.9089, GNorm = 8.9266, lr_0 = 2.1178e-04
Loss = 1.5660e-01, PNorm = 44.9149, GNorm = 5.7742, lr_0 = 2.0747e-04
Loss = 1.7909e-01, PNorm = 44.9210, GNorm = 11.4567, lr_0 = 2.0325e-04
Validation rmse = 0.624249
Epoch 21
Loss = 1.0506e-01, PNorm = 44.9276, GNorm = 12.3841, lr_0 = 1.9871e-04
Loss = 8.5649e-02, PNorm = 44.9346, GNorm = 4.8582, lr_0 = 1.9466e-04
Loss = 1.2069e-01, PNorm = 44.9422, GNorm = 11.3977, lr_0 = 1.9070e-04
Loss = 1.1049e-01, PNorm = 44.9468, GNorm = 2.6208, lr_0 = 1.8682e-04
Validation rmse = 0.630795
Epoch 22
Loss = 1.6368e-01, PNorm = 44.9509, GNorm = 6.3612, lr_0 = 1.8302e-04
Loss = 8.1185e-02, PNorm = 44.9573, GNorm = 3.5781, lr_0 = 1.7930e-04
Loss = 4.2455e-02, PNorm = 44.9651, GNorm = 4.4987, lr_0 = 1.7565e-04
Loss = 5.4061e-02, PNorm = 44.9709, GNorm = 4.8823, lr_0 = 1.7207e-04
Validation rmse = 0.646537
Epoch 23
Loss = 2.5178e-01, PNorm = 44.9746, GNorm = 13.0121, lr_0 = 1.6857e-04
Loss = 1.3603e-01, PNorm = 44.9800, GNorm = 5.6219, lr_0 = 1.6514e-04
Loss = 7.2192e-02, PNorm = 44.9865, GNorm = 9.3595, lr_0 = 1.6178e-04
Loss = 2.5677e-02, PNorm = 44.9927, GNorm = 5.6390, lr_0 = 1.5849e-04
Validation rmse = 0.611513
Epoch 24
Loss = 2.2577e-01, PNorm = 44.9971, GNorm = 15.2631, lr_0 = 1.5526e-04
Loss = -5.3682e-02, PNorm = 45.0023, GNorm = 4.8183, lr_0 = 1.5210e-04
Loss = 1.5781e-01, PNorm = 45.0072, GNorm = 6.6087, lr_0 = 1.4901e-04
Loss = 8.0876e-02, PNorm = 45.0112, GNorm = 3.8724, lr_0 = 1.4598e-04
Loss = 2.0023e-02, PNorm = 45.0173, GNorm = 6.6719, lr_0 = 1.4301e-04
Validation rmse = 0.614012
Epoch 25
Loss = 3.2080e-02, PNorm = 45.0230, GNorm = 6.9493, lr_0 = 1.4010e-04
Loss = 8.4205e-02, PNorm = 45.0267, GNorm = 5.4239, lr_0 = 1.3725e-04
Loss = -1.3699e-02, PNorm = 45.0300, GNorm = 3.4153, lr_0 = 1.3445e-04
Loss = 1.3500e-01, PNorm = 45.0355, GNorm = 18.4673, lr_0 = 1.3172e-04
Loss = 1.7816e-01, PNorm = 45.0357, GNorm = 9.7922, lr_0 = 1.3145e-04
Validation rmse = 0.631696
Epoch 26
Loss = -3.6490e-02, PNorm = 45.0406, GNorm = 3.7975, lr_0 = 1.2877e-04
Loss = 8.7444e-02, PNorm = 45.0443, GNorm = 7.6891, lr_0 = 1.2615e-04
Loss = 2.1683e-02, PNorm = 45.0483, GNorm = 4.9108, lr_0 = 1.2358e-04
Loss = 1.3252e-01, PNorm = 45.0531, GNorm = 6.7450, lr_0 = 1.2107e-04
Validation rmse = 0.624859
Epoch 27
Loss = 5.8474e-02, PNorm = 45.0571, GNorm = 3.7246, lr_0 = 1.1861e-04
Loss = -8.2546e-02, PNorm = 45.0619, GNorm = 4.8614, lr_0 = 1.1619e-04
Loss = 3.9744e-03, PNorm = 45.0659, GNorm = 6.6443, lr_0 = 1.1383e-04
Loss = 1.5621e-01, PNorm = 45.0674, GNorm = 2.8522, lr_0 = 1.1151e-04
Validation rmse = 0.626345
Epoch 28
Loss = 5.2844e-02, PNorm = 45.0702, GNorm = 4.0740, lr_0 = 1.0924e-04
Loss = 1.0427e-02, PNorm = 45.0752, GNorm = 6.0378, lr_0 = 1.0702e-04
Loss = 7.0435e-02, PNorm = 45.0799, GNorm = 10.7662, lr_0 = 1.0484e-04
Loss = -6.2418e-02, PNorm = 45.0838, GNorm = 3.8207, lr_0 = 1.0271e-04
Validation rmse = 0.618536
Epoch 29
Loss = -2.9874e-02, PNorm = 45.0872, GNorm = 11.0026, lr_0 = 1.0062e-04
Loss = -3.8928e-02, PNorm = 45.0915, GNorm = 4.4962, lr_0 = 1.0000e-04
Loss = 3.5701e-02, PNorm = 45.0953, GNorm = 5.7215, lr_0 = 1.0000e-04
Loss = 4.5268e-02, PNorm = 45.0969, GNorm = 7.4690, lr_0 = 1.0000e-04
Validation rmse = 0.619483
Model 0 best validation rmse = 0.602473 on epoch 11
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.654106
Ensemble test rmse = 0.654106
1-fold cross validation
	Seed 0 ==> test rmse = 0.654106
Overall test rmse = 0.654106 +/- 0.000000
Elapsed time = 0:01:40
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7141e+00, PNorm = 43.3126, GNorm = 1.5038, lr_0 = 2.2073e-04
Loss = 1.4611e+00, PNorm = 43.3128, GNorm = 2.4070, lr_0 = 3.3049e-04
Loss = 1.3689e+00, PNorm = 43.3179, GNorm = 2.2017, lr_0 = 4.4024e-04
Loss = 1.2903e+00, PNorm = 43.3315, GNorm = 2.5506, lr_0 = 5.5000e-04
Validation rmse = 1.429445
Epoch 1
Loss = 1.1943e+00, PNorm = 43.3515, GNorm = 1.3762, lr_0 = 6.7073e-04
Loss = 1.1584e+00, PNorm = 43.3791, GNorm = 5.0081, lr_0 = 7.8049e-04
Loss = 1.0083e+00, PNorm = 43.4199, GNorm = 3.4683, lr_0 = 8.9024e-04
Loss = 9.4808e-01, PNorm = 43.4803, GNorm = 5.9187, lr_0 = 1.0000e-03
Validation rmse = 1.091009
Epoch 2
Loss = 8.9046e-01, PNorm = 43.5406, GNorm = 5.1338, lr_0 = 9.8014e-04
Loss = 7.7973e-01, PNorm = 43.5882, GNorm = 3.9421, lr_0 = 9.6068e-04
Loss = 7.9940e-01, PNorm = 43.6391, GNorm = 7.9694, lr_0 = 9.4160e-04
Loss = 6.7282e-01, PNorm = 43.6909, GNorm = 9.6999, lr_0 = 9.2290e-04
Validation rmse = 0.775562
Epoch 3
Loss = 6.7626e-01, PNorm = 43.7493, GNorm = 2.1214, lr_0 = 9.0277e-04
Loss = 6.2299e-01, PNorm = 43.7998, GNorm = 3.6545, lr_0 = 8.8484e-04
Loss = 6.1937e-01, PNorm = 43.8264, GNorm = 6.4048, lr_0 = 8.6727e-04
Loss = 5.9278e-01, PNorm = 43.8701, GNorm = 4.0826, lr_0 = 8.5005e-04
Validation rmse = 0.788582
Epoch 4
Loss = 5.1372e-01, PNorm = 43.9074, GNorm = 6.5033, lr_0 = 8.3317e-04
Loss = 5.5291e-01, PNorm = 43.9473, GNorm = 14.0600, lr_0 = 8.1662e-04
Loss = 7.1547e-01, PNorm = 43.9811, GNorm = 3.1705, lr_0 = 8.0041e-04
Loss = 6.5952e-01, PNorm = 44.0140, GNorm = 10.2716, lr_0 = 7.8451e-04
Validation rmse = 0.973585
Epoch 5
Loss = 6.8426e-01, PNorm = 44.0454, GNorm = 2.4769, lr_0 = 7.6893e-04
Loss = 6.9313e-01, PNorm = 44.0855, GNorm = 2.6729, lr_0 = 7.5366e-04
Loss = 4.6833e-01, PNorm = 44.1282, GNorm = 11.8180, lr_0 = 7.3870e-04
Loss = 4.9031e-01, PNorm = 44.1506, GNorm = 5.7152, lr_0 = 7.2403e-04
Validation rmse = 0.739438
Epoch 6
Loss = 5.8826e-01, PNorm = 44.1721, GNorm = 8.1576, lr_0 = 7.0823e-04
Loss = 4.3231e-01, PNorm = 44.2076, GNorm = 2.7605, lr_0 = 6.9417e-04
Loss = 4.1728e-01, PNorm = 44.2306, GNorm = 9.8319, lr_0 = 6.8038e-04
Loss = 5.0603e-01, PNorm = 44.2495, GNorm = 7.0003, lr_0 = 6.6687e-04
Loss = 4.7175e-01, PNorm = 44.2735, GNorm = 4.9576, lr_0 = 6.5363e-04
Validation rmse = 0.675930
Epoch 7
Loss = 3.7863e-01, PNorm = 44.3068, GNorm = 3.8444, lr_0 = 6.4065e-04
Loss = 3.3739e-01, PNorm = 44.3314, GNorm = 10.3479, lr_0 = 6.2793e-04
Loss = 4.2578e-01, PNorm = 44.3466, GNorm = 4.7278, lr_0 = 6.1546e-04
Loss = 3.8309e-01, PNorm = 44.3670, GNorm = 3.6821, lr_0 = 6.0324e-04
Validation rmse = 0.714163
Epoch 8
Loss = 2.5535e-01, PNorm = 44.3847, GNorm = 4.2096, lr_0 = 5.9007e-04
Loss = 4.8609e-01, PNorm = 44.3976, GNorm = 16.2893, lr_0 = 5.7836e-04
Loss = 5.0272e-01, PNorm = 44.4114, GNorm = 2.1883, lr_0 = 5.6687e-04
Loss = 4.9123e-01, PNorm = 44.4404, GNorm = 12.5715, lr_0 = 5.5561e-04
Validation rmse = 0.669225
Epoch 9
Loss = 3.3483e-01, PNorm = 44.4681, GNorm = 2.5637, lr_0 = 5.4458e-04
Loss = 2.6688e-01, PNorm = 44.4906, GNorm = 4.9684, lr_0 = 5.3377e-04
Loss = 3.8724e-01, PNorm = 44.4968, GNorm = 3.2181, lr_0 = 5.2317e-04
Loss = 3.3225e-01, PNorm = 44.5128, GNorm = 3.6277, lr_0 = 5.1278e-04
Validation rmse = 0.670160
Epoch 10
Loss = 2.7168e-01, PNorm = 44.5315, GNorm = 4.9967, lr_0 = 5.0260e-04
Loss = 3.1675e-01, PNorm = 44.5508, GNorm = 8.6004, lr_0 = 4.9262e-04
Loss = 3.9253e-01, PNorm = 44.5636, GNorm = 4.1909, lr_0 = 4.8283e-04
Loss = 3.1640e-01, PNorm = 44.5798, GNorm = 3.4514, lr_0 = 4.7325e-04
Validation rmse = 0.661971
Epoch 11
Loss = 1.5079e-01, PNorm = 44.5972, GNorm = 8.6665, lr_0 = 4.6292e-04
Loss = 1.0051e-01, PNorm = 44.6153, GNorm = 7.3870, lr_0 = 4.5373e-04
Loss = 3.3236e-01, PNorm = 44.6241, GNorm = 3.1588, lr_0 = 4.4472e-04
Loss = 4.1423e-01, PNorm = 44.6332, GNorm = 2.6984, lr_0 = 4.3589e-04
Validation rmse = 0.660414
Epoch 12
Loss = 5.3043e-01, PNorm = 44.6496, GNorm = 3.1073, lr_0 = 4.2723e-04
Loss = 2.0218e-01, PNorm = 44.6701, GNorm = 7.6253, lr_0 = 4.1875e-04
Loss = 2.8107e-01, PNorm = 44.6831, GNorm = 4.1438, lr_0 = 4.1043e-04
Loss = 2.3241e-01, PNorm = 44.6990, GNorm = 5.6468, lr_0 = 4.0228e-04
Loss = 2.6159e-01, PNorm = 44.7149, GNorm = 3.8684, lr_0 = 3.9429e-04
Loss = 1.8719e-01, PNorm = 44.7165, GNorm = 4.5751, lr_0 = 3.9350e-04
Validation rmse = 0.638415
Epoch 13
Loss = 2.4482e-01, PNorm = 44.7258, GNorm = 4.9611, lr_0 = 3.8569e-04
Loss = 2.3248e-01, PNorm = 44.7354, GNorm = 7.1876, lr_0 = 3.7803e-04
Loss = 3.6850e-01, PNorm = 44.7487, GNorm = 3.7771, lr_0 = 3.7052e-04
Loss = 3.6777e-01, PNorm = 44.7616, GNorm = 4.9614, lr_0 = 3.6317e-04
Validation rmse = 0.675749
Epoch 14
Loss = 2.8785e-01, PNorm = 44.7778, GNorm = 6.1206, lr_0 = 3.5595e-04
Loss = 2.6271e-01, PNorm = 44.7918, GNorm = 4.0502, lr_0 = 3.4889e-04
Loss = 2.0970e-01, PNorm = 44.8073, GNorm = 4.3931, lr_0 = 3.4196e-04
Loss = 1.5473e-01, PNorm = 44.8148, GNorm = 5.4856, lr_0 = 3.3517e-04
Validation rmse = 0.673200
Epoch 15
Loss = 1.0838e-01, PNorm = 44.8264, GNorm = 7.0063, lr_0 = 3.2851e-04
Loss = 2.4729e-01, PNorm = 44.8318, GNorm = 4.0125, lr_0 = 3.2199e-04
Loss = 1.8929e-01, PNorm = 44.8417, GNorm = 4.8854, lr_0 = 3.1559e-04
Loss = 2.3479e-01, PNorm = 44.8472, GNorm = 4.7429, lr_0 = 3.0933e-04
Validation rmse = 0.685382
Epoch 16
Loss = 1.0112e-01, PNorm = 44.8576, GNorm = 6.9314, lr_0 = 3.0258e-04
Loss = 1.7328e-01, PNorm = 44.8705, GNorm = 6.4085, lr_0 = 2.9657e-04
Loss = 1.4199e-01, PNorm = 44.8809, GNorm = 5.2617, lr_0 = 2.9068e-04
Loss = 1.6139e-01, PNorm = 44.8891, GNorm = 3.1556, lr_0 = 2.8491e-04
Validation rmse = 0.636210
Epoch 17
Loss = 1.2529e-01, PNorm = 44.8959, GNorm = 4.4195, lr_0 = 2.7925e-04
Loss = 1.3073e-01, PNorm = 44.9083, GNorm = 7.8023, lr_0 = 2.7370e-04
Loss = 1.4943e-01, PNorm = 44.9209, GNorm = 12.3998, lr_0 = 2.6827e-04
Loss = 1.2703e-01, PNorm = 44.9278, GNorm = 4.6834, lr_0 = 2.6294e-04
Validation rmse = 0.648154
Epoch 18
Loss = -5.3422e-02, PNorm = 44.9367, GNorm = 3.3464, lr_0 = 2.5720e-04
Loss = 1.6973e-01, PNorm = 44.9439, GNorm = 3.6477, lr_0 = 2.5210e-04
Loss = 1.0260e-01, PNorm = 44.9547, GNorm = 5.4718, lr_0 = 2.4709e-04
Loss = 1.5731e-01, PNorm = 44.9616, GNorm = 5.8057, lr_0 = 2.4218e-04
Loss = 8.1622e-02, PNorm = 44.9680, GNorm = 4.1497, lr_0 = 2.3738e-04
Validation rmse = 0.641268
Epoch 19
Loss = 1.1049e-01, PNorm = 44.9782, GNorm = 5.1367, lr_0 = 2.3266e-04
Loss = 8.4843e-02, PNorm = 44.9859, GNorm = 4.4785, lr_0 = 2.2804e-04
Loss = 1.4720e-01, PNorm = 44.9906, GNorm = 5.9160, lr_0 = 2.2351e-04
Loss = 1.1853e-01, PNorm = 45.0014, GNorm = 4.5546, lr_0 = 2.1907e-04
Validation rmse = 0.633909
Epoch 20
Loss = 2.1899e-02, PNorm = 45.0079, GNorm = 3.8498, lr_0 = 2.1472e-04
Loss = 8.7694e-02, PNorm = 45.0138, GNorm = 8.0841, lr_0 = 2.1046e-04
Loss = 4.9892e-02, PNorm = 45.0213, GNorm = 6.0879, lr_0 = 2.0628e-04
Loss = 1.4599e-01, PNorm = 45.0275, GNorm = 8.0157, lr_0 = 2.0219e-04
Validation rmse = 0.638695
Epoch 21
Loss = 4.9210e-02, PNorm = 45.0345, GNorm = 5.3269, lr_0 = 1.9777e-04
Loss = 8.7505e-02, PNorm = 45.0421, GNorm = 3.3686, lr_0 = 1.9385e-04
Loss = 9.7778e-02, PNorm = 45.0492, GNorm = 7.9042, lr_0 = 1.9000e-04
Loss = 1.0833e-01, PNorm = 45.0549, GNorm = 4.0800, lr_0 = 1.8622e-04
Validation rmse = 0.638273
Epoch 22
Loss = 6.0973e-02, PNorm = 45.0613, GNorm = 10.0636, lr_0 = 1.8253e-04
Loss = 1.4998e-01, PNorm = 45.0665, GNorm = 5.4941, lr_0 = 1.7890e-04
Loss = 3.9734e-02, PNorm = 45.0735, GNorm = 11.6369, lr_0 = 1.7535e-04
Loss = 1.1123e-01, PNorm = 45.0785, GNorm = 4.6489, lr_0 = 1.7187e-04
Validation rmse = 0.626175
Epoch 23
Loss = 3.1315e-02, PNorm = 45.0849, GNorm = 4.8952, lr_0 = 1.6812e-04
Loss = -1.2732e-02, PNorm = 45.0927, GNorm = 4.0439, lr_0 = 1.6478e-04
Loss = 2.0266e-02, PNorm = 45.1002, GNorm = 3.9687, lr_0 = 1.6151e-04
Loss = 8.5827e-02, PNorm = 45.1035, GNorm = 4.3166, lr_0 = 1.5830e-04
Validation rmse = 0.642157
Epoch 24
Loss = 2.0836e-01, PNorm = 45.1040, GNorm = 8.4358, lr_0 = 1.5516e-04
Loss = -1.8366e-02, PNorm = 45.1068, GNorm = 3.6504, lr_0 = 1.5207e-04
Loss = 1.7150e-01, PNorm = 45.1124, GNorm = 11.7716, lr_0 = 1.4905e-04
Loss = -3.5524e-02, PNorm = 45.1181, GNorm = 5.3081, lr_0 = 1.4609e-04
Loss = 6.8933e-02, PNorm = 45.1272, GNorm = 7.9502, lr_0 = 1.4319e-04
Validation rmse = 0.627466
Epoch 25
Loss = 1.7451e-02, PNorm = 45.1311, GNorm = 12.4461, lr_0 = 1.4035e-04
Loss = 1.0435e-01, PNorm = 45.1311, GNorm = 6.3982, lr_0 = 1.3756e-04
Loss = 8.2446e-02, PNorm = 45.1352, GNorm = 5.7374, lr_0 = 1.3483e-04
Loss = 6.2426e-02, PNorm = 45.1413, GNorm = 6.1512, lr_0 = 1.3215e-04
Validation rmse = 0.628385
Epoch 26
Loss = -7.7146e-03, PNorm = 45.1486, GNorm = 3.4312, lr_0 = 1.2927e-04
Loss = -6.6980e-03, PNorm = 45.1531, GNorm = 10.3205, lr_0 = 1.2670e-04
Loss = 6.2259e-02, PNorm = 45.1572, GNorm = 7.1364, lr_0 = 1.2419e-04
Loss = 2.7353e-02, PNorm = 45.1604, GNorm = 10.1507, lr_0 = 1.2172e-04
Validation rmse = 0.632951
Epoch 27
Loss = 5.3773e-02, PNorm = 45.1631, GNorm = 8.2858, lr_0 = 1.1930e-04
Loss = -1.8004e-02, PNorm = 45.1671, GNorm = 3.9866, lr_0 = 1.1693e-04
Loss = 4.8484e-02, PNorm = 45.1711, GNorm = 8.2607, lr_0 = 1.1461e-04
Loss = 3.2085e-04, PNorm = 45.1754, GNorm = 14.0768, lr_0 = 1.1234e-04
Validation rmse = 0.643998
Epoch 28
Loss = -8.9045e-02, PNorm = 45.1783, GNorm = 22.2252, lr_0 = 1.0989e-04
Loss = -1.4503e-02, PNorm = 45.1828, GNorm = 6.2783, lr_0 = 1.0770e-04
Loss = -1.1845e-02, PNorm = 45.1861, GNorm = 4.0326, lr_0 = 1.0556e-04
Loss = 1.1278e-01, PNorm = 45.1888, GNorm = 12.5925, lr_0 = 1.0347e-04
Validation rmse = 0.634000
Epoch 29
Loss = -2.3171e-02, PNorm = 45.1899, GNorm = 4.6400, lr_0 = 1.0141e-04
Loss = 7.0476e-02, PNorm = 45.1923, GNorm = 6.7256, lr_0 = 1.0000e-04
Loss = 4.0022e-03, PNorm = 45.1969, GNorm = 6.8632, lr_0 = 1.0000e-04
Loss = -3.9259e-02, PNorm = 45.2008, GNorm = 4.7280, lr_0 = 1.0000e-04
Validation rmse = 0.639023
Model 0 best validation rmse = 0.626175 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.626003
Ensemble test rmse = 0.626003
1-fold cross validation
	Seed 0 ==> test rmse = 0.626003
Overall test rmse = 0.626003 +/- 0.000000
Elapsed time = 0:01:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,325 | train size = 1,060 | val size = 132 | test size = 133
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8691e+00, PNorm = 43.3131, GNorm = 3.2346, lr_0 = 2.1786e-04
Loss = 1.4769e+00, PNorm = 43.3153, GNorm = 1.4884, lr_0 = 3.2500e-04
Loss = 1.4071e+00, PNorm = 43.3200, GNorm = 1.3020, lr_0 = 4.3214e-04
Loss = 1.3598e+00, PNorm = 43.3302, GNorm = 2.5158, lr_0 = 5.3929e-04
Validation rmse = 1.494724
Epoch 1
Loss = 1.1864e+00, PNorm = 43.3529, GNorm = 1.8286, lr_0 = 6.5714e-04
Loss = 1.0938e+00, PNorm = 43.3818, GNorm = 2.3659, lr_0 = 7.6429e-04
Loss = 1.0917e+00, PNorm = 43.4180, GNorm = 2.6679, lr_0 = 8.7143e-04
Loss = 9.1279e-01, PNorm = 43.4810, GNorm = 3.8591, lr_0 = 9.7857e-04
Validation rmse = 0.988312
Epoch 2
Loss = 8.4055e-01, PNorm = 43.5504, GNorm = 5.4117, lr_0 = 9.8253e-04
Loss = 7.4762e-01, PNorm = 43.6063, GNorm = 3.2901, lr_0 = 9.6348e-04
Loss = 6.9931e-01, PNorm = 43.6597, GNorm = 5.0383, lr_0 = 9.4480e-04
Loss = 7.4642e-01, PNorm = 43.7092, GNorm = 5.5294, lr_0 = 9.2648e-04
Validation rmse = 0.836558
Epoch 3
Loss = 6.1662e-01, PNorm = 43.7489, GNorm = 6.8853, lr_0 = 9.0852e-04
Loss = 6.2314e-01, PNorm = 43.7841, GNorm = 5.5763, lr_0 = 8.9090e-04
Loss = 5.6947e-01, PNorm = 43.8200, GNorm = 5.3038, lr_0 = 8.7363e-04
Loss = 6.1394e-01, PNorm = 43.8528, GNorm = 7.1998, lr_0 = 8.5669e-04
Validation rmse = 0.715854
Epoch 4
Loss = 4.8193e-01, PNorm = 43.8917, GNorm = 7.0345, lr_0 = 8.3843e-04
Loss = 5.4329e-01, PNorm = 43.9195, GNorm = 5.0720, lr_0 = 8.2218e-04
Loss = 4.4572e-01, PNorm = 43.9556, GNorm = 4.7554, lr_0 = 8.0624e-04
Loss = 5.1868e-01, PNorm = 43.9761, GNorm = 3.8000, lr_0 = 7.9060e-04
Loss = 4.7815e-01, PNorm = 44.0023, GNorm = 3.9477, lr_0 = 7.7528e-04
Validation rmse = 0.757913
Epoch 5
Loss = 4.4542e-01, PNorm = 44.0327, GNorm = 9.7642, lr_0 = 7.6024e-04
Loss = 5.1374e-01, PNorm = 44.0587, GNorm = 4.1419, lr_0 = 7.4550e-04
Loss = 4.5402e-01, PNorm = 44.0907, GNorm = 2.6684, lr_0 = 7.3105e-04
Loss = 4.9763e-01, PNorm = 44.1116, GNorm = 3.2957, lr_0 = 7.1687e-04
Validation rmse = 0.727004
Epoch 6
Loss = 5.4418e-01, PNorm = 44.1412, GNorm = 4.1764, lr_0 = 7.0160e-04
Loss = 4.6757e-01, PNorm = 44.1657, GNorm = 3.8517, lr_0 = 6.8799e-04
Loss = 3.4725e-01, PNorm = 44.1913, GNorm = 3.4777, lr_0 = 6.7465e-04
Loss = 3.9356e-01, PNorm = 44.2129, GNorm = 4.0838, lr_0 = 6.6157e-04
Validation rmse = 0.620648
Epoch 7
Loss = 2.7148e-01, PNorm = 44.2357, GNorm = 6.9166, lr_0 = 6.4748e-04
Loss = 3.4805e-01, PNorm = 44.2600, GNorm = 7.0133, lr_0 = 6.3492e-04
Loss = 3.6706e-01, PNorm = 44.2798, GNorm = 4.4432, lr_0 = 6.2261e-04
Loss = 5.1806e-01, PNorm = 44.2948, GNorm = 3.7049, lr_0 = 6.1054e-04
Validation rmse = 0.654653
Epoch 8
Loss = 4.8885e-01, PNorm = 44.3126, GNorm = 4.7675, lr_0 = 5.9870e-04
Loss = 2.6975e-01, PNorm = 44.3387, GNorm = 4.6944, lr_0 = 5.8709e-04
Loss = 3.6875e-01, PNorm = 44.3524, GNorm = 3.8661, lr_0 = 5.7571e-04
Loss = 4.2640e-01, PNorm = 44.3681, GNorm = 4.8502, lr_0 = 5.6455e-04
Loss = 3.6766e-01, PNorm = 44.3854, GNorm = 6.5453, lr_0 = 5.5360e-04
Validation rmse = 0.656692
Epoch 9
Loss = 4.5832e-01, PNorm = 44.4037, GNorm = 7.7234, lr_0 = 5.4181e-04
Loss = 2.8187e-01, PNorm = 44.4175, GNorm = 3.6124, lr_0 = 5.3130e-04
Loss = 3.8856e-01, PNorm = 44.4341, GNorm = 3.4882, lr_0 = 5.2100e-04
Loss = 3.0936e-01, PNorm = 44.4470, GNorm = 10.4057, lr_0 = 5.1090e-04
Validation rmse = 0.624445
Epoch 10
Loss = 3.6497e-01, PNorm = 44.4675, GNorm = 6.9512, lr_0 = 5.0099e-04
Loss = 2.0928e-01, PNorm = 44.4905, GNorm = 12.6112, lr_0 = 4.9128e-04
Loss = 3.2210e-01, PNorm = 44.4997, GNorm = 6.7570, lr_0 = 4.8175e-04
Loss = 3.0925e-01, PNorm = 44.5101, GNorm = 3.5567, lr_0 = 4.7241e-04
Validation rmse = 0.633474
Epoch 11
Loss = 9.8565e-02, PNorm = 44.5267, GNorm = 6.3330, lr_0 = 4.6234e-04
Loss = 2.4048e-01, PNorm = 44.5415, GNorm = 3.8164, lr_0 = 4.5338e-04
Loss = 2.8901e-01, PNorm = 44.5565, GNorm = 2.9782, lr_0 = 4.4459e-04
Loss = 2.6320e-01, PNorm = 44.5699, GNorm = 6.5877, lr_0 = 4.3597e-04
Validation rmse = 0.645655
Epoch 12
Loss = 3.3754e-01, PNorm = 44.5784, GNorm = 5.5070, lr_0 = 4.2668e-04
Loss = 1.6978e-01, PNorm = 44.5942, GNorm = 7.6699, lr_0 = 4.1841e-04
Loss = 2.4730e-01, PNorm = 44.6066, GNorm = 4.2902, lr_0 = 4.1029e-04
Loss = 1.4457e-01, PNorm = 44.6162, GNorm = 9.5375, lr_0 = 4.0234e-04
Loss = 3.0395e-01, PNorm = 44.6257, GNorm = 2.5563, lr_0 = 3.9454e-04
Validation rmse = 0.638110
Epoch 13
Loss = 1.6767e-01, PNorm = 44.6440, GNorm = 7.0790, lr_0 = 3.8689e-04
Loss = 3.0364e-01, PNorm = 44.6514, GNorm = 3.2481, lr_0 = 3.7939e-04
Loss = 1.6647e-01, PNorm = 44.6601, GNorm = 5.6213, lr_0 = 3.7203e-04
Loss = 2.3169e-01, PNorm = 44.6738, GNorm = 8.8702, lr_0 = 3.6482e-04
Validation rmse = 0.627860
Epoch 14
Loss = 1.3081e-01, PNorm = 44.6893, GNorm = 5.3286, lr_0 = 3.5704e-04
Loss = 2.0772e-01, PNorm = 44.6963, GNorm = 10.4780, lr_0 = 3.5012e-04
Loss = 2.0887e-01, PNorm = 44.7095, GNorm = 7.2767, lr_0 = 3.4333e-04
Loss = 1.4311e-01, PNorm = 44.7220, GNorm = 13.2288, lr_0 = 3.3668e-04
Validation rmse = 0.614426
Epoch 15
Loss = 1.4729e-01, PNorm = 44.7378, GNorm = 5.0679, lr_0 = 3.3015e-04
Loss = 1.5872e-01, PNorm = 44.7451, GNorm = 11.0993, lr_0 = 3.2375e-04
Loss = 3.1088e-01, PNorm = 44.7525, GNorm = 9.9682, lr_0 = 3.1747e-04
Loss = 2.1879e-01, PNorm = 44.7613, GNorm = 5.0838, lr_0 = 3.1131e-04
Validation rmse = 0.618043
Epoch 16
Loss = 2.7555e-01, PNorm = 44.7756, GNorm = 4.0216, lr_0 = 3.0468e-04
Loss = 1.2138e-01, PNorm = 44.7856, GNorm = 5.0087, lr_0 = 2.9877e-04
Loss = 8.0409e-02, PNorm = 44.7967, GNorm = 15.4952, lr_0 = 2.9298e-04
Loss = 2.7021e-01, PNorm = 44.8022, GNorm = 4.7687, lr_0 = 2.8730e-04
Loss = 2.4085e-01, PNorm = 44.8114, GNorm = 5.3746, lr_0 = 2.8173e-04
Loss = 2.4050e-03, PNorm = 44.8127, GNorm = 7.6198, lr_0 = 2.8118e-04
Validation rmse = 0.610698
Epoch 17
Loss = 2.0398e-01, PNorm = 44.8254, GNorm = 7.1482, lr_0 = 2.7573e-04
Loss = 1.1640e-01, PNorm = 44.8359, GNorm = 4.5572, lr_0 = 2.7038e-04
Loss = 1.1379e-01, PNorm = 44.8445, GNorm = 7.2968, lr_0 = 2.6514e-04
Loss = 1.6150e-01, PNorm = 44.8450, GNorm = 4.4247, lr_0 = 2.6000e-04
Validation rmse = 0.624162
Epoch 18
Loss = 1.8055e-01, PNorm = 44.8513, GNorm = 4.3003, lr_0 = 2.5495e-04
Loss = 1.7754e-01, PNorm = 44.8636, GNorm = 5.3575, lr_0 = 2.5001e-04
Loss = 1.6228e-01, PNorm = 44.8753, GNorm = 6.1978, lr_0 = 2.4516e-04
Loss = 3.8159e-02, PNorm = 44.8809, GNorm = 4.0639, lr_0 = 2.4041e-04
Validation rmse = 0.634359
Epoch 19
Loss = 7.1442e-02, PNorm = 44.8871, GNorm = 3.6954, lr_0 = 2.3529e-04
Loss = 8.1730e-02, PNorm = 44.8968, GNorm = 12.7749, lr_0 = 2.3073e-04
Loss = 1.4312e-01, PNorm = 44.9035, GNorm = 10.2586, lr_0 = 2.2625e-04
Loss = 8.9534e-02, PNorm = 44.9104, GNorm = 4.0198, lr_0 = 2.2186e-04
Validation rmse = 0.625874
Epoch 20
Loss = 9.7913e-02, PNorm = 44.9171, GNorm = 3.7215, lr_0 = 2.1756e-04
Loss = 9.0056e-02, PNorm = 44.9233, GNorm = 4.8103, lr_0 = 2.1334e-04
Loss = 8.4520e-02, PNorm = 44.9300, GNorm = 6.6331, lr_0 = 2.0921e-04
Loss = 4.5213e-02, PNorm = 44.9374, GNorm = 11.8855, lr_0 = 2.0515e-04
Loss = 5.2391e-02, PNorm = 44.9427, GNorm = 5.8452, lr_0 = 2.0117e-04
Loss = 1.5461e-01, PNorm = 44.9428, GNorm = 8.8979, lr_0 = 2.0078e-04
Validation rmse = 0.625344
Epoch 21
Loss = 5.0949e-02, PNorm = 44.9472, GNorm = 5.4978, lr_0 = 1.9689e-04
Loss = 9.6474e-02, PNorm = 44.9543, GNorm = 8.4748, lr_0 = 1.9307e-04
Loss = 1.2830e-01, PNorm = 44.9566, GNorm = 7.9441, lr_0 = 1.8933e-04
Loss = 9.3846e-02, PNorm = 44.9598, GNorm = 4.5382, lr_0 = 1.8566e-04
Validation rmse = 0.635535
Epoch 22
Loss = 5.3130e-02, PNorm = 44.9664, GNorm = 9.9525, lr_0 = 1.8170e-04
Loss = 4.5824e-02, PNorm = 44.9740, GNorm = 6.0815, lr_0 = 1.7818e-04
Loss = 1.6665e-03, PNorm = 44.9808, GNorm = 6.7353, lr_0 = 1.7472e-04
Loss = 1.0592e-01, PNorm = 44.9846, GNorm = 4.9182, lr_0 = 1.7133e-04
Validation rmse = 0.629305
Epoch 23
Loss = 1.6031e-02, PNorm = 44.9899, GNorm = 14.9922, lr_0 = 1.6801e-04
Loss = 2.8406e-02, PNorm = 44.9947, GNorm = 11.0713, lr_0 = 1.6475e-04
Loss = 6.9169e-02, PNorm = 44.9984, GNorm = 3.7130, lr_0 = 1.6156e-04
Loss = -1.9849e-02, PNorm = 45.0036, GNorm = 4.9701, lr_0 = 1.5843e-04
Validation rmse = 0.645008
Epoch 24
Loss = -6.0027e-02, PNorm = 45.0085, GNorm = 5.2660, lr_0 = 1.5505e-04
Loss = 2.9672e-02, PNorm = 45.0148, GNorm = 25.6432, lr_0 = 1.5205e-04
Loss = 9.7650e-02, PNorm = 45.0187, GNorm = 5.0863, lr_0 = 1.4910e-04
Loss = 4.3750e-02, PNorm = 45.0223, GNorm = 11.9137, lr_0 = 1.4621e-04
Loss = 4.1485e-02, PNorm = 45.0274, GNorm = 16.3224, lr_0 = 1.4337e-04
Validation rmse = 0.620065
Epoch 25
Loss = 3.9473e-02, PNorm = 45.0319, GNorm = 7.8848, lr_0 = 1.4059e-04
Loss = 1.4935e-02, PNorm = 45.0353, GNorm = 7.7584, lr_0 = 1.3787e-04
Loss = -4.7060e-02, PNorm = 45.0409, GNorm = 3.9539, lr_0 = 1.3519e-04
Loss = 7.3219e-02, PNorm = 45.0446, GNorm = 11.1508, lr_0 = 1.3257e-04
Validation rmse = 0.650666
Epoch 26
Loss = -4.3855e-02, PNorm = 45.0460, GNorm = 6.9863, lr_0 = 1.2975e-04
Loss = 1.5064e-02, PNorm = 45.0505, GNorm = 6.5416, lr_0 = 1.2723e-04
Loss = 1.0401e-01, PNorm = 45.0542, GNorm = 4.3964, lr_0 = 1.2476e-04
Loss = 3.9670e-02, PNorm = 45.0586, GNorm = 7.5429, lr_0 = 1.2234e-04
Validation rmse = 0.624794
Epoch 27
Loss = -5.2211e-02, PNorm = 45.0625, GNorm = 8.4460, lr_0 = 1.1974e-04
Loss = 9.9250e-02, PNorm = 45.0646, GNorm = 7.2595, lr_0 = 1.1742e-04
Loss = -1.2941e-02, PNorm = 45.0686, GNorm = 4.8511, lr_0 = 1.1514e-04
Loss = -1.1014e-02, PNorm = 45.0733, GNorm = 4.6923, lr_0 = 1.1291e-04
Validation rmse = 0.621904
Epoch 28
Loss = -3.6344e-02, PNorm = 45.0770, GNorm = 12.9060, lr_0 = 1.1072e-04
Loss = 1.2055e-02, PNorm = 45.0795, GNorm = 7.2695, lr_0 = 1.0857e-04
Loss = -9.1144e-03, PNorm = 45.0834, GNorm = 7.1015, lr_0 = 1.0647e-04
Loss = -1.0149e-02, PNorm = 45.0880, GNorm = 8.4745, lr_0 = 1.0440e-04
Validation rmse = 0.636387
Epoch 29
Loss = 9.7588e-04, PNorm = 45.0907, GNorm = 7.5469, lr_0 = 1.0218e-04
Loss = -1.8165e-02, PNorm = 45.0940, GNorm = 5.1723, lr_0 = 1.0020e-04
Loss = -4.4731e-02, PNorm = 45.0972, GNorm = 4.5615, lr_0 = 1.0000e-04
Loss = -1.6896e-02, PNorm = 45.0992, GNorm = 4.7381, lr_0 = 1.0000e-04
Loss = 5.5777e-03, PNorm = 45.1028, GNorm = 5.9470, lr_0 = 1.0000e-04
Validation rmse = 0.621351
Model 0 best validation rmse = 0.610698 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.670365
Ensemble test rmse = 0.670365
1-fold cross validation
	Seed 0 ==> test rmse = 0.670365
Overall test rmse = 0.670365 +/- 0.000000
Elapsed time = 0:01:45
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7992e+00, PNorm = 43.3127, GNorm = 3.2294, lr_0 = 2.1512e-04
Loss = 1.4515e+00, PNorm = 43.3133, GNorm = 2.0217, lr_0 = 3.1977e-04
Loss = 1.4134e+00, PNorm = 43.3178, GNorm = 1.2208, lr_0 = 4.2442e-04
Loss = 1.2199e+00, PNorm = 43.3295, GNorm = 1.3494, lr_0 = 5.2907e-04
Validation rmse = 1.503697
Epoch 1
Loss = 1.2190e+00, PNorm = 43.3472, GNorm = 1.5623, lr_0 = 6.4419e-04
Loss = 1.1544e+00, PNorm = 43.3728, GNorm = 2.4137, lr_0 = 7.4884e-04
Loss = 1.0033e+00, PNorm = 43.4178, GNorm = 7.6080, lr_0 = 8.5349e-04
Loss = 9.2255e-01, PNorm = 43.4773, GNorm = 5.7199, lr_0 = 9.5814e-04
Validation rmse = 1.276233
Epoch 2
Loss = 1.1657e+00, PNorm = 43.5478, GNorm = 7.1787, lr_0 = 9.8670e-04
Loss = 1.0747e+00, PNorm = 43.5914, GNorm = 2.3204, lr_0 = 9.6801e-04
Loss = 9.1161e-01, PNorm = 43.6417, GNorm = 1.9643, lr_0 = 9.4967e-04
Loss = 8.4357e-01, PNorm = 43.7002, GNorm = 9.3814, lr_0 = 9.3168e-04
Validation rmse = 0.950130
Epoch 3
Loss = 7.5752e-01, PNorm = 43.7343, GNorm = 5.3785, lr_0 = 9.1229e-04
Loss = 7.5951e-01, PNorm = 43.7785, GNorm = 2.8212, lr_0 = 8.9501e-04
Loss = 6.9172e-01, PNorm = 43.8198, GNorm = 6.5541, lr_0 = 8.7805e-04
Loss = 6.5203e-01, PNorm = 43.8612, GNorm = 14.6588, lr_0 = 8.6142e-04
Loss = 6.4133e-01, PNorm = 43.9081, GNorm = 8.0931, lr_0 = 8.4510e-04
Validation rmse = 0.749017
Epoch 4
Loss = 4.8765e-01, PNorm = 43.9623, GNorm = 3.7943, lr_0 = 8.2751e-04
Loss = 6.1051e-01, PNorm = 43.9924, GNorm = 4.7261, lr_0 = 8.1184e-04
Loss = 5.4871e-01, PNorm = 44.0135, GNorm = 3.2122, lr_0 = 7.9646e-04
Loss = 4.9061e-01, PNorm = 44.0400, GNorm = 5.6518, lr_0 = 7.8137e-04
Validation rmse = 0.714025
Epoch 5
Loss = 6.6378e-01, PNorm = 44.0702, GNorm = 3.2047, lr_0 = 7.6657e-04
Loss = 5.5894e-01, PNorm = 44.1153, GNorm = 2.9114, lr_0 = 7.5205e-04
Loss = 5.1479e-01, PNorm = 44.1456, GNorm = 3.0119, lr_0 = 7.3780e-04
Loss = 4.8177e-01, PNorm = 44.1735, GNorm = 4.9696, lr_0 = 7.2383e-04
Validation rmse = 0.732676
Epoch 6
Loss = 1.0528e+00, PNorm = 44.1953, GNorm = 11.8854, lr_0 = 7.0876e-04
Loss = 5.6081e-01, PNorm = 44.2201, GNorm = 3.1990, lr_0 = 6.9533e-04
Loss = 4.4753e-01, PNorm = 44.2483, GNorm = 3.1162, lr_0 = 6.8216e-04
Loss = 3.6214e-01, PNorm = 44.2868, GNorm = 4.0938, lr_0 = 6.6924e-04
Loss = 3.6144e-01, PNorm = 44.3065, GNorm = 2.1656, lr_0 = 6.5656e-04
Validation rmse = 0.750774
Epoch 7
Loss = 3.2609e-01, PNorm = 44.3352, GNorm = 2.7155, lr_0 = 6.4289e-04
Loss = 3.0622e-01, PNorm = 44.3584, GNorm = 4.5425, lr_0 = 6.3072e-04
Loss = 3.2889e-01, PNorm = 44.3843, GNorm = 3.4155, lr_0 = 6.1877e-04
Loss = 4.8786e-01, PNorm = 44.4053, GNorm = 1.9349, lr_0 = 6.0705e-04
Validation rmse = 0.673770
Epoch 8
Loss = 4.0578e-01, PNorm = 44.4282, GNorm = 5.6657, lr_0 = 5.9441e-04
Loss = 3.2261e-01, PNorm = 44.4524, GNorm = 2.9640, lr_0 = 5.8315e-04
Loss = 4.0265e-01, PNorm = 44.4679, GNorm = 10.5872, lr_0 = 5.7210e-04
Loss = 4.1772e-01, PNorm = 44.4816, GNorm = 2.4910, lr_0 = 5.6127e-04
Validation rmse = 0.649006
Epoch 9
Loss = 4.0273e-01, PNorm = 44.5094, GNorm = 8.2926, lr_0 = 5.4958e-04
Loss = 2.8169e-01, PNorm = 44.5287, GNorm = 8.0834, lr_0 = 5.3917e-04
Loss = 3.6609e-01, PNorm = 44.5412, GNorm = 5.3974, lr_0 = 5.2896e-04
Loss = 3.4976e-01, PNorm = 44.5527, GNorm = 3.5454, lr_0 = 5.1894e-04
Loss = 3.5812e-01, PNorm = 44.5689, GNorm = 11.9799, lr_0 = 5.0911e-04
Validation rmse = 0.654422
Epoch 10
Loss = 3.1332e-01, PNorm = 44.5819, GNorm = 4.3861, lr_0 = 4.9946e-04
Loss = 2.8211e-01, PNorm = 44.5975, GNorm = 5.2693, lr_0 = 4.9000e-04
Loss = 2.7945e-01, PNorm = 44.6097, GNorm = 3.7192, lr_0 = 4.8072e-04
Loss = 3.7217e-01, PNorm = 44.6254, GNorm = 3.5428, lr_0 = 4.7162e-04
Validation rmse = 0.652463
Epoch 11
Loss = 1.9523e-01, PNorm = 44.6466, GNorm = 8.5155, lr_0 = 4.6180e-04
Loss = 2.2394e-01, PNorm = 44.6650, GNorm = 2.8462, lr_0 = 4.5305e-04
Loss = 2.3378e-01, PNorm = 44.6780, GNorm = 2.9436, lr_0 = 4.4447e-04
Loss = 3.4047e-01, PNorm = 44.6913, GNorm = 3.2729, lr_0 = 4.3605e-04
Validation rmse = 0.625760
Epoch 12
Loss = 3.0942e-01, PNorm = 44.7019, GNorm = 4.8241, lr_0 = 4.2697e-04
Loss = 3.3951e-01, PNorm = 44.7148, GNorm = 2.5292, lr_0 = 4.1888e-04
Loss = 3.0097e-01, PNorm = 44.7326, GNorm = 3.5358, lr_0 = 4.1095e-04
Loss = 2.3960e-01, PNorm = 44.7371, GNorm = 3.7125, lr_0 = 4.0316e-04
Loss = 2.4239e-01, PNorm = 44.7515, GNorm = 5.3616, lr_0 = 3.9553e-04
Validation rmse = 0.612160
Epoch 13
Loss = 1.5671e-01, PNorm = 44.7624, GNorm = 2.5630, lr_0 = 3.8729e-04
Loss = 2.1841e-01, PNorm = 44.7761, GNorm = 6.1222, lr_0 = 3.7996e-04
Loss = 2.4464e-01, PNorm = 44.7870, GNorm = 10.7982, lr_0 = 3.7276e-04
Loss = 2.0909e-01, PNorm = 44.7928, GNorm = 5.2791, lr_0 = 3.6570e-04
Validation rmse = 0.614970
Epoch 14
Loss = 2.5559e-01, PNorm = 44.7998, GNorm = 2.8492, lr_0 = 3.5809e-04
Loss = 2.2352e-01, PNorm = 44.8144, GNorm = 4.0161, lr_0 = 3.5130e-04
Loss = 1.8081e-01, PNorm = 44.8299, GNorm = 5.8306, lr_0 = 3.4465e-04
Loss = 2.1595e-01, PNorm = 44.8371, GNorm = 5.9345, lr_0 = 3.3812e-04
Validation rmse = 0.654277
Epoch 15
Loss = 1.7851e-01, PNorm = 44.8461, GNorm = 6.2322, lr_0 = 3.3171e-04
Loss = 2.2944e-01, PNorm = 44.8566, GNorm = 3.6528, lr_0 = 3.2543e-04
Loss = 2.3702e-01, PNorm = 44.8647, GNorm = 4.6257, lr_0 = 3.1927e-04
Loss = 2.2833e-01, PNorm = 44.8740, GNorm = 7.6154, lr_0 = 3.1322e-04
Loss = 2.0466e-01, PNorm = 44.8813, GNorm = 2.7364, lr_0 = 3.0729e-04
Validation rmse = 0.657235
Epoch 16
Loss = 2.1182e-01, PNorm = 44.8965, GNorm = 4.0668, lr_0 = 3.0089e-04
Loss = 1.1508e-01, PNorm = 44.9095, GNorm = 4.6868, lr_0 = 2.9519e-04
Loss = 1.8353e-01, PNorm = 44.9136, GNorm = 4.4207, lr_0 = 2.8960e-04
Loss = 1.4917e-01, PNorm = 44.9190, GNorm = 3.8930, lr_0 = 2.8411e-04
Validation rmse = 0.598084
Epoch 17
Loss = 6.3104e-02, PNorm = 44.9257, GNorm = 3.3956, lr_0 = 2.7820e-04
Loss = 1.1899e-01, PNorm = 44.9347, GNorm = 8.0326, lr_0 = 2.7293e-04
Loss = 1.1920e-01, PNorm = 44.9477, GNorm = 21.4408, lr_0 = 2.6776e-04
Loss = 1.8475e-01, PNorm = 44.9518, GNorm = 4.3582, lr_0 = 2.6268e-04
Validation rmse = 0.638148
Epoch 18
Loss = 1.8093e-01, PNorm = 44.9601, GNorm = 4.5031, lr_0 = 2.5722e-04
Loss = 1.1007e-01, PNorm = 44.9707, GNorm = 8.2412, lr_0 = 2.5234e-04
Loss = -1.8243e-02, PNorm = 44.9814, GNorm = 6.0698, lr_0 = 2.4756e-04
Loss = 1.8238e-01, PNorm = 44.9835, GNorm = 5.4086, lr_0 = 2.4287e-04
Loss = 1.7745e-01, PNorm = 44.9899, GNorm = 4.5294, lr_0 = 2.3827e-04
Loss = 5.9360e-02, PNorm = 44.9904, GNorm = 14.2433, lr_0 = 2.3782e-04
Validation rmse = 0.648882
Epoch 19
Loss = 1.4267e-01, PNorm = 44.9988, GNorm = 14.4876, lr_0 = 2.3331e-04
Loss = 1.1425e-01, PNorm = 45.0049, GNorm = 4.1658, lr_0 = 2.2889e-04
Loss = 1.2758e-01, PNorm = 45.0114, GNorm = 3.4274, lr_0 = 2.2456e-04
Loss = 8.5803e-02, PNorm = 45.0184, GNorm = 5.0417, lr_0 = 2.2030e-04
Validation rmse = 0.614168
Epoch 20
Loss = 4.9222e-02, PNorm = 45.0270, GNorm = 5.2519, lr_0 = 2.1613e-04
Loss = 5.5998e-02, PNorm = 45.0333, GNorm = 7.4104, lr_0 = 2.1204e-04
Loss = 6.3733e-02, PNorm = 45.0390, GNorm = 2.7740, lr_0 = 2.0802e-04
Loss = 1.0611e-01, PNorm = 45.0430, GNorm = 5.7417, lr_0 = 2.0408e-04
Validation rmse = 0.643446
Epoch 21
Loss = 1.7354e-01, PNorm = 45.0456, GNorm = 5.4122, lr_0 = 1.9983e-04
Loss = -2.9908e-02, PNorm = 45.0558, GNorm = 11.5313, lr_0 = 1.9605e-04
Loss = 3.7646e-03, PNorm = 45.0632, GNorm = 4.5295, lr_0 = 1.9233e-04
Loss = 1.9291e-01, PNorm = 45.0653, GNorm = 18.2946, lr_0 = 1.8869e-04
Loss = 1.4943e-01, PNorm = 45.0647, GNorm = 4.6543, lr_0 = 1.8512e-04
Loss = -2.7636e-01, PNorm = 45.0651, GNorm = 6.9709, lr_0 = 1.8476e-04
Validation rmse = 0.636231
Epoch 22
Loss = 1.1489e-01, PNorm = 45.0720, GNorm = 3.8084, lr_0 = 1.8126e-04
Loss = 9.2988e-02, PNorm = 45.0794, GNorm = 7.3138, lr_0 = 1.7783e-04
Loss = 1.1630e-02, PNorm = 45.0870, GNorm = 7.3815, lr_0 = 1.7446e-04
Loss = 8.6197e-02, PNorm = 45.0924, GNorm = 13.0279, lr_0 = 1.7115e-04
Validation rmse = 0.608215
Epoch 23
Loss = 6.8012e-02, PNorm = 45.0980, GNorm = 3.6455, lr_0 = 1.6759e-04
Loss = -1.6052e-02, PNorm = 45.1046, GNorm = 11.0168, lr_0 = 1.6442e-04
Loss = 5.1936e-02, PNorm = 45.1110, GNorm = 6.3876, lr_0 = 1.6130e-04
Loss = 1.5327e-01, PNorm = 45.1137, GNorm = 4.3061, lr_0 = 1.5825e-04
Validation rmse = 0.633284
Epoch 24
Loss = 6.6807e-02, PNorm = 45.1171, GNorm = 10.2535, lr_0 = 1.5495e-04
Loss = 8.1911e-03, PNorm = 45.1246, GNorm = 4.5530, lr_0 = 1.5202e-04
Loss = 1.0287e-01, PNorm = 45.1309, GNorm = 22.9475, lr_0 = 1.4914e-04
Loss = 9.4850e-02, PNorm = 45.1326, GNorm = 6.9820, lr_0 = 1.4631e-04
Loss = 9.0348e-02, PNorm = 45.1350, GNorm = 7.7083, lr_0 = 1.4354e-04
Validation rmse = 0.621615
Epoch 25
Loss = -4.6689e-02, PNorm = 45.1404, GNorm = 4.5714, lr_0 = 1.4082e-04
Loss = 8.7071e-02, PNorm = 45.1466, GNorm = 14.9704, lr_0 = 1.3815e-04
Loss = 1.0729e-01, PNorm = 45.1497, GNorm = 3.1780, lr_0 = 1.3554e-04
Loss = -1.9855e-02, PNorm = 45.1527, GNorm = 6.7797, lr_0 = 1.3297e-04
Validation rmse = 0.634802
Epoch 26
Loss = 1.0105e-01, PNorm = 45.1572, GNorm = 5.3353, lr_0 = 1.3020e-04
Loss = 6.4835e-03, PNorm = 45.1615, GNorm = 12.7543, lr_0 = 1.2774e-04
Loss = 1.3429e-02, PNorm = 45.1649, GNorm = 12.0596, lr_0 = 1.2532e-04
Loss = -5.9924e-03, PNorm = 45.1693, GNorm = 5.0705, lr_0 = 1.2294e-04
Validation rmse = 0.609841
Epoch 27
Loss = -1.3128e-01, PNorm = 45.1749, GNorm = 3.9430, lr_0 = 1.2038e-04
Loss = -2.3411e-02, PNorm = 45.1775, GNorm = 12.8201, lr_0 = 1.1810e-04
Loss = 8.4352e-02, PNorm = 45.1791, GNorm = 3.3740, lr_0 = 1.1587e-04
Loss = 4.6161e-02, PNorm = 45.1825, GNorm = 4.6863, lr_0 = 1.1367e-04
Validation rmse = 0.614782
Epoch 28
Loss = -1.6860e-01, PNorm = 45.1868, GNorm = 3.6247, lr_0 = 1.1130e-04
Loss = 1.8292e-02, PNorm = 45.1909, GNorm = 3.8797, lr_0 = 1.0920e-04
Loss = -8.4408e-03, PNorm = 45.1939, GNorm = 3.7255, lr_0 = 1.0713e-04
Loss = -3.3127e-02, PNorm = 45.1970, GNorm = 3.7084, lr_0 = 1.0510e-04
Loss = 1.0427e-02, PNorm = 45.2007, GNorm = 10.3890, lr_0 = 1.0311e-04
Validation rmse = 0.605931
Epoch 29
Loss = 6.1574e-02, PNorm = 45.2018, GNorm = 3.0705, lr_0 = 1.0096e-04
Loss = 3.4979e-02, PNorm = 45.2054, GNorm = 4.1515, lr_0 = 1.0000e-04
Loss = -9.2569e-03, PNorm = 45.2093, GNorm = 7.9110, lr_0 = 1.0000e-04
Loss = -7.9231e-02, PNorm = 45.2123, GNorm = 5.4810, lr_0 = 1.0000e-04
Validation rmse = 0.625313
Model 0 best validation rmse = 0.598084 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.630127
Ensemble test rmse = 0.630127
1-fold cross validation
	Seed 0 ==> test rmse = 0.630127
Overall test rmse = 0.630127 +/- 0.000000
Elapsed time = 0:01:47
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,375 | train size = 1,100 | val size = 137 | test size = 138
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0569e+00, PNorm = 43.3123, GNorm = 5.1251, lr_0 = 2.1250e-04
Loss = 1.4712e+00, PNorm = 43.3134, GNorm = 1.6380, lr_0 = 3.1477e-04
Loss = 1.3973e+00, PNorm = 43.3179, GNorm = 2.4103, lr_0 = 4.1705e-04
Loss = 1.2950e+00, PNorm = 43.3291, GNorm = 1.7348, lr_0 = 5.1932e-04
Validation rmse = 1.498200
Epoch 1
Loss = 1.2035e+00, PNorm = 43.3464, GNorm = 5.1578, lr_0 = 6.2159e-04
Loss = 1.1219e+00, PNorm = 43.3745, GNorm = 1.4892, lr_0 = 7.2386e-04
Loss = 1.0397e+00, PNorm = 43.4117, GNorm = 3.2332, lr_0 = 8.2614e-04
Loss = 9.7155e-01, PNorm = 43.4643, GNorm = 1.9464, lr_0 = 9.2841e-04
Validation rmse = 0.915204
Epoch 2
Loss = 1.0139e+00, PNorm = 43.5172, GNorm = 18.9980, lr_0 = 9.9441e-04
Loss = 9.3218e-01, PNorm = 43.5670, GNorm = 1.8386, lr_0 = 9.7600e-04
Loss = 8.3878e-01, PNorm = 43.6326, GNorm = 3.5534, lr_0 = 9.5792e-04
Loss = 7.7243e-01, PNorm = 43.6808, GNorm = 3.6791, lr_0 = 9.4019e-04
Loss = 6.6330e-01, PNorm = 43.7336, GNorm = 5.5559, lr_0 = 9.2278e-04
Validation rmse = 0.696255
Epoch 3
Loss = 5.4675e-01, PNorm = 43.7813, GNorm = 4.6379, lr_0 = 9.0569e-04
Loss = 6.8607e-01, PNorm = 43.8118, GNorm = 3.1699, lr_0 = 8.8892e-04
Loss = 5.7855e-01, PNorm = 43.8592, GNorm = 3.3624, lr_0 = 8.7246e-04
Loss = 6.8118e-01, PNorm = 43.9010, GNorm = 6.3220, lr_0 = 8.5631e-04
Validation rmse = 0.753538
Epoch 4
Loss = 4.6130e-01, PNorm = 43.9409, GNorm = 5.1465, lr_0 = 8.4045e-04
Loss = 5.2165e-01, PNorm = 43.9794, GNorm = 3.5860, lr_0 = 8.2489e-04
Loss = 6.6447e-01, PNorm = 43.9945, GNorm = 9.9076, lr_0 = 8.0962e-04
Loss = 6.2932e-01, PNorm = 44.0279, GNorm = 4.2113, lr_0 = 7.9463e-04
Loss = 5.9482e-01, PNorm = 44.0649, GNorm = 4.2997, lr_0 = 7.7991e-04
Validation rmse = 0.645898
Epoch 5
Loss = 5.0687e-01, PNorm = 44.1003, GNorm = 11.2350, lr_0 = 7.6547e-04
Loss = 4.7654e-01, PNorm = 44.1184, GNorm = 2.4456, lr_0 = 7.5130e-04
Loss = 4.6606e-01, PNorm = 44.1496, GNorm = 2.5918, lr_0 = 7.3739e-04
Loss = 4.3961e-01, PNorm = 44.1680, GNorm = 4.8748, lr_0 = 7.2373e-04
Validation rmse = 0.660970
Epoch 6
Loss = 4.2924e-01, PNorm = 44.1901, GNorm = 6.2880, lr_0 = 7.1033e-04
Loss = 4.3552e-01, PNorm = 44.2158, GNorm = 6.5805, lr_0 = 6.9718e-04
Loss = 3.8385e-01, PNorm = 44.2313, GNorm = 4.5702, lr_0 = 6.8427e-04
Loss = 3.9652e-01, PNorm = 44.2584, GNorm = 13.3587, lr_0 = 6.7160e-04
Validation rmse = 0.660508
Epoch 7
Loss = 5.0122e-01, PNorm = 44.2853, GNorm = 7.5442, lr_0 = 6.5916e-04
Loss = 4.5961e-01, PNorm = 44.3173, GNorm = 3.7935, lr_0 = 6.4696e-04
Loss = 2.5844e-01, PNorm = 44.3444, GNorm = 15.0707, lr_0 = 6.3498e-04
Loss = 3.9892e-01, PNorm = 44.3574, GNorm = 4.0061, lr_0 = 6.2322e-04
Loss = 3.4899e-01, PNorm = 44.3781, GNorm = 9.7396, lr_0 = 6.1168e-04
Validation rmse = 0.659543
Epoch 8
Loss = 4.8325e-01, PNorm = 44.3957, GNorm = 3.5436, lr_0 = 6.0036e-04
Loss = 3.2663e-01, PNorm = 44.4284, GNorm = 11.9321, lr_0 = 5.8924e-04
Loss = 4.4696e-01, PNorm = 44.4386, GNorm = 6.7006, lr_0 = 5.7833e-04
Loss = 4.9712e-01, PNorm = 44.4648, GNorm = 3.6422, lr_0 = 5.6762e-04
Validation rmse = 0.583156
Epoch 9
Loss = 3.0134e-01, PNorm = 44.4806, GNorm = 4.3960, lr_0 = 5.5711e-04
Loss = 2.9262e-01, PNorm = 44.5059, GNorm = 6.9667, lr_0 = 5.4680e-04
Loss = 3.4556e-01, PNorm = 44.5237, GNorm = 3.8523, lr_0 = 5.3667e-04
Loss = 2.9581e-01, PNorm = 44.5459, GNorm = 2.9774, lr_0 = 5.2673e-04
Loss = 3.1033e-01, PNorm = 44.5567, GNorm = 6.5563, lr_0 = 5.1698e-04
Validation rmse = 0.611472
Epoch 10
Loss = 2.3509e-01, PNorm = 44.5729, GNorm = 5.9164, lr_0 = 5.0741e-04
Loss = 2.4659e-01, PNorm = 44.5891, GNorm = 6.1822, lr_0 = 4.9801e-04
Loss = 4.5973e-01, PNorm = 44.6005, GNorm = 7.8003, lr_0 = 4.8879e-04
Loss = 4.2864e-01, PNorm = 44.6099, GNorm = 4.7028, lr_0 = 4.7974e-04
Validation rmse = 0.654475
Epoch 11
Loss = 2.6057e-01, PNorm = 44.6357, GNorm = 3.2956, lr_0 = 4.7086e-04
Loss = 2.9453e-01, PNorm = 44.6561, GNorm = 3.6224, lr_0 = 4.6214e-04
Loss = 2.6112e-01, PNorm = 44.6702, GNorm = 13.7030, lr_0 = 4.5358e-04
Loss = 2.2617e-01, PNorm = 44.6839, GNorm = 4.2375, lr_0 = 4.4518e-04
Validation rmse = 0.601647
Epoch 12
Loss = 4.8404e-02, PNorm = 44.6990, GNorm = 6.8224, lr_0 = 4.3694e-04
Loss = 2.7089e-01, PNorm = 44.7060, GNorm = 10.1940, lr_0 = 4.2885e-04
Loss = 3.4955e-01, PNorm = 44.7192, GNorm = 5.8146, lr_0 = 4.2091e-04
Loss = 3.0470e-01, PNorm = 44.7334, GNorm = 4.7556, lr_0 = 4.1312e-04
Loss = 2.1047e-01, PNorm = 44.7471, GNorm = 3.8666, lr_0 = 4.0547e-04
Validation rmse = 0.612399
Epoch 13
Loss = 1.1811e-01, PNorm = 44.7639, GNorm = 8.7110, lr_0 = 3.9796e-04
Loss = 2.3433e-01, PNorm = 44.7762, GNorm = 15.2959, lr_0 = 3.9059e-04
Loss = 2.6686e-01, PNorm = 44.7874, GNorm = 7.8679, lr_0 = 3.8336e-04
Loss = 2.3212e-01, PNorm = 44.8033, GNorm = 4.0510, lr_0 = 3.7626e-04
Validation rmse = 0.567072
Epoch 14
Loss = 2.3002e-02, PNorm = 44.8163, GNorm = 5.3149, lr_0 = 3.6929e-04
Loss = 1.9097e-01, PNorm = 44.8248, GNorm = 5.5182, lr_0 = 3.6245e-04
Loss = 2.3134e-01, PNorm = 44.8353, GNorm = 6.2489, lr_0 = 3.5574e-04
Loss = 1.2886e-01, PNorm = 44.8471, GNorm = 3.4417, lr_0 = 3.4916e-04
Loss = 2.7690e-01, PNorm = 44.8538, GNorm = 6.0289, lr_0 = 3.4269e-04
Validation rmse = 0.648088
Epoch 15
Loss = 2.1550e-01, PNorm = 44.8622, GNorm = 7.8065, lr_0 = 3.3635e-04
Loss = 2.3052e-01, PNorm = 44.8763, GNorm = 6.6165, lr_0 = 3.3012e-04
Loss = 1.7147e-01, PNorm = 44.8918, GNorm = 4.4654, lr_0 = 3.2401e-04
Loss = 1.5946e-01, PNorm = 44.9010, GNorm = 3.8273, lr_0 = 3.1801e-04
Validation rmse = 0.637135
Epoch 16
Loss = 7.7270e-02, PNorm = 44.9105, GNorm = 5.9137, lr_0 = 3.1212e-04
Loss = 1.7160e-01, PNorm = 44.9188, GNorm = 14.0159, lr_0 = 3.0634e-04
Loss = 1.5818e-01, PNorm = 44.9266, GNorm = 6.3383, lr_0 = 3.0067e-04
Loss = 1.9097e-01, PNorm = 44.9360, GNorm = 3.1942, lr_0 = 2.9510e-04
Validation rmse = 0.607657
Epoch 17
Loss = 9.1063e-02, PNorm = 44.9494, GNorm = 13.1388, lr_0 = 2.8963e-04
Loss = 1.1409e-01, PNorm = 44.9575, GNorm = 5.5211, lr_0 = 2.8427e-04
Loss = 1.2023e-01, PNorm = 44.9658, GNorm = 8.7588, lr_0 = 2.7901e-04
Loss = 1.8178e-01, PNorm = 44.9720, GNorm = 8.0627, lr_0 = 2.7384e-04
Loss = 1.8181e-01, PNorm = 44.9798, GNorm = 9.4581, lr_0 = 2.6877e-04
Validation rmse = 0.603131
Epoch 18
Loss = 8.2480e-02, PNorm = 44.9905, GNorm = 6.8361, lr_0 = 2.6379e-04
Loss = 4.8567e-02, PNorm = 45.0030, GNorm = 4.7942, lr_0 = 2.5891e-04
Loss = 1.4069e-01, PNorm = 45.0075, GNorm = 11.7285, lr_0 = 2.5412e-04
Loss = 1.0970e-01, PNorm = 45.0133, GNorm = 4.4763, lr_0 = 2.4941e-04
Validation rmse = 0.617846
Epoch 19
Loss = -5.6215e-02, PNorm = 45.0189, GNorm = 6.9993, lr_0 = 2.4479e-04
Loss = 1.1068e-01, PNorm = 45.0274, GNorm = 4.4297, lr_0 = 2.4026e-04
Loss = 1.1988e-01, PNorm = 45.0322, GNorm = 3.6242, lr_0 = 2.3581e-04
Loss = 1.3005e-01, PNorm = 45.0393, GNorm = 6.6736, lr_0 = 2.3145e-04
Loss = 1.3825e-01, PNorm = 45.0479, GNorm = 3.2501, lr_0 = 2.2716e-04
Validation rmse = 0.586612
Epoch 20
Loss = 1.1288e-01, PNorm = 45.0545, GNorm = 8.3005, lr_0 = 2.2295e-04
Loss = 2.2815e-02, PNorm = 45.0634, GNorm = 5.6027, lr_0 = 2.1883e-04
Loss = 9.3267e-02, PNorm = 45.0694, GNorm = 7.4889, lr_0 = 2.1477e-04
Loss = 6.4322e-02, PNorm = 45.0747, GNorm = 7.1672, lr_0 = 2.1080e-04
Validation rmse = 0.591507
Epoch 21
Loss = -1.3175e-02, PNorm = 45.0783, GNorm = 6.3495, lr_0 = 2.0689e-04
Loss = 7.5589e-02, PNorm = 45.0846, GNorm = 7.9741, lr_0 = 2.0306e-04
Loss = 1.7258e-01, PNorm = 45.0921, GNorm = 7.2129, lr_0 = 1.9930e-04
Loss = 7.3645e-02, PNorm = 45.0981, GNorm = 5.8231, lr_0 = 1.9561e-04
Validation rmse = 0.610628
Epoch 22
Loss = 2.5328e-02, PNorm = 45.1038, GNorm = 6.9893, lr_0 = 1.9199e-04
Loss = -1.1814e-02, PNorm = 45.1106, GNorm = 5.9999, lr_0 = 1.8844e-04
Loss = 4.8928e-02, PNorm = 45.1164, GNorm = 5.3352, lr_0 = 1.8495e-04
Loss = 9.4446e-02, PNorm = 45.1220, GNorm = 11.5719, lr_0 = 1.8152e-04
Loss = 5.0007e-02, PNorm = 45.1282, GNorm = 5.6466, lr_0 = 1.7816e-04
Validation rmse = 0.627808
Epoch 23
Loss = -4.3141e-03, PNorm = 45.1333, GNorm = 4.0314, lr_0 = 1.7486e-04
Loss = 1.3200e-01, PNorm = 45.1373, GNorm = 3.6195, lr_0 = 1.7162e-04
Loss = -6.3503e-03, PNorm = 45.1423, GNorm = 5.4309, lr_0 = 1.6845e-04
Loss = 4.5546e-02, PNorm = 45.1487, GNorm = 4.1531, lr_0 = 1.6533e-04
Validation rmse = 0.591447
Epoch 24
Loss = -4.6505e-02, PNorm = 45.1533, GNorm = 5.0582, lr_0 = 1.6227e-04
Loss = 8.5926e-02, PNorm = 45.1577, GNorm = 9.5903, lr_0 = 1.5926e-04
Loss = 7.2746e-02, PNorm = 45.1626, GNorm = 4.4615, lr_0 = 1.5631e-04
Loss = 9.2111e-02, PNorm = 45.1677, GNorm = 18.5871, lr_0 = 1.5342e-04
Loss = 3.5827e-03, PNorm = 45.1715, GNorm = 7.0457, lr_0 = 1.5058e-04
Validation rmse = 0.625158
Epoch 25
Loss = 1.6719e-02, PNorm = 45.1773, GNorm = 8.1492, lr_0 = 1.4779e-04
Loss = 3.5356e-02, PNorm = 45.1819, GNorm = 9.7337, lr_0 = 1.4505e-04
Loss = 1.0702e-01, PNorm = 45.1835, GNorm = 3.8037, lr_0 = 1.4237e-04
Loss = 4.8350e-02, PNorm = 45.1876, GNorm = 15.6387, lr_0 = 1.3973e-04
Validation rmse = 0.601603
Epoch 26
Loss = -5.0830e-02, PNorm = 45.1918, GNorm = 3.6750, lr_0 = 1.3714e-04
Loss = -1.3264e-02, PNorm = 45.1981, GNorm = 4.6037, lr_0 = 1.3460e-04
Loss = -3.1467e-02, PNorm = 45.2045, GNorm = 5.0045, lr_0 = 1.3211e-04
Loss = 1.1295e-01, PNorm = 45.2074, GNorm = 6.0558, lr_0 = 1.2967e-04
Validation rmse = 0.619702
Epoch 27
Loss = -8.0605e-02, PNorm = 45.2099, GNorm = 4.4238, lr_0 = 1.2726e-04
Loss = 1.1658e-03, PNorm = 45.2167, GNorm = 11.3042, lr_0 = 1.2491e-04
Loss = -9.0705e-02, PNorm = 45.2218, GNorm = 5.3004, lr_0 = 1.2260e-04
Loss = 1.4069e-02, PNorm = 45.2258, GNorm = 9.5649, lr_0 = 1.2033e-04
Loss = 5.1430e-02, PNorm = 45.2250, GNorm = 11.5861, lr_0 = 1.1810e-04
Validation rmse = 0.646032
Epoch 28
Loss = 5.5729e-02, PNorm = 45.2274, GNorm = 5.5851, lr_0 = 1.1591e-04
Loss = 2.0312e-02, PNorm = 45.2302, GNorm = 12.7047, lr_0 = 1.1376e-04
Loss = 5.3948e-02, PNorm = 45.2341, GNorm = 3.9891, lr_0 = 1.1166e-04
Loss = -1.6771e-02, PNorm = 45.2372, GNorm = 6.2591, lr_0 = 1.0959e-04
Validation rmse = 0.593620
Epoch 29
Loss = -8.7189e-04, PNorm = 45.2409, GNorm = 9.0146, lr_0 = 1.0756e-04
Loss = -5.1502e-03, PNorm = 45.2440, GNorm = 10.9861, lr_0 = 1.0557e-04
Loss = -4.1872e-02, PNorm = 45.2472, GNorm = 6.2402, lr_0 = 1.0361e-04
Loss = 9.8836e-03, PNorm = 45.2517, GNorm = 5.1577, lr_0 = 1.0170e-04
Loss = -5.3187e-02, PNorm = 45.2544, GNorm = 8.9386, lr_0 = 1.0000e-04
Validation rmse = 0.611542
Model 0 best validation rmse = 0.567072 on epoch 13
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.643930
Ensemble test rmse = 0.643930
1-fold cross validation
	Seed 0 ==> test rmse = 0.643930
Overall test rmse = 0.643930 +/- 0.000000
Elapsed time = 0:01:49
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9515e+00, PNorm = 43.3122, GNorm = 1.6050, lr_0 = 2.1250e-04
Loss = 1.4444e+00, PNorm = 43.3130, GNorm = 1.0899, lr_0 = 3.1477e-04
Loss = 1.3945e+00, PNorm = 43.3175, GNorm = 0.9603, lr_0 = 4.1705e-04
Loss = 1.3012e+00, PNorm = 43.3288, GNorm = 3.2948, lr_0 = 5.1932e-04
Validation rmse = 1.539337
Epoch 1
Loss = 1.0963e+00, PNorm = 43.3494, GNorm = 2.3151, lr_0 = 6.3182e-04
Loss = 1.1961e+00, PNorm = 43.3733, GNorm = 1.8637, lr_0 = 7.3409e-04
Loss = 9.6558e-01, PNorm = 43.4127, GNorm = 4.5690, lr_0 = 8.3636e-04
Loss = 9.9879e-01, PNorm = 43.4650, GNorm = 2.8731, lr_0 = 9.3864e-04
Validation rmse = 0.898828
Epoch 2
Loss = 7.3160e-01, PNorm = 43.5296, GNorm = 2.8782, lr_0 = 9.9255e-04
Loss = 8.2993e-01, PNorm = 43.5866, GNorm = 9.5733, lr_0 = 9.7417e-04
Loss = 7.1531e-01, PNorm = 43.6301, GNorm = 5.4654, lr_0 = 9.5614e-04
Loss = 6.5074e-01, PNorm = 43.6765, GNorm = 10.9321, lr_0 = 9.3843e-04
Loss = 9.0209e-01, PNorm = 43.7083, GNorm = 1.9869, lr_0 = 9.2106e-04
Validation rmse = 0.832934
Epoch 3
Loss = 6.9168e-01, PNorm = 43.7580, GNorm = 2.1811, lr_0 = 9.0400e-04
Loss = 6.5801e-01, PNorm = 43.8058, GNorm = 9.5970, lr_0 = 8.8726e-04
Loss = 6.1691e-01, PNorm = 43.8392, GNorm = 3.5309, lr_0 = 8.7083e-04
Loss = 6.0341e-01, PNorm = 43.8697, GNorm = 6.7827, lr_0 = 8.5471e-04
Validation rmse = 0.834969
Epoch 4
Loss = 9.7171e-01, PNorm = 43.9019, GNorm = 14.3554, lr_0 = 8.3888e-04
Loss = 6.3714e-01, PNorm = 43.9404, GNorm = 3.7103, lr_0 = 8.2335e-04
Loss = 4.7586e-01, PNorm = 43.9819, GNorm = 2.2106, lr_0 = 8.0810e-04
Loss = 4.5169e-01, PNorm = 44.0085, GNorm = 5.4902, lr_0 = 7.9314e-04
Loss = 5.6392e-01, PNorm = 44.0344, GNorm = 2.5585, lr_0 = 7.7846e-04
Validation rmse = 0.685674
Epoch 5
Loss = 3.6314e-01, PNorm = 44.0650, GNorm = 3.1262, lr_0 = 7.6404e-04
Loss = 4.3992e-01, PNorm = 44.0978, GNorm = 4.6473, lr_0 = 7.4989e-04
Loss = 6.2035e-01, PNorm = 44.1221, GNorm = 3.3483, lr_0 = 7.3601e-04
Loss = 5.1907e-01, PNorm = 44.1494, GNorm = 3.2713, lr_0 = 7.2238e-04
Validation rmse = 0.688112
Epoch 6
Loss = 3.8341e-01, PNorm = 44.1755, GNorm = 2.9831, lr_0 = 7.0768e-04
Loss = 5.6400e-01, PNorm = 44.2042, GNorm = 8.2480, lr_0 = 6.9458e-04
Loss = 5.5290e-01, PNorm = 44.2285, GNorm = 2.8926, lr_0 = 6.8172e-04
Loss = 5.0861e-01, PNorm = 44.2627, GNorm = 3.0394, lr_0 = 6.6909e-04
Loss = 4.0408e-01, PNorm = 44.2867, GNorm = 3.5397, lr_0 = 6.5670e-04
Validation rmse = 0.667349
Epoch 7
Loss = 4.0146e-01, PNorm = 44.3170, GNorm = 14.4705, lr_0 = 6.4455e-04
Loss = 4.7239e-01, PNorm = 44.3283, GNorm = 5.1591, lr_0 = 6.3261e-04
Loss = 4.2599e-01, PNorm = 44.3513, GNorm = 4.8656, lr_0 = 6.2090e-04
Loss = 3.8814e-01, PNorm = 44.3699, GNorm = 5.0366, lr_0 = 6.0940e-04
Validation rmse = 0.623047
Epoch 8
Loss = 3.2398e-01, PNorm = 44.3904, GNorm = 8.9532, lr_0 = 5.9812e-04
Loss = 2.8857e-01, PNorm = 44.4089, GNorm = 8.3552, lr_0 = 5.8704e-04
Loss = 3.9805e-01, PNorm = 44.4250, GNorm = 3.0830, lr_0 = 5.7617e-04
Loss = 3.9335e-01, PNorm = 44.4445, GNorm = 5.1733, lr_0 = 5.6550e-04
Loss = 4.0718e-01, PNorm = 44.4602, GNorm = 2.2005, lr_0 = 5.5503e-04
Validation rmse = 0.616809
Epoch 9
Loss = 2.6721e-01, PNorm = 44.4797, GNorm = 3.9392, lr_0 = 5.4476e-04
Loss = 2.2571e-01, PNorm = 44.4931, GNorm = 9.3283, lr_0 = 5.3467e-04
Loss = 3.1023e-01, PNorm = 44.5096, GNorm = 6.0724, lr_0 = 5.2477e-04
Loss = 4.7308e-01, PNorm = 44.5149, GNorm = 4.8226, lr_0 = 5.1505e-04
Validation rmse = 0.639000
Epoch 10
Loss = 3.3119e-01, PNorm = 44.5326, GNorm = 2.7932, lr_0 = 5.0551e-04
Loss = 2.8098e-01, PNorm = 44.5546, GNorm = 6.5338, lr_0 = 4.9615e-04
Loss = 2.6029e-01, PNorm = 44.5696, GNorm = 3.8929, lr_0 = 4.8697e-04
Loss = 2.5683e-01, PNorm = 44.5817, GNorm = 6.3494, lr_0 = 4.7795e-04
Loss = 3.3774e-01, PNorm = 44.5931, GNorm = 9.3159, lr_0 = 4.6910e-04
Validation rmse = 0.647108
Epoch 11
Loss = 3.0810e-01, PNorm = 44.6110, GNorm = 6.3205, lr_0 = 4.5956e-04
Loss = 1.8221e-01, PNorm = 44.6260, GNorm = 6.1874, lr_0 = 4.5105e-04
Loss = 2.7110e-01, PNorm = 44.6386, GNorm = 6.3644, lr_0 = 4.4269e-04
Loss = 3.3154e-01, PNorm = 44.6492, GNorm = 8.4009, lr_0 = 4.3450e-04
Validation rmse = 0.631534
Epoch 12
Loss = 2.2471e-01, PNorm = 44.6633, GNorm = 8.5128, lr_0 = 4.2645e-04
Loss = 3.2074e-01, PNorm = 44.6770, GNorm = 6.6512, lr_0 = 4.1856e-04
Loss = 2.5804e-01, PNorm = 44.6903, GNorm = 3.3313, lr_0 = 4.1081e-04
Loss = 2.1483e-01, PNorm = 44.7071, GNorm = 11.0176, lr_0 = 4.0320e-04
Loss = 2.4132e-01, PNorm = 44.7187, GNorm = 9.4211, lr_0 = 3.9573e-04
Validation rmse = 0.642075
Epoch 13
Loss = 2.4587e-01, PNorm = 44.7328, GNorm = 3.3210, lr_0 = 3.8841e-04
Loss = 2.0745e-01, PNorm = 44.7412, GNorm = 6.6006, lr_0 = 3.8121e-04
Loss = 2.4446e-01, PNorm = 44.7496, GNorm = 7.4150, lr_0 = 3.7416e-04
Loss = 2.7004e-01, PNorm = 44.7545, GNorm = 4.9727, lr_0 = 3.6723e-04
Validation rmse = 0.627605
Epoch 14
Loss = 1.5372e-01, PNorm = 44.7643, GNorm = 3.7181, lr_0 = 3.6043e-04
Loss = 2.2753e-01, PNorm = 44.7767, GNorm = 4.5652, lr_0 = 3.5375e-04
Loss = 2.1041e-01, PNorm = 44.7885, GNorm = 3.1695, lr_0 = 3.4720e-04
Loss = 1.9371e-01, PNorm = 44.8044, GNorm = 3.8695, lr_0 = 3.4077e-04
Loss = 2.4506e-01, PNorm = 44.8131, GNorm = 3.3600, lr_0 = 3.3446e-04
Validation rmse = 0.680130
Epoch 15
Loss = 2.3521e-01, PNorm = 44.8243, GNorm = 6.1210, lr_0 = 3.2827e-04
Loss = 6.5507e-02, PNorm = 44.8391, GNorm = 3.2950, lr_0 = 3.2219e-04
Loss = 2.1864e-01, PNorm = 44.8509, GNorm = 3.9035, lr_0 = 3.1623e-04
Loss = 2.1802e-01, PNorm = 44.8548, GNorm = 3.4676, lr_0 = 3.1037e-04
Validation rmse = 0.634177
Epoch 16
Loss = 1.6389e-01, PNorm = 44.8626, GNorm = 6.2328, lr_0 = 3.0406e-04
Loss = 1.8864e-01, PNorm = 44.8758, GNorm = 4.1388, lr_0 = 2.9843e-04
Loss = 1.8782e-01, PNorm = 44.8875, GNorm = 10.1347, lr_0 = 2.9290e-04
Loss = 5.8787e-02, PNorm = 44.8968, GNorm = 5.6911, lr_0 = 2.8748e-04
Loss = 2.2026e-01, PNorm = 44.9002, GNorm = 8.5338, lr_0 = 2.8215e-04
Validation rmse = 0.675254
Epoch 17
Loss = 1.1286e-01, PNorm = 44.9094, GNorm = 3.3250, lr_0 = 2.7693e-04
Loss = 2.0123e-01, PNorm = 44.9196, GNorm = 11.9080, lr_0 = 2.7180e-04
Loss = 8.9056e-02, PNorm = 44.9284, GNorm = 5.1146, lr_0 = 2.6677e-04
Loss = 2.4883e-01, PNorm = 44.9358, GNorm = 10.1529, lr_0 = 2.6183e-04
Validation rmse = 0.626688
Epoch 18
Loss = 8.6657e-02, PNorm = 44.9417, GNorm = 3.9066, lr_0 = 2.5698e-04
Loss = 5.3829e-02, PNorm = 44.9552, GNorm = 4.3618, lr_0 = 2.5222e-04
Loss = 1.5790e-01, PNorm = 44.9616, GNorm = 10.2395, lr_0 = 2.4755e-04
Loss = 1.0951e-01, PNorm = 44.9674, GNorm = 3.0478, lr_0 = 2.4297e-04
Loss = 2.8802e-01, PNorm = 44.9751, GNorm = 9.9615, lr_0 = 2.3847e-04
Validation rmse = 0.620428
Epoch 19
Loss = 1.5238e-01, PNorm = 44.9828, GNorm = 11.0688, lr_0 = 2.3406e-04
Loss = 1.6835e-01, PNorm = 44.9894, GNorm = 15.6809, lr_0 = 2.2972e-04
Loss = 9.1726e-02, PNorm = 44.9966, GNorm = 4.1768, lr_0 = 2.2547e-04
Loss = 1.3007e-01, PNorm = 45.0060, GNorm = 4.1724, lr_0 = 2.2129e-04
Validation rmse = 0.610888
Epoch 20
Loss = 1.7603e-01, PNorm = 45.0116, GNorm = 4.4587, lr_0 = 2.1720e-04
Loss = 1.0670e-01, PNorm = 45.0192, GNorm = 5.5714, lr_0 = 2.1317e-04
Loss = 1.4844e-01, PNorm = 45.0242, GNorm = 10.3144, lr_0 = 2.0923e-04
Loss = 3.2331e-02, PNorm = 45.0285, GNorm = 11.0889, lr_0 = 2.0535e-04
Loss = 7.3902e-02, PNorm = 45.0344, GNorm = 4.0965, lr_0 = 2.0155e-04
Loss = 3.7425e-01, PNorm = 45.0351, GNorm = 7.4712, lr_0 = 2.0117e-04
Validation rmse = 0.617213
Epoch 21
Loss = 8.6621e-02, PNorm = 45.0437, GNorm = 5.8230, lr_0 = 1.9745e-04
Loss = 6.9972e-02, PNorm = 45.0501, GNorm = 5.3835, lr_0 = 1.9379e-04
Loss = 5.5252e-02, PNorm = 45.0557, GNorm = 3.8179, lr_0 = 1.9020e-04
Loss = 3.8888e-02, PNorm = 45.0623, GNorm = 7.6846, lr_0 = 1.8668e-04
Validation rmse = 0.601019
Epoch 22
Loss = -3.9186e-02, PNorm = 45.0669, GNorm = 6.6312, lr_0 = 1.8323e-04
Loss = 1.9101e-02, PNorm = 45.0738, GNorm = 7.4064, lr_0 = 1.7983e-04
Loss = 7.9676e-02, PNorm = 45.0794, GNorm = 6.8689, lr_0 = 1.7650e-04
Loss = 7.1079e-02, PNorm = 45.0852, GNorm = 17.5693, lr_0 = 1.7324e-04
Loss = 1.6924e-01, PNorm = 45.0885, GNorm = 8.8542, lr_0 = 1.7003e-04
Validation rmse = 0.615965
Epoch 23
Loss = 7.2232e-02, PNorm = 45.0940, GNorm = 6.8609, lr_0 = 1.6688e-04
Loss = 5.2615e-02, PNorm = 45.1012, GNorm = 11.2423, lr_0 = 1.6379e-04
Loss = 7.5885e-02, PNorm = 45.1056, GNorm = 13.7024, lr_0 = 1.6076e-04
Loss = 7.2937e-02, PNorm = 45.1107, GNorm = 4.7867, lr_0 = 1.5778e-04
Validation rmse = 0.598349
Epoch 24
Loss = -1.0224e-01, PNorm = 45.1172, GNorm = 4.7492, lr_0 = 1.5486e-04
Loss = 7.7029e-02, PNorm = 45.1207, GNorm = 5.0323, lr_0 = 1.5199e-04
Loss = 1.2664e-01, PNorm = 45.1247, GNorm = 3.0467, lr_0 = 1.4918e-04
Loss = -1.9926e-02, PNorm = 45.1283, GNorm = 5.2791, lr_0 = 1.4641e-04
Loss = 1.1554e-01, PNorm = 45.1327, GNorm = 6.4457, lr_0 = 1.4370e-04
Validation rmse = 0.603060
Epoch 25
Loss = 4.7787e-03, PNorm = 45.1393, GNorm = 3.0037, lr_0 = 1.4104e-04
Loss = 5.3956e-02, PNorm = 45.1426, GNorm = 9.0664, lr_0 = 1.3843e-04
Loss = 8.4244e-02, PNorm = 45.1451, GNorm = 6.1732, lr_0 = 1.3587e-04
Loss = 5.8648e-02, PNorm = 45.1469, GNorm = 3.9614, lr_0 = 1.3335e-04
Validation rmse = 0.629403
Epoch 26
Loss = -1.9346e-02, PNorm = 45.1529, GNorm = 6.1464, lr_0 = 1.3064e-04
Loss = 1.8066e-02, PNorm = 45.1600, GNorm = 13.5567, lr_0 = 1.2822e-04
Loss = 5.3976e-02, PNorm = 45.1630, GNorm = 8.2124, lr_0 = 1.2585e-04
Loss = 2.4070e-02, PNorm = 45.1657, GNorm = 6.1396, lr_0 = 1.2352e-04
Validation rmse = 0.596890
Epoch 27
Loss = 1.5824e-02, PNorm = 45.1683, GNorm = 7.0655, lr_0 = 1.2123e-04
Loss = 4.0188e-02, PNorm = 45.1716, GNorm = 3.2683, lr_0 = 1.1898e-04
Loss = -7.4496e-02, PNorm = 45.1762, GNorm = 10.3973, lr_0 = 1.1678e-04
Loss = 5.1869e-02, PNorm = 45.1801, GNorm = 20.6937, lr_0 = 1.1462e-04
Loss = 7.6509e-02, PNorm = 45.1812, GNorm = 4.6547, lr_0 = 1.1250e-04
Validation rmse = 0.608100
Epoch 28
Loss = 3.5689e-02, PNorm = 45.1853, GNorm = 8.0926, lr_0 = 1.1041e-04
Loss = -2.6278e-02, PNorm = 45.1894, GNorm = 3.1554, lr_0 = 1.0837e-04
Loss = -8.8370e-04, PNorm = 45.1936, GNorm = 5.2641, lr_0 = 1.0636e-04
Loss = 3.3606e-02, PNorm = 45.1963, GNorm = 7.2866, lr_0 = 1.0439e-04
Validation rmse = 0.598968
Epoch 29
Loss = -5.3267e-02, PNorm = 45.1998, GNorm = 3.7267, lr_0 = 1.0246e-04
Loss = -7.9335e-03, PNorm = 45.2023, GNorm = 5.3819, lr_0 = 1.0056e-04
Loss = -1.2767e-02, PNorm = 45.2060, GNorm = 19.1114, lr_0 = 1.0000e-04
Loss = -2.0228e-02, PNorm = 45.2089, GNorm = 9.4618, lr_0 = 1.0000e-04
Loss = 5.6349e-02, PNorm = 45.2112, GNorm = 17.0346, lr_0 = 1.0000e-04
Validation rmse = 0.621725
Model 0 best validation rmse = 0.596890 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.622723
Ensemble test rmse = 0.622723
1-fold cross validation
	Seed 0 ==> test rmse = 0.622723
Overall test rmse = 0.622723 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,425 | train size = 1,140 | val size = 142 | test size = 143
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9517e+00, PNorm = 43.3116, GNorm = 1.8147, lr_0 = 2.1000e-04
Loss = 1.4384e+00, PNorm = 43.3119, GNorm = 1.9791, lr_0 = 3.1000e-04
Loss = 1.4404e+00, PNorm = 43.3164, GNorm = 1.7957, lr_0 = 4.1000e-04
Loss = 1.2725e+00, PNorm = 43.3260, GNorm = 1.0299, lr_0 = 5.1000e-04
Validation rmse = 1.433716
Epoch 1
Loss = 1.2441e+00, PNorm = 43.3441, GNorm = 2.0410, lr_0 = 6.2000e-04
Loss = 1.0843e+00, PNorm = 43.3706, GNorm = 1.7161, lr_0 = 7.2000e-04
Loss = 1.0550e+00, PNorm = 43.4099, GNorm = 2.1545, lr_0 = 8.2000e-04
Loss = 9.3096e-01, PNorm = 43.4710, GNorm = 4.9957, lr_0 = 9.2000e-04
Loss = 8.8074e-01, PNorm = 43.5179, GNorm = 3.6129, lr_0 = 9.9635e-04
Validation rmse = 1.010806
Epoch 2
Loss = 8.7861e-01, PNorm = 43.5714, GNorm = 12.1806, lr_0 = 9.7831e-04
Loss = 8.9082e-01, PNorm = 43.6213, GNorm = 3.6044, lr_0 = 9.6059e-04
Loss = 8.1839e-01, PNorm = 43.6813, GNorm = 2.9871, lr_0 = 9.4320e-04
Loss = 7.6822e-01, PNorm = 43.7316, GNorm = 2.0672, lr_0 = 9.2612e-04
Validation rmse = 0.813004
Epoch 3
Loss = 4.9468e-01, PNorm = 43.7843, GNorm = 3.6266, lr_0 = 9.0769e-04
Loss = 6.1995e-01, PNorm = 43.8156, GNorm = 5.1048, lr_0 = 8.9125e-04
Loss = 6.4580e-01, PNorm = 43.8537, GNorm = 2.1896, lr_0 = 8.7511e-04
Loss = 7.1468e-01, PNorm = 43.8883, GNorm = 4.2964, lr_0 = 8.5926e-04
Loss = 6.0304e-01, PNorm = 43.9275, GNorm = 5.8459, lr_0 = 8.4370e-04
Validation rmse = 0.769702
Epoch 4
Loss = 5.1212e-01, PNorm = 43.9579, GNorm = 2.5547, lr_0 = 8.2843e-04
Loss = 5.3013e-01, PNorm = 43.9928, GNorm = 7.2112, lr_0 = 8.1342e-04
Loss = 5.9237e-01, PNorm = 44.0244, GNorm = 2.8208, lr_0 = 7.9869e-04
Loss = 4.7353e-01, PNorm = 44.0455, GNorm = 2.8625, lr_0 = 7.8423e-04
Validation rmse = 0.737751
Epoch 5
Loss = 2.2401e-01, PNorm = 44.0749, GNorm = 7.0162, lr_0 = 7.7003e-04
Loss = 4.0273e-01, PNorm = 44.0972, GNorm = 4.8623, lr_0 = 7.5609e-04
Loss = 5.1491e-01, PNorm = 44.1265, GNorm = 3.8249, lr_0 = 7.4239e-04
Loss = 4.8058e-01, PNorm = 44.1489, GNorm = 3.5285, lr_0 = 7.2895e-04
Loss = 3.9174e-01, PNorm = 44.1834, GNorm = 9.6462, lr_0 = 7.1575e-04
Validation rmse = 0.735597
Epoch 6
Loss = 4.1464e-01, PNorm = 44.1952, GNorm = 8.3427, lr_0 = 7.0151e-04
Loss = 4.5856e-01, PNorm = 44.2238, GNorm = 6.2124, lr_0 = 6.8880e-04
Loss = 3.3268e-01, PNorm = 44.2557, GNorm = 5.2501, lr_0 = 6.7633e-04
Loss = 3.7192e-01, PNorm = 44.2819, GNorm = 2.8935, lr_0 = 6.6408e-04
Validation rmse = 0.706805
Epoch 7
Loss = 2.5127e-01, PNorm = 44.2944, GNorm = 4.2817, lr_0 = 6.5206e-04
Loss = 3.5915e-01, PNorm = 44.3186, GNorm = 2.6111, lr_0 = 6.4025e-04
Loss = 3.2131e-01, PNorm = 44.3370, GNorm = 3.9970, lr_0 = 6.2866e-04
Loss = 3.4812e-01, PNorm = 44.3571, GNorm = 7.8329, lr_0 = 6.1727e-04
Loss = 3.7119e-01, PNorm = 44.3828, GNorm = 6.9884, lr_0 = 6.0609e-04
Validation rmse = 0.721781
Epoch 8
Loss = 2.5587e-01, PNorm = 44.4089, GNorm = 2.1793, lr_0 = 5.9403e-04
Loss = 3.2549e-01, PNorm = 44.4261, GNorm = 8.7349, lr_0 = 5.8327e-04
Loss = 3.0251e-01, PNorm = 44.4490, GNorm = 2.7102, lr_0 = 5.7271e-04
Loss = 2.4848e-01, PNorm = 44.4696, GNorm = 4.0340, lr_0 = 5.6234e-04
Loss = 4.5016e-01, PNorm = 44.4827, GNorm = 9.3287, lr_0 = 5.5216e-04
Validation rmse = 0.667334
Epoch 9
Loss = 3.9246e-01, PNorm = 44.5015, GNorm = 2.1058, lr_0 = 5.4216e-04
Loss = 1.8380e-01, PNorm = 44.5281, GNorm = 3.5726, lr_0 = 5.3234e-04
Loss = 4.1139e-01, PNorm = 44.5314, GNorm = 12.8982, lr_0 = 5.2270e-04
Loss = 3.6191e-01, PNorm = 44.5433, GNorm = 2.0408, lr_0 = 5.1324e-04
Validation rmse = 0.672595
Epoch 10
Loss = 2.6448e-01, PNorm = 44.5645, GNorm = 3.9230, lr_0 = 5.0394e-04
Loss = 2.0836e-01, PNorm = 44.5833, GNorm = 10.5631, lr_0 = 4.9482e-04
Loss = 2.7987e-01, PNorm = 44.5934, GNorm = 2.8689, lr_0 = 4.8586e-04
Loss = 3.0973e-01, PNorm = 44.6077, GNorm = 7.4460, lr_0 = 4.7706e-04
Loss = 2.7577e-01, PNorm = 44.6224, GNorm = 4.0784, lr_0 = 4.6842e-04
Validation rmse = 0.676566
Epoch 11
Loss = 1.8326e-01, PNorm = 44.6520, GNorm = 6.7009, lr_0 = 4.5910e-04
Loss = 1.1982e-01, PNorm = 44.6635, GNorm = 5.7196, lr_0 = 4.5078e-04
Loss = 3.4655e-01, PNorm = 44.6757, GNorm = 4.8164, lr_0 = 4.4262e-04
Loss = 2.6634e-01, PNorm = 44.6864, GNorm = 3.6249, lr_0 = 4.3461e-04
Validation rmse = 0.633902
Epoch 12
Loss = 2.5014e-01, PNorm = 44.7019, GNorm = 4.8455, lr_0 = 4.2674e-04
Loss = 1.3919e-01, PNorm = 44.7163, GNorm = 2.8038, lr_0 = 4.1901e-04
Loss = 3.1749e-01, PNorm = 44.7251, GNorm = 7.9642, lr_0 = 4.1142e-04
Loss = 2.1809e-01, PNorm = 44.7344, GNorm = 11.1086, lr_0 = 4.0397e-04
Loss = 1.8135e-01, PNorm = 44.7486, GNorm = 8.1590, lr_0 = 3.9665e-04
Validation rmse = 0.663492
Epoch 13
Loss = 1.1747e-01, PNorm = 44.7670, GNorm = 5.6134, lr_0 = 3.8876e-04
Loss = 1.5635e-01, PNorm = 44.7812, GNorm = 6.5539, lr_0 = 3.8172e-04
Loss = 2.0583e-01, PNorm = 44.7871, GNorm = 10.6548, lr_0 = 3.7481e-04
Loss = 2.6208e-01, PNorm = 44.8011, GNorm = 3.2107, lr_0 = 3.6802e-04
Validation rmse = 0.647177
Epoch 14
Loss = 2.8426e-01, PNorm = 44.8069, GNorm = 4.6835, lr_0 = 3.6136e-04
Loss = 7.7967e-02, PNorm = 44.8229, GNorm = 5.9258, lr_0 = 3.5481e-04
Loss = 1.6066e-01, PNorm = 44.8296, GNorm = 3.8838, lr_0 = 3.4839e-04
Loss = 2.5570e-01, PNorm = 44.8402, GNorm = 2.8164, lr_0 = 3.4208e-04
Loss = 2.6799e-01, PNorm = 44.8522, GNorm = 13.0243, lr_0 = 3.3588e-04
Validation rmse = 0.653936
Epoch 15
Loss = 1.5933e-01, PNorm = 44.8610, GNorm = 4.3668, lr_0 = 3.2980e-04
Loss = 1.2161e-01, PNorm = 44.8780, GNorm = 2.8523, lr_0 = 3.2383e-04
Loss = 1.8829e-01, PNorm = 44.8898, GNorm = 4.6278, lr_0 = 3.1797e-04
Loss = 1.8536e-01, PNorm = 44.8975, GNorm = 5.5708, lr_0 = 3.1221e-04
Validation rmse = 0.650169
Epoch 16
Loss = 2.1697e-01, PNorm = 44.9087, GNorm = 3.1040, lr_0 = 3.0599e-04
Loss = 9.1997e-02, PNorm = 44.9210, GNorm = 9.9587, lr_0 = 3.0045e-04
Loss = 1.9013e-01, PNorm = 44.9229, GNorm = 5.9049, lr_0 = 2.9501e-04
Loss = 1.3606e-01, PNorm = 44.9296, GNorm = 3.5364, lr_0 = 2.8967e-04
Loss = 8.6203e-02, PNorm = 44.9428, GNorm = 4.7378, lr_0 = 2.8443e-04
Validation rmse = 0.684843
Epoch 17
Loss = 1.9103e-01, PNorm = 44.9510, GNorm = 6.5428, lr_0 = 2.7927e-04
Loss = 7.5063e-02, PNorm = 44.9578, GNorm = 5.3182, lr_0 = 2.7422e-04
Loss = 1.5461e-01, PNorm = 44.9668, GNorm = 4.2916, lr_0 = 2.6925e-04
Loss = 9.9223e-02, PNorm = 44.9773, GNorm = 3.3627, lr_0 = 2.6438e-04
Loss = 1.3147e-01, PNorm = 44.9903, GNorm = 13.0187, lr_0 = 2.5959e-04
Loss = 2.2455e-01, PNorm = 44.9904, GNorm = 9.4302, lr_0 = 2.5911e-04
Validation rmse = 0.642697
Epoch 18
Loss = -4.8906e-03, PNorm = 44.9942, GNorm = 10.2915, lr_0 = 2.5442e-04
Loss = 1.2050e-01, PNorm = 45.0008, GNorm = 7.1087, lr_0 = 2.4982e-04
Loss = 1.5481e-01, PNorm = 45.0039, GNorm = 4.8769, lr_0 = 2.4529e-04
Loss = 4.2953e-02, PNorm = 45.0156, GNorm = 6.4439, lr_0 = 2.4085e-04
Validation rmse = 0.642500
Epoch 19
Loss = 1.5902e-01, PNorm = 45.0220, GNorm = 8.7322, lr_0 = 2.3649e-04
Loss = 1.9811e-02, PNorm = 45.0299, GNorm = 3.7631, lr_0 = 2.3221e-04
Loss = 5.2001e-02, PNorm = 45.0383, GNorm = 6.7114, lr_0 = 2.2800e-04
Loss = 6.5893e-02, PNorm = 45.0472, GNorm = 6.8218, lr_0 = 2.2387e-04
Loss = 1.7165e-01, PNorm = 45.0499, GNorm = 5.7991, lr_0 = 2.1982e-04
Validation rmse = 0.651784
Epoch 20
Loss = 2.7080e-02, PNorm = 45.0574, GNorm = 2.5951, lr_0 = 2.1584e-04
Loss = 5.7063e-02, PNorm = 45.0667, GNorm = 7.0315, lr_0 = 2.1193e-04
Loss = 7.1344e-02, PNorm = 45.0745, GNorm = 7.0362, lr_0 = 2.0809e-04
Loss = 5.3126e-02, PNorm = 45.0778, GNorm = 6.0003, lr_0 = 2.0432e-04
Validation rmse = 0.650525
Epoch 21
Loss = 6.1180e-02, PNorm = 45.0821, GNorm = 3.9783, lr_0 = 2.0026e-04
Loss = 3.8706e-02, PNorm = 45.0916, GNorm = 4.0465, lr_0 = 1.9663e-04
Loss = 6.7727e-02, PNorm = 45.0967, GNorm = 6.9306, lr_0 = 1.9307e-04
Loss = 4.5339e-02, PNorm = 45.1037, GNorm = 3.0780, lr_0 = 1.8957e-04
Loss = 4.9620e-02, PNorm = 45.1097, GNorm = 5.8867, lr_0 = 1.8614e-04
Validation rmse = 0.643772
Epoch 22
Loss = 1.1498e-01, PNorm = 45.1149, GNorm = 7.8921, lr_0 = 1.8277e-04
Loss = -4.9182e-02, PNorm = 45.1238, GNorm = 10.6868, lr_0 = 1.7946e-04
Loss = 1.3512e-01, PNorm = 45.1249, GNorm = 3.5530, lr_0 = 1.7621e-04
Loss = 7.2121e-02, PNorm = 45.1294, GNorm = 8.6556, lr_0 = 1.7302e-04
Validation rmse = 0.641896
Epoch 23
Loss = 2.5267e-01, PNorm = 45.1330, GNorm = 10.5436, lr_0 = 1.6958e-04
Loss = 6.0232e-02, PNorm = 45.1405, GNorm = 4.3633, lr_0 = 1.6651e-04
Loss = 4.5359e-02, PNorm = 45.1462, GNorm = 4.5311, lr_0 = 1.6349e-04
Loss = 9.8293e-03, PNorm = 45.1510, GNorm = 10.7404, lr_0 = 1.6053e-04
Loss = -1.3079e-02, PNorm = 45.1535, GNorm = 6.8771, lr_0 = 1.5762e-04
Validation rmse = 0.631285
Epoch 24
Loss = 4.9310e-02, PNorm = 45.1595, GNorm = 5.7832, lr_0 = 1.5477e-04
Loss = -1.2418e-02, PNorm = 45.1638, GNorm = 5.4154, lr_0 = 1.5197e-04
Loss = 4.1741e-02, PNorm = 45.1683, GNorm = 7.0227, lr_0 = 1.4921e-04
Loss = 5.3380e-02, PNorm = 45.1719, GNorm = 4.3074, lr_0 = 1.4651e-04
Loss = 1.7285e-02, PNorm = 45.1780, GNorm = 7.8582, lr_0 = 1.4386e-04
Validation rmse = 0.631782
Epoch 25
Loss = -3.0978e-03, PNorm = 45.1847, GNorm = 2.8666, lr_0 = 1.4125e-04
Loss = 8.9037e-04, PNorm = 45.1893, GNorm = 16.1893, lr_0 = 1.3870e-04
Loss = 7.9325e-02, PNorm = 45.1919, GNorm = 13.7126, lr_0 = 1.3618e-04
Loss = -8.6112e-03, PNorm = 45.1952, GNorm = 3.8379, lr_0 = 1.3372e-04
Validation rmse = 0.630812
Epoch 26
Loss = -1.7217e-01, PNorm = 45.2018, GNorm = 4.1428, lr_0 = 1.3106e-04
Loss = -3.2411e-02, PNorm = 45.2082, GNorm = 6.3612, lr_0 = 1.2868e-04
Loss = 8.9145e-02, PNorm = 45.2115, GNorm = 9.9790, lr_0 = 1.2635e-04
Loss = 9.7354e-02, PNorm = 45.2134, GNorm = 3.9178, lr_0 = 1.2407e-04
Loss = 1.1123e-01, PNorm = 45.2160, GNorm = 10.1149, lr_0 = 1.2182e-04
Validation rmse = 0.659311
Epoch 27
Loss = -1.9902e-02, PNorm = 45.2206, GNorm = 5.9113, lr_0 = 1.1961e-04
Loss = 7.0890e-03, PNorm = 45.2279, GNorm = 5.4296, lr_0 = 1.1745e-04
Loss = 6.3780e-03, PNorm = 45.2332, GNorm = 9.8594, lr_0 = 1.1532e-04
Loss = 2.3067e-03, PNorm = 45.2352, GNorm = 6.6652, lr_0 = 1.1323e-04
Validation rmse = 0.646335
Epoch 28
Loss = -6.0165e-02, PNorm = 45.2375, GNorm = 7.4237, lr_0 = 1.1098e-04
Loss = -2.7619e-02, PNorm = 45.2419, GNorm = 9.7704, lr_0 = 1.0897e-04
Loss = 7.7134e-03, PNorm = 45.2439, GNorm = 6.8735, lr_0 = 1.0700e-04
Loss = -1.3269e-02, PNorm = 45.2465, GNorm = 3.9354, lr_0 = 1.0506e-04
Loss = -3.1736e-02, PNorm = 45.2494, GNorm = 4.8550, lr_0 = 1.0316e-04
Validation rmse = 0.639039
Epoch 29
Loss = -6.4134e-02, PNorm = 45.2529, GNorm = 9.6105, lr_0 = 1.0129e-04
Loss = -5.9196e-02, PNorm = 45.2573, GNorm = 4.1130, lr_0 = 1.0000e-04
Loss = -2.5475e-02, PNorm = 45.2606, GNorm = 10.3434, lr_0 = 1.0000e-04
Loss = -4.1434e-02, PNorm = 45.2635, GNorm = 10.9021, lr_0 = 1.0000e-04
Validation rmse = 0.631755
Model 0 best validation rmse = 0.630812 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.624508
Ensemble test rmse = 0.624508
1-fold cross validation
	Seed 0 ==> test rmse = 0.624508
Overall test rmse = 0.624508 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.1313e+00, PNorm = 43.3122, GNorm = 3.6535, lr_0 = 2.0761e-04
Loss = 1.4131e+00, PNorm = 43.3130, GNorm = 1.6527, lr_0 = 3.0543e-04
Loss = 1.4010e+00, PNorm = 43.3172, GNorm = 1.5403, lr_0 = 4.0326e-04
Loss = 1.3480e+00, PNorm = 43.3256, GNorm = 1.2428, lr_0 = 5.0109e-04
Validation rmse = 1.435932
Epoch 1
Loss = 1.1708e+00, PNorm = 43.3442, GNorm = 1.6240, lr_0 = 6.0870e-04
Loss = 1.1300e+00, PNorm = 43.3715, GNorm = 1.7908, lr_0 = 7.0652e-04
Loss = 1.0583e+00, PNorm = 43.4105, GNorm = 7.6270, lr_0 = 8.0435e-04
Loss = 9.2388e-01, PNorm = 43.4635, GNorm = 4.8438, lr_0 = 9.0217e-04
Loss = 9.1971e-01, PNorm = 43.5197, GNorm = 5.1519, lr_0 = 1.0000e-03
Validation rmse = 1.057937
Epoch 2
Loss = 8.1544e-01, PNorm = 43.5859, GNorm = 9.2072, lr_0 = 9.8053e-04
Loss = 7.0214e-01, PNorm = 43.6427, GNorm = 2.2624, lr_0 = 9.6315e-04
Loss = 6.4194e-01, PNorm = 43.6960, GNorm = 6.6033, lr_0 = 9.4609e-04
Loss = 6.7398e-01, PNorm = 43.7263, GNorm = 3.1668, lr_0 = 9.2933e-04
Validation rmse = 1.001888
Epoch 3
Loss = 9.0329e-01, PNorm = 43.7640, GNorm = 19.4007, lr_0 = 9.1286e-04
Loss = 7.2843e-01, PNorm = 43.7987, GNorm = 5.4130, lr_0 = 8.9668e-04
Loss = 5.6856e-01, PNorm = 43.8485, GNorm = 3.5279, lr_0 = 8.8080e-04
Loss = 5.5825e-01, PNorm = 43.8826, GNorm = 7.0519, lr_0 = 8.6519e-04
Loss = 4.7532e-01, PNorm = 43.9118, GNorm = 9.7960, lr_0 = 8.4986e-04
Validation rmse = 0.739423
Epoch 4
Loss = 5.0854e-01, PNorm = 43.9513, GNorm = 3.7100, lr_0 = 8.3331e-04
Loss = 5.6970e-01, PNorm = 43.9840, GNorm = 4.5049, lr_0 = 8.1855e-04
Loss = 4.6915e-01, PNorm = 44.0190, GNorm = 8.6176, lr_0 = 8.0404e-04
Loss = 5.8580e-01, PNorm = 44.0457, GNorm = 2.5407, lr_0 = 7.8980e-04
Loss = 4.3837e-01, PNorm = 44.0770, GNorm = 6.6245, lr_0 = 7.7580e-04
Validation rmse = 0.722795
Epoch 5
Loss = 5.1213e-01, PNorm = 44.1018, GNorm = 2.0686, lr_0 = 7.6206e-04
Loss = 3.9244e-01, PNorm = 44.1379, GNorm = 4.0905, lr_0 = 7.4855e-04
Loss = 4.2036e-01, PNorm = 44.1626, GNorm = 5.2387, lr_0 = 7.3529e-04
Loss = 4.2530e-01, PNorm = 44.1861, GNorm = 5.2948, lr_0 = 7.2226e-04
Validation rmse = 0.692811
Epoch 6
Loss = 1.1371e-01, PNorm = 44.2074, GNorm = 2.4092, lr_0 = 7.0820e-04
Loss = 4.4778e-01, PNorm = 44.2299, GNorm = 9.9879, lr_0 = 6.9565e-04
Loss = 3.6570e-01, PNorm = 44.2508, GNorm = 7.0435, lr_0 = 6.8333e-04
Loss = 3.9263e-01, PNorm = 44.2751, GNorm = 4.8901, lr_0 = 6.7122e-04
Loss = 4.2150e-01, PNorm = 44.2939, GNorm = 4.2769, lr_0 = 6.5932e-04
Validation rmse = 0.653216
Epoch 7
Loss = 3.4469e-01, PNorm = 44.3111, GNorm = 5.0841, lr_0 = 6.4649e-04
Loss = 3.4652e-01, PNorm = 44.3263, GNorm = 3.5416, lr_0 = 6.3503e-04
Loss = 3.2273e-01, PNorm = 44.3448, GNorm = 5.6791, lr_0 = 6.2378e-04
Loss = 3.8127e-01, PNorm = 44.3632, GNorm = 4.6946, lr_0 = 6.1273e-04
Loss = 4.8366e-01, PNorm = 44.3775, GNorm = 9.4444, lr_0 = 6.0187e-04
Validation rmse = 0.671671
Epoch 8
Loss = 3.7022e-01, PNorm = 44.3971, GNorm = 7.8507, lr_0 = 5.9121e-04
Loss = 2.8627e-01, PNorm = 44.4217, GNorm = 9.3031, lr_0 = 5.8073e-04
Loss = 3.2092e-01, PNorm = 44.4416, GNorm = 7.0177, lr_0 = 5.7044e-04
Loss = 2.8304e-01, PNorm = 44.4521, GNorm = 3.2808, lr_0 = 5.6033e-04
Validation rmse = 0.630289
Epoch 9
Loss = 9.4259e-02, PNorm = 44.4688, GNorm = 4.6556, lr_0 = 5.4942e-04
Loss = 3.7285e-01, PNorm = 44.4845, GNorm = 9.3871, lr_0 = 5.3969e-04
Loss = 2.8750e-01, PNorm = 44.5001, GNorm = 3.7507, lr_0 = 5.3013e-04
Loss = 2.5136e-01, PNorm = 44.5180, GNorm = 3.0658, lr_0 = 5.2073e-04
Loss = 4.0177e-01, PNorm = 44.5298, GNorm = 6.2426, lr_0 = 5.1151e-04
Validation rmse = 0.674994
Epoch 10
Loss = 2.4663e-01, PNorm = 44.5445, GNorm = 5.2886, lr_0 = 5.0244e-04
Loss = 2.7786e-01, PNorm = 44.5686, GNorm = 2.4023, lr_0 = 4.9354e-04
Loss = 2.6636e-01, PNorm = 44.5822, GNorm = 3.0864, lr_0 = 4.8480e-04
Loss = 2.6963e-01, PNorm = 44.5902, GNorm = 3.6471, lr_0 = 4.7621e-04
Loss = 2.2586e-01, PNorm = 44.5939, GNorm = 2.8010, lr_0 = 4.6777e-04
Loss = 1.3560e-01, PNorm = 44.5953, GNorm = 5.2361, lr_0 = 4.6693e-04
Validation rmse = 0.679673
Epoch 11
Loss = 2.1721e-01, PNorm = 44.6162, GNorm = 5.4737, lr_0 = 4.5866e-04
Loss = 3.3243e-01, PNorm = 44.6283, GNorm = 3.8812, lr_0 = 4.5053e-04
Loss = 2.7949e-01, PNorm = 44.6436, GNorm = 2.7338, lr_0 = 4.4255e-04
Loss = 2.1438e-01, PNorm = 44.6574, GNorm = 8.1546, lr_0 = 4.3471e-04
Validation rmse = 0.646666
Epoch 12
Loss = 2.9573e-01, PNorm = 44.6710, GNorm = 7.1548, lr_0 = 4.2624e-04
Loss = 1.7880e-01, PNorm = 44.6823, GNorm = 17.1564, lr_0 = 4.1869e-04
Loss = 2.4325e-01, PNorm = 44.6952, GNorm = 6.7117, lr_0 = 4.1127e-04
Loss = 3.1129e-01, PNorm = 44.7051, GNorm = 5.3188, lr_0 = 4.0399e-04
Loss = 2.2626e-01, PNorm = 44.7187, GNorm = 4.6587, lr_0 = 3.9683e-04
Validation rmse = 0.629380
Epoch 13
Loss = 1.2534e-01, PNorm = 44.7312, GNorm = 4.4880, lr_0 = 3.8980e-04
Loss = 1.4404e-01, PNorm = 44.7407, GNorm = 6.0596, lr_0 = 3.8289e-04
Loss = 2.0481e-01, PNorm = 44.7541, GNorm = 7.5821, lr_0 = 3.7611e-04
Loss = 2.7227e-01, PNorm = 44.7654, GNorm = 5.1450, lr_0 = 3.6944e-04
Validation rmse = 0.693671
Epoch 14
Loss = 3.4832e-03, PNorm = 44.7779, GNorm = 11.9062, lr_0 = 3.6225e-04
Loss = 6.1896e-02, PNorm = 44.7863, GNorm = 7.6337, lr_0 = 3.5583e-04
Loss = 1.6047e-01, PNorm = 44.7960, GNorm = 3.2890, lr_0 = 3.4953e-04
Loss = 2.0959e-01, PNorm = 44.8045, GNorm = 8.6752, lr_0 = 3.4333e-04
Loss = 2.6040e-01, PNorm = 44.8132, GNorm = 8.3559, lr_0 = 3.3725e-04
Validation rmse = 0.628881
Epoch 15
Loss = 2.8922e-01, PNorm = 44.8214, GNorm = 9.2980, lr_0 = 3.3127e-04
Loss = 1.3942e-01, PNorm = 44.8349, GNorm = 3.0578, lr_0 = 3.2540e-04
Loss = 2.0421e-01, PNorm = 44.8470, GNorm = 4.9585, lr_0 = 3.1964e-04
Loss = 7.2672e-02, PNorm = 44.8550, GNorm = 6.7477, lr_0 = 3.1397e-04
Loss = 1.6216e-01, PNorm = 44.8579, GNorm = 3.3942, lr_0 = 3.0841e-04
Validation rmse = 0.692900
Epoch 16
Loss = 1.7977e-01, PNorm = 44.8690, GNorm = 3.7591, lr_0 = 3.0241e-04
Loss = 2.1250e-01, PNorm = 44.8794, GNorm = 10.9713, lr_0 = 2.9705e-04
Loss = 1.1169e-01, PNorm = 44.8920, GNorm = 7.5499, lr_0 = 2.9178e-04
Loss = 1.3438e-01, PNorm = 44.8982, GNorm = 2.8037, lr_0 = 2.8661e-04
Validation rmse = 0.652813
Epoch 17
Loss = 1.5519e-01, PNorm = 44.9051, GNorm = 4.3859, lr_0 = 2.8103e-04
Loss = 8.5544e-02, PNorm = 44.9156, GNorm = 10.0733, lr_0 = 2.7605e-04
Loss = 1.3829e-01, PNorm = 44.9253, GNorm = 13.0060, lr_0 = 2.7116e-04
Loss = 1.0718e-01, PNorm = 44.9268, GNorm = 8.1468, lr_0 = 2.6636e-04
Loss = 2.1039e-01, PNorm = 44.9319, GNorm = 4.7572, lr_0 = 2.6164e-04
Validation rmse = 0.636278
Epoch 18
Loss = 1.9482e-01, PNorm = 44.9403, GNorm = 7.7190, lr_0 = 2.5700e-04
Loss = 1.0081e-01, PNorm = 44.9492, GNorm = 6.1369, lr_0 = 2.5245e-04
Loss = 5.6677e-02, PNorm = 44.9573, GNorm = 3.5097, lr_0 = 2.4798e-04
Loss = 1.3411e-01, PNorm = 44.9621, GNorm = 5.6823, lr_0 = 2.4358e-04
Loss = 7.2118e-03, PNorm = 44.9720, GNorm = 11.1108, lr_0 = 2.3927e-04
Validation rmse = 0.630205
Epoch 19
Loss = 8.2194e-02, PNorm = 44.9790, GNorm = 7.8461, lr_0 = 2.3461e-04
Loss = 1.1172e-01, PNorm = 44.9872, GNorm = 10.4792, lr_0 = 2.3045e-04
Loss = 6.7047e-02, PNorm = 44.9939, GNorm = 4.3464, lr_0 = 2.2637e-04
Loss = 7.6856e-02, PNorm = 45.0032, GNorm = 4.1254, lr_0 = 2.2236e-04
Validation rmse = 0.632589
Epoch 20
Loss = 3.4009e-02, PNorm = 45.0044, GNorm = 4.1895, lr_0 = 2.1842e-04
Loss = 7.3031e-02, PNorm = 45.0135, GNorm = 7.8138, lr_0 = 2.1455e-04
Loss = 7.6902e-02, PNorm = 45.0213, GNorm = 4.3476, lr_0 = 2.1075e-04
Loss = 1.6635e-01, PNorm = 45.0279, GNorm = 20.0770, lr_0 = 2.0701e-04
Loss = 2.4293e-01, PNorm = 45.0329, GNorm = 3.2849, lr_0 = 2.0334e-04
Validation rmse = 0.648792
Epoch 21
Loss = 8.8474e-02, PNorm = 45.0392, GNorm = 9.5960, lr_0 = 1.9938e-04
Loss = 1.0029e-01, PNorm = 45.0477, GNorm = 6.7616, lr_0 = 1.9585e-04
Loss = 1.5120e-02, PNorm = 45.0567, GNorm = 7.1407, lr_0 = 1.9238e-04
Loss = 1.4672e-01, PNorm = 45.0617, GNorm = 20.0546, lr_0 = 1.8897e-04
Loss = 1.3718e-01, PNorm = 45.0643, GNorm = 6.7961, lr_0 = 1.8562e-04
Loss = 1.1387e-01, PNorm = 45.0646, GNorm = 8.3687, lr_0 = 1.8529e-04
Validation rmse = 0.640685
Epoch 22
Loss = 1.0645e-01, PNorm = 45.0704, GNorm = 7.7218, lr_0 = 1.8201e-04
Loss = 6.5549e-02, PNorm = 45.0781, GNorm = 8.2111, lr_0 = 1.7878e-04
Loss = 7.8162e-02, PNorm = 45.0849, GNorm = 9.4015, lr_0 = 1.7562e-04
Loss = -9.0696e-03, PNorm = 45.0890, GNorm = 5.1053, lr_0 = 1.7250e-04
Validation rmse = 0.643460
Epoch 23
Loss = 1.5954e-01, PNorm = 45.0912, GNorm = 4.8162, lr_0 = 1.6945e-04
Loss = 5.3485e-02, PNorm = 45.0959, GNorm = 10.0403, lr_0 = 1.6645e-04
Loss = -2.5335e-02, PNorm = 45.1029, GNorm = 4.2430, lr_0 = 1.6350e-04
Loss = 6.7663e-02, PNorm = 45.1086, GNorm = 4.1957, lr_0 = 1.6060e-04
Loss = 4.4036e-02, PNorm = 45.1134, GNorm = 5.6231, lr_0 = 1.5775e-04
Validation rmse = 0.630543
Epoch 24
Loss = -3.1947e-04, PNorm = 45.1163, GNorm = 4.8103, lr_0 = 1.5468e-04
Loss = 2.1920e-02, PNorm = 45.1216, GNorm = 6.4537, lr_0 = 1.5194e-04
Loss = 7.0115e-02, PNorm = 45.1252, GNorm = 7.2433, lr_0 = 1.4925e-04
Loss = 2.5153e-02, PNorm = 45.1287, GNorm = 2.5904, lr_0 = 1.4661e-04
Loss = -3.5946e-02, PNorm = 45.1342, GNorm = 11.2334, lr_0 = 1.4401e-04
Validation rmse = 0.625341
Epoch 25
Loss = 1.6668e-02, PNorm = 45.1379, GNorm = 10.2890, lr_0 = 1.4146e-04
Loss = -1.8631e-02, PNorm = 45.1440, GNorm = 10.3389, lr_0 = 1.3895e-04
Loss = -5.2714e-02, PNorm = 45.1495, GNorm = 4.0281, lr_0 = 1.3649e-04
Loss = 1.1117e-01, PNorm = 45.1514, GNorm = 8.3117, lr_0 = 1.3407e-04
Validation rmse = 0.628897
Epoch 26
Loss = 2.1286e-02, PNorm = 45.1551, GNorm = 3.8654, lr_0 = 1.3146e-04
Loss = 9.1121e-05, PNorm = 45.1605, GNorm = 3.3809, lr_0 = 1.2913e-04
Loss = -4.8559e-02, PNorm = 45.1650, GNorm = 10.8112, lr_0 = 1.2684e-04
Loss = 5.9978e-02, PNorm = 45.1666, GNorm = 9.7646, lr_0 = 1.2459e-04
Loss = -3.0151e-02, PNorm = 45.1706, GNorm = 5.7885, lr_0 = 1.2239e-04
Validation rmse = 0.626473
Epoch 27
Loss = -5.6464e-02, PNorm = 45.1751, GNorm = 8.8590, lr_0 = 1.2000e-04
Loss = 1.3022e-03, PNorm = 45.1779, GNorm = 5.0573, lr_0 = 1.1788e-04
Loss = 2.6714e-02, PNorm = 45.1792, GNorm = 6.1304, lr_0 = 1.1579e-04
Loss = -1.3024e-02, PNorm = 45.1836, GNorm = 3.1888, lr_0 = 1.1374e-04
Validation rmse = 0.629398
Epoch 28
Loss = -1.0354e-01, PNorm = 45.1890, GNorm = 7.2127, lr_0 = 1.1172e-04
Loss = 2.1542e-02, PNorm = 45.1918, GNorm = 8.3185, lr_0 = 1.0974e-04
Loss = 4.6221e-02, PNorm = 45.1946, GNorm = 3.7571, lr_0 = 1.0780e-04
Loss = -1.0742e-02, PNorm = 45.1981, GNorm = 3.0973, lr_0 = 1.0589e-04
Loss = -9.4964e-03, PNorm = 45.2025, GNorm = 6.5134, lr_0 = 1.0401e-04
Validation rmse = 0.621069
Epoch 29
Loss = -2.1549e-02, PNorm = 45.2067, GNorm = 17.1859, lr_0 = 1.0199e-04
Loss = -4.6878e-02, PNorm = 45.2097, GNorm = 8.3015, lr_0 = 1.0018e-04
Loss = 9.5328e-02, PNorm = 45.2112, GNorm = 7.7131, lr_0 = 1.0000e-04
Loss = -3.5634e-02, PNorm = 45.2141, GNorm = 8.2744, lr_0 = 1.0000e-04
Loss = -1.9590e-02, PNorm = 45.2187, GNorm = 4.4419, lr_0 = 1.0000e-04
Validation rmse = 0.619617
Model 0 best validation rmse = 0.619617 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.626676
Ensemble test rmse = 0.626676
1-fold cross validation
	Seed 0 ==> test rmse = 0.626676
Overall test rmse = 0.626676 +/- 0.000000
Elapsed time = 0:01:56
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,475 | train size = 1,180 | val size = 147 | test size = 148
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9399e+00, PNorm = 43.3122, GNorm = 2.5781, lr_0 = 2.0532e-04
Loss = 1.4344e+00, PNorm = 43.3127, GNorm = 1.5306, lr_0 = 3.0106e-04
Loss = 1.3989e+00, PNorm = 43.3178, GNorm = 2.4189, lr_0 = 3.9681e-04
Loss = 1.3373e+00, PNorm = 43.3286, GNorm = 1.1509, lr_0 = 4.9255e-04
Validation rmse = 1.496829
Epoch 1
Loss = 1.0669e+00, PNorm = 43.3496, GNorm = 2.0756, lr_0 = 5.9787e-04
Loss = 1.1459e+00, PNorm = 43.3788, GNorm = 1.2853, lr_0 = 6.9362e-04
Loss = 1.0466e+00, PNorm = 43.4193, GNorm = 1.5450, lr_0 = 7.8936e-04
Loss = 1.0203e+00, PNorm = 43.4671, GNorm = 4.4213, lr_0 = 8.8511e-04
Loss = 9.5130e-01, PNorm = 43.5253, GNorm = 4.7768, lr_0 = 9.8085e-04
Validation rmse = 1.121540
Epoch 2
Loss = 8.5664e-01, PNorm = 43.5839, GNorm = 5.6070, lr_0 = 9.8438e-04
Loss = 8.0245e-01, PNorm = 43.6539, GNorm = 4.4047, lr_0 = 9.6730e-04
Loss = 7.0224e-01, PNorm = 43.6940, GNorm = 4.4869, lr_0 = 9.5052e-04
Loss = 7.7565e-01, PNorm = 43.7558, GNorm = 4.1175, lr_0 = 9.3404e-04
Loss = 7.1592e-01, PNorm = 43.8078, GNorm = 3.3501, lr_0 = 9.1784e-04
Validation rmse = 0.810567
Epoch 3
Loss = 6.1389e-01, PNorm = 43.8565, GNorm = 3.5368, lr_0 = 9.0034e-04
Loss = 6.3014e-01, PNorm = 43.8962, GNorm = 5.6821, lr_0 = 8.8473e-04
Loss = 6.9105e-01, PNorm = 43.9277, GNorm = 3.2980, lr_0 = 8.6938e-04
Loss = 6.0050e-01, PNorm = 43.9612, GNorm = 2.6913, lr_0 = 8.5430e-04
Validation rmse = 0.846511
Epoch 4
Loss = 8.7576e-01, PNorm = 44.0008, GNorm = 10.3554, lr_0 = 8.3802e-04
Loss = 6.3187e-01, PNorm = 44.0271, GNorm = 8.6120, lr_0 = 8.2348e-04
Loss = 5.2825e-01, PNorm = 44.0730, GNorm = 2.2852, lr_0 = 8.0920e-04
Loss = 4.9481e-01, PNorm = 44.1104, GNorm = 5.1999, lr_0 = 7.9516e-04
Loss = 5.2170e-01, PNorm = 44.1387, GNorm = 3.6965, lr_0 = 7.8137e-04
Validation rmse = 0.690933
Epoch 5
Loss = 3.8814e-01, PNorm = 44.1606, GNorm = 4.1952, lr_0 = 7.6782e-04
Loss = 4.4383e-01, PNorm = 44.1862, GNorm = 3.0630, lr_0 = 7.5450e-04
Loss = 4.5840e-01, PNorm = 44.2158, GNorm = 9.8710, lr_0 = 7.4141e-04
Loss = 5.6205e-01, PNorm = 44.2418, GNorm = 8.4072, lr_0 = 7.2855e-04
Loss = 4.6159e-01, PNorm = 44.2610, GNorm = 5.5954, lr_0 = 7.1592e-04
Validation rmse = 0.658268
Epoch 6
Loss = 4.2645e-01, PNorm = 44.2807, GNorm = 3.2662, lr_0 = 7.0227e-04
Loss = 5.0427e-01, PNorm = 44.3019, GNorm = 7.0230, lr_0 = 6.9009e-04
Loss = 3.8051e-01, PNorm = 44.3300, GNorm = 2.8066, lr_0 = 6.7812e-04
Loss = 3.7751e-01, PNorm = 44.3609, GNorm = 5.8110, lr_0 = 6.6636e-04
Loss = 4.3504e-01, PNorm = 44.3776, GNorm = 2.9596, lr_0 = 6.5480e-04
Loss = 9.0401e-02, PNorm = 44.3795, GNorm = 8.5596, lr_0 = 6.5366e-04
Validation rmse = 0.659274
Epoch 7
Loss = 2.8568e-01, PNorm = 44.3996, GNorm = 2.1063, lr_0 = 6.4232e-04
Loss = 3.3633e-01, PNorm = 44.4173, GNorm = 3.7345, lr_0 = 6.3118e-04
Loss = 4.0977e-01, PNorm = 44.4299, GNorm = 3.7543, lr_0 = 6.2023e-04
Loss = 4.3212e-01, PNorm = 44.4434, GNorm = 3.8279, lr_0 = 6.0947e-04
Validation rmse = 0.624907
Epoch 8
Loss = 2.9810e-01, PNorm = 44.4694, GNorm = 4.2421, lr_0 = 5.9785e-04
Loss = 3.6115e-01, PNorm = 44.4814, GNorm = 5.0940, lr_0 = 5.8749e-04
Loss = 4.0838e-01, PNorm = 44.4933, GNorm = 5.1797, lr_0 = 5.7730e-04
Loss = 3.6845e-01, PNorm = 44.5176, GNorm = 4.3502, lr_0 = 5.6728e-04
Loss = 2.6338e-01, PNorm = 44.5440, GNorm = 3.2970, lr_0 = 5.5744e-04
Validation rmse = 0.598012
Epoch 9
Loss = 3.3627e-01, PNorm = 44.5528, GNorm = 6.9321, lr_0 = 5.4682e-04
Loss = 3.5207e-01, PNorm = 44.5680, GNorm = 2.7725, lr_0 = 5.3733e-04
Loss = 2.9016e-01, PNorm = 44.5878, GNorm = 4.1682, lr_0 = 5.2801e-04
Loss = 2.8574e-01, PNorm = 44.6107, GNorm = 2.8604, lr_0 = 5.1885e-04
Loss = 3.0972e-01, PNorm = 44.6232, GNorm = 6.2043, lr_0 = 5.0986e-04
Validation rmse = 0.708397
Epoch 10
Loss = 4.9683e-01, PNorm = 44.6334, GNorm = 6.4211, lr_0 = 5.0101e-04
Loss = 4.7915e-01, PNorm = 44.6518, GNorm = 4.2517, lr_0 = 4.9232e-04
Loss = 2.9564e-01, PNorm = 44.6795, GNorm = 4.9094, lr_0 = 4.8378e-04
Loss = 2.6290e-01, PNorm = 44.6938, GNorm = 3.5909, lr_0 = 4.7539e-04
Validation rmse = 0.654959
Epoch 11
Loss = 4.7357e-01, PNorm = 44.7093, GNorm = 9.6883, lr_0 = 4.6633e-04
Loss = 3.2583e-01, PNorm = 44.7261, GNorm = 4.0066, lr_0 = 4.5824e-04
Loss = 2.1140e-01, PNorm = 44.7461, GNorm = 2.8821, lr_0 = 4.5029e-04
Loss = 2.9261e-01, PNorm = 44.7577, GNorm = 4.0238, lr_0 = 4.4248e-04
Loss = 2.7591e-01, PNorm = 44.7644, GNorm = 4.4372, lr_0 = 4.3481e-04
Validation rmse = 0.637329
Epoch 12
Loss = 3.5482e-01, PNorm = 44.7778, GNorm = 4.0790, lr_0 = 4.2652e-04
Loss = 2.3579e-01, PNorm = 44.7911, GNorm = 2.9061, lr_0 = 4.1912e-04
Loss = 1.9995e-01, PNorm = 44.8073, GNorm = 13.7553, lr_0 = 4.1185e-04
Loss = 1.8855e-01, PNorm = 44.8137, GNorm = 6.5697, lr_0 = 4.0471e-04
Loss = 2.2471e-01, PNorm = 44.8194, GNorm = 7.0695, lr_0 = 3.9769e-04
Validation rmse = 0.680109
Epoch 13
Loss = 1.9431e-01, PNorm = 44.8242, GNorm = 5.2313, lr_0 = 3.9011e-04
Loss = 2.4590e-01, PNorm = 44.8373, GNorm = 7.1277, lr_0 = 3.8334e-04
Loss = 2.8502e-01, PNorm = 44.8470, GNorm = 2.6547, lr_0 = 3.7669e-04
Loss = 3.0143e-01, PNorm = 44.8557, GNorm = 3.8087, lr_0 = 3.7016e-04
Loss = 1.6203e-01, PNorm = 44.8742, GNorm = 4.6201, lr_0 = 3.6374e-04
Loss = -1.3327e-01, PNorm = 44.8753, GNorm = 9.6583, lr_0 = 3.6310e-04
Validation rmse = 0.588564
Epoch 14
Loss = 6.2129e-02, PNorm = 44.8928, GNorm = 10.6919, lr_0 = 3.5681e-04
Loss = 2.6994e-01, PNorm = 44.9001, GNorm = 4.3465, lr_0 = 3.5062e-04
Loss = 2.7307e-01, PNorm = 44.9039, GNorm = 4.6315, lr_0 = 3.4454e-04
Loss = 2.4520e-01, PNorm = 44.9154, GNorm = 5.8854, lr_0 = 3.3856e-04
Validation rmse = 0.631957
Epoch 15
Loss = 1.7636e-01, PNorm = 44.9232, GNorm = 3.3553, lr_0 = 3.3269e-04
Loss = 8.7214e-02, PNorm = 44.9359, GNorm = 4.6153, lr_0 = 3.2692e-04
Loss = 1.7528e-01, PNorm = 44.9451, GNorm = 20.2877, lr_0 = 3.2125e-04
Loss = 2.4232e-01, PNorm = 44.9505, GNorm = 7.8037, lr_0 = 3.1567e-04
Loss = 2.5530e-01, PNorm = 44.9576, GNorm = 2.5624, lr_0 = 3.1020e-04
Validation rmse = 0.592730
Epoch 16
Loss = 1.5866e-01, PNorm = 44.9702, GNorm = 2.7175, lr_0 = 3.0429e-04
Loss = 2.1824e-01, PNorm = 44.9780, GNorm = 4.6531, lr_0 = 2.9901e-04
Loss = 8.1228e-02, PNorm = 44.9907, GNorm = 2.8992, lr_0 = 2.9382e-04
Loss = 2.1205e-01, PNorm = 44.9938, GNorm = 2.5233, lr_0 = 2.8873e-04
Loss = 1.7223e-01, PNorm = 45.0049, GNorm = 4.7118, lr_0 = 2.8372e-04
Validation rmse = 0.567006
Epoch 17
Loss = 1.3832e-01, PNorm = 45.0147, GNorm = 10.4103, lr_0 = 2.7831e-04
Loss = 2.4677e-02, PNorm = 45.0249, GNorm = 4.4503, lr_0 = 2.7348e-04
Loss = 1.0163e-01, PNorm = 45.0346, GNorm = 7.8265, lr_0 = 2.6874e-04
Loss = 2.5010e-01, PNorm = 45.0361, GNorm = 5.0380, lr_0 = 2.6408e-04
Validation rmse = 0.601460
Epoch 18
Loss = 1.8946e-01, PNorm = 45.0443, GNorm = 3.5849, lr_0 = 2.5904e-04
Loss = 1.3190e-01, PNorm = 45.0567, GNorm = 3.0614, lr_0 = 2.5455e-04
Loss = 9.3065e-02, PNorm = 45.0658, GNorm = 3.6674, lr_0 = 2.5014e-04
Loss = 1.7909e-01, PNorm = 45.0711, GNorm = 6.4511, lr_0 = 2.4580e-04
Loss = 1.1402e-01, PNorm = 45.0778, GNorm = 3.8302, lr_0 = 2.4153e-04
Validation rmse = 0.590850
Epoch 19
Loss = 1.4483e-01, PNorm = 45.0870, GNorm = 13.0232, lr_0 = 2.3693e-04
Loss = 8.0901e-03, PNorm = 45.0950, GNorm = 3.8000, lr_0 = 2.3282e-04
Loss = 1.3796e-01, PNorm = 45.0985, GNorm = 6.6322, lr_0 = 2.2878e-04
Loss = 8.3502e-02, PNorm = 45.1046, GNorm = 2.7522, lr_0 = 2.2481e-04
Loss = 1.6505e-01, PNorm = 45.1115, GNorm = 3.6998, lr_0 = 2.2091e-04
Validation rmse = 0.592673
Epoch 20
Loss = 1.0465e-02, PNorm = 45.1173, GNorm = 7.3463, lr_0 = 2.1708e-04
Loss = 1.4388e-01, PNorm = 45.1268, GNorm = 4.4045, lr_0 = 2.1332e-04
Loss = 7.1469e-02, PNorm = 45.1320, GNorm = 5.8196, lr_0 = 2.0962e-04
Loss = 1.2548e-01, PNorm = 45.1422, GNorm = 6.8170, lr_0 = 2.0598e-04
Loss = 8.9835e-02, PNorm = 45.1505, GNorm = 6.6668, lr_0 = 2.0241e-04
Validation rmse = 0.574402
Epoch 21
Loss = 2.0065e-02, PNorm = 45.1532, GNorm = 4.2609, lr_0 = 1.9855e-04
Loss = 1.4902e-01, PNorm = 45.1582, GNorm = 4.1188, lr_0 = 1.9511e-04
Loss = 7.6190e-02, PNorm = 45.1663, GNorm = 9.6780, lr_0 = 1.9172e-04
Loss = 9.4915e-02, PNorm = 45.1707, GNorm = 4.9826, lr_0 = 1.8840e-04
Validation rmse = 0.606706
Epoch 22
Loss = -2.6988e-02, PNorm = 45.1748, GNorm = 3.0765, lr_0 = 1.8481e-04
Loss = 1.1410e-02, PNorm = 45.1816, GNorm = 6.0158, lr_0 = 1.8160e-04
Loss = 1.2967e-01, PNorm = 45.1868, GNorm = 9.1265, lr_0 = 1.7845e-04
Loss = 8.9065e-02, PNorm = 45.1893, GNorm = 6.4833, lr_0 = 1.7536e-04
Loss = 1.0255e-01, PNorm = 45.1959, GNorm = 3.2252, lr_0 = 1.7231e-04
Validation rmse = 0.598876
Epoch 23
Loss = -3.4106e-02, PNorm = 45.2034, GNorm = 5.0369, lr_0 = 1.6903e-04
Loss = 8.2637e-02, PNorm = 45.2083, GNorm = 4.6933, lr_0 = 1.6610e-04
Loss = 1.4428e-01, PNorm = 45.2113, GNorm = 7.2979, lr_0 = 1.6322e-04
Loss = 4.9736e-02, PNorm = 45.2158, GNorm = 9.3337, lr_0 = 1.6039e-04
Loss = 6.7250e-02, PNorm = 45.2200, GNorm = 4.8925, lr_0 = 1.5760e-04
Validation rmse = 0.581688
Epoch 24
Loss = 2.5810e-02, PNorm = 45.2267, GNorm = 5.0302, lr_0 = 1.5460e-04
Loss = 1.9052e-02, PNorm = 45.2302, GNorm = 7.4082, lr_0 = 1.5192e-04
Loss = 9.7514e-02, PNorm = 45.2356, GNorm = 3.1760, lr_0 = 1.4928e-04
Loss = 1.0532e-01, PNorm = 45.2393, GNorm = 5.9180, lr_0 = 1.4669e-04
Loss = -5.6238e-02, PNorm = 45.2424, GNorm = 7.9382, lr_0 = 1.4415e-04
Validation rmse = 0.604424
Epoch 25
Loss = 6.4060e-02, PNorm = 45.2478, GNorm = 3.3493, lr_0 = 1.4165e-04
Loss = -1.5410e-02, PNorm = 45.2533, GNorm = 5.1969, lr_0 = 1.3919e-04
Loss = -2.9224e-02, PNorm = 45.2577, GNorm = 11.5557, lr_0 = 1.3678e-04
Loss = 9.9466e-02, PNorm = 45.2618, GNorm = 7.6405, lr_0 = 1.3441e-04
Validation rmse = 0.596092
Epoch 26
Loss = 6.5879e-03, PNorm = 45.2648, GNorm = 2.9112, lr_0 = 1.3184e-04
Loss = 1.1712e-01, PNorm = 45.2670, GNorm = 4.8838, lr_0 = 1.2956e-04
Loss = -1.8049e-02, PNorm = 45.2701, GNorm = 5.6939, lr_0 = 1.2731e-04
Loss = 4.7191e-02, PNorm = 45.2757, GNorm = 9.0519, lr_0 = 1.2510e-04
Loss = 1.1233e-01, PNorm = 45.2774, GNorm = 5.7618, lr_0 = 1.2293e-04
Validation rmse = 0.584727
Epoch 27
Loss = 3.2579e-02, PNorm = 45.2812, GNorm = 4.0224, lr_0 = 1.2059e-04
Loss = 6.8712e-02, PNorm = 45.2848, GNorm = 3.7115, lr_0 = 1.1850e-04
Loss = 6.8689e-02, PNorm = 45.2873, GNorm = 6.2107, lr_0 = 1.1644e-04
Loss = -6.2673e-04, PNorm = 45.2916, GNorm = 6.7905, lr_0 = 1.1442e-04
Loss = -1.2720e-01, PNorm = 45.2967, GNorm = 6.1282, lr_0 = 1.1244e-04
Validation rmse = 0.576503
Epoch 28
Loss = 1.8514e-02, PNorm = 45.3017, GNorm = 5.2696, lr_0 = 1.1029e-04
Loss = -4.8543e-02, PNorm = 45.3043, GNorm = 11.5312, lr_0 = 1.0838e-04
Loss = 1.1360e-02, PNorm = 45.3059, GNorm = 6.0419, lr_0 = 1.0650e-04
Loss = 6.9442e-02, PNorm = 45.3075, GNorm = 5.3437, lr_0 = 1.0465e-04
Validation rmse = 0.587719
Epoch 29
Loss = 1.0399e-01, PNorm = 45.3117, GNorm = 4.8444, lr_0 = 1.0266e-04
Loss = -3.4382e-02, PNorm = 45.3157, GNorm = 3.9133, lr_0 = 1.0088e-04
Loss = -1.7539e-03, PNorm = 45.3196, GNorm = 5.2970, lr_0 = 1.0000e-04
Loss = 5.0000e-02, PNorm = 45.3217, GNorm = 5.1367, lr_0 = 1.0000e-04
Loss = -1.0234e-01, PNorm = 45.3246, GNorm = 8.6246, lr_0 = 1.0000e-04
Validation rmse = 0.578423
Model 0 best validation rmse = 0.567006 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.630281
Ensemble test rmse = 0.630281
1-fold cross validation
	Seed 0 ==> test rmse = 0.630281
Overall test rmse = 0.630281 +/- 0.000000
Elapsed time = 0:33:06
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8054e+00, PNorm = 43.3130, GNorm = 3.6980, lr_0 = 2.0312e-04
Loss = 1.4053e+00, PNorm = 43.3137, GNorm = 1.2622, lr_0 = 2.9687e-04
Loss = 1.3832e+00, PNorm = 43.3176, GNorm = 1.6985, lr_0 = 3.9062e-04
Loss = 1.3147e+00, PNorm = 43.3270, GNorm = 5.3015, lr_0 = 4.8437e-04
Validation rmse = 1.440618
Epoch 1
Loss = 1.0729e+00, PNorm = 43.3410, GNorm = 0.8478, lr_0 = 5.7812e-04
Loss = 1.0948e+00, PNorm = 43.3726, GNorm = 3.3793, lr_0 = 6.7187e-04
Loss = 9.8826e-01, PNorm = 43.4091, GNorm = 4.2769, lr_0 = 7.6563e-04
Loss = 9.6015e-01, PNorm = 43.4623, GNorm = 3.9722, lr_0 = 8.5938e-04
Loss = 8.8816e-01, PNorm = 43.5077, GNorm = 2.6661, lr_0 = 9.5312e-04
Validation rmse = 0.896730
Epoch 2
Loss = 7.8226e-01, PNorm = 43.5665, GNorm = 2.4272, lr_0 = 9.9147e-04
Loss = 7.4541e-01, PNorm = 43.6248, GNorm = 5.7833, lr_0 = 9.7463e-04
Loss = 7.2236e-01, PNorm = 43.6722, GNorm = 3.9947, lr_0 = 9.5807e-04
Loss = 7.3416e-01, PNorm = 43.7156, GNorm = 2.0054, lr_0 = 9.4180e-04
Loss = 6.5501e-01, PNorm = 43.7717, GNorm = 7.6148, lr_0 = 9.2580e-04
Validation rmse = 0.720355
Epoch 3
Loss = 6.5740e-01, PNorm = 43.8194, GNorm = 2.5764, lr_0 = 9.1008e-04
Loss = 5.5109e-01, PNorm = 43.8579, GNorm = 10.4031, lr_0 = 8.9462e-04
Loss = 5.5468e-01, PNorm = 43.9019, GNorm = 10.9752, lr_0 = 8.7942e-04
Loss = 5.6692e-01, PNorm = 43.9283, GNorm = 7.3760, lr_0 = 8.6448e-04
Loss = 5.7852e-01, PNorm = 43.9597, GNorm = 4.1049, lr_0 = 8.4980e-04
Validation rmse = 0.711059
Epoch 4
Loss = 4.1966e-01, PNorm = 44.0027, GNorm = 4.6657, lr_0 = 8.3536e-04
Loss = 4.7405e-01, PNorm = 44.0391, GNorm = 5.4221, lr_0 = 8.2117e-04
Loss = 4.6063e-01, PNorm = 44.0715, GNorm = 5.1174, lr_0 = 8.0722e-04
Loss = 4.8767e-01, PNorm = 44.0889, GNorm = 3.3169, lr_0 = 7.9351e-04
Loss = 4.7525e-01, PNorm = 44.1199, GNorm = 5.5285, lr_0 = 7.8003e-04
Validation rmse = 0.729581
Epoch 5
Loss = 4.6341e-01, PNorm = 44.1429, GNorm = 3.3068, lr_0 = 7.6678e-04
Loss = 6.2703e-01, PNorm = 44.1642, GNorm = 7.3839, lr_0 = 7.5376e-04
Loss = 4.5392e-01, PNorm = 44.1960, GNorm = 2.7044, lr_0 = 7.4095e-04
Loss = 4.9921e-01, PNorm = 44.2184, GNorm = 4.9551, lr_0 = 7.2837e-04
Validation rmse = 0.658780
Epoch 6
Loss = 5.7740e-01, PNorm = 44.2441, GNorm = 4.1189, lr_0 = 7.1600e-04
Loss = 3.0789e-01, PNorm = 44.2693, GNorm = 2.4149, lr_0 = 7.0383e-04
Loss = 4.4938e-01, PNorm = 44.2854, GNorm = 2.2850, lr_0 = 6.9188e-04
Loss = 4.2401e-01, PNorm = 44.3115, GNorm = 2.8029, lr_0 = 6.8013e-04
Loss = 3.3250e-01, PNorm = 44.3336, GNorm = 6.1072, lr_0 = 6.6857e-04
Validation rmse = 0.638356
Epoch 7
Loss = 4.6226e-01, PNorm = 44.3456, GNorm = 9.1741, lr_0 = 6.5722e-04
Loss = 3.4284e-01, PNorm = 44.3692, GNorm = 8.9071, lr_0 = 6.4605e-04
Loss = 3.7054e-01, PNorm = 44.3864, GNorm = 25.8138, lr_0 = 6.3508e-04
Loss = 4.6748e-01, PNorm = 44.3998, GNorm = 3.2636, lr_0 = 6.2429e-04
Loss = 4.6511e-01, PNorm = 44.4177, GNorm = 3.4571, lr_0 = 6.1369e-04
Validation rmse = 0.660555
Epoch 8
Loss = 3.5632e-01, PNorm = 44.4408, GNorm = 3.6989, lr_0 = 6.0326e-04
Loss = 2.7590e-01, PNorm = 44.4651, GNorm = 10.9069, lr_0 = 5.9301e-04
Loss = 4.6231e-01, PNorm = 44.4706, GNorm = 7.4873, lr_0 = 5.8294e-04
Loss = 4.4149e-01, PNorm = 44.4929, GNorm = 9.2115, lr_0 = 5.7304e-04
Loss = 4.5649e-01, PNorm = 44.5082, GNorm = 16.3298, lr_0 = 5.6331e-04
Validation rmse = 0.641378
Epoch 9
Loss = 3.7513e-01, PNorm = 44.5244, GNorm = 2.5252, lr_0 = 5.5374e-04
Loss = 2.4219e-01, PNorm = 44.5511, GNorm = 4.8160, lr_0 = 5.4433e-04
Loss = 2.9054e-01, PNorm = 44.5708, GNorm = 4.4022, lr_0 = 5.3508e-04
Loss = 4.0185e-01, PNorm = 44.5832, GNorm = 3.1036, lr_0 = 5.2600e-04
Loss = 4.1241e-01, PNorm = 44.5938, GNorm = 2.2032, lr_0 = 5.1706e-04
Validation rmse = 0.604107
Epoch 10
Loss = 2.3446e-01, PNorm = 44.6144, GNorm = 4.6326, lr_0 = 5.0828e-04
Loss = 3.0893e-01, PNorm = 44.6301, GNorm = 6.4136, lr_0 = 4.9964e-04
Loss = 2.6741e-01, PNorm = 44.6378, GNorm = 3.0270, lr_0 = 4.9116e-04
Loss = 3.3539e-01, PNorm = 44.6502, GNorm = 2.7678, lr_0 = 4.8281e-04
Validation rmse = 0.600450
Epoch 11
Loss = 1.3762e-01, PNorm = 44.6672, GNorm = 4.2202, lr_0 = 4.7461e-04
Loss = 2.1780e-01, PNorm = 44.6841, GNorm = 5.7998, lr_0 = 4.6655e-04
Loss = 2.4147e-01, PNorm = 44.7016, GNorm = 9.9320, lr_0 = 4.5863e-04
Loss = 3.6315e-01, PNorm = 44.7105, GNorm = 2.8100, lr_0 = 4.5084e-04
Loss = 4.2234e-01, PNorm = 44.7288, GNorm = 9.7509, lr_0 = 4.4318e-04
Validation rmse = 0.713868
Epoch 12
Loss = 2.1236e-01, PNorm = 44.7444, GNorm = 2.6284, lr_0 = 4.3565e-04
Loss = 1.3272e-01, PNorm = 44.7620, GNorm = 5.0114, lr_0 = 4.2825e-04
Loss = 2.0626e-01, PNorm = 44.7729, GNorm = 5.3940, lr_0 = 4.2097e-04
Loss = 2.9937e-01, PNorm = 44.7806, GNorm = 2.4969, lr_0 = 4.1382e-04
Loss = 2.6081e-01, PNorm = 44.7933, GNorm = 3.8276, lr_0 = 4.0679e-04
Validation rmse = 0.597901
Epoch 13
Loss = 1.5291e-01, PNorm = 44.8046, GNorm = 8.8164, lr_0 = 3.9988e-04
Loss = 2.2854e-01, PNorm = 44.8196, GNorm = 11.6026, lr_0 = 3.9309e-04
Loss = 2.2361e-01, PNorm = 44.8266, GNorm = 5.4878, lr_0 = 3.8641e-04
Loss = 2.3000e-01, PNorm = 44.8383, GNorm = 4.5183, lr_0 = 3.7985e-04
Loss = 2.5003e-01, PNorm = 44.8468, GNorm = 5.0436, lr_0 = 3.7340e-04
Validation rmse = 0.631025
Epoch 14
Loss = 2.1545e-01, PNorm = 44.8603, GNorm = 3.2615, lr_0 = 3.6706e-04
Loss = 1.3012e-01, PNorm = 44.8750, GNorm = 4.5869, lr_0 = 3.6082e-04
Loss = 1.9670e-01, PNorm = 44.8805, GNorm = 4.6991, lr_0 = 3.5469e-04
Loss = 2.8387e-01, PNorm = 44.8880, GNorm = 2.2373, lr_0 = 3.4867e-04
Loss = 2.1983e-01, PNorm = 44.9004, GNorm = 2.3859, lr_0 = 3.4274e-04
Validation rmse = 0.593471
Epoch 15
Loss = 1.6142e-01, PNorm = 44.9183, GNorm = 6.7669, lr_0 = 3.3692e-04
Loss = 1.0241e-01, PNorm = 44.9304, GNorm = 14.9575, lr_0 = 3.3120e-04
Loss = 1.4902e-01, PNorm = 44.9367, GNorm = 5.3213, lr_0 = 3.2557e-04
Loss = 2.4918e-01, PNorm = 44.9432, GNorm = 2.4853, lr_0 = 3.2004e-04
Validation rmse = 0.575347
Epoch 16
Loss = 1.9857e-01, PNorm = 44.9515, GNorm = 5.2724, lr_0 = 3.1461e-04
Loss = 1.5864e-01, PNorm = 44.9609, GNorm = 4.3673, lr_0 = 3.0926e-04
Loss = 1.8191e-01, PNorm = 44.9700, GNorm = 6.7295, lr_0 = 3.0401e-04
Loss = 2.0234e-01, PNorm = 44.9771, GNorm = 4.3845, lr_0 = 2.9885e-04
Loss = 2.0774e-01, PNorm = 44.9861, GNorm = 3.2137, lr_0 = 2.9377e-04
Validation rmse = 0.564747
Epoch 17
Loss = 6.1344e-02, PNorm = 45.0025, GNorm = 5.5528, lr_0 = 2.8878e-04
Loss = 1.0568e-01, PNorm = 45.0143, GNorm = 11.3865, lr_0 = 2.8387e-04
Loss = 1.4243e-01, PNorm = 45.0207, GNorm = 15.1383, lr_0 = 2.7905e-04
Loss = 1.4785e-01, PNorm = 45.0239, GNorm = 5.4944, lr_0 = 2.7431e-04
Loss = 2.0385e-01, PNorm = 45.0308, GNorm = 3.7423, lr_0 = 2.6965e-04
Validation rmse = 0.574392
Epoch 18
Loss = 5.5288e-02, PNorm = 45.0401, GNorm = 3.7781, lr_0 = 2.6507e-04
Loss = -2.9236e-02, PNorm = 45.0504, GNorm = 5.9010, lr_0 = 2.6057e-04
Loss = 1.7170e-01, PNorm = 45.0546, GNorm = 4.1746, lr_0 = 2.5614e-04
Loss = 2.3219e-01, PNorm = 45.0642, GNorm = 4.1579, lr_0 = 2.5179e-04
Loss = 2.2346e-01, PNorm = 45.0703, GNorm = 5.7834, lr_0 = 2.4751e-04
Validation rmse = 0.599753
Epoch 19
Loss = 9.0880e-02, PNorm = 45.0782, GNorm = 5.1788, lr_0 = 2.4331e-04
Loss = 1.0872e-01, PNorm = 45.0917, GNorm = 13.8496, lr_0 = 2.3918e-04
Loss = 1.2799e-01, PNorm = 45.0939, GNorm = 9.6536, lr_0 = 2.3511e-04
Loss = 1.1647e-01, PNorm = 45.1027, GNorm = 5.0415, lr_0 = 2.3112e-04
Loss = 5.5565e-02, PNorm = 45.1091, GNorm = 5.9010, lr_0 = 2.2720e-04
Validation rmse = 0.578710
Epoch 20
Loss = -3.2792e-02, PNorm = 45.1164, GNorm = 3.9924, lr_0 = 2.2334e-04
Loss = 1.0367e-01, PNorm = 45.1208, GNorm = 5.1194, lr_0 = 2.1954e-04
Loss = 1.7753e-01, PNorm = 45.1265, GNorm = 7.5436, lr_0 = 2.1581e-04
Loss = 1.3605e-01, PNorm = 45.1338, GNorm = 11.2166, lr_0 = 2.1215e-04
Validation rmse = 0.587997
Epoch 21
Loss = -5.8391e-02, PNorm = 45.1439, GNorm = 3.6552, lr_0 = 2.0854e-04
Loss = 8.6082e-02, PNorm = 45.1544, GNorm = 5.0101, lr_0 = 2.0500e-04
Loss = 1.1044e-01, PNorm = 45.1599, GNorm = 8.4057, lr_0 = 2.0152e-04
Loss = 9.4837e-02, PNorm = 45.1617, GNorm = 6.7394, lr_0 = 1.9810e-04
Loss = 4.0580e-02, PNorm = 45.1659, GNorm = 6.2502, lr_0 = 1.9473e-04
Validation rmse = 0.580172
Epoch 22
Loss = 7.6458e-02, PNorm = 45.1715, GNorm = 3.0770, lr_0 = 1.9142e-04
Loss = 5.6217e-02, PNorm = 45.1800, GNorm = 4.6520, lr_0 = 1.8817e-04
Loss = 1.0130e-01, PNorm = 45.1885, GNorm = 9.5182, lr_0 = 1.8498e-04
Loss = -1.2177e-02, PNorm = 45.1959, GNorm = 2.9074, lr_0 = 1.8183e-04
Loss = -2.0858e-02, PNorm = 45.1999, GNorm = 13.2095, lr_0 = 1.7874e-04
Validation rmse = 0.602838
Epoch 23
Loss = -9.1712e-02, PNorm = 45.2032, GNorm = 4.0059, lr_0 = 1.7571e-04
Loss = -2.4128e-02, PNorm = 45.2073, GNorm = 4.7604, lr_0 = 1.7272e-04
Loss = 1.0109e-01, PNorm = 45.2128, GNorm = 7.8657, lr_0 = 1.6979e-04
Loss = 1.9442e-01, PNorm = 45.2153, GNorm = 5.8618, lr_0 = 1.6691e-04
Loss = 7.1645e-02, PNorm = 45.2217, GNorm = 4.9643, lr_0 = 1.6407e-04
Validation rmse = 0.588332
Epoch 24
Loss = -5.5665e-02, PNorm = 45.2294, GNorm = 6.0716, lr_0 = 1.6128e-04
Loss = 6.7305e-02, PNorm = 45.2350, GNorm = 5.7120, lr_0 = 1.5854e-04
Loss = 6.9014e-02, PNorm = 45.2373, GNorm = 15.5356, lr_0 = 1.5585e-04
Loss = 8.5994e-02, PNorm = 45.2403, GNorm = 5.2548, lr_0 = 1.5320e-04
Loss = 2.6156e-02, PNorm = 45.2451, GNorm = 4.3244, lr_0 = 1.5060e-04
Validation rmse = 0.573574
Epoch 25
Loss = 2.6497e-02, PNorm = 45.2510, GNorm = 4.5818, lr_0 = 1.4804e-04
Loss = -6.3828e-02, PNorm = 45.2588, GNorm = 11.4501, lr_0 = 1.4553e-04
Loss = -3.2852e-03, PNorm = 45.2621, GNorm = 7.9786, lr_0 = 1.4306e-04
Loss = 1.1723e-01, PNorm = 45.2625, GNorm = 4.0987, lr_0 = 1.4063e-04
Validation rmse = 0.583914
Epoch 26
Loss = -7.2781e-02, PNorm = 45.2659, GNorm = 6.6633, lr_0 = 1.3824e-04
Loss = 2.1004e-02, PNorm = 45.2719, GNorm = 3.5930, lr_0 = 1.3589e-04
Loss = 5.4899e-02, PNorm = 45.2749, GNorm = 7.4242, lr_0 = 1.3358e-04
Loss = 3.8915e-02, PNorm = 45.2789, GNorm = 5.8464, lr_0 = 1.3131e-04
Loss = -1.0947e-01, PNorm = 45.2846, GNorm = 5.9754, lr_0 = 1.2908e-04
Validation rmse = 0.585997
Epoch 27
Loss = 5.1047e-02, PNorm = 45.2883, GNorm = 5.9392, lr_0 = 1.2689e-04
Loss = -1.1070e-02, PNorm = 45.2905, GNorm = 6.1001, lr_0 = 1.2473e-04
Loss = -1.5975e-02, PNorm = 45.2948, GNorm = 8.2756, lr_0 = 1.2261e-04
Loss = -1.1823e-02, PNorm = 45.2989, GNorm = 10.1191, lr_0 = 1.2053e-04
Loss = -5.2337e-03, PNorm = 45.3028, GNorm = 6.3420, lr_0 = 1.1848e-04
Validation rmse = 0.575275
Epoch 28
Loss = 3.4991e-02, PNorm = 45.3059, GNorm = 5.2069, lr_0 = 1.1647e-04
Loss = -4.9607e-02, PNorm = 45.3101, GNorm = 4.2279, lr_0 = 1.1449e-04
Loss = -7.6155e-03, PNorm = 45.3140, GNorm = 9.4663, lr_0 = 1.1255e-04
Loss = -3.5684e-02, PNorm = 45.3160, GNorm = 8.8545, lr_0 = 1.1064e-04
Loss = 7.8053e-02, PNorm = 45.3180, GNorm = 5.4494, lr_0 = 1.0876e-04
Validation rmse = 0.599670
Epoch 29
Loss = -4.8613e-02, PNorm = 45.3203, GNorm = 3.2221, lr_0 = 1.0691e-04
Loss = 6.1069e-03, PNorm = 45.3243, GNorm = 6.4501, lr_0 = 1.0509e-04
Loss = -3.0272e-02, PNorm = 45.3278, GNorm = 3.7059, lr_0 = 1.0331e-04
Loss = -7.2271e-02, PNorm = 45.3315, GNorm = 11.0985, lr_0 = 1.0155e-04
Loss = 5.8833e-02, PNorm = 45.3339, GNorm = 4.8332, lr_0 = 1.0000e-04
Validation rmse = 0.570402
Model 0 best validation rmse = 0.564747 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.629535
Ensemble test rmse = 0.629535
1-fold cross validation
	Seed 0 ==> test rmse = 0.629535
Overall test rmse = 0.629535 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8450e+00, PNorm = 43.3100, GNorm = 2.7463, lr_0 = 2.5469e-04
Loss = 1.5490e+00, PNorm = 43.3104, GNorm = 2.2039, lr_0 = 3.9531e-04
Loss = 1.4708e+00, PNorm = 43.3147, GNorm = 0.7671, lr_0 = 5.3594e-04
Validation rmse = 1.146393
Epoch 1
Loss = 1.3823e+00, PNorm = 43.3230, GNorm = 1.1478, lr_0 = 6.7656e-04
Loss = 1.3699e+00, PNorm = 43.3398, GNorm = 1.1197, lr_0 = 8.1719e-04
Loss = 1.2644e+00, PNorm = 43.3656, GNorm = 1.7220, lr_0 = 9.5781e-04
Validation rmse = 0.986678
Epoch 2
Loss = 1.2346e+00, PNorm = 43.4092, GNorm = 1.6325, lr_0 = 9.8217e-04
Loss = 1.1336e+00, PNorm = 43.4723, GNorm = 4.5398, lr_0 = 9.5725e-04
Loss = 1.0968e+00, PNorm = 43.5321, GNorm = 2.0584, lr_0 = 9.3297e-04
Validation rmse = 0.865575
Epoch 3
Loss = 1.0405e+00, PNorm = 43.5833, GNorm = 2.4888, lr_0 = 9.0930e-04
Loss = 9.7801e-01, PNorm = 43.6350, GNorm = 5.8983, lr_0 = 8.8623e-04
Loss = 9.5025e-01, PNorm = 43.6892, GNorm = 3.7356, lr_0 = 8.6374e-04
Validation rmse = 0.797042
Epoch 4
Loss = 7.7427e-01, PNorm = 43.7442, GNorm = 2.6393, lr_0 = 8.4183e-04
Loss = 9.4820e-01, PNorm = 43.7792, GNorm = 2.3428, lr_0 = 8.2047e-04
Loss = 1.0626e+00, PNorm = 43.8011, GNorm = 2.5496, lr_0 = 7.9965e-04
Loss = 9.5903e-01, PNorm = 43.8424, GNorm = 1.8728, lr_0 = 7.7937e-04
Validation rmse = 0.783450
Epoch 5
Loss = 8.2460e-01, PNorm = 43.8976, GNorm = 5.1968, lr_0 = 7.5959e-04
Loss = 9.0772e-01, PNorm = 43.9492, GNorm = 8.4964, lr_0 = 7.4032e-04
Loss = 7.4185e-01, PNorm = 43.9823, GNorm = 4.0125, lr_0 = 7.2154e-04
Validation rmse = 0.818139
Epoch 6
Loss = 8.1167e-01, PNorm = 43.9979, GNorm = 1.9702, lr_0 = 7.0323e-04
Loss = 8.4176e-01, PNorm = 44.0277, GNorm = 5.7441, lr_0 = 6.8539e-04
Loss = 7.9958e-01, PNorm = 44.0591, GNorm = 3.7686, lr_0 = 6.6800e-04
Validation rmse = 0.727591
Epoch 7
Loss = 8.2073e-01, PNorm = 44.0878, GNorm = 2.0718, lr_0 = 6.5105e-04
Loss = 7.8868e-01, PNorm = 44.1135, GNorm = 3.3979, lr_0 = 6.3453e-04
Loss = 7.0694e-01, PNorm = 44.1486, GNorm = 6.4949, lr_0 = 6.1844e-04
Validation rmse = 0.683815
Epoch 8
Loss = 5.6067e-01, PNorm = 44.1741, GNorm = 7.4705, lr_0 = 6.0275e-04
Loss = 5.9931e-01, PNorm = 44.2023, GNorm = 3.1658, lr_0 = 5.8745e-04
Loss = 7.4654e-01, PNorm = 44.2246, GNorm = 4.2908, lr_0 = 5.7255e-04
Validation rmse = 0.692375
Epoch 9
Loss = 6.0432e-01, PNorm = 44.2476, GNorm = 2.7591, lr_0 = 5.5802e-04
Loss = 5.5790e-01, PNorm = 44.2763, GNorm = 2.3047, lr_0 = 5.4386e-04
Loss = 7.0180e-01, PNorm = 44.2985, GNorm = 2.6011, lr_0 = 5.3007e-04
Loss = 6.3957e-01, PNorm = 44.3162, GNorm = 9.6320, lr_0 = 5.1662e-04
Validation rmse = 0.667287
Epoch 10
Loss = 4.8744e-01, PNorm = 44.3371, GNorm = 10.7590, lr_0 = 5.0351e-04
Loss = 4.8824e-01, PNorm = 44.3598, GNorm = 6.2743, lr_0 = 4.9074e-04
Loss = 8.0837e-01, PNorm = 44.3698, GNorm = 3.3724, lr_0 = 4.7829e-04
Validation rmse = 0.666010
Epoch 11
Loss = 5.7712e-01, PNorm = 44.3907, GNorm = 9.8303, lr_0 = 4.6615e-04
Loss = 6.2888e-01, PNorm = 44.4100, GNorm = 3.8913, lr_0 = 4.5432e-04
Loss = 5.3982e-01, PNorm = 44.4316, GNorm = 3.6932, lr_0 = 4.4280e-04
Validation rmse = 0.685905
Epoch 12
Loss = 3.4405e-01, PNorm = 44.4527, GNorm = 2.2827, lr_0 = 4.3156e-04
Loss = 5.3662e-01, PNorm = 44.4724, GNorm = 3.2817, lr_0 = 4.2061e-04
Loss = 5.9160e-01, PNorm = 44.4819, GNorm = 14.3309, lr_0 = 4.0994e-04
Validation rmse = 0.693212
Epoch 13
Loss = 6.0748e-01, PNorm = 44.4937, GNorm = 4.8747, lr_0 = 3.9954e-04
Loss = 5.2930e-01, PNorm = 44.5103, GNorm = 2.7921, lr_0 = 3.8941e-04
Loss = 6.0182e-01, PNorm = 44.5239, GNorm = 5.8280, lr_0 = 3.7953e-04
Validation rmse = 0.708033
Epoch 14
Loss = 6.6476e-01, PNorm = 44.5375, GNorm = 11.9444, lr_0 = 3.6990e-04
Loss = 4.7605e-01, PNorm = 44.5518, GNorm = 4.4824, lr_0 = 3.6051e-04
Loss = 4.5050e-01, PNorm = 44.5699, GNorm = 5.9540, lr_0 = 3.5137e-04
Loss = 5.2889e-01, PNorm = 44.5818, GNorm = 8.1660, lr_0 = 3.4245e-04
Validation rmse = 0.749605
Epoch 15
Loss = 5.0296e-01, PNorm = 44.5921, GNorm = 2.9098, lr_0 = 3.3376e-04
Loss = 4.4356e-01, PNorm = 44.6039, GNorm = 3.0776, lr_0 = 3.2529e-04
Loss = 4.5910e-01, PNorm = 44.6134, GNorm = 4.2450, lr_0 = 3.1704e-04
Validation rmse = 0.655937
Epoch 16
Loss = 3.9375e-01, PNorm = 44.6274, GNorm = 4.3345, lr_0 = 3.0900e-04
Loss = 5.3892e-01, PNorm = 44.6395, GNorm = 3.6797, lr_0 = 3.0116e-04
Loss = 3.8406e-01, PNorm = 44.6497, GNorm = 5.1245, lr_0 = 2.9352e-04
Validation rmse = 0.664404
Epoch 17
Loss = 3.6941e-01, PNorm = 44.6588, GNorm = 7.0068, lr_0 = 2.8607e-04
Loss = 4.1602e-01, PNorm = 44.6700, GNorm = 4.8909, lr_0 = 2.7881e-04
Loss = 4.8410e-01, PNorm = 44.6803, GNorm = 14.5687, lr_0 = 2.7174e-04
Validation rmse = 0.673917
Epoch 18
Loss = 3.5611e-01, PNorm = 44.6860, GNorm = 9.6224, lr_0 = 2.6484e-04
Loss = 4.1734e-01, PNorm = 44.6984, GNorm = 11.2788, lr_0 = 2.5813e-04
Loss = 4.7038e-01, PNorm = 44.7058, GNorm = 4.3900, lr_0 = 2.5158e-04
Validation rmse = 0.690103
Epoch 19
Loss = 3.2729e-01, PNorm = 44.7132, GNorm = 11.3480, lr_0 = 2.4519e-04
Loss = 3.9990e-01, PNorm = 44.7206, GNorm = 4.8217, lr_0 = 2.3897e-04
Loss = 3.7301e-01, PNorm = 44.7332, GNorm = 7.7983, lr_0 = 2.3291e-04
Loss = 4.9007e-01, PNorm = 44.7385, GNorm = 3.6168, lr_0 = 2.2700e-04
Validation rmse = 0.654522
Epoch 20
Loss = 3.4510e-01, PNorm = 44.7451, GNorm = 2.9230, lr_0 = 2.2124e-04
Loss = 3.9385e-01, PNorm = 44.7559, GNorm = 8.6300, lr_0 = 2.1563e-04
Loss = 4.4433e-01, PNorm = 44.7629, GNorm = 5.7072, lr_0 = 2.1016e-04
Validation rmse = 0.654824
Epoch 21
Loss = 2.9366e-01, PNorm = 44.7702, GNorm = 4.3974, lr_0 = 2.0483e-04
Loss = 4.0537e-01, PNorm = 44.7773, GNorm = 2.7666, lr_0 = 1.9963e-04
Loss = 4.0015e-01, PNorm = 44.7858, GNorm = 9.3768, lr_0 = 1.9456e-04
Validation rmse = 0.665161
Epoch 22
Loss = 3.4231e-01, PNorm = 44.7910, GNorm = 5.7352, lr_0 = 1.8963e-04
Loss = 4.1050e-01, PNorm = 44.7987, GNorm = 5.4032, lr_0 = 1.8482e-04
Loss = 4.1740e-01, PNorm = 44.8041, GNorm = 6.5120, lr_0 = 1.8013e-04
Validation rmse = 0.672266
Epoch 23
Loss = 3.3334e-01, PNorm = 44.8100, GNorm = 8.3108, lr_0 = 1.7556e-04
Loss = 2.7813e-01, PNorm = 44.8175, GNorm = 3.6770, lr_0 = 1.7110e-04
Loss = 3.6558e-01, PNorm = 44.8244, GNorm = 5.0336, lr_0 = 1.6676e-04
Validation rmse = 0.649021
Epoch 24
Loss = 3.6119e-01, PNorm = 44.8292, GNorm = 2.9479, lr_0 = 1.6253e-04
Loss = 3.6115e-01, PNorm = 44.8352, GNorm = 10.0890, lr_0 = 1.5841e-04
Loss = 3.1629e-01, PNorm = 44.8409, GNorm = 8.5140, lr_0 = 1.5439e-04
Loss = 2.8906e-01, PNorm = 44.8455, GNorm = 4.3457, lr_0 = 1.5047e-04
Validation rmse = 0.651959
Epoch 25
Loss = 2.4752e-01, PNorm = 44.8509, GNorm = 7.9260, lr_0 = 1.4665e-04
Loss = 3.0107e-01, PNorm = 44.8559, GNorm = 5.5846, lr_0 = 1.4293e-04
Loss = 4.1276e-01, PNorm = 44.8588, GNorm = 6.6559, lr_0 = 1.3931e-04
Validation rmse = 0.663362
Epoch 26
Loss = 3.2527e-01, PNorm = 44.8631, GNorm = 6.3468, lr_0 = 1.3577e-04
Loss = 3.0451e-01, PNorm = 44.8689, GNorm = 13.2651, lr_0 = 1.3233e-04
Loss = 3.8970e-01, PNorm = 44.8737, GNorm = 16.8931, lr_0 = 1.2897e-04
Validation rmse = 0.642243
Epoch 27
Loss = 2.7877e-01, PNorm = 44.8774, GNorm = 5.0399, lr_0 = 1.2570e-04
Loss = 3.1868e-01, PNorm = 44.8813, GNorm = 4.0764, lr_0 = 1.2251e-04
Loss = 2.3320e-01, PNorm = 44.8865, GNorm = 6.2014, lr_0 = 1.1940e-04
Validation rmse = 0.652126
Epoch 28
Loss = 2.1701e-01, PNorm = 44.8898, GNorm = 4.9939, lr_0 = 1.1637e-04
Loss = 2.4694e-01, PNorm = 44.8937, GNorm = 3.2311, lr_0 = 1.1342e-04
Loss = 2.6352e-01, PNorm = 44.8984, GNorm = 7.8378, lr_0 = 1.1054e-04
Validation rmse = 0.661720
Epoch 29
Loss = 3.7392e-01, PNorm = 44.9015, GNorm = 4.4074, lr_0 = 1.0774e-04
Loss = 2.9983e-01, PNorm = 44.9050, GNorm = 4.4355, lr_0 = 1.0500e-04
Loss = 2.3878e-01, PNorm = 44.9084, GNorm = 3.9728, lr_0 = 1.0234e-04
Loss = 2.7365e-01, PNorm = 44.9123, GNorm = 9.1720, lr_0 = 1.0000e-04
Validation rmse = 0.651912
Model 0 best validation rmse = 0.642243 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.766780
Ensemble test rmse = 0.766780
1-fold cross validation
	Seed 0 ==> test rmse = 0.766780
Overall test rmse = 0.766780 +/- 0.000000
Elapsed time = 0:01:19
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-3bab7214-fe3e-434a-840c-e78196196e7a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 25,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,025 | train size = 820 | val size = 102 | test size = 103
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9334e+00, PNorm = 43.3107, GNorm = 1.6420, lr_0 = 2.5469e-04
Loss = 1.4784e+00, PNorm = 43.3122, GNorm = 1.7135, lr_0 = 3.9531e-04
Loss = 1.5213e+00, PNorm = 43.3167, GNorm = 1.4069, lr_0 = 5.3594e-04
Validation rmse = 1.243107
Epoch 1
Loss = 1.3876e+00, PNorm = 43.3287, GNorm = 1.6101, lr_0 = 6.9063e-04
Loss = 1.3426e+00, PNorm = 43.3474, GNorm = 1.9079, lr_0 = 8.3125e-04
Loss = 1.3217e+00, PNorm = 43.3778, GNorm = 3.6404, lr_0 = 9.7187e-04
Validation rmse = 1.113497
Epoch 2
Loss = 1.1771e+00, PNorm = 43.4167, GNorm = 1.3095, lr_0 = 9.7965e-04
Loss = 1.2262e+00, PNorm = 43.4606, GNorm = 3.9981, lr_0 = 9.5480e-04
Loss = 1.1974e+00, PNorm = 43.5165, GNorm = 2.0803, lr_0 = 9.3057e-04
Validation rmse = 0.864357
Epoch 3
Loss = 9.7497e-01, PNorm = 43.5779, GNorm = 3.5863, lr_0 = 9.0696e-04
Loss = 9.7320e-01, PNorm = 43.6430, GNorm = 3.2201, lr_0 = 8.8395e-04
Loss = 9.8290e-01, PNorm = 43.6936, GNorm = 2.5965, lr_0 = 8.6152e-04
Loss = 1.0289e+00, PNorm = 43.7309, GNorm = 1.6988, lr_0 = 8.3967e-04
Validation rmse = 0.944650
Epoch 4
Loss = 1.0034e+00, PNorm = 43.7632, GNorm = 1.5321, lr_0 = 8.1836e-04
Loss = 9.5060e-01, PNorm = 43.8136, GNorm = 2.5332, lr_0 = 7.9760e-04
Loss = 8.4683e-01, PNorm = 43.8633, GNorm = 4.5620, lr_0 = 7.7737e-04
Validation rmse = 0.741721
Epoch 5
Loss = 8.4795e-01, PNorm = 43.9012, GNorm = 1.6277, lr_0 = 7.5764e-04
Loss = 6.9275e-01, PNorm = 43.9410, GNorm = 4.2904, lr_0 = 7.3842e-04
Loss = 8.4043e-01, PNorm = 43.9813, GNorm = 6.6485, lr_0 = 7.1969e-04
Validation rmse = 0.765796
Epoch 6
Loss = 7.1499e-01, PNorm = 44.0153, GNorm = 6.9804, lr_0 = 6.9963e-04
Loss = 6.6452e-01, PNorm = 44.0658, GNorm = 8.5199, lr_0 = 6.8188e-04
Loss = 7.5436e-01, PNorm = 44.0985, GNorm = 4.1101, lr_0 = 6.6458e-04
Validation rmse = 0.681562
Epoch 7
Loss = 8.3049e-01, PNorm = 44.1189, GNorm = 2.7878, lr_0 = 6.4771e-04
Loss = 6.4571e-01, PNorm = 44.1518, GNorm = 6.1496, lr_0 = 6.3128e-04
Loss = 7.2099e-01, PNorm = 44.1843, GNorm = 4.4973, lr_0 = 6.1527e-04
Loss = 6.5570e-01, PNorm = 44.2144, GNorm = 4.1972, lr_0 = 5.9966e-04
Validation rmse = 0.768441
Epoch 8
Loss = 6.2144e-01, PNorm = 44.2434, GNorm = 3.9043, lr_0 = 5.8444e-04
Loss = 6.3680e-01, PNorm = 44.2657, GNorm = 2.3387, lr_0 = 5.6961e-04
Loss = 6.2515e-01, PNorm = 44.2913, GNorm = 5.5008, lr_0 = 5.5516e-04
Validation rmse = 0.693952
Epoch 9
Loss = 6.5038e-01, PNorm = 44.3213, GNorm = 4.8583, lr_0 = 5.4108e-04
Loss = 6.1521e-01, PNorm = 44.3444, GNorm = 5.7332, lr_0 = 5.2735e-04
Loss = 7.1243e-01, PNorm = 44.3570, GNorm = 3.2211, lr_0 = 5.1397e-04
Validation rmse = 0.730833
Epoch 10
Loss = 6.5358e-01, PNorm = 44.3852, GNorm = 8.7291, lr_0 = 5.0093e-04
Loss = 5.2128e-01, PNorm = 44.4123, GNorm = 7.7421, lr_0 = 4.8822e-04
Loss = 6.6162e-01, PNorm = 44.4330, GNorm = 5.5832, lr_0 = 4.7583e-04
Loss = 5.3330e-01, PNorm = 44.4506, GNorm = 3.7690, lr_0 = 4.6376e-04
Loss = 5.3647e-01, PNorm = 44.4530, GNorm = 4.2364, lr_0 = 4.6257e-04
Validation rmse = 0.676072
Epoch 11
Loss = 4.8514e-01, PNorm = 44.4790, GNorm = 6.9549, lr_0 = 4.5084e-04
Loss = 5.7710e-01, PNorm = 44.4930, GNorm = 13.0209, lr_0 = 4.3940e-04
Loss = 4.7012e-01, PNorm = 44.5040, GNorm = 7.0828, lr_0 = 4.2825e-04
Validation rmse = 0.674312
Epoch 12
Loss = 4.6948e-01, PNorm = 44.5260, GNorm = 4.0921, lr_0 = 4.1738e-04
Loss = 5.3442e-01, PNorm = 44.5427, GNorm = 2.6799, lr_0 = 4.0679e-04
Loss = 5.4055e-01, PNorm = 44.5584, GNorm = 5.1027, lr_0 = 3.9647e-04
Validation rmse = 0.653539
Epoch 13
Loss = 4.3943e-01, PNorm = 44.5727, GNorm = 8.7667, lr_0 = 3.8641e-04
Loss = 4.9792e-01, PNorm = 44.5907, GNorm = 5.9023, lr_0 = 3.7661e-04
Loss = 5.2306e-01, PNorm = 44.6033, GNorm = 5.3601, lr_0 = 3.6706e-04
Validation rmse = 0.673511
Epoch 14
Loss = 4.9752e-01, PNorm = 44.6170, GNorm = 6.5504, lr_0 = 3.5774e-04
Loss = 4.5436e-01, PNorm = 44.6281, GNorm = 4.5551, lr_0 = 3.4867e-04
Loss = 4.2683e-01, PNorm = 44.6402, GNorm = 4.8536, lr_0 = 3.3982e-04
Loss = 5.2033e-01, PNorm = 44.6496, GNorm = 7.5650, lr_0 = 3.3120e-04
Validation rmse = 0.653346
Epoch 15
Loss = 4.4980e-01, PNorm = 44.6598, GNorm = 2.4730, lr_0 = 3.2280e-04
Loss = 4.0764e-01, PNorm = 44.6759, GNorm = 8.8450, lr_0 = 3.1461e-04
Loss = 4.7034e-01, PNorm = 44.6865, GNorm = 8.5687, lr_0 = 3.0662e-04
Validation rmse = 0.649524
Epoch 16
Loss = 3.2696e-01, PNorm = 44.6990, GNorm = 3.8692, lr_0 = 2.9808e-04
Loss = 4.0274e-01, PNorm = 44.7089, GNorm = 5.3154, lr_0 = 2.9052e-04
Loss = 4.2605e-01, PNorm = 44.7182, GNorm = 4.0348, lr_0 = 2.8315e-04
Validation rmse = 0.642768
Epoch 17
Loss = 2.8355e-01, PNorm = 44.7308, GNorm = 3.9311, lr_0 = 2.7596e-04
Loss = 3.9232e-01, PNorm = 44.7421, GNorm = 2.7959, lr_0 = 2.6896e-04
Loss = 4.4353e-01, PNorm = 44.7504, GNorm = 8.7641, lr_0 = 2.6214e-04
Loss = 3.5911e-01, PNorm = 44.7590, GNorm = 3.8428, lr_0 = 2.5549e-04
Validation rmse = 0.647735
Epoch 18
Loss = 3.2277e-01, PNorm = 44.7718, GNorm = 9.5827, lr_0 = 2.4900e-04
Loss = 3.6511e-01, PNorm = 44.7773, GNorm = 5.5990, lr_0 = 2.4269e-04
Loss = 4.3012e-01, PNorm = 44.7833, GNorm = 3.3035, lr_0 = 2.3653e-04
Validation rmse = 0.706541
Epoch 19
Loss = 4.5064e-01, PNorm = 44.7924, GNorm = 10.5318, lr_0 = 2.3053e-04
Loss = 3.8672e-01, PNorm = 44.8012, GNorm = 4.2828, lr_0 = 2.2468e-04
Loss = 2.9514e-01, PNorm = 44.8128, GNorm = 5.9784, lr_0 = 2.1898e-04
Validation rmse = 0.626353
Epoch 20
Loss = 2.8276e-01, PNorm = 44.8221, GNorm = 12.3586, lr_0 = 2.1342e-04
Loss = 3.4153e-01, PNorm = 44.8292, GNorm = 6.3609, lr_0 = 2.0801e-04
Loss = 3.1138e-01, PNorm = 44.8360, GNorm = 7.6646, lr_0 = 2.0273e-04
Validation rmse = 0.661081
Epoch 21
Loss = 3.6566e-01, PNorm = 44.8423, GNorm = 4.3343, lr_0 = 1.9708e-04
Loss = 2.7362e-01, PNorm = 44.8523, GNorm = 3.3087, lr_0 = 1.9208e-04
Loss = 3.4966e-01, PNorm = 44.8608, GNorm = 7.2562, lr_0 = 1.8721e-04
Loss = 3.6088e-01, PNorm = 44.8633, GNorm = 12.2941, lr_0 = 1.8246e-04
Validation rmse = 0.620567
Epoch 22
Loss = 3.7406e-01, PNorm = 44.8687, GNorm = 8.1422, lr_0 = 1.7783e-04
Loss = 3.1799e-01, PNorm = 44.8754, GNorm = 7.4178, lr_0 = 1.7332e-04
Loss = 2.9726e-01, PNorm = 44.8824, GNorm = 3.7121, lr_0 = 1.6892e-04
Validation rmse = 0.614529
Epoch 23
Loss = 2.9782e-01, PNorm = 44.8896, GNorm = 9.6783, lr_0 = 1.6463e-04
Loss = 3.1267e-01, PNorm = 44.8953, GNorm = 3.0204, lr_0 = 1.6046e-04
Loss = 3.3934e-01, PNorm = 44.8989, GNorm = 6.1840, lr_0 = 1.5639e-04
Validation rmse = 0.611944
Epoch 24
Loss = 2.5063e-01, PNorm = 44.9069, GNorm = 14.0217, lr_0 = 1.5242e-04
Loss = 3.5032e-01, PNorm = 44.9140, GNorm = 7.2059, lr_0 = 1.4855e-04
Loss = 2.2117e-01, PNorm = 44.9190, GNorm = 3.8027, lr_0 = 1.4478e-04
Loss = 3.1281e-01, PNorm = 44.9221, GNorm = 6.7483, lr_0 = 1.4111e-04
Validation rmse = 0.626019
Epoch 25
Loss = 2.7779e-01, PNorm = 44.9277, GNorm = 5.3634, lr_0 = 1.3753e-04
Loss = 2.9006e-01, PNorm = 44.9343, GNorm = 4.3388, lr_0 = 1.3404e-04
Loss = 2.3232e-01, PNorm = 44.9379, GNorm = 7.3200, lr_0 = 1.3064e-04
Validation rmse = 0.636855
Epoch 26
Loss = 2.6429e-01, PNorm = 44.9443, GNorm = 6.3157, lr_0 = 1.2700e-04
Loss = 3.1806e-01, PNorm = 44.9495, GNorm = 6.4531, lr_0 = 1.2378e-04
Loss = 2.4057e-01, PNorm = 44.9534, GNorm = 11.6525, lr_0 = 1.2063e-04
Validation rmse = 0.612552
Epoch 27
Loss = 2.4862e-01, PNorm = 44.9579, GNorm = 3.6965, lr_0 = 1.1757e-04
Loss = 2.5055e-01, PNorm = 44.9639, GNorm = 8.5085, lr_0 = 1.1459e-04
Loss = 3.1384e-01, PNorm = 44.9671, GNorm = 6.3916, lr_0 = 1.1168e-04
Validation rmse = 0.619829
Epoch 28
Loss = 9.6741e-02, PNorm = 44.9691, GNorm = 6.1735, lr_0 = 1.0885e-04
Loss = 2.0991e-01, PNorm = 44.9739, GNorm = 5.1659, lr_0 = 1.0609e-04
Loss = 2.9130e-01, PNorm = 44.9779, GNorm = 8.0161, lr_0 = 1.0340e-04
Loss = 3.0440e-01, PNorm = 44.9814, GNorm = 5.8384, lr_0 = 1.0077e-04
Validation rmse = 0.633660
Epoch 29
Loss = 2.2769e-01, PNorm = 44.9843, GNorm = 4.2943, lr_0 = 1.0000e-04
Loss = 2.0950e-01, PNorm = 44.9873, GNorm = 9.7930, lr_0 = 1.0000e-04
Loss = 3.3038e-01, PNorm = 44.9911, GNorm = 4.4310, lr_0 = 1.0000e-04
Validation rmse = 0.617607
Model 0 best validation rmse = 0.611944 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.802415
Ensemble test rmse = 0.802415
1-fold cross validation
	Seed 0 ==> test rmse = 0.802415
Overall test rmse = 0.802415 +/- 0.000000
Elapsed time = 0:01:24
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-9125107f-aa91-4851-96da-58874f5b2420.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9872, lr_0 = 3.0475e-04
Loss = 1.4487e+00, PNorm = 34.0770, GNorm = 2.0191, lr_0 = 3.2725e-04
Loss = 1.1913e+00, PNorm = 34.0841, GNorm = 1.2119, lr_0 = 3.4975e-04
Loss = 1.4935e+00, PNorm = 34.0956, GNorm = 6.5507, lr_0 = 3.7225e-04
Loss = 1.3780e+00, PNorm = 34.1090, GNorm = 0.8872, lr_0 = 3.9475e-04
Loss = 1.2917e+00, PNorm = 34.1167, GNorm = 4.5210, lr_0 = 4.1725e-04
Loss = 1.2137e+00, PNorm = 34.1218, GNorm = 2.5117, lr_0 = 4.3975e-04
Loss = 1.4005e+00, PNorm = 34.1337, GNorm = 1.0219, lr_0 = 4.6225e-04
Loss = 1.4215e+00, PNorm = 34.1523, GNorm = 3.1036, lr_0 = 4.8475e-04
Loss = 1.2907e+00, PNorm = 34.1736, GNorm = 7.7724, lr_0 = 5.0725e-04
Loss = 1.3125e+00, PNorm = 34.1881, GNorm = 1.1320, lr_0 = 5.2975e-04
Loss = 1.0965e+00, PNorm = 34.2071, GNorm = 2.9247, lr_0 = 5.5225e-04
Loss = 7.1203e-01, PNorm = 34.2086, GNorm = 2.4040, lr_0 = 5.5450e-04
Validation rmse = 1.209434
Epoch 1
Loss = 1.1117e+00, PNorm = 34.2184, GNorm = 0.7801, lr_0 = 5.7700e-04
Loss = 1.3994e+00, PNorm = 34.2350, GNorm = 3.2568, lr_0 = 5.9950e-04
Loss = 1.1748e+00, PNorm = 34.2551, GNorm = 5.3760, lr_0 = 6.2200e-04
Loss = 1.1728e+00, PNorm = 34.2705, GNorm = 1.4029, lr_0 = 6.4450e-04
Loss = 1.2711e+00, PNorm = 34.2796, GNorm = 3.3512, lr_0 = 6.6700e-04
Loss = 1.2136e+00, PNorm = 34.2950, GNorm = 2.7076, lr_0 = 6.8950e-04
Loss = 1.1828e+00, PNorm = 34.3168, GNorm = 2.3498, lr_0 = 7.1200e-04
Loss = 1.2654e+00, PNorm = 34.3384, GNorm = 3.6762, lr_0 = 7.3450e-04
Loss = 1.1856e+00, PNorm = 34.3639, GNorm = 1.3647, lr_0 = 7.5700e-04
Loss = 1.2826e+00, PNorm = 34.4015, GNorm = 1.1586, lr_0 = 7.7950e-04
Loss = 1.1580e+00, PNorm = 34.4335, GNorm = 1.5224, lr_0 = 8.0200e-04
Loss = 1.2200e+00, PNorm = 34.4596, GNorm = 2.3144, lr_0 = 8.2450e-04
Loss = 1.3247e+00, PNorm = 34.5033, GNorm = 1.6859, lr_0 = 8.4700e-04
Loss = 1.4433e+00, PNorm = 34.5414, GNorm = 2.9983, lr_0 = 8.6950e-04
Loss = 1.2127e+00, PNorm = 34.5973, GNorm = 1.2213, lr_0 = 8.9200e-04
Loss = 1.2703e+00, PNorm = 34.6369, GNorm = 1.1361, lr_0 = 9.1450e-04
Loss = 1.2536e+00, PNorm = 34.6651, GNorm = 0.9653, lr_0 = 9.3700e-04
Loss = 1.1656e+00, PNorm = 34.6913, GNorm = 0.8989, lr_0 = 9.5950e-04
Loss = 1.1503e+00, PNorm = 34.7172, GNorm = 1.5909, lr_0 = 9.8200e-04
Loss = 1.2009e+00, PNorm = 34.7547, GNorm = 0.9700, lr_0 = 9.9918e-04
Loss = 4.2872e+00, PNorm = 34.7580, GNorm = 20.4139, lr_0 = 9.9877e-04
Validation rmse = 1.162579
Epoch 2
Loss = 1.4808e+00, PNorm = 34.8160, GNorm = 0.4341, lr_0 = 9.9467e-04
Loss = 1.2840e+00, PNorm = 34.8894, GNorm = 1.0099, lr_0 = 9.9059e-04
Loss = 1.1087e+00, PNorm = 34.9487, GNorm = 1.6417, lr_0 = 9.8652e-04
Loss = 1.3241e+00, PNorm = 34.9836, GNorm = 0.6012, lr_0 = 9.8247e-04
Loss = 1.2190e+00, PNorm = 35.0182, GNorm = 0.5220, lr_0 = 9.7844e-04
Loss = 1.1861e+00, PNorm = 35.0520, GNorm = 0.8792, lr_0 = 9.7443e-04
Loss = 1.0429e+00, PNorm = 35.0794, GNorm = 1.1117, lr_0 = 9.7043e-04
Loss = 1.3118e+00, PNorm = 35.0961, GNorm = 0.7277, lr_0 = 9.6645e-04
Loss = 1.1535e+00, PNorm = 35.1100, GNorm = 0.9130, lr_0 = 9.6248e-04
Loss = 1.1551e+00, PNorm = 35.1345, GNorm = 1.0251, lr_0 = 9.5853e-04
Loss = 1.2314e+00, PNorm = 35.1597, GNorm = 2.0375, lr_0 = 9.5460e-04
Loss = 1.1528e+00, PNorm = 35.1714, GNorm = 0.7116, lr_0 = 9.5068e-04
Loss = 1.2240e+00, PNorm = 35.1880, GNorm = 0.4897, lr_0 = 9.4678e-04
Loss = 1.1530e+00, PNorm = 35.2138, GNorm = 0.4412, lr_0 = 9.4290e-04
Loss = 1.1872e+00, PNorm = 35.2374, GNorm = 1.1181, lr_0 = 9.3903e-04
Loss = 1.3188e+00, PNorm = 35.2632, GNorm = 0.6857, lr_0 = 9.3517e-04
Loss = 1.0817e+00, PNorm = 35.2836, GNorm = 0.5594, lr_0 = 9.3134e-04
Loss = 1.2077e+00, PNorm = 35.3057, GNorm = 0.5831, lr_0 = 9.2752e-04
Loss = 1.0939e+00, PNorm = 35.3263, GNorm = 1.8879, lr_0 = 9.2371e-04
Loss = 1.1137e+00, PNorm = 35.3617, GNorm = 2.2495, lr_0 = 9.1992e-04
Loss = 6.0208e-01, PNorm = 35.3645, GNorm = 1.5083, lr_0 = 9.1954e-04
Validation rmse = 1.087523
Epoch 3
Loss = 1.1631e+00, PNorm = 35.3866, GNorm = 0.6308, lr_0 = 9.1577e-04
Loss = 1.1138e+00, PNorm = 35.4266, GNorm = 1.6757, lr_0 = 9.1201e-04
Loss = 1.2397e+00, PNorm = 35.4555, GNorm = 0.9308, lr_0 = 9.0827e-04
Loss = 1.0749e+00, PNorm = 35.4763, GNorm = 1.6905, lr_0 = 9.0454e-04
Loss = 1.0768e+00, PNorm = 35.4927, GNorm = 0.5324, lr_0 = 9.0083e-04
Loss = 1.0909e+00, PNorm = 35.5300, GNorm = 1.2492, lr_0 = 8.9713e-04
Loss = 1.1401e+00, PNorm = 35.5656, GNorm = 0.6611, lr_0 = 8.9345e-04
Loss = 1.1478e+00, PNorm = 35.6081, GNorm = 4.2570, lr_0 = 8.8979e-04
Loss = 1.2508e+00, PNorm = 35.6313, GNorm = 0.8159, lr_0 = 8.8614e-04
Loss = 1.0870e+00, PNorm = 35.6731, GNorm = 2.1411, lr_0 = 8.8250e-04
Loss = 1.1228e+00, PNorm = 35.7095, GNorm = 1.3838, lr_0 = 8.7888e-04
Loss = 1.1669e+00, PNorm = 35.7558, GNorm = 1.1087, lr_0 = 8.7527e-04
Loss = 1.2247e+00, PNorm = 35.7860, GNorm = 1.1249, lr_0 = 8.7168e-04
Loss = 1.1864e+00, PNorm = 35.8086, GNorm = 1.0116, lr_0 = 8.6810e-04
Loss = 1.2220e+00, PNorm = 35.8315, GNorm = 1.1691, lr_0 = 8.6454e-04
Loss = 1.2398e+00, PNorm = 35.8552, GNorm = 1.7001, lr_0 = 8.6099e-04
Loss = 1.0516e+00, PNorm = 35.8746, GNorm = 0.9922, lr_0 = 8.5746e-04
Loss = 9.2647e-01, PNorm = 35.9023, GNorm = 1.2269, lr_0 = 8.5394e-04
Loss = 1.0618e+00, PNorm = 35.9240, GNorm = 0.8621, lr_0 = 8.5044e-04
Loss = 1.0928e+00, PNorm = 35.9419, GNorm = 1.8806, lr_0 = 8.4695e-04
Loss = 5.7195e-01, PNorm = 35.9441, GNorm = 1.4559, lr_0 = 8.4660e-04
Validation rmse = 1.066597
Epoch 4
Loss = 9.9979e-01, PNorm = 35.9617, GNorm = 0.8173, lr_0 = 8.4313e-04
Loss = 1.1701e+00, PNorm = 35.9934, GNorm = 1.0171, lr_0 = 8.3967e-04
Loss = 1.1493e+00, PNorm = 36.0397, GNorm = 0.7189, lr_0 = 8.3622e-04
Loss = 1.1762e+00, PNorm = 36.0863, GNorm = 1.4201, lr_0 = 8.3279e-04
Loss = 1.1703e+00, PNorm = 36.1297, GNorm = 0.7587, lr_0 = 8.2937e-04
Loss = 1.0879e+00, PNorm = 36.1703, GNorm = 3.3094, lr_0 = 8.2597e-04
Loss = 1.0724e+00, PNorm = 36.2149, GNorm = 1.3661, lr_0 = 8.2258e-04
Loss = 1.0834e+00, PNorm = 36.2503, GNorm = 0.9561, lr_0 = 8.1921e-04
Loss = 1.0950e+00, PNorm = 36.3052, GNorm = 2.1036, lr_0 = 8.1584e-04
Loss = 1.0869e+00, PNorm = 36.3301, GNorm = 1.4850, lr_0 = 8.1250e-04
Loss = 1.0927e+00, PNorm = 36.3538, GNorm = 0.7707, lr_0 = 8.0916e-04
Loss = 1.0054e+00, PNorm = 36.3791, GNorm = 1.2253, lr_0 = 8.0584e-04
Loss = 1.3000e+00, PNorm = 36.4156, GNorm = 2.7271, lr_0 = 8.0254e-04
Loss = 1.0799e+00, PNorm = 36.4519, GNorm = 1.1843, lr_0 = 7.9924e-04
Loss = 9.9472e-01, PNorm = 36.5043, GNorm = 1.7342, lr_0 = 7.9596e-04
Loss = 1.1785e+00, PNorm = 36.5344, GNorm = 2.6840, lr_0 = 7.9270e-04
Loss = 1.0482e+00, PNorm = 36.5654, GNorm = 1.0283, lr_0 = 7.8944e-04
Loss = 1.0196e+00, PNorm = 36.5929, GNorm = 1.5270, lr_0 = 7.8620e-04
Loss = 1.0218e+00, PNorm = 36.6217, GNorm = 1.7880, lr_0 = 7.8298e-04
Loss = 1.0676e+00, PNorm = 36.6578, GNorm = 2.3154, lr_0 = 7.7977e-04
Loss = 5.7094e-01, PNorm = 36.6613, GNorm = 3.3144, lr_0 = 7.7945e-04
Validation rmse = 1.004652
Epoch 5
Loss = 1.0449e+00, PNorm = 36.7125, GNorm = 0.9136, lr_0 = 7.7625e-04
Loss = 9.9990e-01, PNorm = 36.7402, GNorm = 1.0164, lr_0 = 7.7306e-04
Loss = 1.0348e+00, PNorm = 36.7753, GNorm = 1.3441, lr_0 = 7.6989e-04
Loss = 1.0870e+00, PNorm = 36.8174, GNorm = 0.8164, lr_0 = 7.6673e-04
Loss = 1.0803e+00, PNorm = 36.8571, GNorm = 3.3342, lr_0 = 7.6358e-04
Loss = 9.8999e-01, PNorm = 36.8922, GNorm = 1.4848, lr_0 = 7.6045e-04
Loss = 1.1143e+00, PNorm = 36.9325, GNorm = 1.4498, lr_0 = 7.5733e-04
Loss = 1.0210e+00, PNorm = 36.9704, GNorm = 1.2986, lr_0 = 7.5422e-04
Loss = 1.0850e+00, PNorm = 37.0043, GNorm = 3.0765, lr_0 = 7.5113e-04
Loss = 9.2674e-01, PNorm = 37.0314, GNorm = 1.2360, lr_0 = 7.4805e-04
Loss = 1.2059e+00, PNorm = 37.0634, GNorm = 2.6852, lr_0 = 7.4498e-04
Loss = 9.6265e-01, PNorm = 37.0990, GNorm = 1.7017, lr_0 = 7.4192e-04
Loss = 1.0453e+00, PNorm = 37.1316, GNorm = 1.0789, lr_0 = 7.3888e-04
Loss = 1.1824e+00, PNorm = 37.1658, GNorm = 3.7815, lr_0 = 7.3584e-04
Loss = 1.0518e+00, PNorm = 37.2021, GNorm = 1.5210, lr_0 = 7.3282e-04
Loss = 1.0232e+00, PNorm = 37.2309, GNorm = 1.2770, lr_0 = 7.2982e-04
Loss = 9.6002e-01, PNorm = 37.2436, GNorm = 1.0109, lr_0 = 7.2682e-04
Loss = 1.0386e+00, PNorm = 37.2712, GNorm = 1.7225, lr_0 = 7.2384e-04
Loss = 9.8706e-01, PNorm = 37.3120, GNorm = 2.9350, lr_0 = 7.2087e-04
Loss = 1.1700e+00, PNorm = 37.3579, GNorm = 0.7385, lr_0 = 7.1791e-04
Loss = 9.0437e-01, PNorm = 37.3616, GNorm = 5.9055, lr_0 = 7.1762e-04
Validation rmse = 0.999880
Epoch 6
Loss = 1.0080e+00, PNorm = 37.3917, GNorm = 1.7822, lr_0 = 7.1467e-04
Loss = 1.0634e+00, PNorm = 37.4015, GNorm = 1.9925, lr_0 = 7.1174e-04
Loss = 1.0170e+00, PNorm = 37.4295, GNorm = 1.2032, lr_0 = 7.0882e-04
Loss = 1.1029e+00, PNorm = 37.4693, GNorm = 1.6491, lr_0 = 7.0591e-04
Loss = 1.0313e+00, PNorm = 37.5052, GNorm = 2.9702, lr_0 = 7.0301e-04
Loss = 1.0164e+00, PNorm = 37.5486, GNorm = 0.9421, lr_0 = 7.0013e-04
Loss = 9.6213e-01, PNorm = 37.5784, GNorm = 1.2292, lr_0 = 6.9726e-04
Loss = 1.0228e+00, PNorm = 37.6133, GNorm = 2.1660, lr_0 = 6.9440e-04
Loss = 9.5887e-01, PNorm = 37.6466, GNorm = 2.5682, lr_0 = 6.9155e-04
Loss = 9.8359e-01, PNorm = 37.6706, GNorm = 1.0118, lr_0 = 6.8871e-04
Loss = 9.9044e-01, PNorm = 37.6943, GNorm = 3.0762, lr_0 = 6.8588e-04
Loss = 1.0509e+00, PNorm = 37.7256, GNorm = 2.0179, lr_0 = 6.8307e-04
Loss = 1.0326e+00, PNorm = 37.7634, GNorm = 1.4357, lr_0 = 6.8027e-04
Loss = 9.9413e-01, PNorm = 37.8012, GNorm = 1.3138, lr_0 = 6.7747e-04
Loss = 9.2520e-01, PNorm = 37.8383, GNorm = 1.9332, lr_0 = 6.7469e-04
Loss = 8.9473e-01, PNorm = 37.8768, GNorm = 1.7203, lr_0 = 6.7193e-04
Loss = 1.1092e+00, PNorm = 37.8996, GNorm = 3.5351, lr_0 = 6.6917e-04
Loss = 1.0838e+00, PNorm = 37.9184, GNorm = 0.8951, lr_0 = 6.6642e-04
Loss = 8.9400e-01, PNorm = 37.9614, GNorm = 1.6044, lr_0 = 6.6369e-04
Loss = 1.0139e+00, PNorm = 37.9891, GNorm = 1.3707, lr_0 = 6.6097e-04
Loss = 5.3633e-01, PNorm = 37.9913, GNorm = 1.4708, lr_0 = 6.6069e-04
Validation rmse = 0.940829
Epoch 7
Loss = 1.0352e+00, PNorm = 38.0253, GNorm = 1.8070, lr_0 = 6.5798e-04
Loss = 1.0340e+00, PNorm = 38.0619, GNorm = 1.2152, lr_0 = 6.5528e-04
Loss = 8.8851e-01, PNorm = 38.1002, GNorm = 1.8637, lr_0 = 6.5259e-04
Loss = 1.0692e+00, PNorm = 38.1327, GNorm = 4.1411, lr_0 = 6.4992e-04
Loss = 1.0092e+00, PNorm = 38.1590, GNorm = 1.8655, lr_0 = 6.4725e-04
Loss = 9.7496e-01, PNorm = 38.1773, GNorm = 1.9227, lr_0 = 6.4459e-04
Loss = 9.7588e-01, PNorm = 38.2300, GNorm = 5.7910, lr_0 = 6.4195e-04
Loss = 9.4777e-01, PNorm = 38.2819, GNorm = 2.9510, lr_0 = 6.3931e-04
Loss = 8.8816e-01, PNorm = 38.3276, GNorm = 2.7987, lr_0 = 6.3669e-04
Loss = 9.0209e-01, PNorm = 38.3593, GNorm = 1.2520, lr_0 = 6.3408e-04
Loss = 8.8146e-01, PNorm = 38.3993, GNorm = 3.2130, lr_0 = 6.3148e-04
Loss = 9.5554e-01, PNorm = 38.4316, GNorm = 2.4212, lr_0 = 6.2889e-04
Loss = 1.0094e+00, PNorm = 38.4648, GNorm = 2.6987, lr_0 = 6.2630e-04
Loss = 1.0172e+00, PNorm = 38.4985, GNorm = 1.5263, lr_0 = 6.2373e-04
Loss = 9.6193e-01, PNorm = 38.5283, GNorm = 2.9840, lr_0 = 6.2118e-04
Loss = 9.6728e-01, PNorm = 38.5589, GNorm = 1.2643, lr_0 = 6.1863e-04
Loss = 9.5041e-01, PNorm = 38.5772, GNorm = 3.0746, lr_0 = 6.1609e-04
Loss = 9.1160e-01, PNorm = 38.6008, GNorm = 2.4180, lr_0 = 6.1356e-04
Loss = 1.0670e+00, PNorm = 38.6368, GNorm = 1.7838, lr_0 = 6.1104e-04
Loss = 9.5251e-01, PNorm = 38.6668, GNorm = 1.6030, lr_0 = 6.0854e-04
Loss = 1.0743e+00, PNorm = 38.6692, GNorm = 6.3172, lr_0 = 6.0829e-04
Validation rmse = 0.901072
Epoch 8
Loss = 1.0274e+00, PNorm = 38.6993, GNorm = 1.9930, lr_0 = 6.0579e-04
Loss = 9.7325e-01, PNorm = 38.7345, GNorm = 3.5615, lr_0 = 6.0330e-04
Loss = 9.7812e-01, PNorm = 38.7657, GNorm = 2.6934, lr_0 = 6.0083e-04
Loss = 8.7389e-01, PNorm = 38.8017, GNorm = 1.3799, lr_0 = 5.9836e-04
Loss = 8.8459e-01, PNorm = 38.8292, GNorm = 2.0403, lr_0 = 5.9591e-04
Loss = 9.5955e-01, PNorm = 38.8475, GNorm = 4.5411, lr_0 = 5.9346e-04
Loss = 6.7023e-01, PNorm = 38.8694, GNorm = 2.1687, lr_0 = 5.9103e-04
Loss = 9.6878e-01, PNorm = 38.9232, GNorm = 6.6817, lr_0 = 5.8860e-04
Loss = 1.1073e+00, PNorm = 38.9608, GNorm = 1.3277, lr_0 = 5.8619e-04
Loss = 9.1408e-01, PNorm = 38.9960, GNorm = 1.4071, lr_0 = 5.8378e-04
Loss = 1.0869e+00, PNorm = 39.0239, GNorm = 2.1586, lr_0 = 5.8139e-04
Loss = 9.6783e-01, PNorm = 39.0452, GNorm = 1.5083, lr_0 = 5.7900e-04
Loss = 9.8169e-01, PNorm = 39.0731, GNorm = 1.1246, lr_0 = 5.7662e-04
Loss = 9.8760e-01, PNorm = 39.1039, GNorm = 2.2153, lr_0 = 5.7426e-04
Loss = 8.7926e-01, PNorm = 39.1226, GNorm = 3.1422, lr_0 = 5.7190e-04
Loss = 9.0810e-01, PNorm = 39.1457, GNorm = 4.0208, lr_0 = 5.6956e-04
Loss = 7.7988e-01, PNorm = 39.1750, GNorm = 1.8988, lr_0 = 5.6722e-04
Loss = 7.9455e-01, PNorm = 39.2050, GNorm = 3.7183, lr_0 = 5.6489e-04
Loss = 9.5438e-01, PNorm = 39.2350, GNorm = 2.6675, lr_0 = 5.6257e-04
Loss = 9.8449e-01, PNorm = 39.2562, GNorm = 2.8198, lr_0 = 5.6026e-04
Loss = 2.1208e+00, PNorm = 39.2593, GNorm = 3.6602, lr_0 = 5.6003e-04
Validation rmse = 0.864172
Epoch 9
Loss = 8.8125e-01, PNorm = 39.2897, GNorm = 2.6953, lr_0 = 5.5774e-04
Loss = 8.1909e-01, PNorm = 39.3156, GNorm = 2.1877, lr_0 = 5.5545e-04
Loss = 9.5231e-01, PNorm = 39.3315, GNorm = 5.8780, lr_0 = 5.5317e-04
Loss = 8.0207e-01, PNorm = 39.3442, GNorm = 2.6952, lr_0 = 5.5090e-04
Loss = 9.9360e-01, PNorm = 39.3716, GNorm = 2.2107, lr_0 = 5.4864e-04
Loss = 8.7472e-01, PNorm = 39.3955, GNorm = 1.8443, lr_0 = 5.4639e-04
Loss = 8.4573e-01, PNorm = 39.4249, GNorm = 1.3413, lr_0 = 5.4414e-04
Loss = 8.3484e-01, PNorm = 39.4533, GNorm = 6.1217, lr_0 = 5.4191e-04
Loss = 9.6595e-01, PNorm = 39.4727, GNorm = 3.0509, lr_0 = 5.3969e-04
Loss = 8.2499e-01, PNorm = 39.4977, GNorm = 1.9123, lr_0 = 5.3747e-04
Loss = 8.7223e-01, PNorm = 39.5281, GNorm = 1.9978, lr_0 = 5.3527e-04
Loss = 8.4942e-01, PNorm = 39.5561, GNorm = 3.4156, lr_0 = 5.3307e-04
Loss = 8.0590e-01, PNorm = 39.5934, GNorm = 1.7959, lr_0 = 5.3088e-04
Loss = 9.3741e-01, PNorm = 39.6083, GNorm = 2.3499, lr_0 = 5.2871e-04
Loss = 8.8942e-01, PNorm = 39.6346, GNorm = 1.2972, lr_0 = 5.2654e-04
Loss = 1.0203e+00, PNorm = 39.6649, GNorm = 2.9255, lr_0 = 5.2438e-04
Loss = 1.0611e+00, PNorm = 39.6891, GNorm = 2.1018, lr_0 = 5.2222e-04
Loss = 8.5643e-01, PNorm = 39.7115, GNorm = 2.7332, lr_0 = 5.2008e-04
Loss = 7.8589e-01, PNorm = 39.7247, GNorm = 1.1395, lr_0 = 5.1795e-04
Loss = 9.2631e-01, PNorm = 39.7466, GNorm = 3.8514, lr_0 = 5.1582e-04
Validation rmse = 0.882609
Epoch 10
Loss = 8.2333e-01, PNorm = 39.7807, GNorm = 3.0006, lr_0 = 5.1371e-04
Loss = 8.6328e-01, PNorm = 39.8162, GNorm = 4.5245, lr_0 = 5.1160e-04
Loss = 8.9093e-01, PNorm = 39.8436, GNorm = 1.6291, lr_0 = 5.0950e-04
Loss = 8.4373e-01, PNorm = 39.8678, GNorm = 1.8407, lr_0 = 5.0741e-04
Loss = 8.4277e-01, PNorm = 39.8862, GNorm = 2.4015, lr_0 = 5.0533e-04
Loss = 8.3724e-01, PNorm = 39.9038, GNorm = 1.9867, lr_0 = 5.0325e-04
Loss = 1.0180e+00, PNorm = 39.9269, GNorm = 3.9555, lr_0 = 5.0119e-04
Loss = 8.0460e-01, PNorm = 39.9491, GNorm = 2.4900, lr_0 = 4.9913e-04
Loss = 1.0243e+00, PNorm = 39.9769, GNorm = 1.5935, lr_0 = 4.9708e-04
Loss = 8.2828e-01, PNorm = 40.0013, GNorm = 2.4981, lr_0 = 4.9504e-04
Loss = 8.4759e-01, PNorm = 40.0143, GNorm = 1.5852, lr_0 = 4.9301e-04
Loss = 8.4695e-01, PNorm = 40.0379, GNorm = 2.2084, lr_0 = 4.9099e-04
Loss = 7.8307e-01, PNorm = 40.0558, GNorm = 3.2699, lr_0 = 4.8897e-04
Loss = 8.9149e-01, PNorm = 40.0777, GNorm = 6.2954, lr_0 = 4.8697e-04
Loss = 8.2316e-01, PNorm = 40.0970, GNorm = 1.0783, lr_0 = 4.8497e-04
Loss = 8.8353e-01, PNorm = 40.1172, GNorm = 1.7176, lr_0 = 4.8298e-04
Loss = 9.1088e-01, PNorm = 40.1337, GNorm = 1.2519, lr_0 = 4.8100e-04
Loss = 7.7057e-01, PNorm = 40.1493, GNorm = 2.5815, lr_0 = 4.7902e-04
Loss = 8.5124e-01, PNorm = 40.1692, GNorm = 2.6975, lr_0 = 4.7706e-04
Loss = 7.5987e-01, PNorm = 40.1856, GNorm = 3.1092, lr_0 = 4.7510e-04
Validation rmse = 0.806183
Epoch 11
Loss = 7.3002e-01, PNorm = 40.2032, GNorm = 5.1092, lr_0 = 4.7296e-04
Loss = 9.1577e-01, PNorm = 40.2265, GNorm = 4.2827, lr_0 = 4.7102e-04
Loss = 7.4919e-01, PNorm = 40.2661, GNorm = 1.6158, lr_0 = 4.6908e-04
Loss = 7.2660e-01, PNorm = 40.2948, GNorm = 5.5812, lr_0 = 4.6716e-04
Loss = 8.2004e-01, PNorm = 40.3165, GNorm = 2.5686, lr_0 = 4.6524e-04
Loss = 9.5688e-01, PNorm = 40.3371, GNorm = 2.7242, lr_0 = 4.6333e-04
Loss = 6.9137e-01, PNorm = 40.3589, GNorm = 1.6509, lr_0 = 4.6143e-04
Loss = 8.4944e-01, PNorm = 40.3825, GNorm = 1.6636, lr_0 = 4.5954e-04
Loss = 6.9522e-01, PNorm = 40.4048, GNorm = 3.0238, lr_0 = 4.5765e-04
Loss = 7.0239e-01, PNorm = 40.4263, GNorm = 2.6138, lr_0 = 4.5577e-04
Loss = 6.8955e-01, PNorm = 40.4480, GNorm = 2.8349, lr_0 = 4.5390e-04
Loss = 7.9199e-01, PNorm = 40.4721, GNorm = 5.0912, lr_0 = 4.5204e-04
Loss = 8.2683e-01, PNorm = 40.4937, GNorm = 2.5348, lr_0 = 4.5019e-04
Loss = 9.2121e-01, PNorm = 40.5166, GNorm = 1.8122, lr_0 = 4.4834e-04
Loss = 8.2311e-01, PNorm = 40.5348, GNorm = 2.1253, lr_0 = 4.4650e-04
Loss = 8.5733e-01, PNorm = 40.5525, GNorm = 3.0432, lr_0 = 4.4467e-04
Loss = 7.3341e-01, PNorm = 40.5682, GNorm = 5.4559, lr_0 = 4.4284e-04
Loss = 9.6643e-01, PNorm = 40.5953, GNorm = 1.9674, lr_0 = 4.4103e-04
Loss = 7.8796e-01, PNorm = 40.6171, GNorm = 2.6507, lr_0 = 4.3922e-04
Loss = 8.6192e-01, PNorm = 40.6339, GNorm = 2.3289, lr_0 = 4.3741e-04
Validation rmse = 0.773688
Epoch 12
Loss = 7.2495e-01, PNorm = 40.6578, GNorm = 4.6336, lr_0 = 4.3544e-04
Loss = 6.3508e-01, PNorm = 40.6804, GNorm = 2.0036, lr_0 = 4.3365e-04
Loss = 7.9850e-01, PNorm = 40.6955, GNorm = 14.9885, lr_0 = 4.3187e-04
Loss = 8.9882e-01, PNorm = 40.7085, GNorm = 2.6397, lr_0 = 4.3010e-04
Loss = 8.5560e-01, PNorm = 40.7259, GNorm = 2.1677, lr_0 = 4.2834e-04
Loss = 7.4063e-01, PNorm = 40.7420, GNorm = 4.4495, lr_0 = 4.2658e-04
Loss = 8.2712e-01, PNorm = 40.7628, GNorm = 2.6563, lr_0 = 4.2483e-04
Loss = 7.8968e-01, PNorm = 40.7845, GNorm = 4.2475, lr_0 = 4.2309e-04
Loss = 8.6514e-01, PNorm = 40.8052, GNorm = 4.3542, lr_0 = 4.2135e-04
Loss = 6.8160e-01, PNorm = 40.8254, GNorm = 2.0779, lr_0 = 4.1962e-04
Loss = 5.6900e-01, PNorm = 40.8395, GNorm = 2.2110, lr_0 = 4.1790e-04
Loss = 7.5824e-01, PNorm = 40.8647, GNorm = 2.7136, lr_0 = 4.1618e-04
Loss = 6.6660e-01, PNorm = 40.8752, GNorm = 2.8259, lr_0 = 4.1448e-04
Loss = 8.0092e-01, PNorm = 40.8848, GNorm = 1.9561, lr_0 = 4.1278e-04
Loss = 7.0010e-01, PNorm = 40.9079, GNorm = 2.5668, lr_0 = 4.1108e-04
Loss = 7.5316e-01, PNorm = 40.9239, GNorm = 3.1708, lr_0 = 4.0940e-04
Loss = 7.0835e-01, PNorm = 40.9392, GNorm = 2.0452, lr_0 = 4.0772e-04
Loss = 7.8963e-01, PNorm = 40.9615, GNorm = 2.7975, lr_0 = 4.0604e-04
Loss = 7.4754e-01, PNorm = 40.9765, GNorm = 3.1295, lr_0 = 4.0438e-04
Loss = 8.3230e-01, PNorm = 40.9877, GNorm = 5.3703, lr_0 = 4.0272e-04
Validation rmse = 0.799819
Epoch 13
Loss = 7.1026e-01, PNorm = 41.0178, GNorm = 3.8639, lr_0 = 4.0090e-04
Loss = 8.3069e-01, PNorm = 41.0393, GNorm = 1.6714, lr_0 = 3.9925e-04
Loss = 8.8915e-01, PNorm = 41.0572, GNorm = 1.7332, lr_0 = 3.9762e-04
Loss = 8.9281e-01, PNorm = 41.0746, GNorm = 3.6540, lr_0 = 3.9598e-04
Loss = 6.3427e-01, PNorm = 41.0863, GNorm = 4.4167, lr_0 = 3.9436e-04
Loss = 7.4162e-01, PNorm = 41.1040, GNorm = 4.9781, lr_0 = 3.9274e-04
Loss = 7.1152e-01, PNorm = 41.1253, GNorm = 3.7296, lr_0 = 3.9113e-04
Loss = 7.1497e-01, PNorm = 41.1412, GNorm = 3.4223, lr_0 = 3.8953e-04
Loss = 6.3550e-01, PNorm = 41.1555, GNorm = 3.7261, lr_0 = 3.8793e-04
Loss = 7.1667e-01, PNorm = 41.1723, GNorm = 5.5530, lr_0 = 3.8634e-04
Loss = 6.9646e-01, PNorm = 41.1951, GNorm = 3.5204, lr_0 = 3.8475e-04
Loss = 7.2592e-01, PNorm = 41.2128, GNorm = 2.3209, lr_0 = 3.8317e-04
Loss = 8.1965e-01, PNorm = 41.2244, GNorm = 3.8668, lr_0 = 3.8160e-04
Loss = 7.1435e-01, PNorm = 41.2393, GNorm = 2.2103, lr_0 = 3.8003e-04
Loss = 7.1929e-01, PNorm = 41.2457, GNorm = 2.0258, lr_0 = 3.7847e-04
Loss = 7.2661e-01, PNorm = 41.2565, GNorm = 5.3332, lr_0 = 3.7692e-04
Loss = 7.4663e-01, PNorm = 41.2697, GNorm = 4.6385, lr_0 = 3.7537e-04
Loss = 7.1602e-01, PNorm = 41.2866, GNorm = 5.5146, lr_0 = 3.7383e-04
Loss = 7.5854e-01, PNorm = 41.3034, GNorm = 2.1596, lr_0 = 3.7230e-04
Loss = 7.8679e-01, PNorm = 41.3184, GNorm = 2.3145, lr_0 = 3.7077e-04
Validation rmse = 0.743175
Epoch 14
Loss = 7.5965e-01, PNorm = 41.3289, GNorm = 3.2284, lr_0 = 3.6910e-04
Loss = 6.8266e-01, PNorm = 41.3468, GNorm = 3.0150, lr_0 = 3.6758e-04
Loss = 6.5897e-01, PNorm = 41.3642, GNorm = 4.1999, lr_0 = 3.6608e-04
Loss = 7.2857e-01, PNorm = 41.3795, GNorm = 2.7238, lr_0 = 3.6457e-04
Loss = 7.0416e-01, PNorm = 41.3943, GNorm = 2.8696, lr_0 = 3.6308e-04
Loss = 7.1628e-01, PNorm = 41.4139, GNorm = 2.4106, lr_0 = 3.6159e-04
Loss = 6.0211e-01, PNorm = 41.4341, GNorm = 5.6837, lr_0 = 3.6010e-04
Loss = 6.6295e-01, PNorm = 41.4480, GNorm = 3.4979, lr_0 = 3.5863e-04
Loss = 5.9463e-01, PNorm = 41.4573, GNorm = 5.0974, lr_0 = 3.5716e-04
Loss = 6.6152e-01, PNorm = 41.4684, GNorm = 2.0942, lr_0 = 3.5569e-04
Loss = 7.3887e-01, PNorm = 41.4761, GNorm = 3.6271, lr_0 = 3.5423e-04
Loss = 6.8146e-01, PNorm = 41.4845, GNorm = 3.5997, lr_0 = 3.5278e-04
Loss = 6.4548e-01, PNorm = 41.5014, GNorm = 4.6655, lr_0 = 3.5133e-04
Loss = 6.9954e-01, PNorm = 41.5163, GNorm = 3.7143, lr_0 = 3.4989e-04
Loss = 7.5988e-01, PNorm = 41.5295, GNorm = 2.2377, lr_0 = 3.4845e-04
Loss = 6.9204e-01, PNorm = 41.5433, GNorm = 2.3289, lr_0 = 3.4702e-04
Loss = 6.4400e-01, PNorm = 41.5588, GNorm = 6.6913, lr_0 = 3.4560e-04
Loss = 7.6326e-01, PNorm = 41.5713, GNorm = 12.9185, lr_0 = 3.4418e-04
Loss = 6.7879e-01, PNorm = 41.5840, GNorm = 2.2115, lr_0 = 3.4277e-04
Loss = 6.8868e-01, PNorm = 41.5976, GNorm = 2.4312, lr_0 = 3.4136e-04
Validation rmse = 0.831717
Epoch 15
Loss = 7.4641e-01, PNorm = 41.6184, GNorm = 3.5895, lr_0 = 3.3982e-04
Loss = 7.9234e-01, PNorm = 41.6361, GNorm = 2.0153, lr_0 = 3.3843e-04
Loss = 7.1259e-01, PNorm = 41.6523, GNorm = 2.9084, lr_0 = 3.3704e-04
Loss = 5.2411e-01, PNorm = 41.6683, GNorm = 2.6349, lr_0 = 3.3565e-04
Loss = 6.4618e-01, PNorm = 41.6854, GNorm = 4.0155, lr_0 = 3.3428e-04
Loss = 7.9888e-01, PNorm = 41.6998, GNorm = 3.2208, lr_0 = 3.3291e-04
Loss = 6.6135e-01, PNorm = 41.7089, GNorm = 3.7457, lr_0 = 3.3154e-04
Loss = 6.0423e-01, PNorm = 41.7151, GNorm = 2.4948, lr_0 = 3.3018e-04
Loss = 6.4817e-01, PNorm = 41.7293, GNorm = 3.4317, lr_0 = 3.2882e-04
Loss = 6.7290e-01, PNorm = 41.7379, GNorm = 2.8553, lr_0 = 3.2748e-04
Loss = 5.4452e-01, PNorm = 41.7509, GNorm = 3.2165, lr_0 = 3.2613e-04
Loss = 6.9295e-01, PNorm = 41.7596, GNorm = 2.1228, lr_0 = 3.2479e-04
Loss = 7.5919e-01, PNorm = 41.7666, GNorm = 1.9973, lr_0 = 3.2346e-04
Loss = 5.8158e-01, PNorm = 41.7797, GNorm = 2.9109, lr_0 = 3.2213e-04
Loss = 5.6510e-01, PNorm = 41.7895, GNorm = 5.1231, lr_0 = 3.2081e-04
Loss = 7.1654e-01, PNorm = 41.8019, GNorm = 4.2247, lr_0 = 3.1950e-04
Loss = 7.7572e-01, PNorm = 41.8152, GNorm = 2.4879, lr_0 = 3.1818e-04
Loss = 6.4058e-01, PNorm = 41.8265, GNorm = 2.6592, lr_0 = 3.1688e-04
Loss = 6.5924e-01, PNorm = 41.8401, GNorm = 5.2130, lr_0 = 3.1558e-04
Loss = 6.2597e-01, PNorm = 41.8521, GNorm = 3.4302, lr_0 = 3.1428e-04
Validation rmse = 0.724800
Epoch 16
Loss = 6.6540e-01, PNorm = 41.8716, GNorm = 3.8442, lr_0 = 3.1287e-04
Loss = 6.7511e-01, PNorm = 41.8885, GNorm = 3.4719, lr_0 = 3.1158e-04
Loss = 7.0162e-01, PNorm = 41.8982, GNorm = 3.0552, lr_0 = 3.1030e-04
Loss = 6.1957e-01, PNorm = 41.9121, GNorm = 2.6277, lr_0 = 3.0903e-04
Loss = 5.4794e-01, PNorm = 41.9283, GNorm = 4.4655, lr_0 = 3.0776e-04
Loss = 6.8146e-01, PNorm = 41.9439, GNorm = 3.1900, lr_0 = 3.0650e-04
Loss = 6.3652e-01, PNorm = 41.9559, GNorm = 2.2878, lr_0 = 3.0524e-04
Loss = 5.0885e-01, PNorm = 41.9679, GNorm = 3.8191, lr_0 = 3.0399e-04
Loss = 4.7742e-01, PNorm = 41.9779, GNorm = 7.9855, lr_0 = 3.0274e-04
Loss = 5.6073e-01, PNorm = 41.9850, GNorm = 7.0057, lr_0 = 3.0150e-04
Loss = 6.7452e-01, PNorm = 41.9949, GNorm = 3.3127, lr_0 = 3.0026e-04
Loss = 6.9831e-01, PNorm = 42.0010, GNorm = 2.7988, lr_0 = 2.9903e-04
Loss = 6.2140e-01, PNorm = 42.0076, GNorm = 2.8722, lr_0 = 2.9780e-04
Loss = 6.3863e-01, PNorm = 42.0158, GNorm = 4.9990, lr_0 = 2.9658e-04
Loss = 6.0053e-01, PNorm = 42.0259, GNorm = 3.2410, lr_0 = 2.9536e-04
Loss = 7.5495e-01, PNorm = 42.0317, GNorm = 3.5656, lr_0 = 2.9415e-04
Loss = 5.5805e-01, PNorm = 42.0419, GNorm = 4.0942, lr_0 = 2.9294e-04
Loss = 6.8002e-01, PNorm = 42.0579, GNorm = 2.5059, lr_0 = 2.9174e-04
Loss = 5.5636e-01, PNorm = 42.0695, GNorm = 3.5591, lr_0 = 2.9055e-04
Loss = 6.7863e-01, PNorm = 42.0833, GNorm = 3.6495, lr_0 = 2.8935e-04
Validation rmse = 0.771862
Epoch 17
Loss = 5.9771e-01, PNorm = 42.0961, GNorm = 5.2746, lr_0 = 2.8805e-04
Loss = 5.6676e-01, PNorm = 42.1000, GNorm = 3.8893, lr_0 = 2.8687e-04
Loss = 5.7404e-01, PNorm = 42.1137, GNorm = 2.8591, lr_0 = 2.8569e-04
Loss = 6.4325e-01, PNorm = 42.1275, GNorm = 4.6101, lr_0 = 2.8452e-04
Loss = 5.6098e-01, PNorm = 42.1370, GNorm = 2.8550, lr_0 = 2.8335e-04
Loss = 5.1719e-01, PNorm = 42.1449, GNorm = 7.9985, lr_0 = 2.8219e-04
Loss = 6.9931e-01, PNorm = 42.1522, GNorm = 7.3693, lr_0 = 2.8103e-04
Loss = 6.4938e-01, PNorm = 42.1604, GNorm = 5.0235, lr_0 = 2.7988e-04
Loss = 6.0569e-01, PNorm = 42.1673, GNorm = 3.6311, lr_0 = 2.7873e-04
Loss = 5.3798e-01, PNorm = 42.1755, GNorm = 2.5904, lr_0 = 2.7758e-04
Loss = 5.7543e-01, PNorm = 42.1893, GNorm = 4.7206, lr_0 = 2.7644e-04
Loss = 5.5580e-01, PNorm = 42.1970, GNorm = 3.7237, lr_0 = 2.7531e-04
Loss = 7.2816e-01, PNorm = 42.2082, GNorm = 4.7437, lr_0 = 2.7418e-04
Loss = 5.2912e-01, PNorm = 42.2173, GNorm = 3.7208, lr_0 = 2.7305e-04
Loss = 5.3595e-01, PNorm = 42.2272, GNorm = 6.3706, lr_0 = 2.7193e-04
Loss = 5.9061e-01, PNorm = 42.2370, GNorm = 4.5450, lr_0 = 2.7082e-04
Loss = 4.9453e-01, PNorm = 42.2426, GNorm = 6.3270, lr_0 = 2.6971e-04
Loss = 5.8765e-01, PNorm = 42.2525, GNorm = 2.7092, lr_0 = 2.6860e-04
Loss = 6.6503e-01, PNorm = 42.2678, GNorm = 5.2431, lr_0 = 2.6750e-04
Loss = 4.9841e-01, PNorm = 42.2822, GNorm = 6.2397, lr_0 = 2.6640e-04
Validation rmse = 0.737211
Epoch 18
Loss = 5.4939e-01, PNorm = 42.2958, GNorm = 3.9455, lr_0 = 2.6520e-04
Loss = 6.0087e-01, PNorm = 42.3017, GNorm = 3.9205, lr_0 = 2.6411e-04
Loss = 5.4491e-01, PNorm = 42.3080, GNorm = 5.5461, lr_0 = 2.6303e-04
Loss = 5.3392e-01, PNorm = 42.3211, GNorm = 5.1892, lr_0 = 2.6195e-04
Loss = 4.0391e-01, PNorm = 42.3315, GNorm = 4.1585, lr_0 = 2.6087e-04
Loss = 4.7097e-01, PNorm = 42.3435, GNorm = 14.7956, lr_0 = 2.5980e-04
Loss = 5.2656e-01, PNorm = 42.3537, GNorm = 8.2305, lr_0 = 2.5874e-04
Loss = 6.7227e-01, PNorm = 42.3661, GNorm = 2.8350, lr_0 = 2.5767e-04
Loss = 5.5666e-01, PNorm = 42.3772, GNorm = 6.5649, lr_0 = 2.5662e-04
Loss = 5.5945e-01, PNorm = 42.3826, GNorm = 2.8267, lr_0 = 2.5556e-04
Loss = 5.8815e-01, PNorm = 42.3893, GNorm = 2.7089, lr_0 = 2.5452e-04
Loss = 5.7233e-01, PNorm = 42.3986, GNorm = 2.7411, lr_0 = 2.5347e-04
Loss = 6.5343e-01, PNorm = 42.4065, GNorm = 4.5289, lr_0 = 2.5243e-04
Loss = 5.2984e-01, PNorm = 42.4165, GNorm = 4.9198, lr_0 = 2.5140e-04
Loss = 3.5087e-01, PNorm = 42.4282, GNorm = 3.4910, lr_0 = 2.5036e-04
Loss = 4.9159e-01, PNorm = 42.4354, GNorm = 6.5274, lr_0 = 2.4934e-04
Loss = 5.5500e-01, PNorm = 42.4486, GNorm = 4.7539, lr_0 = 2.4831e-04
Loss = 6.1695e-01, PNorm = 42.4573, GNorm = 5.9892, lr_0 = 2.4729e-04
Loss = 6.2678e-01, PNorm = 42.4654, GNorm = 3.4977, lr_0 = 2.4628e-04
Loss = 6.9291e-01, PNorm = 42.4738, GNorm = 2.8977, lr_0 = 2.4527e-04
Validation rmse = 0.720736
Epoch 19
Loss = 4.3572e-01, PNorm = 42.4852, GNorm = 12.5163, lr_0 = 2.4416e-04
Loss = 5.8163e-01, PNorm = 42.4902, GNorm = 4.1694, lr_0 = 2.4316e-04
Loss = 5.8333e-01, PNorm = 42.4982, GNorm = 5.9710, lr_0 = 2.4216e-04
Loss = 5.9141e-01, PNorm = 42.5078, GNorm = 3.6925, lr_0 = 2.4117e-04
Loss = 5.3370e-01, PNorm = 42.5174, GNorm = 6.6875, lr_0 = 2.4018e-04
Loss = 4.6910e-01, PNorm = 42.5232, GNorm = 6.8998, lr_0 = 2.3919e-04
Loss = 5.2186e-01, PNorm = 42.5324, GNorm = 7.0986, lr_0 = 2.3821e-04
Loss = 5.0154e-01, PNorm = 42.5390, GNorm = 5.8341, lr_0 = 2.3723e-04
Loss = 6.1914e-01, PNorm = 42.5466, GNorm = 10.6610, lr_0 = 2.3626e-04
Loss = 5.4127e-01, PNorm = 42.5558, GNorm = 3.5198, lr_0 = 2.3529e-04
Loss = 4.9150e-01, PNorm = 42.5621, GNorm = 2.9057, lr_0 = 2.3433e-04
Loss = 5.1808e-01, PNorm = 42.5694, GNorm = 3.8975, lr_0 = 2.3336e-04
Loss = 6.0908e-01, PNorm = 42.5794, GNorm = 3.6692, lr_0 = 2.3241e-04
Loss = 5.9695e-01, PNorm = 42.5869, GNorm = 3.4731, lr_0 = 2.3145e-04
Loss = 5.5411e-01, PNorm = 42.5915, GNorm = 3.0912, lr_0 = 2.3050e-04
Loss = 4.4135e-01, PNorm = 42.5977, GNorm = 3.5076, lr_0 = 2.2956e-04
Loss = 4.2625e-01, PNorm = 42.6037, GNorm = 5.8027, lr_0 = 2.2862e-04
Loss = 4.3176e-01, PNorm = 42.6092, GNorm = 7.7814, lr_0 = 2.2768e-04
Loss = 5.4943e-01, PNorm = 42.6189, GNorm = 6.8461, lr_0 = 2.2674e-04
Loss = 4.8697e-01, PNorm = 42.6303, GNorm = 2.7366, lr_0 = 2.2581e-04
Validation rmse = 0.721146
Epoch 20
Loss = 3.6999e-01, PNorm = 42.6409, GNorm = 5.0115, lr_0 = 2.2489e-04
Loss = 4.2966e-01, PNorm = 42.6510, GNorm = 13.3561, lr_0 = 2.2396e-04
Loss = 4.1579e-01, PNorm = 42.6583, GNorm = 5.1712, lr_0 = 2.2305e-04
Loss = 4.3432e-01, PNorm = 42.6650, GNorm = 5.8109, lr_0 = 2.2213e-04
Loss = 4.7829e-01, PNorm = 42.6753, GNorm = 4.3807, lr_0 = 2.2122e-04
Loss = 5.2397e-01, PNorm = 42.6851, GNorm = 3.5116, lr_0 = 2.2031e-04
Loss = 5.1250e-01, PNorm = 42.6904, GNorm = 5.7406, lr_0 = 2.1941e-04
Loss = 4.0057e-01, PNorm = 42.6915, GNorm = 3.8389, lr_0 = 2.1851e-04
Loss = 4.4712e-01, PNorm = 42.6998, GNorm = 4.2066, lr_0 = 2.1761e-04
Loss = 5.7760e-01, PNorm = 42.7048, GNorm = 5.3141, lr_0 = 2.1672e-04
Loss = 4.1586e-01, PNorm = 42.7136, GNorm = 6.2282, lr_0 = 2.1583e-04
Loss = 5.0292e-01, PNorm = 42.7210, GNorm = 4.9780, lr_0 = 2.1494e-04
Loss = 6.0570e-01, PNorm = 42.7268, GNorm = 6.6265, lr_0 = 2.1406e-04
Loss = 4.4292e-01, PNorm = 42.7345, GNorm = 2.4875, lr_0 = 2.1318e-04
Loss = 5.2840e-01, PNorm = 42.7397, GNorm = 3.4297, lr_0 = 2.1231e-04
Loss = 5.4600e-01, PNorm = 42.7445, GNorm = 8.4997, lr_0 = 2.1144e-04
Loss = 5.5721e-01, PNorm = 42.7530, GNorm = 4.6998, lr_0 = 2.1057e-04
Loss = 4.9406e-01, PNorm = 42.7612, GNorm = 7.1592, lr_0 = 2.0970e-04
Loss = 4.7310e-01, PNorm = 42.7691, GNorm = 4.9815, lr_0 = 2.0884e-04
Loss = 4.3303e-01, PNorm = 42.7762, GNorm = 3.8503, lr_0 = 2.0799e-04
Validation rmse = 0.722820
Epoch 21
Loss = 5.6195e-01, PNorm = 42.7856, GNorm = 5.2526, lr_0 = 2.0705e-04
Loss = 3.6225e-01, PNorm = 42.7933, GNorm = 4.5323, lr_0 = 2.0620e-04
Loss = 5.1180e-01, PNorm = 42.7976, GNorm = 6.2877, lr_0 = 2.0535e-04
Loss = 5.0527e-01, PNorm = 42.8040, GNorm = 3.8991, lr_0 = 2.0451e-04
Loss = 5.8756e-01, PNorm = 42.8104, GNorm = 2.9215, lr_0 = 2.0367e-04
Loss = 4.2508e-01, PNorm = 42.8181, GNorm = 5.5688, lr_0 = 2.0283e-04
Loss = 4.1766e-01, PNorm = 42.8247, GNorm = 3.9089, lr_0 = 2.0200e-04
Loss = 3.7071e-01, PNorm = 42.8359, GNorm = 6.4557, lr_0 = 2.0117e-04
Loss = 5.0220e-01, PNorm = 42.8452, GNorm = 9.3791, lr_0 = 2.0035e-04
Loss = 2.8687e-01, PNorm = 42.8550, GNorm = 5.1380, lr_0 = 1.9953e-04
Loss = 6.0292e-01, PNorm = 42.8631, GNorm = 4.7867, lr_0 = 1.9871e-04
Loss = 5.5632e-01, PNorm = 42.8661, GNorm = 7.3054, lr_0 = 1.9789e-04
Loss = 5.5832e-01, PNorm = 42.8676, GNorm = 6.7403, lr_0 = 1.9708e-04
Loss = 4.1623e-01, PNorm = 42.8731, GNorm = 3.7843, lr_0 = 1.9627e-04
Loss = 4.1289e-01, PNorm = 42.8808, GNorm = 6.3520, lr_0 = 1.9547e-04
Loss = 6.1878e-01, PNorm = 42.8898, GNorm = 5.0821, lr_0 = 1.9466e-04
Loss = 3.6609e-01, PNorm = 42.8962, GNorm = 5.0983, lr_0 = 1.9387e-04
Loss = 3.9312e-01, PNorm = 42.9022, GNorm = 3.9814, lr_0 = 1.9307e-04
Loss = 5.2345e-01, PNorm = 42.9052, GNorm = 6.6580, lr_0 = 1.9228e-04
Loss = 5.0341e-01, PNorm = 42.9099, GNorm = 2.4848, lr_0 = 1.9149e-04
Validation rmse = 0.731117
Epoch 22
Loss = 4.2207e-01, PNorm = 42.9117, GNorm = 3.3216, lr_0 = 1.9062e-04
Loss = 4.3942e-01, PNorm = 42.9171, GNorm = 6.1586, lr_0 = 1.8984e-04
Loss = 3.8230e-01, PNorm = 42.9246, GNorm = 3.4367, lr_0 = 1.8906e-04
Loss = 5.3747e-01, PNorm = 42.9335, GNorm = 9.0723, lr_0 = 1.8829e-04
Loss = 5.0609e-01, PNorm = 42.9423, GNorm = 5.4942, lr_0 = 1.8751e-04
Loss = 4.5156e-01, PNorm = 42.9466, GNorm = 6.7566, lr_0 = 1.8675e-04
Loss = 4.4546e-01, PNorm = 42.9523, GNorm = 8.6142, lr_0 = 1.8598e-04
Loss = 5.7192e-01, PNorm = 42.9600, GNorm = 5.4939, lr_0 = 1.8522e-04
Loss = 2.5065e-01, PNorm = 42.9661, GNorm = 4.3344, lr_0 = 1.8446e-04
Loss = 4.2019e-01, PNorm = 42.9689, GNorm = 3.8779, lr_0 = 1.8370e-04
Loss = 3.3039e-01, PNorm = 42.9751, GNorm = 10.1599, lr_0 = 1.8295e-04
Loss = 4.3199e-01, PNorm = 42.9806, GNorm = 5.1391, lr_0 = 1.8219e-04
Loss = 3.2232e-01, PNorm = 42.9876, GNorm = 6.0737, lr_0 = 1.8145e-04
Loss = 3.5158e-01, PNorm = 42.9928, GNorm = 6.2157, lr_0 = 1.8070e-04
Loss = 5.2296e-01, PNorm = 42.9986, GNorm = 6.2219, lr_0 = 1.7996e-04
Loss = 4.3026e-01, PNorm = 43.0018, GNorm = 3.9435, lr_0 = 1.7922e-04
Loss = 4.9483e-01, PNorm = 43.0049, GNorm = 3.4932, lr_0 = 1.7849e-04
Loss = 5.0712e-01, PNorm = 43.0075, GNorm = 3.5763, lr_0 = 1.7775e-04
Loss = 5.4658e-01, PNorm = 43.0102, GNorm = 4.3187, lr_0 = 1.7703e-04
Loss = 5.3894e-01, PNorm = 43.0145, GNorm = 2.8145, lr_0 = 1.7630e-04
Validation rmse = 0.722716
Epoch 23
Loss = 3.6021e-01, PNorm = 43.0201, GNorm = 5.6584, lr_0 = 1.7550e-04
Loss = 4.7166e-01, PNorm = 43.0249, GNorm = 6.3124, lr_0 = 1.7478e-04
Loss = 5.1937e-01, PNorm = 43.0305, GNorm = 3.8448, lr_0 = 1.7407e-04
Loss = 4.3956e-01, PNorm = 43.0374, GNorm = 8.7768, lr_0 = 1.7335e-04
Loss = 4.5229e-01, PNorm = 43.0427, GNorm = 7.5323, lr_0 = 1.7264e-04
Loss = 4.0982e-01, PNorm = 43.0488, GNorm = 6.7775, lr_0 = 1.7193e-04
Loss = 3.1274e-01, PNorm = 43.0542, GNorm = 3.8497, lr_0 = 1.7123e-04
Loss = 4.9344e-01, PNorm = 43.0576, GNorm = 10.9487, lr_0 = 1.7052e-04
Loss = 2.9932e-01, PNorm = 43.0629, GNorm = 3.9606, lr_0 = 1.6982e-04
Loss = 3.1518e-01, PNorm = 43.0681, GNorm = 11.0967, lr_0 = 1.6913e-04
Loss = 3.7322e-01, PNorm = 43.0725, GNorm = 3.9438, lr_0 = 1.6843e-04
Loss = 2.3853e-01, PNorm = 43.0771, GNorm = 5.6378, lr_0 = 1.6774e-04
Loss = 5.6205e-01, PNorm = 43.0812, GNorm = 5.9546, lr_0 = 1.6705e-04
Loss = 4.0467e-01, PNorm = 43.0850, GNorm = 6.9220, lr_0 = 1.6637e-04
Loss = 3.8928e-01, PNorm = 43.0891, GNorm = 8.6132, lr_0 = 1.6569e-04
Loss = 4.4071e-01, PNorm = 43.0945, GNorm = 2.4962, lr_0 = 1.6501e-04
Loss = 4.8462e-01, PNorm = 43.0990, GNorm = 5.5449, lr_0 = 1.6433e-04
Loss = 4.4808e-01, PNorm = 43.1026, GNorm = 5.1684, lr_0 = 1.6365e-04
Loss = 5.1395e-01, PNorm = 43.1033, GNorm = 6.7423, lr_0 = 1.6298e-04
Loss = 3.0177e-01, PNorm = 43.1067, GNorm = 7.7151, lr_0 = 1.6231e-04
Validation rmse = 0.715884
Epoch 24
Loss = 4.2899e-01, PNorm = 43.1146, GNorm = 6.7156, lr_0 = 1.6158e-04
Loss = 3.6307e-01, PNorm = 43.1194, GNorm = 6.2134, lr_0 = 1.6092e-04
Loss = 4.9063e-01, PNorm = 43.1230, GNorm = 5.8511, lr_0 = 1.6026e-04
Loss = 4.2292e-01, PNorm = 43.1302, GNorm = 4.6693, lr_0 = 1.5960e-04
Loss = 4.6697e-01, PNorm = 43.1360, GNorm = 15.2764, lr_0 = 1.5895e-04
Loss = 4.8081e-01, PNorm = 43.1396, GNorm = 3.2213, lr_0 = 1.5829e-04
Loss = 5.0407e-01, PNorm = 43.1440, GNorm = 2.7913, lr_0 = 1.5764e-04
Loss = 4.2030e-01, PNorm = 43.1494, GNorm = 3.8499, lr_0 = 1.5700e-04
Loss = 2.9177e-01, PNorm = 43.1538, GNorm = 5.1338, lr_0 = 1.5635e-04
Loss = 4.0644e-01, PNorm = 43.1572, GNorm = 6.7942, lr_0 = 1.5571e-04
Loss = 3.8037e-01, PNorm = 43.1608, GNorm = 7.9229, lr_0 = 1.5507e-04
Loss = 3.2035e-01, PNorm = 43.1646, GNorm = 5.3939, lr_0 = 1.5444e-04
Loss = 3.9976e-01, PNorm = 43.1685, GNorm = 4.1030, lr_0 = 1.5380e-04
Loss = 3.9146e-01, PNorm = 43.1784, GNorm = 3.5271, lr_0 = 1.5317e-04
Loss = 3.3292e-01, PNorm = 43.1856, GNorm = 17.8105, lr_0 = 1.5254e-04
Loss = 2.7737e-01, PNorm = 43.1929, GNorm = 11.7570, lr_0 = 1.5192e-04
Loss = 1.1446e-01, PNorm = 43.1992, GNorm = 3.8024, lr_0 = 1.5129e-04
Loss = 4.0974e-01, PNorm = 43.2058, GNorm = 7.3078, lr_0 = 1.5067e-04
Loss = 3.2700e-01, PNorm = 43.2089, GNorm = 10.9988, lr_0 = 1.5005e-04
Loss = 5.0748e-01, PNorm = 43.2112, GNorm = 8.2678, lr_0 = 1.4944e-04
Validation rmse = 0.713256
Epoch 25
Loss = 3.3020e-01, PNorm = 43.2162, GNorm = 8.5599, lr_0 = 1.4876e-04
Loss = 2.7831e-01, PNorm = 43.2212, GNorm = 9.2255, lr_0 = 1.4815e-04
Loss = 3.9124e-01, PNorm = 43.2266, GNorm = 5.7471, lr_0 = 1.4755e-04
Loss = 3.4766e-01, PNorm = 43.2309, GNorm = 5.9927, lr_0 = 1.4694e-04
Loss = 1.5560e-01, PNorm = 43.2356, GNorm = 6.9766, lr_0 = 1.4634e-04
Loss = 4.8011e-01, PNorm = 43.2333, GNorm = 8.7811, lr_0 = 1.4574e-04
Loss = 1.6715e-01, PNorm = 43.2314, GNorm = 3.4906, lr_0 = 1.4514e-04
Loss = 3.2458e-01, PNorm = 43.2333, GNorm = 7.1479, lr_0 = 1.4454e-04
Loss = 3.6861e-01, PNorm = 43.2386, GNorm = 20.4477, lr_0 = 1.4395e-04
Loss = 2.7997e-01, PNorm = 43.2450, GNorm = 6.4229, lr_0 = 1.4336e-04
Loss = 2.7018e-01, PNorm = 43.2508, GNorm = 9.8326, lr_0 = 1.4277e-04
Loss = 4.4982e-01, PNorm = 43.2569, GNorm = 14.1342, lr_0 = 1.4219e-04
Loss = 4.4062e-01, PNorm = 43.2609, GNorm = 5.4458, lr_0 = 1.4160e-04
Loss = 4.0193e-01, PNorm = 43.2653, GNorm = 4.1199, lr_0 = 1.4102e-04
Loss = 5.3709e-01, PNorm = 43.2688, GNorm = 12.1091, lr_0 = 1.4044e-04
Loss = 3.5632e-01, PNorm = 43.2717, GNorm = 6.5394, lr_0 = 1.3987e-04
Loss = 4.3496e-01, PNorm = 43.2762, GNorm = 8.0056, lr_0 = 1.3929e-04
Loss = 4.4761e-01, PNorm = 43.2797, GNorm = 7.2861, lr_0 = 1.3872e-04
Loss = 3.8085e-01, PNorm = 43.2820, GNorm = 9.6168, lr_0 = 1.3815e-04
Loss = 3.5457e-01, PNorm = 43.2847, GNorm = 3.3905, lr_0 = 1.3759e-04
Validation rmse = 0.701709
Epoch 26
Loss = 4.1023e-01, PNorm = 43.2908, GNorm = 6.7992, lr_0 = 1.3696e-04
Loss = 3.0173e-01, PNorm = 43.2974, GNorm = 3.4905, lr_0 = 1.3640e-04
Loss = 3.5331e-01, PNorm = 43.3023, GNorm = 7.0905, lr_0 = 1.3584e-04
Loss = 3.3049e-01, PNorm = 43.3069, GNorm = 8.6665, lr_0 = 1.3529e-04
Loss = 2.6462e-01, PNorm = 43.3094, GNorm = 4.2777, lr_0 = 1.3473e-04
Loss = 3.7690e-01, PNorm = 43.3135, GNorm = 6.1130, lr_0 = 1.3418e-04
Loss = 4.8652e-01, PNorm = 43.3158, GNorm = 8.2765, lr_0 = 1.3363e-04
Loss = 3.4623e-01, PNorm = 43.3194, GNorm = 4.5493, lr_0 = 1.3308e-04
Loss = 2.8992e-01, PNorm = 43.3244, GNorm = 5.0217, lr_0 = 1.3253e-04
Loss = 3.1404e-01, PNorm = 43.3287, GNorm = 7.5991, lr_0 = 1.3199e-04
Loss = 3.3199e-01, PNorm = 43.3335, GNorm = 5.9004, lr_0 = 1.3145e-04
Loss = 2.9835e-01, PNorm = 43.3379, GNorm = 6.7334, lr_0 = 1.3091e-04
Loss = 4.5339e-01, PNorm = 43.3427, GNorm = 3.9681, lr_0 = 1.3037e-04
Loss = 2.8892e-01, PNorm = 43.3468, GNorm = 10.7952, lr_0 = 1.2984e-04
Loss = 4.6140e-01, PNorm = 43.3504, GNorm = 5.4560, lr_0 = 1.2930e-04
Loss = 3.2908e-01, PNorm = 43.3521, GNorm = 3.7459, lr_0 = 1.2877e-04
Loss = 2.5946e-01, PNorm = 43.3547, GNorm = 5.6697, lr_0 = 1.2824e-04
Loss = 2.9667e-01, PNorm = 43.3586, GNorm = 13.9972, lr_0 = 1.2772e-04
Loss = 2.3874e-01, PNorm = 43.3623, GNorm = 6.9117, lr_0 = 1.2719e-04
Loss = 4.5528e-01, PNorm = 43.3650, GNorm = 5.5367, lr_0 = 1.2667e-04
Validation rmse = 0.707331
Epoch 27
Loss = 4.5834e-01, PNorm = 43.3677, GNorm = 4.8321, lr_0 = 1.2610e-04
Loss = 3.7040e-01, PNorm = 43.3718, GNorm = 7.0662, lr_0 = 1.2558e-04
Loss = 2.8846e-01, PNorm = 43.3767, GNorm = 7.1181, lr_0 = 1.2507e-04
Loss = 2.3071e-01, PNorm = 43.3814, GNorm = 4.5288, lr_0 = 1.2455e-04
Loss = 3.5513e-01, PNorm = 43.3856, GNorm = 6.5209, lr_0 = 1.2404e-04
Loss = 3.7892e-01, PNorm = 43.3904, GNorm = 8.9247, lr_0 = 1.2353e-04
Loss = 2.0333e-01, PNorm = 43.3958, GNorm = 6.2078, lr_0 = 1.2303e-04
Loss = 2.5994e-01, PNorm = 43.4017, GNorm = 3.8563, lr_0 = 1.2252e-04
Loss = 3.4247e-01, PNorm = 43.4054, GNorm = 10.2414, lr_0 = 1.2202e-04
Loss = 2.9579e-01, PNorm = 43.4082, GNorm = 5.9623, lr_0 = 1.2152e-04
Loss = 2.8221e-01, PNorm = 43.4106, GNorm = 7.6520, lr_0 = 1.2102e-04
Loss = 1.5316e-01, PNorm = 43.4141, GNorm = 6.5715, lr_0 = 1.2052e-04
Loss = 4.2670e-01, PNorm = 43.4155, GNorm = 13.2016, lr_0 = 1.2003e-04
Loss = 3.8064e-01, PNorm = 43.4180, GNorm = 5.8764, lr_0 = 1.1954e-04
Loss = 3.7135e-01, PNorm = 43.4229, GNorm = 10.9352, lr_0 = 1.1905e-04
Loss = 3.8372e-01, PNorm = 43.4259, GNorm = 10.8581, lr_0 = 1.1856e-04
Loss = 2.8645e-01, PNorm = 43.4274, GNorm = 9.5860, lr_0 = 1.1807e-04
Loss = 4.0958e-01, PNorm = 43.4269, GNorm = 7.4704, lr_0 = 1.1759e-04
Loss = 2.1451e-01, PNorm = 43.4281, GNorm = 8.3045, lr_0 = 1.1710e-04
Loss = 3.3949e-01, PNorm = 43.4285, GNorm = 3.7631, lr_0 = 1.1662e-04
Validation rmse = 0.708408
Epoch 28
Loss = 2.4550e-01, PNorm = 43.4313, GNorm = 14.9840, lr_0 = 1.1610e-04
Loss = 1.9684e-01, PNorm = 43.4337, GNorm = 14.2389, lr_0 = 1.1562e-04
Loss = 3.1035e-01, PNorm = 43.4415, GNorm = 7.3090, lr_0 = 1.1515e-04
Loss = 2.5906e-01, PNorm = 43.4484, GNorm = 11.7804, lr_0 = 1.1467e-04
Loss = 2.8071e-01, PNorm = 43.4527, GNorm = 5.4576, lr_0 = 1.1420e-04
Loss = 2.8750e-01, PNorm = 43.4571, GNorm = 9.7231, lr_0 = 1.1373e-04
Loss = 3.0146e-01, PNorm = 43.4603, GNorm = 8.3559, lr_0 = 1.1327e-04
Loss = 3.3215e-01, PNorm = 43.4631, GNorm = 7.3160, lr_0 = 1.1280e-04
Loss = 2.5954e-01, PNorm = 43.4656, GNorm = 10.0434, lr_0 = 1.1234e-04
Loss = 4.5564e-01, PNorm = 43.4683, GNorm = 8.2096, lr_0 = 1.1188e-04
Loss = 4.1586e-01, PNorm = 43.4726, GNorm = 5.2728, lr_0 = 1.1142e-04
Loss = 2.8867e-01, PNorm = 43.4757, GNorm = 8.5952, lr_0 = 1.1096e-04
Loss = 3.0685e-01, PNorm = 43.4782, GNorm = 6.4123, lr_0 = 1.1051e-04
Loss = 2.9597e-01, PNorm = 43.4819, GNorm = 7.6882, lr_0 = 1.1005e-04
Loss = 2.8331e-01, PNorm = 43.4830, GNorm = 4.5016, lr_0 = 1.0960e-04
Loss = 3.1295e-01, PNorm = 43.4859, GNorm = 11.6585, lr_0 = 1.0915e-04
Loss = 3.7006e-01, PNorm = 43.4883, GNorm = 6.6396, lr_0 = 1.0871e-04
Loss = 1.9281e-01, PNorm = 43.4914, GNorm = 5.0731, lr_0 = 1.0826e-04
Loss = 3.2734e-01, PNorm = 43.4938, GNorm = 7.5180, lr_0 = 1.0781e-04
Loss = 1.9648e-01, PNorm = 43.4959, GNorm = 6.4499, lr_0 = 1.0737e-04
Validation rmse = 0.704267
Epoch 29
Loss = 3.2952e-01, PNorm = 43.4983, GNorm = 5.5638, lr_0 = 1.0689e-04
Loss = 2.3277e-01, PNorm = 43.5003, GNorm = 12.1734, lr_0 = 1.0645e-04
Loss = 2.2767e-01, PNorm = 43.5020, GNorm = 8.6839, lr_0 = 1.0601e-04
Loss = 1.3754e-01, PNorm = 43.5044, GNorm = 5.9080, lr_0 = 1.0558e-04
Loss = 4.2139e-01, PNorm = 43.5069, GNorm = 7.1670, lr_0 = 1.0514e-04
Loss = 2.2894e-01, PNorm = 43.5103, GNorm = 11.1284, lr_0 = 1.0471e-04
Loss = 2.3733e-01, PNorm = 43.5151, GNorm = 9.2131, lr_0 = 1.0428e-04
Loss = 3.3419e-01, PNorm = 43.5191, GNorm = 5.2602, lr_0 = 1.0386e-04
Loss = 4.4306e-01, PNorm = 43.5209, GNorm = 6.7255, lr_0 = 1.0343e-04
Loss = 3.5736e-01, PNorm = 43.5215, GNorm = 4.6459, lr_0 = 1.0300e-04
Loss = 2.6324e-01, PNorm = 43.5220, GNorm = 10.6459, lr_0 = 1.0258e-04
Loss = 4.0366e-01, PNorm = 43.5244, GNorm = 9.4862, lr_0 = 1.0216e-04
Loss = 2.1207e-01, PNorm = 43.5289, GNorm = 4.9487, lr_0 = 1.0174e-04
Loss = 2.6943e-01, PNorm = 43.5332, GNorm = 6.0973, lr_0 = 1.0132e-04
Loss = 3.3927e-01, PNorm = 43.5358, GNorm = 10.0140, lr_0 = 1.0091e-04
Loss = 2.8140e-01, PNorm = 43.5388, GNorm = 3.9632, lr_0 = 1.0049e-04
Loss = 3.2437e-01, PNorm = 43.5415, GNorm = 5.1816, lr_0 = 1.0008e-04
Loss = 2.1948e-01, PNorm = 43.5449, GNorm = 4.0910, lr_0 = 1.0000e-04
Loss = 2.9529e-01, PNorm = 43.5492, GNorm = 7.9782, lr_0 = 1.0000e-04
Loss = 3.4081e-01, PNorm = 43.5499, GNorm = 4.5428, lr_0 = 1.0000e-04
Validation rmse = 0.703250
Model 0 best validation rmse = 0.701709 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.795558
Ensemble test rmse = 0.795558
1-fold cross validation
	Seed 0 ==> test rmse = 0.795558
Overall test rmse = 0.795558 +/- 0.000000
Elapsed time = 0:04:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-9125107f-aa91-4851-96da-58874f5b2420.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.408649
Epoch 1
Loss = 1.4207e+00, PNorm = 43.2913, GNorm = 1.1431, lr_0 = 7.1875e-04
Validation rmse = 1.319862
Epoch 2
Loss = 1.4301e+00, PNorm = 43.3218, GNorm = 0.9164, lr_0 = 6.1897e-04
Validation rmse = 1.291640
Epoch 3
Loss = 1.3663e+00, PNorm = 43.3375, GNorm = 0.6125, lr_0 = 2.3714e-04
Validation rmse = 1.277205
Epoch 4
Loss = 1.3474e+00, PNorm = 43.3433, GNorm = 0.4803, lr_0 = 1.0000e-04
Validation rmse = 1.270445
Model 0 best validation rmse = 1.270445 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.323022
Ensemble test rmse = 1.323022
1-fold cross validation
	Seed 0 ==> test rmse = 1.323022
Overall test rmse = 1.323022 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-2575de15-4d1d-4fdb-a402-d96103437ef1.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-2575de15-4d1d-4fdb-a402-d96103437ef1.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9871, lr_0 = 3.0475e-04
Loss = 1.4488e+00, PNorm = 34.0770, GNorm = 2.0192, lr_0 = 3.2725e-04
Loss = 1.1913e+00, PNorm = 34.0841, GNorm = 1.2117, lr_0 = 3.4975e-04
Loss = 1.4935e+00, PNorm = 34.0956, GNorm = 6.5481, lr_0 = 3.7225e-04
Loss = 1.3781e+00, PNorm = 34.1090, GNorm = 0.8826, lr_0 = 3.9475e-04
Loss = 1.2925e+00, PNorm = 34.1167, GNorm = 4.5639, lr_0 = 4.1725e-04
Loss = 1.2139e+00, PNorm = 34.1219, GNorm = 2.5208, lr_0 = 4.3975e-04
Loss = 1.3999e+00, PNorm = 34.1336, GNorm = 1.0461, lr_0 = 4.6225e-04
Loss = 1.4194e+00, PNorm = 34.1524, GNorm = 3.0312, lr_0 = 4.8475e-04
Loss = 1.2914e+00, PNorm = 34.1743, GNorm = 6.9870, lr_0 = 5.0725e-04
Loss = 1.3128e+00, PNorm = 34.1889, GNorm = 1.3131, lr_0 = 5.2975e-04
Loss = 1.0944e+00, PNorm = 34.2085, GNorm = 2.8883, lr_0 = 5.5225e-04
Loss = 6.9382e-01, PNorm = 34.2099, GNorm = 2.4146, lr_0 = 5.5450e-04
Validation rmse = 1.215821
Epoch 1
Loss = 1.1131e+00, PNorm = 34.2202, GNorm = 0.8222, lr_0 = 5.7700e-04
Loss = 1.4017e+00, PNorm = 34.2374, GNorm = 3.5246, lr_0 = 5.9950e-04
Loss = 1.1803e+00, PNorm = 34.2575, GNorm = 5.1749, lr_0 = 6.2200e-04
Loss = 1.1723e+00, PNorm = 34.2731, GNorm = 1.2502, lr_0 = 6.4450e-04
Loss = 1.2695e+00, PNorm = 34.2829, GNorm = 3.0905, lr_0 = 6.6700e-04
Loss = 1.2156e+00, PNorm = 34.2988, GNorm = 2.6864, lr_0 = 6.8950e-04
Loss = 1.1847e+00, PNorm = 34.3205, GNorm = 2.2419, lr_0 = 7.1200e-04
Loss = 1.2660e+00, PNorm = 34.3411, GNorm = 3.6527, lr_0 = 7.3450e-04
Loss = 1.1880e+00, PNorm = 34.3646, GNorm = 1.2314, lr_0 = 7.5700e-04
Loss = 1.2760e+00, PNorm = 34.3988, GNorm = 1.1619, lr_0 = 7.7950e-04
Loss = 1.1525e+00, PNorm = 34.4288, GNorm = 1.5589, lr_0 = 8.0200e-04
Loss = 1.2201e+00, PNorm = 34.4550, GNorm = 2.2002, lr_0 = 8.2450e-04
Loss = 1.3312e+00, PNorm = 34.4997, GNorm = 1.9761, lr_0 = 8.4700e-04
Loss = 1.4509e+00, PNorm = 34.5384, GNorm = 2.8909, lr_0 = 8.6950e-04
Loss = 1.2159e+00, PNorm = 34.5942, GNorm = 1.0708, lr_0 = 8.9200e-04
Loss = 1.2759e+00, PNorm = 34.6327, GNorm = 1.1676, lr_0 = 9.1450e-04
Loss = 1.2527e+00, PNorm = 34.6586, GNorm = 1.1479, lr_0 = 9.3700e-04
Loss = 1.1578e+00, PNorm = 34.6842, GNorm = 1.1777, lr_0 = 9.5950e-04
Loss = 1.1417e+00, PNorm = 34.7099, GNorm = 1.3797, lr_0 = 9.8200e-04
Loss = 1.2205e+00, PNorm = 34.7473, GNorm = 0.9929, lr_0 = 9.9918e-04
Loss = 3.8117e+00, PNorm = 34.7515, GNorm = 20.2592, lr_0 = 9.9877e-04
Validation rmse = 1.179950
Epoch 2
Loss = 1.4805e+00, PNorm = 34.8183, GNorm = 0.4251, lr_0 = 9.9467e-04
Loss = 1.2712e+00, PNorm = 34.8914, GNorm = 1.2219, lr_0 = 9.9059e-04
Loss = 1.1074e+00, PNorm = 34.9520, GNorm = 2.9447, lr_0 = 9.8652e-04
Loss = 1.3274e+00, PNorm = 34.9856, GNorm = 0.6428, lr_0 = 9.8247e-04
Loss = 1.2146e+00, PNorm = 35.0183, GNorm = 0.5180, lr_0 = 9.7844e-04
Loss = 1.1819e+00, PNorm = 35.0530, GNorm = 0.8715, lr_0 = 9.7443e-04
Loss = 1.0330e+00, PNorm = 35.0840, GNorm = 1.5672, lr_0 = 9.7043e-04
Loss = 1.3406e+00, PNorm = 35.1034, GNorm = 1.0030, lr_0 = 9.6645e-04
Loss = 1.1582e+00, PNorm = 35.1185, GNorm = 0.9045, lr_0 = 9.6248e-04
Loss = 1.1610e+00, PNorm = 35.1491, GNorm = 1.5333, lr_0 = 9.5853e-04
Loss = 1.2338e+00, PNorm = 35.1790, GNorm = 1.5972, lr_0 = 9.5460e-04
Loss = 1.1597e+00, PNorm = 35.1987, GNorm = 0.7295, lr_0 = 9.5068e-04
Loss = 1.2303e+00, PNorm = 35.2199, GNorm = 0.5085, lr_0 = 9.4678e-04
Loss = 1.1552e+00, PNorm = 35.2464, GNorm = 0.4316, lr_0 = 9.4290e-04
Loss = 1.1856e+00, PNorm = 35.2733, GNorm = 1.1975, lr_0 = 9.3903e-04
Loss = 1.3167e+00, PNorm = 35.2990, GNorm = 0.6999, lr_0 = 9.3517e-04
Loss = 1.0857e+00, PNorm = 35.3200, GNorm = 0.6225, lr_0 = 9.3134e-04
Loss = 1.1942e+00, PNorm = 35.3427, GNorm = 0.5538, lr_0 = 9.2752e-04
Loss = 1.0895e+00, PNorm = 35.3636, GNorm = 1.3565, lr_0 = 9.2371e-04
Loss = 1.1001e+00, PNorm = 35.3993, GNorm = 2.0044, lr_0 = 9.1992e-04
Loss = 6.0987e-01, PNorm = 35.4022, GNorm = 1.3264, lr_0 = 9.1954e-04
Validation rmse = 1.078473
Epoch 3
Loss = 1.1600e+00, PNorm = 35.4253, GNorm = 0.6408, lr_0 = 9.1577e-04
Loss = 1.1063e+00, PNorm = 35.4652, GNorm = 1.7721, lr_0 = 9.1201e-04
Loss = 1.2361e+00, PNorm = 35.4866, GNorm = 1.0262, lr_0 = 9.0827e-04
Loss = 1.0675e+00, PNorm = 35.5096, GNorm = 1.9608, lr_0 = 9.0454e-04
Loss = 1.0745e+00, PNorm = 35.5283, GNorm = 0.4114, lr_0 = 9.0083e-04
Loss = 1.0808e+00, PNorm = 35.5657, GNorm = 1.3330, lr_0 = 8.9713e-04
Loss = 1.1546e+00, PNorm = 35.5989, GNorm = 0.7064, lr_0 = 8.9345e-04
Loss = 1.1433e+00, PNorm = 35.6446, GNorm = 4.2592, lr_0 = 8.8979e-04
Loss = 1.2355e+00, PNorm = 35.6730, GNorm = 0.9376, lr_0 = 8.8614e-04
Loss = 1.0854e+00, PNorm = 35.7185, GNorm = 2.4464, lr_0 = 8.8250e-04
Loss = 1.1266e+00, PNorm = 35.7542, GNorm = 1.4566, lr_0 = 8.7888e-04
Loss = 1.1517e+00, PNorm = 35.7947, GNorm = 1.2575, lr_0 = 8.7527e-04
Loss = 1.2289e+00, PNorm = 35.8218, GNorm = 1.2680, lr_0 = 8.7168e-04
Loss = 1.1716e+00, PNorm = 35.8432, GNorm = 0.9364, lr_0 = 8.6810e-04
Loss = 1.2189e+00, PNorm = 35.8646, GNorm = 1.3168, lr_0 = 8.6454e-04
Loss = 1.2151e+00, PNorm = 35.8936, GNorm = 1.7712, lr_0 = 8.6099e-04
Loss = 1.0470e+00, PNorm = 35.9087, GNorm = 1.2077, lr_0 = 8.5746e-04
Loss = 9.3177e-01, PNorm = 35.9351, GNorm = 1.2795, lr_0 = 8.5394e-04
Loss = 1.0564e+00, PNorm = 35.9570, GNorm = 0.7399, lr_0 = 8.5044e-04
Loss = 1.0819e+00, PNorm = 35.9791, GNorm = 2.0250, lr_0 = 8.4695e-04
Loss = 5.8516e-01, PNorm = 35.9818, GNorm = 1.7708, lr_0 = 8.4660e-04
Validation rmse = 1.059248
Epoch 4
Loss = 1.0059e+00, PNorm = 36.0035, GNorm = 0.9808, lr_0 = 8.4313e-04
Loss = 1.1541e+00, PNorm = 36.0341, GNorm = 0.7946, lr_0 = 8.3967e-04
Loss = 1.1424e+00, PNorm = 36.0817, GNorm = 0.8224, lr_0 = 8.3622e-04
Loss = 1.1807e+00, PNorm = 36.1252, GNorm = 0.9972, lr_0 = 8.3279e-04
Loss = 1.1725e+00, PNorm = 36.1683, GNorm = 0.6439, lr_0 = 8.2937e-04
Loss = 1.1002e+00, PNorm = 36.2063, GNorm = 2.9267, lr_0 = 8.2597e-04
Loss = 1.0831e+00, PNorm = 36.2460, GNorm = 1.6337, lr_0 = 8.2258e-04
Loss = 1.0789e+00, PNorm = 36.2818, GNorm = 0.9038, lr_0 = 8.1921e-04
Loss = 1.1009e+00, PNorm = 36.3385, GNorm = 2.1049, lr_0 = 8.1584e-04
Loss = 1.0808e+00, PNorm = 36.3586, GNorm = 1.5864, lr_0 = 8.1250e-04
Loss = 1.0610e+00, PNorm = 36.3853, GNorm = 0.9768, lr_0 = 8.0916e-04
Loss = 9.9806e-01, PNorm = 36.4214, GNorm = 1.1949, lr_0 = 8.0584e-04
Loss = 1.2733e+00, PNorm = 36.4611, GNorm = 2.9250, lr_0 = 8.0254e-04
Loss = 1.0715e+00, PNorm = 36.4953, GNorm = 1.3550, lr_0 = 7.9924e-04
Loss = 9.7633e-01, PNorm = 36.5477, GNorm = 1.8164, lr_0 = 7.9596e-04
Loss = 1.1672e+00, PNorm = 36.5755, GNorm = 3.0955, lr_0 = 7.9270e-04
Loss = 1.0530e+00, PNorm = 36.6095, GNorm = 1.2106, lr_0 = 7.8944e-04
Loss = 1.0349e+00, PNorm = 36.6268, GNorm = 1.2914, lr_0 = 7.8620e-04
Loss = 9.9306e-01, PNorm = 36.6513, GNorm = 1.3348, lr_0 = 7.8298e-04
Loss = 1.0544e+00, PNorm = 36.6834, GNorm = 3.0831, lr_0 = 7.7977e-04
Loss = 5.2422e-01, PNorm = 36.6858, GNorm = 3.9612, lr_0 = 7.7945e-04
Validation rmse = 0.997992
Epoch 5
Loss = 1.0883e+00, PNorm = 36.7298, GNorm = 1.2557, lr_0 = 7.7625e-04
Loss = 9.9562e-01, PNorm = 36.7668, GNorm = 1.1988, lr_0 = 7.7306e-04
Loss = 1.0338e+00, PNorm = 36.8040, GNorm = 1.5057, lr_0 = 7.6989e-04
Loss = 1.0820e+00, PNorm = 36.8357, GNorm = 0.9004, lr_0 = 7.6673e-04
Loss = 1.0728e+00, PNorm = 36.8760, GNorm = 2.8084, lr_0 = 7.6358e-04
Loss = 9.7605e-01, PNorm = 36.9152, GNorm = 1.6412, lr_0 = 7.6045e-04
Loss = 1.1263e+00, PNorm = 36.9527, GNorm = 1.7080, lr_0 = 7.5733e-04
Loss = 1.0205e+00, PNorm = 36.9895, GNorm = 1.1165, lr_0 = 7.5422e-04
Loss = 1.1180e+00, PNorm = 37.0127, GNorm = 3.0289, lr_0 = 7.5113e-04
Loss = 9.3496e-01, PNorm = 37.0275, GNorm = 1.1118, lr_0 = 7.4805e-04
Loss = 1.1840e+00, PNorm = 37.0632, GNorm = 2.5307, lr_0 = 7.4498e-04
Loss = 9.6288e-01, PNorm = 37.1023, GNorm = 2.1435, lr_0 = 7.4192e-04
Loss = 1.0267e+00, PNorm = 37.1357, GNorm = 1.0338, lr_0 = 7.3888e-04
Loss = 1.2094e+00, PNorm = 37.1689, GNorm = 3.6130, lr_0 = 7.3584e-04
Loss = 1.0779e+00, PNorm = 37.1989, GNorm = 1.2234, lr_0 = 7.3282e-04
Loss = 1.0308e+00, PNorm = 37.2277, GNorm = 1.2002, lr_0 = 7.2982e-04
Loss = 9.8645e-01, PNorm = 37.2341, GNorm = 0.9381, lr_0 = 7.2682e-04
Loss = 1.0644e+00, PNorm = 37.2582, GNorm = 1.6395, lr_0 = 7.2384e-04
Loss = 1.0208e+00, PNorm = 37.3022, GNorm = 3.0788, lr_0 = 7.2087e-04
Loss = 1.1806e+00, PNorm = 37.3458, GNorm = 0.7121, lr_0 = 7.1791e-04
Loss = 8.5141e-01, PNorm = 37.3486, GNorm = 4.3038, lr_0 = 7.1762e-04
Validation rmse = 0.988654
Epoch 6
Loss = 9.9706e-01, PNorm = 37.3768, GNorm = 2.2988, lr_0 = 7.1467e-04
Loss = 1.0663e+00, PNorm = 37.3878, GNorm = 1.4725, lr_0 = 7.1174e-04
Loss = 9.9349e-01, PNorm = 37.4112, GNorm = 1.2835, lr_0 = 7.0882e-04
Loss = 1.1184e+00, PNorm = 37.4503, GNorm = 1.9457, lr_0 = 7.0591e-04
Loss = 1.0362e+00, PNorm = 37.4875, GNorm = 2.1915, lr_0 = 7.0301e-04
Loss = 1.0006e+00, PNorm = 37.5311, GNorm = 1.0545, lr_0 = 7.0013e-04
Loss = 9.3349e-01, PNorm = 37.5614, GNorm = 1.1947, lr_0 = 6.9726e-04
Loss = 1.0389e+00, PNorm = 37.5929, GNorm = 2.0591, lr_0 = 6.9440e-04
Loss = 9.5810e-01, PNorm = 37.6259, GNorm = 2.4248, lr_0 = 6.9155e-04
Loss = 9.9649e-01, PNorm = 37.6435, GNorm = 1.0090, lr_0 = 6.8871e-04
Loss = 9.9277e-01, PNorm = 37.6699, GNorm = 2.5892, lr_0 = 6.8588e-04
Loss = 1.0354e+00, PNorm = 37.6981, GNorm = 2.2276, lr_0 = 6.8307e-04
Loss = 1.0211e+00, PNorm = 37.7293, GNorm = 1.4828, lr_0 = 6.8027e-04
Loss = 9.5929e-01, PNorm = 37.7680, GNorm = 1.2152, lr_0 = 6.7747e-04
Loss = 9.1112e-01, PNorm = 37.8040, GNorm = 1.9757, lr_0 = 6.7469e-04
Loss = 9.1196e-01, PNorm = 37.8415, GNorm = 2.0158, lr_0 = 6.7193e-04
Loss = 1.0924e+00, PNorm = 37.8678, GNorm = 3.8167, lr_0 = 6.6917e-04
Loss = 1.0648e+00, PNorm = 37.8942, GNorm = 0.8743, lr_0 = 6.6642e-04
Loss = 9.3106e-01, PNorm = 37.9300, GNorm = 1.3644, lr_0 = 6.6369e-04
Loss = 9.9510e-01, PNorm = 37.9597, GNorm = 1.7747, lr_0 = 6.6097e-04
Loss = 5.5939e-01, PNorm = 37.9625, GNorm = 1.5238, lr_0 = 6.6069e-04
Validation rmse = 0.960763
Epoch 7
Loss = 1.0607e+00, PNorm = 37.9800, GNorm = 1.1626, lr_0 = 6.5798e-04
Loss = 1.0248e+00, PNorm = 38.0146, GNorm = 1.3037, lr_0 = 6.5528e-04
Loss = 9.3808e-01, PNorm = 38.0518, GNorm = 2.2113, lr_0 = 6.5259e-04
Loss = 1.0227e+00, PNorm = 38.0874, GNorm = 3.3773, lr_0 = 6.4992e-04
Loss = 1.0075e+00, PNorm = 38.1142, GNorm = 2.1654, lr_0 = 6.4725e-04
Loss = 9.7617e-01, PNorm = 38.1334, GNorm = 1.7505, lr_0 = 6.4459e-04
Loss = 9.8158e-01, PNorm = 38.1787, GNorm = 4.1547, lr_0 = 6.4195e-04
Loss = 9.5559e-01, PNorm = 38.2203, GNorm = 3.6439, lr_0 = 6.3931e-04
Loss = 9.0076e-01, PNorm = 38.2585, GNorm = 3.0135, lr_0 = 6.3669e-04
Loss = 8.9603e-01, PNorm = 38.2870, GNorm = 1.3343, lr_0 = 6.3408e-04
Loss = 9.3414e-01, PNorm = 38.3341, GNorm = 3.5879, lr_0 = 6.3148e-04
Loss = 9.6193e-01, PNorm = 38.3686, GNorm = 2.2688, lr_0 = 6.2889e-04
Loss = 1.0292e+00, PNorm = 38.4003, GNorm = 2.5420, lr_0 = 6.2630e-04
Loss = 1.0218e+00, PNorm = 38.4328, GNorm = 1.6623, lr_0 = 6.2373e-04
Loss = 9.5861e-01, PNorm = 38.4579, GNorm = 2.9060, lr_0 = 6.2118e-04
Loss = 9.8206e-01, PNorm = 38.4858, GNorm = 1.1924, lr_0 = 6.1863e-04
Loss = 9.5251e-01, PNorm = 38.5053, GNorm = 2.5410, lr_0 = 6.1609e-04
Loss = 9.0937e-01, PNorm = 38.5303, GNorm = 2.7164, lr_0 = 6.1356e-04
Loss = 1.0699e+00, PNorm = 38.5645, GNorm = 1.6613, lr_0 = 6.1104e-04
Loss = 9.4499e-01, PNorm = 38.5927, GNorm = 2.1617, lr_0 = 6.0854e-04
Loss = 1.0202e+00, PNorm = 38.5945, GNorm = 6.8828, lr_0 = 6.0829e-04
Validation rmse = 0.957763
Epoch 8
Loss = 1.0734e+00, PNorm = 38.6171, GNorm = 1.5186, lr_0 = 6.0579e-04
Loss = 9.8083e-01, PNorm = 38.6468, GNorm = 2.8530, lr_0 = 6.0330e-04
Loss = 9.9295e-01, PNorm = 38.6733, GNorm = 2.5617, lr_0 = 6.0083e-04
Loss = 9.0998e-01, PNorm = 38.7046, GNorm = 1.2365, lr_0 = 5.9836e-04
Loss = 8.8780e-01, PNorm = 38.7353, GNorm = 2.1470, lr_0 = 5.9591e-04
Loss = 9.5525e-01, PNorm = 38.7575, GNorm = 4.4380, lr_0 = 5.9346e-04
Loss = 6.7760e-01, PNorm = 38.7844, GNorm = 2.2661, lr_0 = 5.9103e-04
Loss = 9.7095e-01, PNorm = 38.8296, GNorm = 7.0663, lr_0 = 5.8860e-04
Loss = 1.0590e+00, PNorm = 38.8672, GNorm = 1.1448, lr_0 = 5.8619e-04
Loss = 8.9894e-01, PNorm = 38.9033, GNorm = 1.9062, lr_0 = 5.8378e-04
Loss = 1.0902e+00, PNorm = 38.9299, GNorm = 2.2943, lr_0 = 5.8139e-04
Loss = 9.8549e-01, PNorm = 38.9468, GNorm = 1.4128, lr_0 = 5.7900e-04
Loss = 9.9961e-01, PNorm = 38.9724, GNorm = 0.9691, lr_0 = 5.7662e-04
Loss = 9.7135e-01, PNorm = 39.0000, GNorm = 1.7479, lr_0 = 5.7426e-04
Loss = 8.3109e-01, PNorm = 39.0205, GNorm = 3.2031, lr_0 = 5.7190e-04
Loss = 8.8695e-01, PNorm = 39.0451, GNorm = 3.4692, lr_0 = 5.6956e-04
Loss = 7.6291e-01, PNorm = 39.0747, GNorm = 2.7570, lr_0 = 5.6722e-04
Loss = 8.2632e-01, PNorm = 39.1060, GNorm = 3.8295, lr_0 = 5.6489e-04
Loss = 9.5255e-01, PNorm = 39.1314, GNorm = 2.8973, lr_0 = 5.6257e-04
Loss = 1.0252e+00, PNorm = 39.1539, GNorm = 1.8910, lr_0 = 5.6026e-04
Loss = 2.1579e+00, PNorm = 39.1588, GNorm = 5.2339, lr_0 = 5.6003e-04
Validation rmse = 0.880491
Epoch 9
Loss = 9.4834e-01, PNorm = 39.1987, GNorm = 1.8527, lr_0 = 5.5774e-04
Loss = 8.3124e-01, PNorm = 39.2319, GNorm = 1.5589, lr_0 = 5.5545e-04
Loss = 9.7481e-01, PNorm = 39.2502, GNorm = 5.6297, lr_0 = 5.5317e-04
Loss = 8.3869e-01, PNorm = 39.2671, GNorm = 3.4604, lr_0 = 5.5090e-04
Loss = 9.9761e-01, PNorm = 39.2859, GNorm = 1.9790, lr_0 = 5.4864e-04
Loss = 8.7343e-01, PNorm = 39.3058, GNorm = 1.9975, lr_0 = 5.4639e-04
Loss = 8.7309e-01, PNorm = 39.3362, GNorm = 1.4973, lr_0 = 5.4414e-04
Loss = 8.5176e-01, PNorm = 39.3665, GNorm = 3.6527, lr_0 = 5.4191e-04
Loss = 9.5943e-01, PNorm = 39.3878, GNorm = 1.8298, lr_0 = 5.3969e-04
Loss = 8.0487e-01, PNorm = 39.4148, GNorm = 2.4933, lr_0 = 5.3747e-04
Loss = 8.2641e-01, PNorm = 39.4473, GNorm = 2.8289, lr_0 = 5.3527e-04
Loss = 8.1783e-01, PNorm = 39.4807, GNorm = 3.1966, lr_0 = 5.3307e-04
Loss = 8.4223e-01, PNorm = 39.5177, GNorm = 3.0032, lr_0 = 5.3088e-04
Loss = 8.7565e-01, PNorm = 39.5359, GNorm = 2.6682, lr_0 = 5.2871e-04
Loss = 8.8425e-01, PNorm = 39.5635, GNorm = 1.2320, lr_0 = 5.2654e-04
Loss = 1.0393e+00, PNorm = 39.5976, GNorm = 4.0842, lr_0 = 5.2438e-04
Loss = 1.0658e+00, PNorm = 39.6283, GNorm = 2.4294, lr_0 = 5.2222e-04
Loss = 8.5714e-01, PNorm = 39.6570, GNorm = 3.0210, lr_0 = 5.2008e-04
Loss = 7.8931e-01, PNorm = 39.6725, GNorm = 1.2499, lr_0 = 5.1795e-04
Loss = 9.6256e-01, PNorm = 39.6932, GNorm = 3.9541, lr_0 = 5.1582e-04
Validation rmse = 0.891223
Epoch 10
Loss = 8.4425e-01, PNorm = 39.7257, GNorm = 4.1979, lr_0 = 5.1371e-04
Loss = 9.4421e-01, PNorm = 39.7526, GNorm = 3.3642, lr_0 = 5.1160e-04
Loss = 9.1170e-01, PNorm = 39.7820, GNorm = 2.1744, lr_0 = 5.0950e-04
Loss = 9.0111e-01, PNorm = 39.8097, GNorm = 2.1031, lr_0 = 5.0741e-04
Loss = 8.4702e-01, PNorm = 39.8378, GNorm = 1.6179, lr_0 = 5.0533e-04
Loss = 8.8362e-01, PNorm = 39.8595, GNorm = 1.8824, lr_0 = 5.0325e-04
Loss = 9.8597e-01, PNorm = 39.8830, GNorm = 4.6770, lr_0 = 5.0119e-04
Loss = 7.7437e-01, PNorm = 39.9050, GNorm = 1.7683, lr_0 = 4.9913e-04
Loss = 9.6231e-01, PNorm = 39.9359, GNorm = 1.7182, lr_0 = 4.9708e-04
Loss = 8.0723e-01, PNorm = 39.9624, GNorm = 1.9587, lr_0 = 4.9504e-04
Loss = 8.3704e-01, PNorm = 39.9870, GNorm = 2.7422, lr_0 = 4.9301e-04
Loss = 7.8363e-01, PNorm = 40.0194, GNorm = 1.9553, lr_0 = 4.9099e-04
Loss = 7.5970e-01, PNorm = 40.0362, GNorm = 3.3640, lr_0 = 4.8897e-04
Loss = 8.2713e-01, PNorm = 40.0579, GNorm = 6.0014, lr_0 = 4.8697e-04
Loss = 8.4700e-01, PNorm = 40.0831, GNorm = 1.0472, lr_0 = 4.8497e-04
Loss = 8.8548e-01, PNorm = 40.1061, GNorm = 1.4484, lr_0 = 4.8298e-04
Loss = 8.9506e-01, PNorm = 40.1266, GNorm = 1.8513, lr_0 = 4.8100e-04
Loss = 8.0329e-01, PNorm = 40.1438, GNorm = 2.2975, lr_0 = 4.7902e-04
Loss = 8.5028e-01, PNorm = 40.1608, GNorm = 2.3064, lr_0 = 4.7706e-04
Loss = 7.6486e-01, PNorm = 40.1805, GNorm = 4.9238, lr_0 = 4.7510e-04
Validation rmse = 0.825592
Epoch 11
Loss = 7.4721e-01, PNorm = 40.1976, GNorm = 2.4578, lr_0 = 4.7296e-04
Loss = 9.2379e-01, PNorm = 40.2115, GNorm = 3.3866, lr_0 = 4.7102e-04
Loss = 7.0994e-01, PNorm = 40.2510, GNorm = 1.7720, lr_0 = 4.6908e-04
Loss = 7.2199e-01, PNorm = 40.2837, GNorm = 7.5540, lr_0 = 4.6716e-04
Loss = 8.0271e-01, PNorm = 40.3027, GNorm = 2.8132, lr_0 = 4.6524e-04
Loss = 9.4411e-01, PNorm = 40.3271, GNorm = 2.2641, lr_0 = 4.6333e-04
Loss = 6.8056e-01, PNorm = 40.3532, GNorm = 1.3203, lr_0 = 4.6143e-04
Loss = 8.7042e-01, PNorm = 40.3717, GNorm = 1.9590, lr_0 = 4.5954e-04
Loss = 6.7365e-01, PNorm = 40.3901, GNorm = 2.8473, lr_0 = 4.5765e-04
Loss = 7.3144e-01, PNorm = 40.4089, GNorm = 2.0763, lr_0 = 4.5577e-04
Loss = 7.2819e-01, PNorm = 40.4254, GNorm = 2.7293, lr_0 = 4.5390e-04
Loss = 7.5739e-01, PNorm = 40.4505, GNorm = 3.5697, lr_0 = 4.5204e-04
Loss = 8.2806e-01, PNorm = 40.4735, GNorm = 2.3368, lr_0 = 4.5019e-04
Loss = 9.4897e-01, PNorm = 40.4987, GNorm = 1.5682, lr_0 = 4.4834e-04
Loss = 8.1809e-01, PNorm = 40.5237, GNorm = 2.1176, lr_0 = 4.4650e-04
Loss = 8.7270e-01, PNorm = 40.5413, GNorm = 4.0609, lr_0 = 4.4467e-04
Loss = 7.0277e-01, PNorm = 40.5558, GNorm = 4.7925, lr_0 = 4.4284e-04
Loss = 9.9448e-01, PNorm = 40.5771, GNorm = 2.0162, lr_0 = 4.4103e-04
Loss = 7.8538e-01, PNorm = 40.6014, GNorm = 2.4126, lr_0 = 4.3922e-04
Loss = 8.6582e-01, PNorm = 40.6215, GNorm = 2.9965, lr_0 = 4.3741e-04
Validation rmse = 0.792029
Epoch 12
Loss = 7.5782e-01, PNorm = 40.6448, GNorm = 4.0811, lr_0 = 4.3544e-04
Loss = 6.9406e-01, PNorm = 40.6676, GNorm = 2.6483, lr_0 = 4.3365e-04
Loss = 8.0554e-01, PNorm = 40.6831, GNorm = 10.4897, lr_0 = 4.3187e-04
Loss = 8.6178e-01, PNorm = 40.6969, GNorm = 1.4003, lr_0 = 4.3010e-04
Loss = 8.7495e-01, PNorm = 40.7117, GNorm = 2.0850, lr_0 = 4.2834e-04
Loss = 7.5309e-01, PNorm = 40.7260, GNorm = 4.3999, lr_0 = 4.2658e-04
Loss = 8.2199e-01, PNorm = 40.7459, GNorm = 4.5131, lr_0 = 4.2483e-04
Loss = 8.1454e-01, PNorm = 40.7671, GNorm = 3.4807, lr_0 = 4.2309e-04
Loss = 8.6820e-01, PNorm = 40.7787, GNorm = 2.6502, lr_0 = 4.2135e-04
Loss = 7.0850e-01, PNorm = 40.7922, GNorm = 1.9242, lr_0 = 4.1962e-04
Loss = 5.7942e-01, PNorm = 40.8087, GNorm = 2.1694, lr_0 = 4.1790e-04
Loss = 7.6206e-01, PNorm = 40.8339, GNorm = 3.3748, lr_0 = 4.1618e-04
Loss = 6.6301e-01, PNorm = 40.8440, GNorm = 2.7529, lr_0 = 4.1448e-04
Loss = 7.3213e-01, PNorm = 40.8567, GNorm = 2.5398, lr_0 = 4.1278e-04
Loss = 6.0620e-01, PNorm = 40.8785, GNorm = 2.5577, lr_0 = 4.1108e-04
Loss = 7.7254e-01, PNorm = 40.8937, GNorm = 2.0244, lr_0 = 4.0940e-04
Loss = 7.6050e-01, PNorm = 40.9084, GNorm = 2.0053, lr_0 = 4.0772e-04
Loss = 8.3623e-01, PNorm = 40.9299, GNorm = 2.4031, lr_0 = 4.0604e-04
Loss = 7.4650e-01, PNorm = 40.9433, GNorm = 3.0097, lr_0 = 4.0438e-04
Loss = 8.8258e-01, PNorm = 40.9592, GNorm = 6.1298, lr_0 = 4.0272e-04
Validation rmse = 0.792260
Epoch 13
Loss = 6.7707e-01, PNorm = 40.9881, GNorm = 3.5310, lr_0 = 4.0090e-04
Loss = 7.5888e-01, PNorm = 41.0148, GNorm = 1.5842, lr_0 = 3.9925e-04
Loss = 8.9414e-01, PNorm = 41.0344, GNorm = 2.1252, lr_0 = 3.9762e-04
Loss = 8.8029e-01, PNorm = 41.0493, GNorm = 2.8377, lr_0 = 3.9598e-04
Loss = 6.4985e-01, PNorm = 41.0605, GNorm = 4.6112, lr_0 = 3.9436e-04
Loss = 7.6150e-01, PNorm = 41.0757, GNorm = 4.2163, lr_0 = 3.9274e-04
Loss = 7.2122e-01, PNorm = 41.0934, GNorm = 3.5742, lr_0 = 3.9113e-04
Loss = 7.2379e-01, PNorm = 41.1045, GNorm = 3.9933, lr_0 = 3.8953e-04
Loss = 6.0760e-01, PNorm = 41.1194, GNorm = 2.7358, lr_0 = 3.8793e-04
Loss = 7.4508e-01, PNorm = 41.1360, GNorm = 6.5267, lr_0 = 3.8634e-04
Loss = 6.6573e-01, PNorm = 41.1594, GNorm = 2.8073, lr_0 = 3.8475e-04
Loss = 7.2252e-01, PNorm = 41.1796, GNorm = 2.0659, lr_0 = 3.8317e-04
Loss = 8.0871e-01, PNorm = 41.1930, GNorm = 4.0253, lr_0 = 3.8160e-04
Loss = 7.0293e-01, PNorm = 41.2111, GNorm = 2.5986, lr_0 = 3.8003e-04
Loss = 6.5739e-01, PNorm = 41.2296, GNorm = 1.9872, lr_0 = 3.7847e-04
Loss = 6.8947e-01, PNorm = 41.2453, GNorm = 4.8758, lr_0 = 3.7692e-04
Loss = 7.7156e-01, PNorm = 41.2581, GNorm = 5.7523, lr_0 = 3.7537e-04
Loss = 7.4336e-01, PNorm = 41.2716, GNorm = 5.9989, lr_0 = 3.7383e-04
Loss = 7.6416e-01, PNorm = 41.2882, GNorm = 2.0320, lr_0 = 3.7230e-04
Loss = 7.8803e-01, PNorm = 41.3003, GNorm = 1.8428, lr_0 = 3.7077e-04
Validation rmse = 0.741369
Epoch 14
Loss = 7.3770e-01, PNorm = 41.3122, GNorm = 2.2244, lr_0 = 3.6910e-04
Loss = 6.8266e-01, PNorm = 41.3314, GNorm = 3.9923, lr_0 = 3.6758e-04
Loss = 6.1985e-01, PNorm = 41.3549, GNorm = 3.9421, lr_0 = 3.6608e-04
Loss = 7.3902e-01, PNorm = 41.3727, GNorm = 3.9588, lr_0 = 3.6457e-04
Loss = 6.9456e-01, PNorm = 41.3843, GNorm = 3.3914, lr_0 = 3.6308e-04
Loss = 7.2415e-01, PNorm = 41.3998, GNorm = 3.2116, lr_0 = 3.6159e-04
Loss = 6.3139e-01, PNorm = 41.4159, GNorm = 5.7415, lr_0 = 3.6010e-04
Loss = 6.7993e-01, PNorm = 41.4262, GNorm = 4.1198, lr_0 = 3.5863e-04
Loss = 5.6841e-01, PNorm = 41.4354, GNorm = 5.4589, lr_0 = 3.5716e-04
Loss = 6.8978e-01, PNorm = 41.4511, GNorm = 1.9697, lr_0 = 3.5569e-04
Loss = 7.0663e-01, PNorm = 41.4629, GNorm = 3.1045, lr_0 = 3.5423e-04
Loss = 6.6528e-01, PNorm = 41.4743, GNorm = 3.1292, lr_0 = 3.5278e-04
Loss = 6.3029e-01, PNorm = 41.4904, GNorm = 4.2788, lr_0 = 3.5133e-04
Loss = 6.7128e-01, PNorm = 41.5066, GNorm = 4.2077, lr_0 = 3.4989e-04
Loss = 7.8944e-01, PNorm = 41.5201, GNorm = 2.1600, lr_0 = 3.4845e-04
Loss = 6.9689e-01, PNorm = 41.5280, GNorm = 1.9978, lr_0 = 3.4702e-04
Loss = 6.6466e-01, PNorm = 41.5400, GNorm = 7.0308, lr_0 = 3.4560e-04
Loss = 7.3902e-01, PNorm = 41.5524, GNorm = 11.5917, lr_0 = 3.4418e-04
Loss = 6.9607e-01, PNorm = 41.5675, GNorm = 2.1549, lr_0 = 3.4277e-04
Loss = 7.0122e-01, PNorm = 41.5819, GNorm = 2.2009, lr_0 = 3.4136e-04
Validation rmse = 0.821498
Epoch 15
Loss = 7.4084e-01, PNorm = 41.6069, GNorm = 3.2140, lr_0 = 3.3982e-04
Loss = 7.5362e-01, PNorm = 41.6211, GNorm = 2.2727, lr_0 = 3.3843e-04
Loss = 7.3405e-01, PNorm = 41.6342, GNorm = 3.9594, lr_0 = 3.3704e-04
Loss = 5.3990e-01, PNorm = 41.6531, GNorm = 4.0225, lr_0 = 3.3565e-04
Loss = 6.6283e-01, PNorm = 41.6717, GNorm = 4.1441, lr_0 = 3.3428e-04
Loss = 7.5521e-01, PNorm = 41.6855, GNorm = 3.7015, lr_0 = 3.3291e-04
Loss = 6.1881e-01, PNorm = 41.6988, GNorm = 4.9984, lr_0 = 3.3154e-04
Loss = 5.8378e-01, PNorm = 41.7104, GNorm = 3.2255, lr_0 = 3.3018e-04
Loss = 5.8183e-01, PNorm = 41.7245, GNorm = 3.5417, lr_0 = 3.2882e-04
Loss = 7.0788e-01, PNorm = 41.7324, GNorm = 3.3313, lr_0 = 3.2748e-04
Loss = 5.4946e-01, PNorm = 41.7464, GNorm = 4.5284, lr_0 = 3.2613e-04
Loss = 6.9660e-01, PNorm = 41.7543, GNorm = 2.2117, lr_0 = 3.2479e-04
Loss = 7.5931e-01, PNorm = 41.7583, GNorm = 1.7903, lr_0 = 3.2346e-04
Loss = 5.7470e-01, PNorm = 41.7716, GNorm = 3.7014, lr_0 = 3.2213e-04
Loss = 5.8094e-01, PNorm = 41.7854, GNorm = 5.7145, lr_0 = 3.2081e-04
Loss = 7.2741e-01, PNorm = 41.7987, GNorm = 4.4262, lr_0 = 3.1950e-04
Loss = 7.4646e-01, PNorm = 41.8115, GNorm = 2.9422, lr_0 = 3.1818e-04
Loss = 6.4702e-01, PNorm = 41.8247, GNorm = 3.2646, lr_0 = 3.1688e-04
Loss = 6.7843e-01, PNorm = 41.8389, GNorm = 4.6554, lr_0 = 3.1558e-04
Loss = 6.3267e-01, PNorm = 41.8531, GNorm = 3.0543, lr_0 = 3.1428e-04
Validation rmse = 0.716736
Epoch 16
Loss = 7.6596e-01, PNorm = 41.8714, GNorm = 4.8316, lr_0 = 3.1287e-04
Loss = 7.4569e-01, PNorm = 41.8837, GNorm = 3.0637, lr_0 = 3.1158e-04
Loss = 6.8506e-01, PNorm = 41.8950, GNorm = 2.6455, lr_0 = 3.1030e-04
Loss = 5.9391e-01, PNorm = 41.9109, GNorm = 3.9689, lr_0 = 3.0903e-04
Loss = 5.7459e-01, PNorm = 41.9255, GNorm = 5.8892, lr_0 = 3.0776e-04
Loss = 6.5778e-01, PNorm = 41.9403, GNorm = 3.3411, lr_0 = 3.0650e-04
Loss = 6.1586e-01, PNorm = 41.9534, GNorm = 2.1734, lr_0 = 3.0524e-04
Loss = 4.9544e-01, PNorm = 41.9660, GNorm = 2.9133, lr_0 = 3.0399e-04
Loss = 4.3505e-01, PNorm = 41.9791, GNorm = 7.2061, lr_0 = 3.0274e-04
Loss = 5.9594e-01, PNorm = 41.9833, GNorm = 8.4556, lr_0 = 3.0150e-04
Loss = 7.0200e-01, PNorm = 41.9915, GNorm = 2.3137, lr_0 = 3.0026e-04
Loss = 6.7016e-01, PNorm = 41.9992, GNorm = 2.6562, lr_0 = 2.9903e-04
Loss = 6.0593e-01, PNorm = 42.0061, GNorm = 2.8280, lr_0 = 2.9780e-04
Loss = 6.2829e-01, PNorm = 42.0150, GNorm = 5.5045, lr_0 = 2.9658e-04
Loss = 5.9250e-01, PNorm = 42.0279, GNorm = 4.5698, lr_0 = 2.9536e-04
Loss = 7.7176e-01, PNorm = 42.0337, GNorm = 3.7111, lr_0 = 2.9415e-04
Loss = 5.9725e-01, PNorm = 42.0427, GNorm = 3.3973, lr_0 = 2.9294e-04
Loss = 6.6258e-01, PNorm = 42.0575, GNorm = 2.1823, lr_0 = 2.9174e-04
Loss = 5.3300e-01, PNorm = 42.0711, GNorm = 3.3669, lr_0 = 2.9055e-04
Loss = 6.7389e-01, PNorm = 42.0857, GNorm = 5.4350, lr_0 = 2.8935e-04
Validation rmse = 0.764194
Epoch 17
Loss = 6.5848e-01, PNorm = 42.0954, GNorm = 5.8906, lr_0 = 2.8805e-04
Loss = 6.1040e-01, PNorm = 42.0976, GNorm = 3.5153, lr_0 = 2.8687e-04
Loss = 5.2408e-01, PNorm = 42.1091, GNorm = 2.8208, lr_0 = 2.8569e-04
Loss = 6.7374e-01, PNorm = 42.1238, GNorm = 4.3825, lr_0 = 2.8452e-04
Loss = 5.6314e-01, PNorm = 42.1339, GNorm = 2.9030, lr_0 = 2.8335e-04
Loss = 5.4175e-01, PNorm = 42.1404, GNorm = 6.4010, lr_0 = 2.8219e-04
Loss = 6.4016e-01, PNorm = 42.1480, GNorm = 7.0191, lr_0 = 2.8103e-04
Loss = 6.1274e-01, PNorm = 42.1553, GNorm = 4.8372, lr_0 = 2.7988e-04
Loss = 5.7091e-01, PNorm = 42.1636, GNorm = 3.4277, lr_0 = 2.7873e-04
Loss = 5.5693e-01, PNorm = 42.1728, GNorm = 2.5172, lr_0 = 2.7758e-04
Loss = 5.5864e-01, PNorm = 42.1871, GNorm = 3.3438, lr_0 = 2.7644e-04
Loss = 5.5861e-01, PNorm = 42.1957, GNorm = 4.1186, lr_0 = 2.7531e-04
Loss = 7.4172e-01, PNorm = 42.2045, GNorm = 5.7324, lr_0 = 2.7418e-04
Loss = 5.5363e-01, PNorm = 42.2122, GNorm = 3.4199, lr_0 = 2.7305e-04
Loss = 6.8181e-01, PNorm = 42.2099, GNorm = 4.5691, lr_0 = 2.7193e-04
Loss = 6.0309e-01, PNorm = 42.2160, GNorm = 3.2851, lr_0 = 2.7082e-04
Loss = 4.8986e-01, PNorm = 42.2219, GNorm = 7.3856, lr_0 = 2.6971e-04
Loss = 5.9050e-01, PNorm = 42.2309, GNorm = 2.7293, lr_0 = 2.6860e-04
Loss = 6.8926e-01, PNorm = 42.2466, GNorm = 4.8392, lr_0 = 2.6750e-04
Loss = 5.3951e-01, PNorm = 42.2599, GNorm = 4.8174, lr_0 = 2.6640e-04
Validation rmse = 0.699502
Epoch 18
Loss = 5.5484e-01, PNorm = 42.2746, GNorm = 4.0309, lr_0 = 2.6520e-04
Loss = 5.7551e-01, PNorm = 42.2845, GNorm = 4.8065, lr_0 = 2.6411e-04
Loss = 5.1795e-01, PNorm = 42.2931, GNorm = 6.0646, lr_0 = 2.6303e-04
Loss = 4.9603e-01, PNorm = 42.3064, GNorm = 7.1319, lr_0 = 2.6195e-04
Loss = 3.6574e-01, PNorm = 42.3194, GNorm = 3.8269, lr_0 = 2.6087e-04
Loss = 4.4110e-01, PNorm = 42.3299, GNorm = 12.3959, lr_0 = 2.5980e-04
Loss = 5.0348e-01, PNorm = 42.3429, GNorm = 12.7109, lr_0 = 2.5874e-04
Loss = 6.8484e-01, PNorm = 42.3534, GNorm = 3.1314, lr_0 = 2.5767e-04
Loss = 5.9942e-01, PNorm = 42.3608, GNorm = 6.5084, lr_0 = 2.5662e-04
Loss = 5.2818e-01, PNorm = 42.3655, GNorm = 3.0312, lr_0 = 2.5556e-04
Loss = 5.3048e-01, PNorm = 42.3747, GNorm = 3.2078, lr_0 = 2.5452e-04
Loss = 5.8164e-01, PNorm = 42.3864, GNorm = 2.2988, lr_0 = 2.5347e-04
Loss = 6.6106e-01, PNorm = 42.3935, GNorm = 4.0587, lr_0 = 2.5243e-04
Loss = 5.0177e-01, PNorm = 42.4022, GNorm = 4.3624, lr_0 = 2.5140e-04
Loss = 3.5602e-01, PNorm = 42.4130, GNorm = 3.6401, lr_0 = 2.5036e-04
Loss = 5.3675e-01, PNorm = 42.4172, GNorm = 3.4984, lr_0 = 2.4934e-04
Loss = 5.2083e-01, PNorm = 42.4271, GNorm = 3.9228, lr_0 = 2.4831e-04
Loss = 5.9251e-01, PNorm = 42.4345, GNorm = 5.6627, lr_0 = 2.4729e-04
Loss = 6.2731e-01, PNorm = 42.4444, GNorm = 3.0442, lr_0 = 2.4628e-04
Loss = 7.0176e-01, PNorm = 42.4527, GNorm = 2.5247, lr_0 = 2.4527e-04
Validation rmse = 0.713831
Epoch 19
Loss = 4.8671e-01, PNorm = 42.4593, GNorm = 7.1479, lr_0 = 2.4416e-04
Loss = 6.0772e-01, PNorm = 42.4651, GNorm = 5.6455, lr_0 = 2.4316e-04
Loss = 5.9747e-01, PNorm = 42.4718, GNorm = 5.6961, lr_0 = 2.4216e-04
Loss = 5.8449e-01, PNorm = 42.4778, GNorm = 3.0505, lr_0 = 2.4117e-04
Loss = 5.0768e-01, PNorm = 42.4863, GNorm = 5.3201, lr_0 = 2.4018e-04
Loss = 4.4631e-01, PNorm = 42.4922, GNorm = 6.3711, lr_0 = 2.3919e-04
Loss = 5.4203e-01, PNorm = 42.5012, GNorm = 7.1526, lr_0 = 2.3821e-04
Loss = 4.8518e-01, PNorm = 42.5125, GNorm = 4.5676, lr_0 = 2.3723e-04
Loss = 6.1401e-01, PNorm = 42.5223, GNorm = 10.1217, lr_0 = 2.3626e-04
Loss = 5.5642e-01, PNorm = 42.5276, GNorm = 3.8903, lr_0 = 2.3529e-04
Loss = 4.8720e-01, PNorm = 42.5320, GNorm = 2.8978, lr_0 = 2.3433e-04
Loss = 5.6258e-01, PNorm = 42.5403, GNorm = 4.2261, lr_0 = 2.3336e-04
Loss = 6.2901e-01, PNorm = 42.5497, GNorm = 3.4573, lr_0 = 2.3241e-04
Loss = 5.5031e-01, PNorm = 42.5577, GNorm = 4.3974, lr_0 = 2.3145e-04
Loss = 5.5157e-01, PNorm = 42.5634, GNorm = 3.0060, lr_0 = 2.3050e-04
Loss = 4.1671e-01, PNorm = 42.5701, GNorm = 3.4042, lr_0 = 2.2956e-04
Loss = 4.0331e-01, PNorm = 42.5779, GNorm = 7.4503, lr_0 = 2.2862e-04
Loss = 5.1183e-01, PNorm = 42.5837, GNorm = 7.1645, lr_0 = 2.2768e-04
Loss = 5.4111e-01, PNorm = 42.5936, GNorm = 7.1483, lr_0 = 2.2674e-04
Loss = 4.6671e-01, PNorm = 42.6073, GNorm = 3.0431, lr_0 = 2.2581e-04
Validation rmse = 0.698013
Epoch 20
Loss = 4.0050e-01, PNorm = 42.6183, GNorm = 5.5181, lr_0 = 2.2489e-04
Loss = 3.8982e-01, PNorm = 42.6297, GNorm = 14.3874, lr_0 = 2.2396e-04
Loss = 4.1836e-01, PNorm = 42.6371, GNorm = 7.2133, lr_0 = 2.2305e-04
Loss = 3.6264e-01, PNorm = 42.6441, GNorm = 7.2500, lr_0 = 2.2213e-04
Loss = 5.0428e-01, PNorm = 42.6542, GNorm = 5.4278, lr_0 = 2.2122e-04
Loss = 5.8155e-01, PNorm = 42.6615, GNorm = 3.6261, lr_0 = 2.2031e-04
Loss = 5.3710e-01, PNorm = 42.6644, GNorm = 5.4144, lr_0 = 2.1941e-04
Loss = 4.2268e-01, PNorm = 42.6674, GNorm = 3.5510, lr_0 = 2.1851e-04
Loss = 4.8535e-01, PNorm = 42.6747, GNorm = 5.3605, lr_0 = 2.1761e-04
Loss = 5.7279e-01, PNorm = 42.6796, GNorm = 4.8611, lr_0 = 2.1672e-04
Loss = 3.9690e-01, PNorm = 42.6886, GNorm = 5.9464, lr_0 = 2.1583e-04
Loss = 4.6932e-01, PNorm = 42.6962, GNorm = 3.9377, lr_0 = 2.1494e-04
Loss = 5.7111e-01, PNorm = 42.7024, GNorm = 7.7921, lr_0 = 2.1406e-04
Loss = 4.6242e-01, PNorm = 42.7098, GNorm = 2.4525, lr_0 = 2.1318e-04
Loss = 5.3774e-01, PNorm = 42.7161, GNorm = 3.0964, lr_0 = 2.1231e-04
Loss = 5.6342e-01, PNorm = 42.7214, GNorm = 8.9824, lr_0 = 2.1144e-04
Loss = 5.9638e-01, PNorm = 42.7285, GNorm = 5.7340, lr_0 = 2.1057e-04
Loss = 4.6831e-01, PNorm = 42.7354, GNorm = 5.3737, lr_0 = 2.0970e-04
Loss = 4.2969e-01, PNorm = 42.7436, GNorm = 3.4677, lr_0 = 2.0884e-04
Loss = 4.7237e-01, PNorm = 42.7507, GNorm = 5.8049, lr_0 = 2.0799e-04
Validation rmse = 0.710338
Epoch 21
Loss = 5.7732e-01, PNorm = 42.7590, GNorm = 5.3272, lr_0 = 2.0705e-04
Loss = 3.9451e-01, PNorm = 42.7669, GNorm = 4.7118, lr_0 = 2.0620e-04
Loss = 4.4146e-01, PNorm = 42.7738, GNorm = 3.5793, lr_0 = 2.0535e-04
Loss = 4.4140e-01, PNorm = 42.7798, GNorm = 4.4500, lr_0 = 2.0451e-04
Loss = 5.7304e-01, PNorm = 42.7843, GNorm = 3.4059, lr_0 = 2.0367e-04
Loss = 4.4963e-01, PNorm = 42.7900, GNorm = 6.4419, lr_0 = 2.0283e-04
Loss = 4.1908e-01, PNorm = 42.7980, GNorm = 3.0581, lr_0 = 2.0200e-04
Loss = 3.4877e-01, PNorm = 42.8110, GNorm = 4.4028, lr_0 = 2.0117e-04
Loss = 5.5149e-01, PNorm = 42.8205, GNorm = 12.7291, lr_0 = 2.0035e-04
Loss = 2.9789e-01, PNorm = 42.8288, GNorm = 4.8055, lr_0 = 1.9953e-04
Loss = 5.6560e-01, PNorm = 42.8367, GNorm = 5.7302, lr_0 = 1.9871e-04
Loss = 5.7858e-01, PNorm = 42.8370, GNorm = 6.9696, lr_0 = 1.9789e-04
Loss = 5.6303e-01, PNorm = 42.8372, GNorm = 6.6519, lr_0 = 1.9708e-04
Loss = 4.3441e-01, PNorm = 42.8421, GNorm = 3.4454, lr_0 = 1.9627e-04
Loss = 4.3338e-01, PNorm = 42.8494, GNorm = 6.4346, lr_0 = 1.9547e-04
Loss = 5.6031e-01, PNorm = 42.8570, GNorm = 4.2500, lr_0 = 1.9466e-04
Loss = 3.6322e-01, PNorm = 42.8628, GNorm = 5.4807, lr_0 = 1.9387e-04
Loss = 3.2246e-01, PNorm = 42.8715, GNorm = 4.2839, lr_0 = 1.9307e-04
Loss = 5.8370e-01, PNorm = 42.8758, GNorm = 7.7686, lr_0 = 1.9228e-04
Loss = 4.4144e-01, PNorm = 42.8819, GNorm = 2.2770, lr_0 = 1.9149e-04
Validation rmse = 0.708323
Epoch 22
Loss = 4.8653e-01, PNorm = 42.8859, GNorm = 3.9646, lr_0 = 1.9062e-04
Loss = 4.1669e-01, PNorm = 42.8915, GNorm = 4.7328, lr_0 = 1.8984e-04
Loss = 4.2009e-01, PNorm = 42.8994, GNorm = 2.6615, lr_0 = 1.8906e-04
Loss = 5.2293e-01, PNorm = 42.9081, GNorm = 8.9498, lr_0 = 1.8829e-04
Loss = 4.4506e-01, PNorm = 42.9175, GNorm = 5.5058, lr_0 = 1.8751e-04
Loss = 4.4155e-01, PNorm = 42.9233, GNorm = 7.2297, lr_0 = 1.8675e-04
Loss = 4.5514e-01, PNorm = 42.9271, GNorm = 7.1013, lr_0 = 1.8598e-04
Loss = 5.5708e-01, PNorm = 42.9347, GNorm = 5.2569, lr_0 = 1.8522e-04
Loss = 2.4703e-01, PNorm = 42.9412, GNorm = 6.2136, lr_0 = 1.8446e-04
Loss = 3.7189e-01, PNorm = 42.9458, GNorm = 5.3154, lr_0 = 1.8370e-04
Loss = 3.9019e-01, PNorm = 42.9488, GNorm = 8.2027, lr_0 = 1.8295e-04
Loss = 4.6442e-01, PNorm = 42.9518, GNorm = 6.4245, lr_0 = 1.8219e-04
Loss = 3.3712e-01, PNorm = 42.9579, GNorm = 4.9922, lr_0 = 1.8145e-04
Loss = 3.4614e-01, PNorm = 42.9633, GNorm = 4.2993, lr_0 = 1.8070e-04
Loss = 4.4973e-01, PNorm = 42.9697, GNorm = 10.6977, lr_0 = 1.7996e-04
Loss = 4.5526e-01, PNorm = 42.9731, GNorm = 5.6874, lr_0 = 1.7922e-04
Loss = 4.5274e-01, PNorm = 42.9766, GNorm = 3.8917, lr_0 = 1.7849e-04
Loss = 5.0390e-01, PNorm = 42.9808, GNorm = 3.5027, lr_0 = 1.7775e-04
Loss = 5.5552e-01, PNorm = 42.9850, GNorm = 3.5027, lr_0 = 1.7703e-04
Loss = 4.9528e-01, PNorm = 42.9895, GNorm = 3.1976, lr_0 = 1.7630e-04
Validation rmse = 0.699032
Epoch 23
Loss = 3.1694e-01, PNorm = 42.9948, GNorm = 7.3005, lr_0 = 1.7550e-04
Loss = 4.0731e-01, PNorm = 43.0014, GNorm = 3.8950, lr_0 = 1.7478e-04
Loss = 5.1555e-01, PNorm = 43.0064, GNorm = 4.5321, lr_0 = 1.7407e-04
Loss = 4.4028e-01, PNorm = 43.0144, GNorm = 10.5766, lr_0 = 1.7335e-04
Loss = 4.6837e-01, PNorm = 43.0202, GNorm = 7.6779, lr_0 = 1.7264e-04
Loss = 4.4804e-01, PNorm = 43.0271, GNorm = 6.1415, lr_0 = 1.7193e-04
Loss = 3.3485e-01, PNorm = 43.0332, GNorm = 4.1153, lr_0 = 1.7123e-04
Loss = 4.8930e-01, PNorm = 43.0367, GNorm = 11.5308, lr_0 = 1.7052e-04
Loss = 2.7972e-01, PNorm = 43.0410, GNorm = 5.7357, lr_0 = 1.6982e-04
Loss = 2.7710e-01, PNorm = 43.0471, GNorm = 19.6602, lr_0 = 1.6913e-04
Loss = 4.1137e-01, PNorm = 43.0524, GNorm = 5.0752, lr_0 = 1.6843e-04
Loss = 2.1677e-01, PNorm = 43.0568, GNorm = 5.1036, lr_0 = 1.6774e-04
Loss = 5.8418e-01, PNorm = 43.0609, GNorm = 4.8911, lr_0 = 1.6705e-04
Loss = 4.4513e-01, PNorm = 43.0643, GNorm = 6.0160, lr_0 = 1.6637e-04
Loss = 3.6480e-01, PNorm = 43.0683, GNorm = 11.4180, lr_0 = 1.6569e-04
Loss = 4.2726e-01, PNorm = 43.0738, GNorm = 3.2044, lr_0 = 1.6501e-04
Loss = 4.3758e-01, PNorm = 43.0774, GNorm = 4.8706, lr_0 = 1.6433e-04
Loss = 4.4444e-01, PNorm = 43.0823, GNorm = 3.7131, lr_0 = 1.6365e-04
Loss = 6.0096e-01, PNorm = 43.0836, GNorm = 7.4298, lr_0 = 1.6298e-04
Loss = 2.9373e-01, PNorm = 43.0865, GNorm = 7.4305, lr_0 = 1.6231e-04
Validation rmse = 0.711049
Epoch 24
Loss = 4.0050e-01, PNorm = 43.0948, GNorm = 5.8433, lr_0 = 1.6158e-04
Loss = 3.2892e-01, PNorm = 43.1011, GNorm = 6.1749, lr_0 = 1.6092e-04
Loss = 4.5712e-01, PNorm = 43.1064, GNorm = 7.4893, lr_0 = 1.6026e-04
Loss = 4.0107e-01, PNorm = 43.1138, GNorm = 6.0358, lr_0 = 1.5960e-04
Loss = 4.9993e-01, PNorm = 43.1167, GNorm = 15.0302, lr_0 = 1.5895e-04
Loss = 4.8838e-01, PNorm = 43.1200, GNorm = 3.3272, lr_0 = 1.5829e-04
Loss = 4.9162e-01, PNorm = 43.1238, GNorm = 3.2966, lr_0 = 1.5764e-04
Loss = 4.1757e-01, PNorm = 43.1289, GNorm = 2.7318, lr_0 = 1.5700e-04
Loss = 3.0473e-01, PNorm = 43.1339, GNorm = 8.2425, lr_0 = 1.5635e-04
Loss = 4.2866e-01, PNorm = 43.1378, GNorm = 6.8613, lr_0 = 1.5571e-04
Loss = 3.9186e-01, PNorm = 43.1411, GNorm = 5.0304, lr_0 = 1.5507e-04
Loss = 3.2142e-01, PNorm = 43.1444, GNorm = 4.7383, lr_0 = 1.5444e-04
Loss = 4.6899e-01, PNorm = 43.1469, GNorm = 3.3899, lr_0 = 1.5380e-04
Loss = 3.8966e-01, PNorm = 43.1543, GNorm = 3.1935, lr_0 = 1.5317e-04
Loss = 3.4607e-01, PNorm = 43.1610, GNorm = 23.8598, lr_0 = 1.5254e-04
Loss = 2.3234e-01, PNorm = 43.1682, GNorm = 8.0040, lr_0 = 1.5192e-04
Loss = 1.0898e-01, PNorm = 43.1745, GNorm = 4.4119, lr_0 = 1.5129e-04
Loss = 4.3013e-01, PNorm = 43.1817, GNorm = 8.7408, lr_0 = 1.5067e-04
Loss = 3.3704e-01, PNorm = 43.1877, GNorm = 12.4878, lr_0 = 1.5005e-04
Loss = 5.1853e-01, PNorm = 43.1908, GNorm = 9.5211, lr_0 = 1.4944e-04
Validation rmse = 0.692549
Epoch 25
Loss = 3.6257e-01, PNorm = 43.1953, GNorm = 9.8289, lr_0 = 1.4876e-04
Loss = 2.5371e-01, PNorm = 43.2000, GNorm = 5.7895, lr_0 = 1.4815e-04
Loss = 3.3959e-01, PNorm = 43.2040, GNorm = 4.6701, lr_0 = 1.4755e-04
Loss = 3.2073e-01, PNorm = 43.2078, GNorm = 6.8093, lr_0 = 1.4694e-04
Loss = 1.2917e-01, PNorm = 43.2126, GNorm = 6.1601, lr_0 = 1.4634e-04
Loss = 4.8649e-01, PNorm = 43.2111, GNorm = 9.9779, lr_0 = 1.4574e-04
Loss = 1.8722e-01, PNorm = 43.2115, GNorm = 2.9242, lr_0 = 1.4514e-04
Loss = 2.7865e-01, PNorm = 43.2139, GNorm = 10.0823, lr_0 = 1.4454e-04
Loss = 3.7501e-01, PNorm = 43.2184, GNorm = 23.7550, lr_0 = 1.4395e-04
Loss = 2.9973e-01, PNorm = 43.2237, GNorm = 5.1618, lr_0 = 1.4336e-04
Loss = 2.5440e-01, PNorm = 43.2292, GNorm = 8.1572, lr_0 = 1.4277e-04
Loss = 4.2969e-01, PNorm = 43.2350, GNorm = 11.7493, lr_0 = 1.4219e-04
Loss = 4.3104e-01, PNorm = 43.2400, GNorm = 3.6932, lr_0 = 1.4160e-04
Loss = 3.9805e-01, PNorm = 43.2439, GNorm = 4.0583, lr_0 = 1.4102e-04
Loss = 4.9058e-01, PNorm = 43.2467, GNorm = 10.8496, lr_0 = 1.4044e-04
Loss = 3.3629e-01, PNorm = 43.2487, GNorm = 6.8047, lr_0 = 1.3987e-04
Loss = 4.6113e-01, PNorm = 43.2531, GNorm = 7.3081, lr_0 = 1.3929e-04
Loss = 4.5436e-01, PNorm = 43.2572, GNorm = 4.3540, lr_0 = 1.3872e-04
Loss = 4.0720e-01, PNorm = 43.2610, GNorm = 5.5865, lr_0 = 1.3815e-04
Loss = 3.6568e-01, PNorm = 43.2644, GNorm = 4.0042, lr_0 = 1.3759e-04
Validation rmse = 0.692738
Epoch 26
Loss = 3.9882e-01, PNorm = 43.2708, GNorm = 6.2523, lr_0 = 1.3696e-04
Loss = 3.0139e-01, PNorm = 43.2775, GNorm = 4.1155, lr_0 = 1.3640e-04
Loss = 3.3362e-01, PNorm = 43.2819, GNorm = 7.4268, lr_0 = 1.3584e-04
Loss = 2.8274e-01, PNorm = 43.2854, GNorm = 8.6312, lr_0 = 1.3529e-04
Loss = 2.4716e-01, PNorm = 43.2889, GNorm = 3.8975, lr_0 = 1.3473e-04
Loss = 3.5951e-01, PNorm = 43.2933, GNorm = 6.4550, lr_0 = 1.3418e-04
Loss = 4.9003e-01, PNorm = 43.2946, GNorm = 11.9345, lr_0 = 1.3363e-04
Loss = 3.4307e-01, PNorm = 43.2970, GNorm = 8.5476, lr_0 = 1.3308e-04
Loss = 2.9881e-01, PNorm = 43.3017, GNorm = 5.2365, lr_0 = 1.3253e-04
Loss = 3.1482e-01, PNorm = 43.3054, GNorm = 7.7833, lr_0 = 1.3199e-04
Loss = 3.1740e-01, PNorm = 43.3094, GNorm = 3.8490, lr_0 = 1.3145e-04
Loss = 3.2363e-01, PNorm = 43.3135, GNorm = 7.9773, lr_0 = 1.3091e-04
Loss = 4.9347e-01, PNorm = 43.3176, GNorm = 4.7286, lr_0 = 1.3037e-04
Loss = 2.5547e-01, PNorm = 43.3216, GNorm = 5.8850, lr_0 = 1.2984e-04
Loss = 4.6073e-01, PNorm = 43.3244, GNorm = 5.9057, lr_0 = 1.2930e-04
Loss = 2.4751e-01, PNorm = 43.3273, GNorm = 5.6993, lr_0 = 1.2877e-04
Loss = 2.3057e-01, PNorm = 43.3313, GNorm = 5.7187, lr_0 = 1.2824e-04
Loss = 2.6044e-01, PNorm = 43.3360, GNorm = 9.7549, lr_0 = 1.2772e-04
Loss = 2.5184e-01, PNorm = 43.3390, GNorm = 6.7952, lr_0 = 1.2719e-04
Loss = 4.1023e-01, PNorm = 43.3415, GNorm = 5.4240, lr_0 = 1.2667e-04
Validation rmse = 0.703460
Epoch 27
Loss = 5.0139e-01, PNorm = 43.3440, GNorm = 4.7277, lr_0 = 1.2610e-04
Loss = 3.4028e-01, PNorm = 43.3469, GNorm = 7.5799, lr_0 = 1.2558e-04
Loss = 2.6058e-01, PNorm = 43.3515, GNorm = 6.5329, lr_0 = 1.2507e-04
Loss = 2.4336e-01, PNorm = 43.3561, GNorm = 5.1732, lr_0 = 1.2455e-04
Loss = 3.9740e-01, PNorm = 43.3619, GNorm = 5.6881, lr_0 = 1.2404e-04
Loss = 3.0327e-01, PNorm = 43.3673, GNorm = 7.4060, lr_0 = 1.2353e-04
Loss = 1.7360e-01, PNorm = 43.3729, GNorm = 6.4787, lr_0 = 1.2303e-04
Loss = 3.3606e-01, PNorm = 43.3788, GNorm = 5.0392, lr_0 = 1.2252e-04
Loss = 3.4004e-01, PNorm = 43.3806, GNorm = 8.8847, lr_0 = 1.2202e-04
Loss = 2.8624e-01, PNorm = 43.3812, GNorm = 4.1915, lr_0 = 1.2152e-04
Loss = 3.0508e-01, PNorm = 43.3833, GNorm = 8.7037, lr_0 = 1.2102e-04
Loss = 2.1118e-01, PNorm = 43.3874, GNorm = 6.1864, lr_0 = 1.2052e-04
Loss = 4.0116e-01, PNorm = 43.3901, GNorm = 12.5380, lr_0 = 1.2003e-04
Loss = 3.5467e-01, PNorm = 43.3935, GNorm = 3.6814, lr_0 = 1.1954e-04
Loss = 3.8423e-01, PNorm = 43.3992, GNorm = 17.4507, lr_0 = 1.1905e-04
Loss = 3.7470e-01, PNorm = 43.4035, GNorm = 9.8859, lr_0 = 1.1856e-04
Loss = 3.0877e-01, PNorm = 43.4050, GNorm = 10.6768, lr_0 = 1.1807e-04
Loss = 3.6246e-01, PNorm = 43.4049, GNorm = 6.6082, lr_0 = 1.1759e-04
Loss = 2.0950e-01, PNorm = 43.4060, GNorm = 10.7247, lr_0 = 1.1710e-04
Loss = 2.6970e-01, PNorm = 43.4064, GNorm = 3.8420, lr_0 = 1.1662e-04
Validation rmse = 0.696602
Epoch 28
Loss = 2.1354e-01, PNorm = 43.4098, GNorm = 9.4262, lr_0 = 1.1610e-04
Loss = 1.6918e-01, PNorm = 43.4128, GNorm = 10.7353, lr_0 = 1.1562e-04
Loss = 3.7477e-01, PNorm = 43.4195, GNorm = 4.3967, lr_0 = 1.1515e-04
Loss = 2.3718e-01, PNorm = 43.4247, GNorm = 6.7399, lr_0 = 1.1467e-04
Loss = 3.2004e-01, PNorm = 43.4280, GNorm = 5.4359, lr_0 = 1.1420e-04
Loss = 4.1426e-01, PNorm = 43.4276, GNorm = 5.5840, lr_0 = 1.1373e-04
Loss = 2.5027e-01, PNorm = 43.4300, GNorm = 7.2281, lr_0 = 1.1327e-04
Loss = 3.1435e-01, PNorm = 43.4324, GNorm = 5.6850, lr_0 = 1.1280e-04
Loss = 2.4836e-01, PNorm = 43.4346, GNorm = 10.0708, lr_0 = 1.1234e-04
Loss = 4.3358e-01, PNorm = 43.4379, GNorm = 9.0127, lr_0 = 1.1188e-04
Loss = 3.9536e-01, PNorm = 43.4420, GNorm = 4.9222, lr_0 = 1.1142e-04
Loss = 3.1378e-01, PNorm = 43.4451, GNorm = 6.7515, lr_0 = 1.1096e-04
Loss = 3.2867e-01, PNorm = 43.4475, GNorm = 6.1279, lr_0 = 1.1051e-04
Loss = 2.3476e-01, PNorm = 43.4511, GNorm = 7.6550, lr_0 = 1.1005e-04
Loss = 2.6235e-01, PNorm = 43.4526, GNorm = 4.6419, lr_0 = 1.0960e-04
Loss = 3.6371e-01, PNorm = 43.4548, GNorm = 14.1998, lr_0 = 1.0915e-04
Loss = 3.4338e-01, PNorm = 43.4574, GNorm = 6.0878, lr_0 = 1.0871e-04
Loss = 1.6231e-01, PNorm = 43.4610, GNorm = 4.8636, lr_0 = 1.0826e-04
Loss = 2.9708e-01, PNorm = 43.4635, GNorm = 7.7621, lr_0 = 1.0781e-04
Loss = 1.5862e-01, PNorm = 43.4654, GNorm = 6.8170, lr_0 = 1.0737e-04
Validation rmse = 0.696712
Epoch 29
Loss = 3.0210e-01, PNorm = 43.4682, GNorm = 5.4173, lr_0 = 1.0689e-04
Loss = 2.4354e-01, PNorm = 43.4716, GNorm = 16.1996, lr_0 = 1.0645e-04
Loss = 2.1893e-01, PNorm = 43.4738, GNorm = 6.6203, lr_0 = 1.0601e-04
Loss = 1.5678e-01, PNorm = 43.4754, GNorm = 8.6082, lr_0 = 1.0558e-04
Loss = 3.6161e-01, PNorm = 43.4774, GNorm = 5.8262, lr_0 = 1.0514e-04
Loss = 2.1831e-01, PNorm = 43.4802, GNorm = 9.4118, lr_0 = 1.0471e-04
Loss = 2.3746e-01, PNorm = 43.4843, GNorm = 8.2339, lr_0 = 1.0428e-04
Loss = 3.3546e-01, PNorm = 43.4882, GNorm = 6.9462, lr_0 = 1.0386e-04
Loss = 3.9257e-01, PNorm = 43.4908, GNorm = 6.4460, lr_0 = 1.0343e-04
Loss = 3.9534e-01, PNorm = 43.4927, GNorm = 4.7706, lr_0 = 1.0300e-04
Loss = 2.9753e-01, PNorm = 43.4943, GNorm = 11.2133, lr_0 = 1.0258e-04
Loss = 3.1172e-01, PNorm = 43.4974, GNorm = 8.7499, lr_0 = 1.0216e-04
Loss = 2.1618e-01, PNorm = 43.5011, GNorm = 19.6214, lr_0 = 1.0174e-04
Loss = 2.8340e-01, PNorm = 43.5041, GNorm = 5.6323, lr_0 = 1.0132e-04
Loss = 2.7614e-01, PNorm = 43.5068, GNorm = 9.8929, lr_0 = 1.0091e-04
Loss = 2.8329e-01, PNorm = 43.5095, GNorm = 3.4932, lr_0 = 1.0049e-04
Loss = 3.3227e-01, PNorm = 43.5128, GNorm = 8.5070, lr_0 = 1.0008e-04
Loss = 2.0343e-01, PNorm = 43.5167, GNorm = 5.5847, lr_0 = 1.0000e-04
Loss = 2.8796e-01, PNorm = 43.5209, GNorm = 8.6104, lr_0 = 1.0000e-04
Loss = 2.9964e-01, PNorm = 43.5220, GNorm = 4.4746, lr_0 = 1.0000e-04
Validation rmse = 0.692059
Model 0 best validation rmse = 0.692059 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.787104
Ensemble test rmse = 0.787104
1-fold cross validation
	Seed 0 ==> test rmse = 0.787104
Overall test rmse = 0.787104 +/- 0.000000
Elapsed time = 0:04:22
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.411305
Epoch 1
Loss = 1.4706e+00, PNorm = 43.5229, GNorm = 1.2636, lr_0 = 7.1875e-04
Validation rmse = 1.268709
Epoch 2
Loss = 1.4521e+00, PNorm = 43.5484, GNorm = 0.9123, lr_0 = 6.1897e-04
Validation rmse = 1.234196
Epoch 3
Loss = 1.3561e+00, PNorm = 43.5639, GNorm = 0.7406, lr_0 = 2.3714e-04
Validation rmse = 1.223086
Epoch 4
Loss = 1.3299e+00, PNorm = 43.5706, GNorm = 0.4798, lr_0 = 1.0000e-04
Validation rmse = 1.216295
Model 0 best validation rmse = 1.216295 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.350408
Ensemble test rmse = 1.350408
1-fold cross validation
	Seed 0 ==> test rmse = 1.350408
Overall test rmse = 1.350408 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.274001
Epoch 1
Loss = 1.5413e+00, PNorm = 43.5170, GNorm = 0.8239, lr_0 = 7.7500e-04
Validation rmse = 1.271375
Epoch 2
Loss = 1.4782e+00, PNorm = 43.5394, GNorm = 0.8493, lr_0 = 5.6234e-04
Validation rmse = 1.238095
Epoch 3
Loss = 1.3815e+00, PNorm = 43.5518, GNorm = 1.1109, lr_0 = 2.1544e-04
Validation rmse = 1.217027
Epoch 4
Loss = 1.3521e+00, PNorm = 43.5569, GNorm = 0.5653, lr_0 = 1.0000e-04
Validation rmse = 1.203873
Model 0 best validation rmse = 1.203873 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.181628
Ensemble test rmse = 1.181628
1-fold cross validation
	Seed 0 ==> test rmse = 1.181628
Overall test rmse = 1.181628 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.278269
Epoch 1
Loss = 1.5057e+00, PNorm = 43.5173, GNorm = 1.0819, lr_0 = 7.0000e-04
Validation rmse = 1.241379
Epoch 2
Loss = 1.4006e+00, PNorm = 43.5371, GNorm = 0.7873, lr_0 = 7.1097e-04
Validation rmse = 1.163309
Epoch 3
Loss = 1.3037e+00, PNorm = 43.5558, GNorm = 0.5124, lr_0 = 2.7826e-04
Validation rmse = 1.129171
Epoch 4
Loss = 1.3023e+00, PNorm = 43.5635, GNorm = 0.4413, lr_0 = 1.1860e-04
Validation rmse = 1.114043
Model 0 best validation rmse = 1.114043 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.241037
Ensemble test rmse = 1.241037
1-fold cross validation
	Seed 0 ==> test rmse = 1.241037
Overall test rmse = 1.241037 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8613e+00, PNorm = 43.5166, GNorm = 1.4415, lr_0 = 5.9500e-04
Loss = 1.4526e+00, PNorm = 43.5171, GNorm = 1.4960, lr_0 = 6.4000e-04
Validation rmse = 1.474280
Epoch 1
Loss = 1.4666e+00, PNorm = 43.5371, GNorm = 0.7677, lr_0 = 8.5770e-04
Loss = 1.3156e+00, PNorm = 43.5398, GNorm = 1.5071, lr_0 = 7.9433e-04
Validation rmse = 1.406759
Epoch 2
Loss = 1.3378e+00, PNorm = 43.5594, GNorm = 0.5877, lr_0 = 3.6869e-04
Validation rmse = 1.341778
Epoch 3
Loss = 1.2870e+00, PNorm = 43.5711, GNorm = 0.6594, lr_0 = 1.7113e-04
Validation rmse = 1.320158
Epoch 4
Loss = 1.2643e+00, PNorm = 43.5767, GNorm = 0.5669, lr_0 = 1.0000e-04
Validation rmse = 1.300953
Model 0 best validation rmse = 1.300953 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.230023
Ensemble test rmse = 1.230023
1-fold cross validation
	Seed 0 ==> test rmse = 1.230023
Overall test rmse = 1.230023 +/- 0.000000
Elapsed time = 0:00:18
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8446e+00, PNorm = 43.5159, GNorm = 1.2987, lr_0 = 5.5000e-04
Validation rmse = 1.462085
Epoch 1
Loss = 1.4536e+00, PNorm = 43.5347, GNorm = 0.8307, lr_0 = 1.0000e-03
Validation rmse = 1.417603
Epoch 2
Loss = 1.3087e+00, PNorm = 43.5638, GNorm = 0.4296, lr_0 = 4.6416e-04
Validation rmse = 1.330595
Epoch 3
Loss = 1.2506e+00, PNorm = 43.5788, GNorm = 1.2186, lr_0 = 2.1544e-04
Validation rmse = 1.284192
Epoch 4
Loss = 1.2239e+00, PNorm = 43.5857, GNorm = 1.8666, lr_0 = 1.0000e-04
Validation rmse = 1.267570
Model 0 best validation rmse = 1.267570 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.159150
Ensemble test rmse = 1.159150
1-fold cross validation
	Seed 0 ==> test rmse = 1.159150
Overall test rmse = 1.159150 +/- 0.000000
Elapsed time = 0:00:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9032e+00, PNorm = 43.5167, GNorm = 1.3034, lr_0 = 5.1250e-04
Validation rmse = 1.444482
Epoch 1
Loss = 1.4821e+00, PNorm = 43.5264, GNorm = 1.1455, lr_0 = 8.8750e-04
Validation rmse = 1.377883
Epoch 2
Loss = 1.3446e+00, PNorm = 43.5540, GNorm = 0.5740, lr_0 = 6.3908e-04
Validation rmse = 1.319469
Epoch 3
Loss = 1.2502e+00, PNorm = 43.5733, GNorm = 0.8088, lr_0 = 3.3711e-04
Validation rmse = 1.277545
Epoch 4
Loss = 1.2295e+00, PNorm = 43.5848, GNorm = 0.4834, lr_0 = 1.7783e-04
Loss = 1.1990e+00, PNorm = 43.5910, GNorm = 1.0518, lr_0 = 1.0000e-04
Validation rmse = 1.241930
Model 0 best validation rmse = 1.241930 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.157849
Ensemble test rmse = 1.157849
1-fold cross validation
	Seed 0 ==> test rmse = 1.157849
Overall test rmse = 1.157849 +/- 0.000000
Elapsed time = 0:00:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.481136
Epoch 1
Loss = 1.4706e+00, PNorm = 43.5221, GNorm = 1.3227, lr_0 = 7.1875e-04
Validation rmse = 1.358662
Epoch 2
Loss = 1.4832e+00, PNorm = 43.5439, GNorm = 0.9650, lr_0 = 6.1897e-04
Validation rmse = 1.332424
Epoch 3
Loss = 1.4048e+00, PNorm = 43.5581, GNorm = 0.6960, lr_0 = 2.3714e-04
Validation rmse = 1.307276
Epoch 4
Loss = 1.3592e+00, PNorm = 43.5632, GNorm = 0.8175, lr_0 = 1.0000e-04
Validation rmse = 1.294896
Model 0 best validation rmse = 1.294896 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.156065
Ensemble test rmse = 1.156065
1-fold cross validation
	Seed 0 ==> test rmse = 1.156065
Overall test rmse = 1.156065 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.361457
Epoch 1
Loss = 1.5216e+00, PNorm = 43.5171, GNorm = 1.0825, lr_0 = 7.7500e-04
Validation rmse = 1.310402
Epoch 2
Loss = 1.4460e+00, PNorm = 43.5367, GNorm = 0.7551, lr_0 = 5.6234e-04
Validation rmse = 1.270550
Epoch 3
Loss = 1.3572e+00, PNorm = 43.5510, GNorm = 0.8950, lr_0 = 2.1544e-04
Validation rmse = 1.232797
Epoch 4
Loss = 1.2978e+00, PNorm = 43.5562, GNorm = 0.5297, lr_0 = 1.0000e-04
Validation rmse = 1.206870
Model 0 best validation rmse = 1.206870 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.201845
Ensemble test rmse = 1.201845
1-fold cross validation
	Seed 0 ==> test rmse = 1.201845
Overall test rmse = 1.201845 +/- 0.000000
Elapsed time = 0:00:15
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.366227
Epoch 1
Loss = 1.5206e+00, PNorm = 43.5148, GNorm = 0.9738, lr_0 = 7.0000e-04
Validation rmse = 1.329269
Epoch 2
Loss = 1.4382e+00, PNorm = 43.5350, GNorm = 0.7749, lr_0 = 7.1097e-04
Validation rmse = 1.289960
Epoch 3
Loss = 1.2909e+00, PNorm = 43.5538, GNorm = 0.6820, lr_0 = 2.7826e-04
Validation rmse = 1.262949
Epoch 4
Loss = 1.2471e+00, PNorm = 43.5617, GNorm = 0.5098, lr_0 = 1.1860e-04
Validation rmse = 1.249874
Model 0 best validation rmse = 1.249874 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.200516
Ensemble test rmse = 1.200516
1-fold cross validation
	Seed 0 ==> test rmse = 1.200516
Overall test rmse = 1.200516 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7722e+00, PNorm = 43.5151, GNorm = 1.1281, lr_0 = 5.9500e-04
Loss = 1.5590e+00, PNorm = 43.5153, GNorm = 1.2005, lr_0 = 6.4000e-04
Validation rmse = 1.407652
Epoch 1
Loss = 1.4716e+00, PNorm = 43.5347, GNorm = 0.7973, lr_0 = 8.5770e-04
Loss = 1.3208e+00, PNorm = 43.5377, GNorm = 0.9431, lr_0 = 7.9433e-04
Validation rmse = 1.358766
Epoch 2
Loss = 1.3371e+00, PNorm = 43.5582, GNorm = 0.9574, lr_0 = 3.6869e-04
Validation rmse = 1.288749
Epoch 3
Loss = 1.2900e+00, PNorm = 43.5692, GNorm = 0.4859, lr_0 = 1.7113e-04
Validation rmse = 1.254626
Epoch 4
Loss = 1.2680e+00, PNorm = 43.5756, GNorm = 0.5625, lr_0 = 1.0000e-04
Validation rmse = 1.236597
Model 0 best validation rmse = 1.236597 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.139607
Ensemble test rmse = 1.139607
1-fold cross validation
	Seed 0 ==> test rmse = 1.139607
Overall test rmse = 1.139607 +/- 0.000000
Elapsed time = 0:00:18
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8560e+00, PNorm = 43.5143, GNorm = 1.1403, lr_0 = 5.5000e-04
Validation rmse = 1.417485
Epoch 1
Loss = 1.4715e+00, PNorm = 43.5260, GNorm = 1.2395, lr_0 = 1.0000e-03
Validation rmse = 1.346990
Epoch 2
Loss = 1.3258e+00, PNorm = 43.5516, GNorm = 0.6040, lr_0 = 4.6416e-04
Validation rmse = 1.299845
Epoch 3
Loss = 1.2923e+00, PNorm = 43.5661, GNorm = 1.5689, lr_0 = 2.1544e-04
Validation rmse = 1.248660
Epoch 4
Loss = 1.2108e+00, PNorm = 43.5718, GNorm = 0.7319, lr_0 = 1.0000e-04
Validation rmse = 1.238496
Model 0 best validation rmse = 1.238496 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.152765
Ensemble test rmse = 1.152765
1-fold cross validation
	Seed 0 ==> test rmse = 1.152765
Overall test rmse = 1.152765 +/- 0.000000
Elapsed time = 0:00:19
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8346e+00, PNorm = 43.5166, GNorm = 1.0127, lr_0 = 5.1250e-04
Validation rmse = 1.462290
Epoch 1
Loss = 1.4754e+00, PNorm = 43.5246, GNorm = 1.1711, lr_0 = 8.8750e-04
Validation rmse = 1.374995
Epoch 2
Loss = 1.3500e+00, PNorm = 43.5514, GNorm = 1.2656, lr_0 = 6.3908e-04
Validation rmse = 1.293088
Epoch 3
Loss = 1.2621e+00, PNorm = 43.5684, GNorm = 0.5223, lr_0 = 3.3711e-04
Validation rmse = 1.242992
Epoch 4
Loss = 1.1626e+00, PNorm = 43.5795, GNorm = 0.8987, lr_0 = 1.7783e-04
Loss = 1.1978e+00, PNorm = 43.5853, GNorm = 0.9615, lr_0 = 1.0000e-04
Validation rmse = 1.220054
Model 0 best validation rmse = 1.220054 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.117356
Ensemble test rmse = 1.117356
1-fold cross validation
	Seed 0 ==> test rmse = 1.117356
Overall test rmse = 1.117356 +/- 0.000000
Elapsed time = 0:00:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.280609
Epoch 1
Loss = 1.5317e+00, PNorm = 43.5218, GNorm = 1.7949, lr_0 = 7.1875e-04
Validation rmse = 1.172265
Epoch 2
Loss = 1.5352e+00, PNorm = 43.5408, GNorm = 1.1938, lr_0 = 6.1897e-04
Validation rmse = 1.125039
Epoch 3
Loss = 1.4267e+00, PNorm = 43.5518, GNorm = 0.8273, lr_0 = 2.3714e-04
Validation rmse = 1.108278
Epoch 4
Loss = 1.3917e+00, PNorm = 43.5557, GNorm = 0.7094, lr_0 = 1.0000e-04
Validation rmse = 1.098079
Model 0 best validation rmse = 1.098079 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.204274
Ensemble test rmse = 1.204274
1-fold cross validation
	Seed 0 ==> test rmse = 1.204274
Overall test rmse = 1.204274 +/- 0.000000
Elapsed time = 0:00:15
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.312471
Epoch 1
Loss = 1.5635e+00, PNorm = 43.5185, GNorm = 1.0065, lr_0 = 7.7500e-04
Validation rmse = 1.278425
Epoch 2
Loss = 1.4614e+00, PNorm = 43.5397, GNorm = 1.2215, lr_0 = 5.6234e-04
Validation rmse = 1.247713
Epoch 3
Loss = 1.3386e+00, PNorm = 43.5520, GNorm = 0.7150, lr_0 = 2.1544e-04
Validation rmse = 1.236638
Epoch 4
Loss = 1.3175e+00, PNorm = 43.5568, GNorm = 0.5359, lr_0 = 1.0000e-04
Validation rmse = 1.212888
Model 0 best validation rmse = 1.212888 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.046909
Ensemble test rmse = 1.046909
1-fold cross validation
	Seed 0 ==> test rmse = 1.046909
Overall test rmse = 1.046909 +/- 0.000000
Elapsed time = 0:00:15
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.294064
Epoch 1
Loss = 1.4970e+00, PNorm = 43.5131, GNorm = 1.5221, lr_0 = 7.0000e-04
Validation rmse = 1.162178
Epoch 2
Loss = 1.4182e+00, PNorm = 43.5274, GNorm = 0.9153, lr_0 = 7.1097e-04
Validation rmse = 1.146865
Epoch 3
Loss = 1.3078e+00, PNorm = 43.5422, GNorm = 0.4164, lr_0 = 2.7826e-04
Validation rmse = 1.128967
Epoch 4
Loss = 1.2718e+00, PNorm = 43.5481, GNorm = 0.5929, lr_0 = 1.1860e-04
Validation rmse = 1.112863
Model 0 best validation rmse = 1.112863 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.177220
Ensemble test rmse = 1.177220
1-fold cross validation
	Seed 0 ==> test rmse = 1.177220
Overall test rmse = 1.177220 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9019e+00, PNorm = 43.5149, GNorm = 1.0196, lr_0 = 5.9500e-04
Loss = 1.5485e+00, PNorm = 43.5149, GNorm = 1.6496, lr_0 = 6.4000e-04
Validation rmse = 1.404411
Epoch 1
Loss = 1.5091e+00, PNorm = 43.5287, GNorm = 0.9442, lr_0 = 8.5770e-04
Loss = 1.3727e+00, PNorm = 43.5310, GNorm = 1.3468, lr_0 = 7.9433e-04
Validation rmse = 1.297508
Epoch 2
Loss = 1.3617e+00, PNorm = 43.5480, GNorm = 0.8608, lr_0 = 3.6869e-04
Validation rmse = 1.258196
Epoch 3
Loss = 1.3102e+00, PNorm = 43.5556, GNorm = 0.7693, lr_0 = 1.7113e-04
Validation rmse = 1.227020
Epoch 4
Loss = 1.2969e+00, PNorm = 43.5598, GNorm = 0.4224, lr_0 = 1.0000e-04
Validation rmse = 1.211741
Model 0 best validation rmse = 1.211741 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.168840
Ensemble test rmse = 1.168840
1-fold cross validation
	Seed 0 ==> test rmse = 1.168840
Overall test rmse = 1.168840 +/- 0.000000
Elapsed time = 0:00:18
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9393e+00, PNorm = 43.5159, GNorm = 1.7836, lr_0 = 5.5000e-04
Validation rmse = 1.449284
Epoch 1
Loss = 1.5119e+00, PNorm = 43.5258, GNorm = 1.1400, lr_0 = 1.0000e-03
Validation rmse = 1.307213
Epoch 2
Loss = 1.3392e+00, PNorm = 43.5488, GNorm = 0.8504, lr_0 = 4.6416e-04
Validation rmse = 1.264901
Epoch 3
Loss = 1.2950e+00, PNorm = 43.5608, GNorm = 0.6945, lr_0 = 2.1544e-04
Validation rmse = 1.231637
Epoch 4
Loss = 1.2641e+00, PNorm = 43.5664, GNorm = 0.6798, lr_0 = 1.0000e-04
Validation rmse = 1.214602
Model 0 best validation rmse = 1.214602 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.167456
Ensemble test rmse = 1.167456
1-fold cross validation
	Seed 0 ==> test rmse = 1.167456
Overall test rmse = 1.167456 +/- 0.000000
Elapsed time = 0:00:19
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9370e+00, PNorm = 43.5153, GNorm = 0.8980, lr_0 = 5.1250e-04
Validation rmse = 1.487693
Epoch 1
Loss = 1.5087e+00, PNorm = 43.5199, GNorm = 1.2982, lr_0 = 8.8750e-04
Validation rmse = 1.327312
Epoch 2
Loss = 1.3041e+00, PNorm = 43.5445, GNorm = 0.7158, lr_0 = 6.3908e-04
Validation rmse = 1.271094
Epoch 3
Loss = 1.2218e+00, PNorm = 43.5608, GNorm = 0.8040, lr_0 = 3.3711e-04
Validation rmse = 1.227004
Epoch 4
Loss = 1.1880e+00, PNorm = 43.5703, GNorm = 0.5243, lr_0 = 1.7783e-04
Loss = 1.2209e+00, PNorm = 43.5761, GNorm = 0.9400, lr_0 = 1.0000e-04
Validation rmse = 1.200618
Model 0 best validation rmse = 1.200618 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.109370
Ensemble test rmse = 1.109370
1-fold cross validation
	Seed 0 ==> test rmse = 1.109370
Overall test rmse = 1.109370 +/- 0.000000
Elapsed time = 0:00:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9882, lr_0 = 3.0475e-04
Loss = 1.4487e+00, PNorm = 34.0770, GNorm = 2.0143, lr_0 = 3.2725e-04
Loss = 1.1911e+00, PNorm = 34.0840, GNorm = 1.1740, lr_0 = 3.4975e-04
Loss = 1.4932e+00, PNorm = 34.0957, GNorm = 6.5595, lr_0 = 3.7225e-04
Loss = 1.3793e+00, PNorm = 34.1087, GNorm = 0.8898, lr_0 = 3.9475e-04
Loss = 1.2901e+00, PNorm = 34.1163, GNorm = 4.6377, lr_0 = 4.1725e-04
Loss = 1.2130e+00, PNorm = 34.1212, GNorm = 2.5290, lr_0 = 4.3975e-04
Loss = 1.3996e+00, PNorm = 34.1328, GNorm = 1.0566, lr_0 = 4.6225e-04
Loss = 1.4239e+00, PNorm = 34.1507, GNorm = 3.1485, lr_0 = 4.8475e-04
Loss = 1.2936e+00, PNorm = 34.1719, GNorm = 7.1906, lr_0 = 5.0725e-04
Loss = 1.3156e+00, PNorm = 34.1865, GNorm = 1.1419, lr_0 = 5.2975e-04
Loss = 1.0982e+00, PNorm = 34.2056, GNorm = 2.9755, lr_0 = 5.5225e-04
Loss = 6.9225e-01, PNorm = 34.2070, GNorm = 2.3838, lr_0 = 5.5450e-04
Validation rmse = 1.214944
Epoch 1
Loss = 1.1118e+00, PNorm = 34.2168, GNorm = 0.8024, lr_0 = 5.7700e-04
Loss = 1.4121e+00, PNorm = 34.2314, GNorm = 3.2823, lr_0 = 5.9950e-04
Loss = 1.1898e+00, PNorm = 34.2498, GNorm = 5.0451, lr_0 = 6.2200e-04
Loss = 1.1724e+00, PNorm = 34.2666, GNorm = 1.1786, lr_0 = 6.4450e-04
Loss = 1.2785e+00, PNorm = 34.2786, GNorm = 3.3408, lr_0 = 6.6700e-04
Loss = 1.2185e+00, PNorm = 34.2944, GNorm = 2.6400, lr_0 = 6.8950e-04
Loss = 1.1843e+00, PNorm = 34.3151, GNorm = 1.9048, lr_0 = 7.1200e-04
Loss = 1.2714e+00, PNorm = 34.3343, GNorm = 3.2605, lr_0 = 7.3450e-04
Loss = 1.1960e+00, PNorm = 34.3584, GNorm = 1.4073, lr_0 = 7.5700e-04
Loss = 1.2776e+00, PNorm = 34.3951, GNorm = 1.0274, lr_0 = 7.7950e-04
Loss = 1.1630e+00, PNorm = 34.4260, GNorm = 1.4248, lr_0 = 8.0200e-04
Loss = 1.2254e+00, PNorm = 34.4512, GNorm = 1.7424, lr_0 = 8.2450e-04
Loss = 1.3537e+00, PNorm = 34.4964, GNorm = 2.0062, lr_0 = 8.4700e-04
Loss = 1.4326e+00, PNorm = 34.5340, GNorm = 2.4093, lr_0 = 8.6950e-04
Loss = 1.2081e+00, PNorm = 34.5871, GNorm = 0.9746, lr_0 = 8.9200e-04
Loss = 1.2639e+00, PNorm = 34.6255, GNorm = 1.2842, lr_0 = 9.1450e-04
Loss = 1.2526e+00, PNorm = 34.6524, GNorm = 1.1104, lr_0 = 9.3700e-04
Loss = 1.1741e+00, PNorm = 34.6785, GNorm = 0.9730, lr_0 = 9.5950e-04
Loss = 1.1576e+00, PNorm = 34.7051, GNorm = 1.7359, lr_0 = 9.8200e-04
Loss = 1.1972e+00, PNorm = 34.7459, GNorm = 1.0449, lr_0 = 9.9918e-04
Loss = 4.6937e+00, PNorm = 34.7493, GNorm = 23.8904, lr_0 = 9.9877e-04
Validation rmse = 1.165627
Epoch 2
Loss = 1.4892e+00, PNorm = 34.8156, GNorm = 0.4271, lr_0 = 9.9467e-04
Loss = 1.2966e+00, PNorm = 34.8957, GNorm = 1.1033, lr_0 = 9.9059e-04
Loss = 1.1203e+00, PNorm = 34.9586, GNorm = 1.9843, lr_0 = 9.8652e-04
Loss = 1.3263e+00, PNorm = 34.9934, GNorm = 0.5661, lr_0 = 9.8247e-04
Loss = 1.2202e+00, PNorm = 35.0284, GNorm = 0.6044, lr_0 = 9.7844e-04
Loss = 1.1852e+00, PNorm = 35.0632, GNorm = 0.9745, lr_0 = 9.7443e-04
Loss = 1.0391e+00, PNorm = 35.0908, GNorm = 2.3723, lr_0 = 9.7043e-04
Loss = 1.3291e+00, PNorm = 35.1057, GNorm = 0.5174, lr_0 = 9.6645e-04
Loss = 1.1666e+00, PNorm = 35.1237, GNorm = 0.8391, lr_0 = 9.6248e-04
Loss = 1.1638e+00, PNorm = 35.1556, GNorm = 1.1918, lr_0 = 9.5853e-04
Loss = 1.2265e+00, PNorm = 35.1896, GNorm = 1.5532, lr_0 = 9.5460e-04
Loss = 1.1553e+00, PNorm = 35.2085, GNorm = 0.6755, lr_0 = 9.5068e-04
Loss = 1.2322e+00, PNorm = 35.2304, GNorm = 0.5357, lr_0 = 9.4678e-04
Loss = 1.1559e+00, PNorm = 35.2608, GNorm = 0.4845, lr_0 = 9.4290e-04
Loss = 1.1893e+00, PNorm = 35.2873, GNorm = 1.1363, lr_0 = 9.3903e-04
Loss = 1.3217e+00, PNorm = 35.3137, GNorm = 0.7049, lr_0 = 9.3517e-04
Loss = 1.0975e+00, PNorm = 35.3370, GNorm = 0.6759, lr_0 = 9.3134e-04
Loss = 1.2034e+00, PNorm = 35.3658, GNorm = 0.5541, lr_0 = 9.2752e-04
Loss = 1.1029e+00, PNorm = 35.3914, GNorm = 1.6965, lr_0 = 9.2371e-04
Loss = 1.1122e+00, PNorm = 35.4261, GNorm = 1.9430, lr_0 = 9.1992e-04
Loss = 5.9686e-01, PNorm = 35.4294, GNorm = 1.2260, lr_0 = 9.1954e-04
Validation rmse = 1.095617
Epoch 3
Loss = 1.1711e+00, PNorm = 35.4572, GNorm = 0.6325, lr_0 = 9.1577e-04
Loss = 1.0923e+00, PNorm = 35.5018, GNorm = 2.0961, lr_0 = 9.1201e-04
Loss = 1.2412e+00, PNorm = 35.5238, GNorm = 1.0741, lr_0 = 9.0827e-04
Loss = 1.0752e+00, PNorm = 35.5455, GNorm = 1.2351, lr_0 = 9.0454e-04
Loss = 1.0831e+00, PNorm = 35.5659, GNorm = 0.3203, lr_0 = 9.0083e-04
Loss = 1.1106e+00, PNorm = 35.6070, GNorm = 1.1318, lr_0 = 8.9713e-04
Loss = 1.1477e+00, PNorm = 35.6424, GNorm = 0.7337, lr_0 = 8.9345e-04
Loss = 1.1529e+00, PNorm = 35.6868, GNorm = 5.5847, lr_0 = 8.8979e-04
Loss = 1.2474e+00, PNorm = 35.7040, GNorm = 0.9576, lr_0 = 8.8614e-04
Loss = 1.0842e+00, PNorm = 35.7461, GNorm = 2.1702, lr_0 = 8.8250e-04
Loss = 1.1207e+00, PNorm = 35.7847, GNorm = 1.3002, lr_0 = 8.7888e-04
Loss = 1.1741e+00, PNorm = 35.8236, GNorm = 1.2268, lr_0 = 8.7527e-04
Loss = 1.2199e+00, PNorm = 35.8515, GNorm = 0.8220, lr_0 = 8.7168e-04
Loss = 1.1884e+00, PNorm = 35.8766, GNorm = 0.8852, lr_0 = 8.6810e-04
Loss = 1.2302e+00, PNorm = 35.8972, GNorm = 1.3260, lr_0 = 8.6454e-04
Loss = 1.2334e+00, PNorm = 35.9188, GNorm = 1.8636, lr_0 = 8.6099e-04
Loss = 1.0708e+00, PNorm = 35.9335, GNorm = 1.3747, lr_0 = 8.5746e-04
Loss = 9.3829e-01, PNorm = 35.9649, GNorm = 1.4726, lr_0 = 8.5394e-04
Loss = 1.0607e+00, PNorm = 35.9877, GNorm = 0.8996, lr_0 = 8.5044e-04
Loss = 1.0862e+00, PNorm = 36.0101, GNorm = 1.8025, lr_0 = 8.4695e-04
Loss = 5.6127e-01, PNorm = 36.0127, GNorm = 1.7101, lr_0 = 8.4660e-04
Validation rmse = 1.077994
Epoch 4
Loss = 1.0132e+00, PNorm = 36.0333, GNorm = 0.7524, lr_0 = 8.4313e-04
Loss = 1.1703e+00, PNorm = 36.0603, GNorm = 0.9269, lr_0 = 8.3967e-04
Loss = 1.1601e+00, PNorm = 36.1014, GNorm = 0.7178, lr_0 = 8.3622e-04
Loss = 1.1727e+00, PNorm = 36.1402, GNorm = 0.8395, lr_0 = 8.3279e-04
Loss = 1.1819e+00, PNorm = 36.1791, GNorm = 0.8075, lr_0 = 8.2937e-04
Loss = 1.0824e+00, PNorm = 36.2139, GNorm = 2.6428, lr_0 = 8.2597e-04
Loss = 1.0674e+00, PNorm = 36.2568, GNorm = 1.6345, lr_0 = 8.2258e-04
Loss = 1.0907e+00, PNorm = 36.2922, GNorm = 0.9661, lr_0 = 8.1921e-04
Loss = 1.1120e+00, PNorm = 36.3427, GNorm = 1.8692, lr_0 = 8.1584e-04
Loss = 1.0660e+00, PNorm = 36.3642, GNorm = 1.3838, lr_0 = 8.1250e-04
Loss = 1.0970e+00, PNorm = 36.3943, GNorm = 0.8294, lr_0 = 8.0916e-04
Loss = 1.0156e+00, PNorm = 36.4228, GNorm = 1.2338, lr_0 = 8.0584e-04
Loss = 1.3109e+00, PNorm = 36.4589, GNorm = 2.3895, lr_0 = 8.0254e-04
Loss = 1.0816e+00, PNorm = 36.4946, GNorm = 1.0109, lr_0 = 7.9924e-04
Loss = 1.0054e+00, PNorm = 36.5500, GNorm = 1.9164, lr_0 = 7.9596e-04
Loss = 1.1765e+00, PNorm = 36.5667, GNorm = 2.7966, lr_0 = 7.9270e-04
Loss = 1.0605e+00, PNorm = 36.5938, GNorm = 0.9998, lr_0 = 7.8944e-04
Loss = 1.0083e+00, PNorm = 36.6201, GNorm = 1.3164, lr_0 = 7.8620e-04
Loss = 1.0405e+00, PNorm = 36.6459, GNorm = 1.6741, lr_0 = 7.8298e-04
Loss = 1.0868e+00, PNorm = 36.6789, GNorm = 1.8379, lr_0 = 7.7977e-04
Loss = 5.1316e-01, PNorm = 36.6825, GNorm = 2.0713, lr_0 = 7.7945e-04
Validation rmse = 1.022039
Epoch 5
Loss = 1.0368e+00, PNorm = 36.7285, GNorm = 0.7994, lr_0 = 7.7625e-04
Loss = 9.8577e-01, PNorm = 36.7679, GNorm = 1.1075, lr_0 = 7.7306e-04
Loss = 1.0935e+00, PNorm = 36.7845, GNorm = 3.6339, lr_0 = 7.6989e-04
Loss = 1.1013e+00, PNorm = 36.8008, GNorm = 1.0795, lr_0 = 7.6673e-04
Loss = 1.1028e+00, PNorm = 36.8408, GNorm = 2.1176, lr_0 = 7.6358e-04
Loss = 9.7519e-01, PNorm = 36.8819, GNorm = 1.1114, lr_0 = 7.6045e-04
Loss = 1.1352e+00, PNorm = 36.9249, GNorm = 1.5998, lr_0 = 7.5733e-04
Loss = 1.0326e+00, PNorm = 36.9700, GNorm = 1.2105, lr_0 = 7.5422e-04
Loss = 1.1057e+00, PNorm = 37.0031, GNorm = 3.1523, lr_0 = 7.5113e-04
Loss = 9.4069e-01, PNorm = 37.0278, GNorm = 1.1374, lr_0 = 7.4805e-04
Loss = 1.1957e+00, PNorm = 37.0521, GNorm = 2.9405, lr_0 = 7.4498e-04
Loss = 9.7837e-01, PNorm = 37.0873, GNorm = 1.5939, lr_0 = 7.4192e-04
Loss = 1.0630e+00, PNorm = 37.1166, GNorm = 1.0136, lr_0 = 7.3888e-04
Loss = 1.1836e+00, PNorm = 37.1450, GNorm = 3.9896, lr_0 = 7.3584e-04
Loss = 1.0660e+00, PNorm = 37.1710, GNorm = 1.5526, lr_0 = 7.3282e-04
Loss = 9.9236e-01, PNorm = 37.2026, GNorm = 1.1034, lr_0 = 7.2982e-04
Loss = 9.5435e-01, PNorm = 37.2301, GNorm = 1.0227, lr_0 = 7.2682e-04
Loss = 1.0604e+00, PNorm = 37.2594, GNorm = 1.5371, lr_0 = 7.2384e-04
Loss = 1.0585e+00, PNorm = 37.3056, GNorm = 2.4927, lr_0 = 7.2087e-04
Loss = 1.1635e+00, PNorm = 37.3542, GNorm = 0.7717, lr_0 = 7.1791e-04
Loss = 7.2594e-01, PNorm = 37.3580, GNorm = 3.9646, lr_0 = 7.1762e-04
Validation rmse = 1.029100
Epoch 6
Loss = 1.0026e+00, PNorm = 37.3917, GNorm = 2.0873, lr_0 = 7.1467e-04
Loss = 1.1799e+00, PNorm = 37.3947, GNorm = 2.3025, lr_0 = 7.1174e-04
Loss = 1.0456e+00, PNorm = 37.4198, GNorm = 0.9488, lr_0 = 7.0882e-04
Loss = 1.1195e+00, PNorm = 37.4527, GNorm = 1.9907, lr_0 = 7.0591e-04
Loss = 1.0456e+00, PNorm = 37.4823, GNorm = 3.1697, lr_0 = 7.0301e-04
Loss = 1.0257e+00, PNorm = 37.5193, GNorm = 0.8757, lr_0 = 7.0013e-04
Loss = 9.7003e-01, PNorm = 37.5551, GNorm = 1.3642, lr_0 = 6.9726e-04
Loss = 1.0536e+00, PNorm = 37.5871, GNorm = 1.9136, lr_0 = 6.9440e-04
Loss = 9.9105e-01, PNorm = 37.6199, GNorm = 3.1782, lr_0 = 6.9155e-04
Loss = 1.0086e+00, PNorm = 37.6418, GNorm = 0.9098, lr_0 = 6.8871e-04
Loss = 1.0535e+00, PNorm = 37.6663, GNorm = 2.4873, lr_0 = 6.8588e-04
Loss = 1.0655e+00, PNorm = 37.6908, GNorm = 1.7008, lr_0 = 6.8307e-04
Loss = 1.0532e+00, PNorm = 37.7213, GNorm = 1.0485, lr_0 = 6.8027e-04
Loss = 1.0046e+00, PNorm = 37.7519, GNorm = 1.4733, lr_0 = 6.7747e-04
Loss = 9.2116e-01, PNorm = 37.7797, GNorm = 1.7789, lr_0 = 6.7469e-04
Loss = 8.7799e-01, PNorm = 37.8174, GNorm = 1.9655, lr_0 = 6.7193e-04
Loss = 1.1192e+00, PNorm = 37.8428, GNorm = 3.6648, lr_0 = 6.6917e-04
Loss = 1.0769e+00, PNorm = 37.8601, GNorm = 0.8285, lr_0 = 6.6642e-04
Loss = 9.3872e-01, PNorm = 37.8945, GNorm = 1.2915, lr_0 = 6.6369e-04
Loss = 9.7416e-01, PNorm = 37.9232, GNorm = 1.4691, lr_0 = 6.6097e-04
Loss = 5.3900e-01, PNorm = 37.9255, GNorm = 1.6786, lr_0 = 6.6069e-04
Validation rmse = 0.964618
Epoch 7
Loss = 1.0695e+00, PNorm = 37.9521, GNorm = 1.5569, lr_0 = 6.5798e-04
Loss = 1.0579e+00, PNorm = 37.9853, GNorm = 1.4111, lr_0 = 6.5528e-04
Loss = 9.1572e-01, PNorm = 38.0203, GNorm = 1.2371, lr_0 = 6.5259e-04
Loss = 1.0215e+00, PNorm = 38.0496, GNorm = 4.7495, lr_0 = 6.4992e-04
Loss = 9.8539e-01, PNorm = 38.0723, GNorm = 1.9611, lr_0 = 6.4725e-04
Loss = 9.5464e-01, PNorm = 38.0891, GNorm = 1.9924, lr_0 = 6.4459e-04
Loss = 9.8553e-01, PNorm = 38.1296, GNorm = 3.4230, lr_0 = 6.4195e-04
Loss = 9.8016e-01, PNorm = 38.1632, GNorm = 3.7830, lr_0 = 6.3931e-04
Loss = 8.9538e-01, PNorm = 38.1984, GNorm = 2.3713, lr_0 = 6.3669e-04
Loss = 8.7699e-01, PNorm = 38.2231, GNorm = 1.2494, lr_0 = 6.3408e-04
Loss = 9.1095e-01, PNorm = 38.2599, GNorm = 3.6611, lr_0 = 6.3148e-04
Loss = 9.6394e-01, PNorm = 38.2892, GNorm = 1.9677, lr_0 = 6.2889e-04
Loss = 1.0386e+00, PNorm = 38.3154, GNorm = 3.0096, lr_0 = 6.2630e-04
Loss = 1.0458e+00, PNorm = 38.3474, GNorm = 2.0676, lr_0 = 6.2373e-04
Loss = 9.7166e-01, PNorm = 38.3853, GNorm = 3.3534, lr_0 = 6.2118e-04
Loss = 9.8315e-01, PNorm = 38.4148, GNorm = 0.9306, lr_0 = 6.1863e-04
Loss = 9.6730e-01, PNorm = 38.4370, GNorm = 2.8434, lr_0 = 6.1609e-04
Loss = 9.2883e-01, PNorm = 38.4612, GNorm = 2.6265, lr_0 = 6.1356e-04
Loss = 1.0839e+00, PNorm = 38.4924, GNorm = 1.8471, lr_0 = 6.1104e-04
Loss = 9.7607e-01, PNorm = 38.5176, GNorm = 1.9463, lr_0 = 6.0854e-04
Loss = 9.5044e-01, PNorm = 38.5191, GNorm = 5.6196, lr_0 = 6.0829e-04
Validation rmse = 0.942318
Epoch 8
Loss = 1.0285e+00, PNorm = 38.5406, GNorm = 1.4110, lr_0 = 6.0579e-04
Loss = 9.7078e-01, PNorm = 38.5737, GNorm = 2.6340, lr_0 = 6.0330e-04
Loss = 1.0078e+00, PNorm = 38.6073, GNorm = 3.0833, lr_0 = 6.0083e-04
Loss = 9.2485e-01, PNorm = 38.6421, GNorm = 1.1882, lr_0 = 5.9836e-04
Loss = 9.0080e-01, PNorm = 38.6726, GNorm = 2.3898, lr_0 = 5.9591e-04
Loss = 9.5715e-01, PNorm = 38.6970, GNorm = 5.0366, lr_0 = 5.9346e-04
Loss = 7.0480e-01, PNorm = 38.7190, GNorm = 1.6963, lr_0 = 5.9103e-04
Loss = 9.6192e-01, PNorm = 38.7590, GNorm = 7.7629, lr_0 = 5.8860e-04
Loss = 1.0519e+00, PNorm = 38.7976, GNorm = 1.7833, lr_0 = 5.8619e-04
Loss = 8.8757e-01, PNorm = 38.8280, GNorm = 1.3569, lr_0 = 5.8378e-04
Loss = 1.0754e+00, PNorm = 38.8512, GNorm = 2.4201, lr_0 = 5.8139e-04
Loss = 1.0137e+00, PNorm = 38.8670, GNorm = 1.3530, lr_0 = 5.7900e-04
Loss = 1.0131e+00, PNorm = 38.8897, GNorm = 0.9595, lr_0 = 5.7662e-04
Loss = 1.0280e+00, PNorm = 38.9193, GNorm = 1.8063, lr_0 = 5.7426e-04
Loss = 8.5762e-01, PNorm = 38.9366, GNorm = 3.5407, lr_0 = 5.7190e-04
Loss = 9.0726e-01, PNorm = 38.9571, GNorm = 3.4022, lr_0 = 5.6956e-04
Loss = 7.5168e-01, PNorm = 38.9892, GNorm = 1.5139, lr_0 = 5.6722e-04
Loss = 8.0511e-01, PNorm = 39.0239, GNorm = 3.3115, lr_0 = 5.6489e-04
Loss = 9.6682e-01, PNorm = 39.0551, GNorm = 3.9422, lr_0 = 5.6257e-04
Loss = 9.8995e-01, PNorm = 39.0884, GNorm = 2.2252, lr_0 = 5.6026e-04
Loss = 2.2106e+00, PNorm = 39.0939, GNorm = 5.9449, lr_0 = 5.6003e-04
Validation rmse = 0.900866
Epoch 9
Loss = 9.0473e-01, PNorm = 39.1388, GNorm = 1.9141, lr_0 = 5.5774e-04
Loss = 8.0688e-01, PNorm = 39.1781, GNorm = 2.0812, lr_0 = 5.5545e-04
Loss = 9.8650e-01, PNorm = 39.1944, GNorm = 4.6350, lr_0 = 5.5317e-04
Loss = 8.4317e-01, PNorm = 39.2041, GNorm = 2.6850, lr_0 = 5.5090e-04
Loss = 1.0201e+00, PNorm = 39.2325, GNorm = 1.5604, lr_0 = 5.4864e-04
Loss = 8.9419e-01, PNorm = 39.2573, GNorm = 1.2608, lr_0 = 5.4639e-04
Loss = 8.8182e-01, PNorm = 39.2896, GNorm = 1.3264, lr_0 = 5.4414e-04
Loss = 9.1027e-01, PNorm = 39.3164, GNorm = 5.5379, lr_0 = 5.4191e-04
Loss = 9.5725e-01, PNorm = 39.3343, GNorm = 2.5679, lr_0 = 5.3969e-04
Loss = 8.3101e-01, PNorm = 39.3577, GNorm = 2.0518, lr_0 = 5.3747e-04
Loss = 8.8736e-01, PNorm = 39.3774, GNorm = 2.3489, lr_0 = 5.3527e-04
Loss = 8.8701e-01, PNorm = 39.3915, GNorm = 2.6917, lr_0 = 5.3307e-04
Loss = 8.5005e-01, PNorm = 39.4271, GNorm = 1.5833, lr_0 = 5.3088e-04
Loss = 9.3760e-01, PNorm = 39.4468, GNorm = 1.9369, lr_0 = 5.2871e-04
Loss = 9.1141e-01, PNorm = 39.4691, GNorm = 1.2541, lr_0 = 5.2654e-04
Loss = 1.0796e+00, PNorm = 39.4957, GNorm = 3.9872, lr_0 = 5.2438e-04
Loss = 1.0827e+00, PNorm = 39.5152, GNorm = 2.1737, lr_0 = 5.2222e-04
Loss = 8.9585e-01, PNorm = 39.5392, GNorm = 3.5340, lr_0 = 5.2008e-04
Loss = 8.1695e-01, PNorm = 39.5529, GNorm = 1.1092, lr_0 = 5.1795e-04
Loss = 1.0029e+00, PNorm = 39.5754, GNorm = 2.7341, lr_0 = 5.1582e-04
Validation rmse = 0.917705
Epoch 10
Loss = 8.6842e-01, PNorm = 39.6124, GNorm = 2.4560, lr_0 = 5.1371e-04
Loss = 8.4163e-01, PNorm = 39.6483, GNorm = 3.0261, lr_0 = 5.1160e-04
Loss = 8.9919e-01, PNorm = 39.6762, GNorm = 2.6552, lr_0 = 5.0950e-04
Loss = 8.7638e-01, PNorm = 39.6970, GNorm = 1.7640, lr_0 = 5.0741e-04
Loss = 8.2160e-01, PNorm = 39.7223, GNorm = 1.3270, lr_0 = 5.0533e-04
Loss = 8.8743e-01, PNorm = 39.7442, GNorm = 1.9342, lr_0 = 5.0325e-04
Loss = 1.0403e+00, PNorm = 39.7694, GNorm = 4.9927, lr_0 = 5.0119e-04
Loss = 7.9445e-01, PNorm = 39.7948, GNorm = 2.0197, lr_0 = 4.9913e-04
Loss = 1.0101e+00, PNorm = 39.8280, GNorm = 1.6314, lr_0 = 4.9708e-04
Loss = 8.4307e-01, PNorm = 39.8524, GNorm = 1.9165, lr_0 = 4.9504e-04
Loss = 8.5537e-01, PNorm = 39.8751, GNorm = 1.8950, lr_0 = 4.9301e-04
Loss = 8.3772e-01, PNorm = 39.9107, GNorm = 2.0858, lr_0 = 4.9099e-04
Loss = 8.2648e-01, PNorm = 39.9315, GNorm = 3.0547, lr_0 = 4.8897e-04
Loss = 8.4611e-01, PNorm = 39.9456, GNorm = 5.9287, lr_0 = 4.8697e-04
Loss = 8.6650e-01, PNorm = 39.9660, GNorm = 0.9850, lr_0 = 4.8497e-04
Loss = 8.9561e-01, PNorm = 39.9892, GNorm = 1.4493, lr_0 = 4.8298e-04
Loss = 8.8234e-01, PNorm = 40.0101, GNorm = 1.3053, lr_0 = 4.8100e-04
Loss = 8.2460e-01, PNorm = 40.0277, GNorm = 2.5434, lr_0 = 4.7902e-04
Loss = 8.2209e-01, PNorm = 40.0497, GNorm = 2.3302, lr_0 = 4.7706e-04
Loss = 7.8035e-01, PNorm = 40.0726, GNorm = 3.0318, lr_0 = 4.7510e-04
Validation rmse = 0.848014
Epoch 11
Loss = 7.7707e-01, PNorm = 40.0924, GNorm = 2.1650, lr_0 = 4.7296e-04
Loss = 8.7624e-01, PNorm = 40.1136, GNorm = 3.1711, lr_0 = 4.7102e-04
Loss = 7.6006e-01, PNorm = 40.1505, GNorm = 1.9132, lr_0 = 4.6908e-04
Loss = 7.7389e-01, PNorm = 40.1794, GNorm = 7.4644, lr_0 = 4.6716e-04
Loss = 8.0388e-01, PNorm = 40.2015, GNorm = 2.1356, lr_0 = 4.6524e-04
Loss = 9.5521e-01, PNorm = 40.2278, GNorm = 2.9422, lr_0 = 4.6333e-04
Loss = 6.8977e-01, PNorm = 40.2516, GNorm = 1.6213, lr_0 = 4.6143e-04
Loss = 8.7489e-01, PNorm = 40.2738, GNorm = 1.6595, lr_0 = 4.5954e-04
Loss = 7.3708e-01, PNorm = 40.2931, GNorm = 2.8522, lr_0 = 4.5765e-04
Loss = 7.1030e-01, PNorm = 40.3133, GNorm = 1.7951, lr_0 = 4.5577e-04
Loss = 7.5159e-01, PNorm = 40.3334, GNorm = 2.8007, lr_0 = 4.5390e-04
Loss = 7.7158e-01, PNorm = 40.3578, GNorm = 4.1224, lr_0 = 4.5204e-04
Loss = 8.2931e-01, PNorm = 40.3803, GNorm = 2.0326, lr_0 = 4.5019e-04
Loss = 9.4593e-01, PNorm = 40.4019, GNorm = 1.5610, lr_0 = 4.4834e-04
Loss = 8.2188e-01, PNorm = 40.4199, GNorm = 2.1496, lr_0 = 4.4650e-04
Loss = 8.6981e-01, PNorm = 40.4348, GNorm = 2.9010, lr_0 = 4.4467e-04
Loss = 7.1127e-01, PNorm = 40.4517, GNorm = 5.0690, lr_0 = 4.4284e-04
Loss = 9.8155e-01, PNorm = 40.4760, GNorm = 2.1799, lr_0 = 4.4103e-04
Loss = 8.2919e-01, PNorm = 40.4975, GNorm = 2.3420, lr_0 = 4.3922e-04
Loss = 9.1125e-01, PNorm = 40.5131, GNorm = 2.6015, lr_0 = 4.3741e-04
Validation rmse = 0.803717
Epoch 12
Loss = 8.0987e-01, PNorm = 40.5394, GNorm = 3.5295, lr_0 = 4.3544e-04
Loss = 6.5511e-01, PNorm = 40.5633, GNorm = 1.6364, lr_0 = 4.3365e-04
Loss = 7.6078e-01, PNorm = 40.5798, GNorm = 21.0561, lr_0 = 4.3187e-04
Loss = 9.1131e-01, PNorm = 40.5894, GNorm = 1.5182, lr_0 = 4.3010e-04
Loss = 9.0713e-01, PNorm = 40.6053, GNorm = 1.7021, lr_0 = 4.2834e-04
Loss = 7.8186e-01, PNorm = 40.6193, GNorm = 4.6660, lr_0 = 4.2658e-04
Loss = 8.7736e-01, PNorm = 40.6373, GNorm = 3.7130, lr_0 = 4.2483e-04
Loss = 8.0752e-01, PNorm = 40.6611, GNorm = 4.1231, lr_0 = 4.2309e-04
Loss = 8.8035e-01, PNorm = 40.6860, GNorm = 3.2569, lr_0 = 4.2135e-04
Loss = 7.2817e-01, PNorm = 40.7041, GNorm = 2.3076, lr_0 = 4.1962e-04
Loss = 5.9677e-01, PNorm = 40.7139, GNorm = 3.2644, lr_0 = 4.1790e-04
Loss = 7.4814e-01, PNorm = 40.7371, GNorm = 2.6796, lr_0 = 4.1618e-04
Loss = 7.4175e-01, PNorm = 40.7461, GNorm = 4.1043, lr_0 = 4.1448e-04
Loss = 7.3242e-01, PNorm = 40.7575, GNorm = 1.9331, lr_0 = 4.1278e-04
Loss = 6.9240e-01, PNorm = 40.7799, GNorm = 2.4328, lr_0 = 4.1108e-04
Loss = 7.3051e-01, PNorm = 40.7957, GNorm = 2.8170, lr_0 = 4.0940e-04
Loss = 7.4734e-01, PNorm = 40.8145, GNorm = 2.6406, lr_0 = 4.0772e-04
Loss = 8.4443e-01, PNorm = 40.8361, GNorm = 1.9862, lr_0 = 4.0604e-04
Loss = 7.5665e-01, PNorm = 40.8471, GNorm = 3.2052, lr_0 = 4.0438e-04
Loss = 8.9185e-01, PNorm = 40.8596, GNorm = 5.7309, lr_0 = 4.0272e-04
Validation rmse = 0.821238
Epoch 13
Loss = 7.4981e-01, PNorm = 40.8856, GNorm = 3.2520, lr_0 = 4.0090e-04
Loss = 8.1447e-01, PNorm = 40.9110, GNorm = 1.4582, lr_0 = 3.9925e-04
Loss = 8.7913e-01, PNorm = 40.9300, GNorm = 1.6768, lr_0 = 3.9762e-04
Loss = 8.9066e-01, PNorm = 40.9488, GNorm = 2.7839, lr_0 = 3.9598e-04
Loss = 6.6129e-01, PNorm = 40.9613, GNorm = 5.2740, lr_0 = 3.9436e-04
Loss = 7.5389e-01, PNorm = 40.9780, GNorm = 3.5007, lr_0 = 3.9274e-04
Loss = 8.0031e-01, PNorm = 40.9958, GNorm = 3.5147, lr_0 = 3.9113e-04
Loss = 7.0942e-01, PNorm = 41.0101, GNorm = 3.8104, lr_0 = 3.8953e-04
Loss = 6.2885e-01, PNorm = 41.0241, GNorm = 3.1606, lr_0 = 3.8793e-04
Loss = 7.8985e-01, PNorm = 41.0370, GNorm = 7.7885, lr_0 = 3.8634e-04
Loss = 7.2779e-01, PNorm = 41.0517, GNorm = 2.7148, lr_0 = 3.8475e-04
Loss = 7.5736e-01, PNorm = 41.0694, GNorm = 2.4410, lr_0 = 3.8317e-04
Loss = 7.8586e-01, PNorm = 41.0852, GNorm = 3.3490, lr_0 = 3.8160e-04
Loss = 7.2612e-01, PNorm = 41.0994, GNorm = 2.8524, lr_0 = 3.8003e-04
Loss = 7.1352e-01, PNorm = 41.1097, GNorm = 2.1450, lr_0 = 3.7847e-04
Loss = 7.3730e-01, PNorm = 41.1233, GNorm = 6.6236, lr_0 = 3.7692e-04
Loss = 7.9876e-01, PNorm = 41.1330, GNorm = 4.3470, lr_0 = 3.7537e-04
Loss = 7.3860e-01, PNorm = 41.1458, GNorm = 6.8701, lr_0 = 3.7383e-04
Loss = 7.8970e-01, PNorm = 41.1592, GNorm = 2.0732, lr_0 = 3.7230e-04
Loss = 7.9735e-01, PNorm = 41.1748, GNorm = 1.7396, lr_0 = 3.7077e-04
Validation rmse = 0.762393
Epoch 14
Loss = 7.6660e-01, PNorm = 41.1881, GNorm = 2.5436, lr_0 = 3.6910e-04
Loss = 6.6767e-01, PNorm = 41.2040, GNorm = 3.0835, lr_0 = 3.6758e-04
Loss = 6.6736e-01, PNorm = 41.2209, GNorm = 2.9285, lr_0 = 3.6608e-04
Loss = 7.5859e-01, PNorm = 41.2330, GNorm = 2.8165, lr_0 = 3.6457e-04
Loss = 7.0574e-01, PNorm = 41.2435, GNorm = 2.5548, lr_0 = 3.6308e-04
Loss = 7.4400e-01, PNorm = 41.2588, GNorm = 2.3031, lr_0 = 3.6159e-04
Loss = 6.1376e-01, PNorm = 41.2776, GNorm = 5.0448, lr_0 = 3.6010e-04
Loss = 7.1830e-01, PNorm = 41.2961, GNorm = 3.6543, lr_0 = 3.5863e-04
Loss = 5.7585e-01, PNorm = 41.3117, GNorm = 6.2032, lr_0 = 3.5716e-04
Loss = 6.6738e-01, PNorm = 41.3308, GNorm = 2.5428, lr_0 = 3.5569e-04
Loss = 6.9945e-01, PNorm = 41.3457, GNorm = 2.7660, lr_0 = 3.5423e-04
Loss = 7.0302e-01, PNorm = 41.3590, GNorm = 3.1714, lr_0 = 3.5278e-04
Loss = 7.0876e-01, PNorm = 41.3752, GNorm = 3.6367, lr_0 = 3.5133e-04
Loss = 7.6331e-01, PNorm = 41.3916, GNorm = 2.1450, lr_0 = 3.4989e-04
Loss = 7.9138e-01, PNorm = 41.4081, GNorm = 1.8351, lr_0 = 3.4845e-04
Loss = 6.6808e-01, PNorm = 41.4226, GNorm = 1.9876, lr_0 = 3.4702e-04
Loss = 7.0757e-01, PNorm = 41.4379, GNorm = 7.7566, lr_0 = 3.4560e-04
Loss = 7.8764e-01, PNorm = 41.4571, GNorm = 16.0122, lr_0 = 3.4418e-04
Loss = 7.5111e-01, PNorm = 41.4704, GNorm = 2.0406, lr_0 = 3.4277e-04
Loss = 7.7412e-01, PNorm = 41.4851, GNorm = 1.9733, lr_0 = 3.4136e-04
Validation rmse = 0.846762
Epoch 15
Loss = 8.1153e-01, PNorm = 41.5055, GNorm = 2.3001, lr_0 = 3.3982e-04
Loss = 7.9379e-01, PNorm = 41.5239, GNorm = 2.0529, lr_0 = 3.3843e-04
Loss = 7.3956e-01, PNorm = 41.5408, GNorm = 3.9224, lr_0 = 3.3704e-04
Loss = 5.6785e-01, PNorm = 41.5544, GNorm = 3.3052, lr_0 = 3.3565e-04
Loss = 6.2277e-01, PNorm = 41.5681, GNorm = 3.9547, lr_0 = 3.3428e-04
Loss = 8.0869e-01, PNorm = 41.5805, GNorm = 4.0715, lr_0 = 3.3291e-04
Loss = 5.9394e-01, PNorm = 41.5936, GNorm = 3.0024, lr_0 = 3.3154e-04
Loss = 6.1383e-01, PNorm = 41.6074, GNorm = 2.8718, lr_0 = 3.3018e-04
Loss = 6.5416e-01, PNorm = 41.6215, GNorm = 3.7789, lr_0 = 3.2882e-04
Loss = 7.2430e-01, PNorm = 41.6257, GNorm = 3.2202, lr_0 = 3.2748e-04
Loss = 5.9453e-01, PNorm = 41.6406, GNorm = 4.8833, lr_0 = 3.2613e-04
Loss = 7.0976e-01, PNorm = 41.6524, GNorm = 1.8286, lr_0 = 3.2479e-04
Loss = 7.4283e-01, PNorm = 41.6595, GNorm = 2.0521, lr_0 = 3.2346e-04
Loss = 5.8670e-01, PNorm = 41.6724, GNorm = 2.6399, lr_0 = 3.2213e-04
Loss = 5.7512e-01, PNorm = 41.6857, GNorm = 6.3923, lr_0 = 3.2081e-04
Loss = 8.1138e-01, PNorm = 41.6965, GNorm = 3.9536, lr_0 = 3.1950e-04
Loss = 8.0453e-01, PNorm = 41.7054, GNorm = 2.8517, lr_0 = 3.1818e-04
Loss = 6.7922e-01, PNorm = 41.7166, GNorm = 2.6090, lr_0 = 3.1688e-04
Loss = 7.1631e-01, PNorm = 41.7313, GNorm = 3.3686, lr_0 = 3.1558e-04
Loss = 6.3036e-01, PNorm = 41.7465, GNorm = 2.7116, lr_0 = 3.1428e-04
Validation rmse = 0.746853
Epoch 16
Loss = 7.6098e-01, PNorm = 41.7638, GNorm = 5.1854, lr_0 = 3.1287e-04
Loss = 7.2001e-01, PNorm = 41.7753, GNorm = 3.1519, lr_0 = 3.1158e-04
Loss = 7.1455e-01, PNorm = 41.7856, GNorm = 2.3140, lr_0 = 3.1030e-04
Loss = 6.5455e-01, PNorm = 41.8007, GNorm = 2.4819, lr_0 = 3.0903e-04
Loss = 5.8729e-01, PNorm = 41.8169, GNorm = 3.7933, lr_0 = 3.0776e-04
Loss = 6.7846e-01, PNorm = 41.8321, GNorm = 2.7504, lr_0 = 3.0650e-04
Loss = 6.6156e-01, PNorm = 41.8429, GNorm = 1.9775, lr_0 = 3.0524e-04
Loss = 5.1604e-01, PNorm = 41.8550, GNorm = 3.6350, lr_0 = 3.0399e-04
Loss = 4.9660e-01, PNorm = 41.8687, GNorm = 6.6824, lr_0 = 3.0274e-04
Loss = 5.3355e-01, PNorm = 41.8843, GNorm = 6.3180, lr_0 = 3.0150e-04
Loss = 7.0395e-01, PNorm = 41.8902, GNorm = 3.4968, lr_0 = 3.0026e-04
Loss = 7.2609e-01, PNorm = 41.8892, GNorm = 2.1045, lr_0 = 2.9903e-04
Loss = 6.4385e-01, PNorm = 41.8935, GNorm = 2.8375, lr_0 = 2.9780e-04
Loss = 6.8676e-01, PNorm = 41.9025, GNorm = 3.9687, lr_0 = 2.9658e-04
Loss = 6.0322e-01, PNorm = 41.9155, GNorm = 3.1853, lr_0 = 2.9536e-04
Loss = 7.7845e-01, PNorm = 41.9205, GNorm = 3.5607, lr_0 = 2.9415e-04
Loss = 5.9799e-01, PNorm = 41.9308, GNorm = 3.3213, lr_0 = 2.9294e-04
Loss = 7.1136e-01, PNorm = 41.9461, GNorm = 2.5173, lr_0 = 2.9174e-04
Loss = 5.6899e-01, PNorm = 41.9610, GNorm = 3.3219, lr_0 = 2.9055e-04
Loss = 7.0834e-01, PNorm = 41.9730, GNorm = 4.3162, lr_0 = 2.8935e-04
Validation rmse = 0.762101
Epoch 17
Loss = 5.9188e-01, PNorm = 41.9861, GNorm = 3.9573, lr_0 = 2.8805e-04
Loss = 6.1702e-01, PNorm = 41.9954, GNorm = 4.1251, lr_0 = 2.8687e-04
Loss = 5.4754e-01, PNorm = 42.0064, GNorm = 2.3584, lr_0 = 2.8569e-04
Loss = 6.3859e-01, PNorm = 42.0183, GNorm = 5.2167, lr_0 = 2.8452e-04
Loss = 5.9123e-01, PNorm = 42.0279, GNorm = 2.1514, lr_0 = 2.8335e-04
Loss = 5.5874e-01, PNorm = 42.0329, GNorm = 8.1273, lr_0 = 2.8219e-04
Loss = 6.9849e-01, PNorm = 42.0409, GNorm = 7.1707, lr_0 = 2.8103e-04
Loss = 6.8301e-01, PNorm = 42.0466, GNorm = 3.6574, lr_0 = 2.7988e-04
Loss = 6.4401e-01, PNorm = 42.0535, GNorm = 3.0867, lr_0 = 2.7873e-04
Loss = 5.8395e-01, PNorm = 42.0616, GNorm = 4.3090, lr_0 = 2.7758e-04
Loss = 6.0497e-01, PNorm = 42.0743, GNorm = 3.4733, lr_0 = 2.7644e-04
Loss = 5.7601e-01, PNorm = 42.0851, GNorm = 5.0631, lr_0 = 2.7531e-04
Loss = 7.3791e-01, PNorm = 42.1002, GNorm = 6.2229, lr_0 = 2.7418e-04
Loss = 6.1371e-01, PNorm = 42.1090, GNorm = 2.4532, lr_0 = 2.7305e-04
Loss = 6.1823e-01, PNorm = 42.1116, GNorm = 4.3676, lr_0 = 2.7193e-04
Loss = 6.1812e-01, PNorm = 42.1171, GNorm = 3.4747, lr_0 = 2.7082e-04
Loss = 5.0698e-01, PNorm = 42.1229, GNorm = 5.0932, lr_0 = 2.6971e-04
Loss = 6.1144e-01, PNorm = 42.1316, GNorm = 2.1018, lr_0 = 2.6860e-04
Loss = 6.5250e-01, PNorm = 42.1467, GNorm = 4.1698, lr_0 = 2.6750e-04
Loss = 4.9664e-01, PNorm = 42.1615, GNorm = 4.5898, lr_0 = 2.6640e-04
Validation rmse = 0.735150
Epoch 18
Loss = 6.0771e-01, PNorm = 42.1736, GNorm = 5.0473, lr_0 = 2.6520e-04
Loss = 5.9053e-01, PNorm = 42.1802, GNorm = 3.7929, lr_0 = 2.6411e-04
Loss = 6.1218e-01, PNorm = 42.1878, GNorm = 4.1437, lr_0 = 2.6303e-04
Loss = 5.2733e-01, PNorm = 42.2026, GNorm = 7.3738, lr_0 = 2.6195e-04
Loss = 4.0107e-01, PNorm = 42.2162, GNorm = 4.9665, lr_0 = 2.6087e-04
Loss = 5.2829e-01, PNorm = 42.2254, GNorm = 16.3650, lr_0 = 2.5980e-04
Loss = 5.3033e-01, PNorm = 42.2377, GNorm = 10.2378, lr_0 = 2.5874e-04
Loss = 6.9341e-01, PNorm = 42.2489, GNorm = 3.0157, lr_0 = 2.5767e-04
Loss = 5.9913e-01, PNorm = 42.2564, GNorm = 7.1256, lr_0 = 2.5662e-04
Loss = 5.8454e-01, PNorm = 42.2605, GNorm = 2.4052, lr_0 = 2.5556e-04
Loss = 5.3648e-01, PNorm = 42.2675, GNorm = 4.1772, lr_0 = 2.5452e-04
Loss = 5.5649e-01, PNorm = 42.2770, GNorm = 2.4780, lr_0 = 2.5347e-04
Loss = 6.7082e-01, PNorm = 42.2831, GNorm = 5.9558, lr_0 = 2.5243e-04
Loss = 5.5110e-01, PNorm = 42.2932, GNorm = 5.1936, lr_0 = 2.5140e-04
Loss = 3.6714e-01, PNorm = 42.3069, GNorm = 2.9629, lr_0 = 2.5036e-04
Loss = 5.6472e-01, PNorm = 42.3115, GNorm = 5.3747, lr_0 = 2.4934e-04
Loss = 5.5621e-01, PNorm = 42.3232, GNorm = 3.6346, lr_0 = 2.4831e-04
Loss = 6.6922e-01, PNorm = 42.3326, GNorm = 6.4327, lr_0 = 2.4729e-04
Loss = 6.8255e-01, PNorm = 42.3367, GNorm = 2.7268, lr_0 = 2.4628e-04
Loss = 7.3256e-01, PNorm = 42.3422, GNorm = 2.6015, lr_0 = 2.4527e-04
Validation rmse = 0.726896
Epoch 19
Loss = 4.9005e-01, PNorm = 42.3513, GNorm = 7.1933, lr_0 = 2.4416e-04
Loss = 5.9877e-01, PNorm = 42.3592, GNorm = 3.3708, lr_0 = 2.4316e-04
Loss = 6.2827e-01, PNorm = 42.3667, GNorm = 5.6982, lr_0 = 2.4216e-04
Loss = 6.4440e-01, PNorm = 42.3701, GNorm = 2.8912, lr_0 = 2.4117e-04
Loss = 5.0789e-01, PNorm = 42.3762, GNorm = 4.4828, lr_0 = 2.4018e-04
Loss = 5.0802e-01, PNorm = 42.3816, GNorm = 7.0466, lr_0 = 2.3919e-04
Loss = 5.3266e-01, PNorm = 42.3887, GNorm = 5.4593, lr_0 = 2.3821e-04
Loss = 5.6876e-01, PNorm = 42.3977, GNorm = 4.0430, lr_0 = 2.3723e-04
Loss = 6.5955e-01, PNorm = 42.4044, GNorm = 7.3687, lr_0 = 2.3626e-04
Loss = 5.2542e-01, PNorm = 42.4107, GNorm = 3.1054, lr_0 = 2.3529e-04
Loss = 5.1035e-01, PNorm = 42.4165, GNorm = 3.0044, lr_0 = 2.3433e-04
Loss = 5.3137e-01, PNorm = 42.4232, GNorm = 4.3777, lr_0 = 2.3336e-04
Loss = 6.2495e-01, PNorm = 42.4328, GNorm = 3.7237, lr_0 = 2.3241e-04
Loss = 6.0413e-01, PNorm = 42.4426, GNorm = 4.6571, lr_0 = 2.3145e-04
Loss = 5.7914e-01, PNorm = 42.4470, GNorm = 2.4921, lr_0 = 2.3050e-04
Loss = 4.7669e-01, PNorm = 42.4542, GNorm = 3.1235, lr_0 = 2.2956e-04
Loss = 4.2769e-01, PNorm = 42.4630, GNorm = 6.8985, lr_0 = 2.2862e-04
Loss = 5.0814e-01, PNorm = 42.4715, GNorm = 8.5012, lr_0 = 2.2768e-04
Loss = 6.0995e-01, PNorm = 42.4803, GNorm = 7.4226, lr_0 = 2.2674e-04
Loss = 5.2415e-01, PNorm = 42.4915, GNorm = 2.9586, lr_0 = 2.2581e-04
Validation rmse = 0.725719
Epoch 20
Loss = 4.2453e-01, PNorm = 42.5015, GNorm = 3.9141, lr_0 = 2.2489e-04
Loss = 4.4632e-01, PNorm = 42.5137, GNorm = 12.1408, lr_0 = 2.2396e-04
Loss = 4.4736e-01, PNorm = 42.5241, GNorm = 5.6725, lr_0 = 2.2305e-04
Loss = 4.6672e-01, PNorm = 42.5318, GNorm = 6.9479, lr_0 = 2.2213e-04
Loss = 4.6359e-01, PNorm = 42.5395, GNorm = 3.9163, lr_0 = 2.2122e-04
Loss = 5.7073e-01, PNorm = 42.5469, GNorm = 3.1240, lr_0 = 2.2031e-04
Loss = 6.1218e-01, PNorm = 42.5520, GNorm = 4.2719, lr_0 = 2.1941e-04
Loss = 4.3672e-01, PNorm = 42.5560, GNorm = 3.7312, lr_0 = 2.1851e-04
Loss = 5.0077e-01, PNorm = 42.5642, GNorm = 3.5080, lr_0 = 2.1761e-04
Loss = 5.7260e-01, PNorm = 42.5689, GNorm = 4.9917, lr_0 = 2.1672e-04
Loss = 4.5682e-01, PNorm = 42.5783, GNorm = 6.6239, lr_0 = 2.1583e-04
Loss = 5.6773e-01, PNorm = 42.5856, GNorm = 4.7861, lr_0 = 2.1494e-04
Loss = 5.6230e-01, PNorm = 42.5910, GNorm = 3.9130, lr_0 = 2.1406e-04
Loss = 4.5831e-01, PNorm = 42.5984, GNorm = 2.6191, lr_0 = 2.1318e-04
Loss = 6.1663e-01, PNorm = 42.6037, GNorm = 3.0895, lr_0 = 2.1231e-04
Loss = 6.4410e-01, PNorm = 42.6075, GNorm = 10.0577, lr_0 = 2.1144e-04
Loss = 6.2658e-01, PNorm = 42.6136, GNorm = 3.3284, lr_0 = 2.1057e-04
Loss = 5.5636e-01, PNorm = 42.6201, GNorm = 4.5515, lr_0 = 2.0970e-04
Loss = 5.2241e-01, PNorm = 42.6273, GNorm = 3.4639, lr_0 = 2.0884e-04
Loss = 4.9941e-01, PNorm = 42.6351, GNorm = 5.7429, lr_0 = 2.0799e-04
Validation rmse = 0.731410
Epoch 21
Loss = 6.2460e-01, PNorm = 42.6425, GNorm = 5.5311, lr_0 = 2.0705e-04
Loss = 4.2629e-01, PNorm = 42.6507, GNorm = 3.4438, lr_0 = 2.0620e-04
Loss = 4.4266e-01, PNorm = 42.6570, GNorm = 4.4818, lr_0 = 2.0535e-04
Loss = 5.2389e-01, PNorm = 42.6621, GNorm = 5.0439, lr_0 = 2.0451e-04
Loss = 5.5208e-01, PNorm = 42.6652, GNorm = 2.5037, lr_0 = 2.0367e-04
Loss = 4.2871e-01, PNorm = 42.6734, GNorm = 6.0322, lr_0 = 2.0283e-04
Loss = 4.3311e-01, PNorm = 42.6842, GNorm = 3.1948, lr_0 = 2.0200e-04
Loss = 4.5222e-01, PNorm = 42.6971, GNorm = 4.3926, lr_0 = 2.0117e-04
Loss = 5.9528e-01, PNorm = 42.7061, GNorm = 8.0013, lr_0 = 2.0035e-04
Loss = 3.5658e-01, PNorm = 42.7145, GNorm = 3.9735, lr_0 = 1.9953e-04
Loss = 6.7666e-01, PNorm = 42.7219, GNorm = 5.8360, lr_0 = 1.9871e-04
Loss = 5.4936e-01, PNorm = 42.7266, GNorm = 7.1449, lr_0 = 1.9789e-04
Loss = 5.8007e-01, PNorm = 42.7265, GNorm = 6.0235, lr_0 = 1.9708e-04
Loss = 4.5184e-01, PNorm = 42.7312, GNorm = 4.5076, lr_0 = 1.9627e-04
Loss = 4.2624e-01, PNorm = 42.7373, GNorm = 5.2662, lr_0 = 1.9547e-04
Loss = 5.9379e-01, PNorm = 42.7440, GNorm = 3.9122, lr_0 = 1.9466e-04
Loss = 4.0703e-01, PNorm = 42.7515, GNorm = 5.8208, lr_0 = 1.9387e-04
Loss = 3.6503e-01, PNorm = 42.7605, GNorm = 3.1902, lr_0 = 1.9307e-04
Loss = 5.8436e-01, PNorm = 42.7664, GNorm = 6.3938, lr_0 = 1.9228e-04
Loss = 5.0978e-01, PNorm = 42.7741, GNorm = 2.1628, lr_0 = 1.9149e-04
Validation rmse = 0.725543
Epoch 22
Loss = 4.8536e-01, PNorm = 42.7768, GNorm = 4.7673, lr_0 = 1.9062e-04
Loss = 5.1574e-01, PNorm = 42.7823, GNorm = 4.2061, lr_0 = 1.8984e-04
Loss = 4.6641e-01, PNorm = 42.7891, GNorm = 3.1072, lr_0 = 1.8906e-04
Loss = 5.5315e-01, PNorm = 42.7959, GNorm = 7.6301, lr_0 = 1.8829e-04
Loss = 4.9706e-01, PNorm = 42.8043, GNorm = 5.3239, lr_0 = 1.8751e-04
Loss = 4.5176e-01, PNorm = 42.8082, GNorm = 5.4741, lr_0 = 1.8675e-04
Loss = 4.6910e-01, PNorm = 42.8149, GNorm = 4.7848, lr_0 = 1.8598e-04
Loss = 6.0437e-01, PNorm = 42.8216, GNorm = 5.0302, lr_0 = 1.8522e-04
Loss = 2.9660e-01, PNorm = 42.8273, GNorm = 4.3123, lr_0 = 1.8446e-04
Loss = 4.6606e-01, PNorm = 42.8307, GNorm = 3.9828, lr_0 = 1.8370e-04
Loss = 3.9620e-01, PNorm = 42.8344, GNorm = 17.1519, lr_0 = 1.8295e-04
Loss = 4.7174e-01, PNorm = 42.8389, GNorm = 6.6981, lr_0 = 1.8219e-04
Loss = 3.2543e-01, PNorm = 42.8461, GNorm = 5.0103, lr_0 = 1.8145e-04
Loss = 3.7935e-01, PNorm = 42.8524, GNorm = 5.0449, lr_0 = 1.8070e-04
Loss = 5.0457e-01, PNorm = 42.8600, GNorm = 6.5879, lr_0 = 1.7996e-04
Loss = 4.9022e-01, PNorm = 42.8661, GNorm = 5.7807, lr_0 = 1.7922e-04
Loss = 5.2304e-01, PNorm = 42.8703, GNorm = 3.2233, lr_0 = 1.7849e-04
Loss = 5.6511e-01, PNorm = 42.8737, GNorm = 2.9215, lr_0 = 1.7775e-04
Loss = 6.2459e-01, PNorm = 42.8760, GNorm = 4.1740, lr_0 = 1.7703e-04
Loss = 5.3008e-01, PNorm = 42.8803, GNorm = 2.9932, lr_0 = 1.7630e-04
Validation rmse = 0.725498
Epoch 23
Loss = 3.7378e-01, PNorm = 42.8846, GNorm = 6.2701, lr_0 = 1.7550e-04
Loss = 4.3442e-01, PNorm = 42.8888, GNorm = 7.9817, lr_0 = 1.7478e-04
Loss = 5.8932e-01, PNorm = 42.8947, GNorm = 4.5639, lr_0 = 1.7407e-04
Loss = 4.9485e-01, PNorm = 42.9007, GNorm = 6.6748, lr_0 = 1.7335e-04
Loss = 4.9833e-01, PNorm = 42.9067, GNorm = 4.6254, lr_0 = 1.7264e-04
Loss = 4.1725e-01, PNorm = 42.9134, GNorm = 5.7213, lr_0 = 1.7193e-04
Loss = 3.7797e-01, PNorm = 42.9197, GNorm = 4.7523, lr_0 = 1.7123e-04
Loss = 5.0551e-01, PNorm = 42.9237, GNorm = 12.9224, lr_0 = 1.7052e-04
Loss = 3.3847e-01, PNorm = 42.9281, GNorm = 4.5693, lr_0 = 1.6982e-04
Loss = 4.1420e-01, PNorm = 42.9336, GNorm = 28.9133, lr_0 = 1.6913e-04
Loss = 4.5879e-01, PNorm = 42.9376, GNorm = 4.4835, lr_0 = 1.6843e-04
Loss = 2.7628e-01, PNorm = 42.9425, GNorm = 3.7371, lr_0 = 1.6774e-04
Loss = 6.0284e-01, PNorm = 42.9483, GNorm = 4.3083, lr_0 = 1.6705e-04
Loss = 4.2667e-01, PNorm = 42.9545, GNorm = 8.6276, lr_0 = 1.6637e-04
Loss = 4.3837e-01, PNorm = 42.9581, GNorm = 9.4255, lr_0 = 1.6569e-04
Loss = 4.2749e-01, PNorm = 42.9638, GNorm = 2.9120, lr_0 = 1.6501e-04
Loss = 5.0662e-01, PNorm = 42.9683, GNorm = 6.3875, lr_0 = 1.6433e-04
Loss = 4.5882e-01, PNorm = 42.9740, GNorm = 3.2628, lr_0 = 1.6365e-04
Loss = 5.7547e-01, PNorm = 42.9772, GNorm = 7.2970, lr_0 = 1.6298e-04
Loss = 3.2732e-01, PNorm = 42.9807, GNorm = 7.2428, lr_0 = 1.6231e-04
Validation rmse = 0.718081
Epoch 24
Loss = 4.8135e-01, PNorm = 42.9896, GNorm = 8.7989, lr_0 = 1.6158e-04
Loss = 3.5076e-01, PNorm = 42.9946, GNorm = 6.1427, lr_0 = 1.6092e-04
Loss = 5.2778e-01, PNorm = 42.9981, GNorm = 4.0219, lr_0 = 1.6026e-04
Loss = 4.3676e-01, PNorm = 43.0051, GNorm = 6.2573, lr_0 = 1.5960e-04
Loss = 5.8218e-01, PNorm = 43.0100, GNorm = 11.1153, lr_0 = 1.5895e-04
Loss = 5.9825e-01, PNorm = 43.0137, GNorm = 2.9135, lr_0 = 1.5829e-04
Loss = 4.8854e-01, PNorm = 43.0184, GNorm = 2.9245, lr_0 = 1.5764e-04
Loss = 3.9345e-01, PNorm = 43.0238, GNorm = 3.5241, lr_0 = 1.5700e-04
Loss = 3.3461e-01, PNorm = 43.0290, GNorm = 7.9397, lr_0 = 1.5635e-04
Loss = 4.1914e-01, PNorm = 43.0331, GNorm = 5.6997, lr_0 = 1.5571e-04
Loss = 4.7704e-01, PNorm = 43.0354, GNorm = 9.4756, lr_0 = 1.5507e-04
Loss = 3.2500e-01, PNorm = 43.0382, GNorm = 4.9573, lr_0 = 1.5444e-04
Loss = 4.7205e-01, PNorm = 43.0406, GNorm = 4.1956, lr_0 = 1.5380e-04
Loss = 4.6421e-01, PNorm = 43.0483, GNorm = 3.3560, lr_0 = 1.5317e-04
Loss = 4.1435e-01, PNorm = 43.0553, GNorm = 26.3070, lr_0 = 1.5254e-04
Loss = 2.6809e-01, PNorm = 43.0624, GNorm = 10.1385, lr_0 = 1.5192e-04
Loss = 1.9928e-01, PNorm = 43.0693, GNorm = 3.4476, lr_0 = 1.5129e-04
Loss = 4.2785e-01, PNorm = 43.0765, GNorm = 6.9433, lr_0 = 1.5067e-04
Loss = 3.0032e-01, PNorm = 43.0819, GNorm = 8.9112, lr_0 = 1.5005e-04
Loss = 5.4570e-01, PNorm = 43.0874, GNorm = 8.1143, lr_0 = 1.4944e-04
Validation rmse = 0.723807
Epoch 25
Loss = 3.5378e-01, PNorm = 43.0931, GNorm = 12.6271, lr_0 = 1.4876e-04
Loss = 2.8272e-01, PNorm = 43.0985, GNorm = 7.2409, lr_0 = 1.4815e-04
Loss = 4.2902e-01, PNorm = 43.1045, GNorm = 5.2378, lr_0 = 1.4755e-04
Loss = 3.3823e-01, PNorm = 43.1094, GNorm = 5.1498, lr_0 = 1.4694e-04
Loss = 2.0891e-01, PNorm = 43.1140, GNorm = 7.0900, lr_0 = 1.4634e-04
Loss = 5.0636e-01, PNorm = 43.1131, GNorm = 11.4970, lr_0 = 1.4574e-04
Loss = 2.0922e-01, PNorm = 43.1122, GNorm = 3.8052, lr_0 = 1.4514e-04
Loss = 3.3529e-01, PNorm = 43.1139, GNorm = 6.4929, lr_0 = 1.4454e-04
Loss = 4.6400e-01, PNorm = 43.1187, GNorm = 16.8668, lr_0 = 1.4395e-04
Loss = 3.1859e-01, PNorm = 43.1234, GNorm = 4.2014, lr_0 = 1.4336e-04
Loss = 3.4867e-01, PNorm = 43.1295, GNorm = 5.9525, lr_0 = 1.4277e-04
Loss = 4.4385e-01, PNorm = 43.1361, GNorm = 10.3589, lr_0 = 1.4219e-04
Loss = 4.9566e-01, PNorm = 43.1420, GNorm = 5.9729, lr_0 = 1.4160e-04
Loss = 3.9396e-01, PNorm = 43.1472, GNorm = 5.8249, lr_0 = 1.4102e-04
Loss = 5.3187e-01, PNorm = 43.1501, GNorm = 11.8713, lr_0 = 1.4044e-04
Loss = 3.8716e-01, PNorm = 43.1526, GNorm = 6.1857, lr_0 = 1.3987e-04
Loss = 4.5169e-01, PNorm = 43.1564, GNorm = 4.5203, lr_0 = 1.3929e-04
Loss = 4.8658e-01, PNorm = 43.1589, GNorm = 4.6871, lr_0 = 1.3872e-04
Loss = 4.4385e-01, PNorm = 43.1617, GNorm = 5.2916, lr_0 = 1.3815e-04
Loss = 4.2026e-01, PNorm = 43.1658, GNorm = 2.8944, lr_0 = 1.3759e-04
Validation rmse = 0.713152
Epoch 26
Loss = 3.9285e-01, PNorm = 43.1715, GNorm = 6.4607, lr_0 = 1.3696e-04
Loss = 3.3199e-01, PNorm = 43.1770, GNorm = 3.1750, lr_0 = 1.3640e-04
Loss = 3.4650e-01, PNorm = 43.1823, GNorm = 8.6179, lr_0 = 1.3584e-04
Loss = 3.4344e-01, PNorm = 43.1875, GNorm = 9.9467, lr_0 = 1.3529e-04
Loss = 3.0281e-01, PNorm = 43.1907, GNorm = 4.3619, lr_0 = 1.3473e-04
Loss = 4.5692e-01, PNorm = 43.1945, GNorm = 6.9616, lr_0 = 1.3418e-04
Loss = 5.3095e-01, PNorm = 43.1966, GNorm = 6.8134, lr_0 = 1.3363e-04
Loss = 4.2090e-01, PNorm = 43.2002, GNorm = 3.1825, lr_0 = 1.3308e-04
Loss = 3.7519e-01, PNorm = 43.2055, GNorm = 6.1563, lr_0 = 1.3253e-04
Loss = 3.1240e-01, PNorm = 43.2112, GNorm = 6.6439, lr_0 = 1.3199e-04
Loss = 3.7457e-01, PNorm = 43.2170, GNorm = 4.7179, lr_0 = 1.3145e-04
Loss = 3.6807e-01, PNorm = 43.2223, GNorm = 9.5664, lr_0 = 1.3091e-04
Loss = 4.8939e-01, PNorm = 43.2281, GNorm = 3.6219, lr_0 = 1.3037e-04
Loss = 3.1948e-01, PNorm = 43.2335, GNorm = 8.3509, lr_0 = 1.2984e-04
Loss = 4.6021e-01, PNorm = 43.2381, GNorm = 5.2094, lr_0 = 1.2930e-04
Loss = 3.3555e-01, PNorm = 43.2392, GNorm = 4.2220, lr_0 = 1.2877e-04
Loss = 3.1690e-01, PNorm = 43.2416, GNorm = 5.7352, lr_0 = 1.2824e-04
Loss = 3.5342e-01, PNorm = 43.2458, GNorm = 10.8523, lr_0 = 1.2772e-04
Loss = 3.0419e-01, PNorm = 43.2487, GNorm = 6.3289, lr_0 = 1.2719e-04
Loss = 4.6423e-01, PNorm = 43.2510, GNorm = 4.0974, lr_0 = 1.2667e-04
Validation rmse = 0.719459
Epoch 27
Loss = 5.3238e-01, PNorm = 43.2536, GNorm = 7.0280, lr_0 = 1.2610e-04
Loss = 4.2030e-01, PNorm = 43.2572, GNorm = 5.3249, lr_0 = 1.2558e-04
Loss = 2.8406e-01, PNorm = 43.2614, GNorm = 8.4591, lr_0 = 1.2507e-04
Loss = 2.8120e-01, PNorm = 43.2656, GNorm = 5.4288, lr_0 = 1.2455e-04
Loss = 3.8876e-01, PNorm = 43.2703, GNorm = 3.9298, lr_0 = 1.2404e-04
Loss = 4.0881e-01, PNorm = 43.2748, GNorm = 6.5526, lr_0 = 1.2353e-04
Loss = 2.1993e-01, PNorm = 43.2797, GNorm = 4.1406, lr_0 = 1.2303e-04
Loss = 3.2840e-01, PNorm = 43.2858, GNorm = 3.7397, lr_0 = 1.2252e-04
Loss = 3.8174e-01, PNorm = 43.2901, GNorm = 6.5543, lr_0 = 1.2202e-04
Loss = 3.1829e-01, PNorm = 43.2945, GNorm = 5.6182, lr_0 = 1.2152e-04
Loss = 3.5241e-01, PNorm = 43.2986, GNorm = 12.3335, lr_0 = 1.2102e-04
Loss = 2.3279e-01, PNorm = 43.3028, GNorm = 6.5623, lr_0 = 1.2052e-04
Loss = 4.3274e-01, PNorm = 43.3057, GNorm = 9.6300, lr_0 = 1.2003e-04
Loss = 3.9527e-01, PNorm = 43.3098, GNorm = 5.0571, lr_0 = 1.1954e-04
Loss = 4.0157e-01, PNorm = 43.3158, GNorm = 16.0655, lr_0 = 1.1905e-04
Loss = 3.8246e-01, PNorm = 43.3194, GNorm = 6.3942, lr_0 = 1.1856e-04
Loss = 3.6961e-01, PNorm = 43.3209, GNorm = 9.9682, lr_0 = 1.1807e-04
Loss = 3.8799e-01, PNorm = 43.3215, GNorm = 9.1317, lr_0 = 1.1759e-04
Loss = 2.2753e-01, PNorm = 43.3235, GNorm = 6.4610, lr_0 = 1.1710e-04
Loss = 3.7160e-01, PNorm = 43.3247, GNorm = 5.3309, lr_0 = 1.1662e-04
Validation rmse = 0.710056
Epoch 28
Loss = 2.6467e-01, PNorm = 43.3272, GNorm = 10.2154, lr_0 = 1.1610e-04
Loss = 2.7155e-01, PNorm = 43.3294, GNorm = 17.0561, lr_0 = 1.1562e-04
Loss = 3.1952e-01, PNorm = 43.3353, GNorm = 6.7858, lr_0 = 1.1515e-04
Loss = 2.9769e-01, PNorm = 43.3420, GNorm = 7.9028, lr_0 = 1.1467e-04
Loss = 2.9794e-01, PNorm = 43.3477, GNorm = 5.9443, lr_0 = 1.1420e-04
Loss = 4.0621e-01, PNorm = 43.3514, GNorm = 13.3040, lr_0 = 1.1373e-04
Loss = 2.6703e-01, PNorm = 43.3540, GNorm = 6.4215, lr_0 = 1.1327e-04
Loss = 3.0579e-01, PNorm = 43.3573, GNorm = 9.3421, lr_0 = 1.1280e-04
Loss = 2.8373e-01, PNorm = 43.3593, GNorm = 10.7023, lr_0 = 1.1234e-04
Loss = 5.3480e-01, PNorm = 43.3626, GNorm = 8.7437, lr_0 = 1.1188e-04
Loss = 4.6719e-01, PNorm = 43.3671, GNorm = 4.7360, lr_0 = 1.1142e-04
Loss = 3.7643e-01, PNorm = 43.3708, GNorm = 7.6432, lr_0 = 1.1096e-04
Loss = 3.6267e-01, PNorm = 43.3743, GNorm = 7.3119, lr_0 = 1.1051e-04
Loss = 3.4865e-01, PNorm = 43.3778, GNorm = 7.0878, lr_0 = 1.1005e-04
Loss = 3.4921e-01, PNorm = 43.3797, GNorm = 6.4433, lr_0 = 1.0960e-04
Loss = 3.6353e-01, PNorm = 43.3820, GNorm = 13.0705, lr_0 = 1.0915e-04
Loss = 4.0364e-01, PNorm = 43.3846, GNorm = 6.6040, lr_0 = 1.0871e-04
Loss = 2.5135e-01, PNorm = 43.3873, GNorm = 4.1252, lr_0 = 1.0826e-04
Loss = 3.1358e-01, PNorm = 43.3905, GNorm = 5.0878, lr_0 = 1.0781e-04
Loss = 1.8277e-01, PNorm = 43.3930, GNorm = 5.9094, lr_0 = 1.0737e-04
Validation rmse = 0.713163
Epoch 29
Loss = 3.7895e-01, PNorm = 43.3961, GNorm = 5.0137, lr_0 = 1.0689e-04
Loss = 3.2446e-01, PNorm = 43.3995, GNorm = 15.9701, lr_0 = 1.0645e-04
Loss = 2.2029e-01, PNorm = 43.4023, GNorm = 8.9005, lr_0 = 1.0601e-04
Loss = 2.2483e-01, PNorm = 43.4055, GNorm = 6.2212, lr_0 = 1.0558e-04
Loss = 4.1927e-01, PNorm = 43.4081, GNorm = 8.8129, lr_0 = 1.0514e-04
Loss = 1.8425e-01, PNorm = 43.4118, GNorm = 8.4271, lr_0 = 1.0471e-04
Loss = 3.3768e-01, PNorm = 43.4165, GNorm = 9.8581, lr_0 = 1.0428e-04
Loss = 4.3564e-01, PNorm = 43.4197, GNorm = 8.4003, lr_0 = 1.0386e-04
Loss = 4.7281e-01, PNorm = 43.4212, GNorm = 5.1772, lr_0 = 1.0343e-04
Loss = 3.4605e-01, PNorm = 43.4242, GNorm = 4.1521, lr_0 = 1.0300e-04
Loss = 3.1397e-01, PNorm = 43.4269, GNorm = 11.3466, lr_0 = 1.0258e-04
Loss = 3.4438e-01, PNorm = 43.4302, GNorm = 11.4960, lr_0 = 1.0216e-04
Loss = 2.3926e-01, PNorm = 43.4344, GNorm = 6.7943, lr_0 = 1.0174e-04
Loss = 3.1342e-01, PNorm = 43.4378, GNorm = 4.5254, lr_0 = 1.0132e-04
Loss = 3.1568e-01, PNorm = 43.4396, GNorm = 11.1669, lr_0 = 1.0091e-04
Loss = 2.9537e-01, PNorm = 43.4423, GNorm = 4.4537, lr_0 = 1.0049e-04
Loss = 3.3789e-01, PNorm = 43.4456, GNorm = 7.8489, lr_0 = 1.0008e-04
Loss = 2.5669e-01, PNorm = 43.4500, GNorm = 5.6084, lr_0 = 1.0000e-04
Loss = 3.5048e-01, PNorm = 43.4545, GNorm = 9.3309, lr_0 = 1.0000e-04
Loss = 3.3648e-01, PNorm = 43.4559, GNorm = 4.3253, lr_0 = 1.0000e-04
Validation rmse = 0.720505
Model 0 best validation rmse = 0.710056 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.856314
Ensemble test rmse = 0.856314
1-fold cross validation
	Seed 0 ==> test rmse = 0.856314
Overall test rmse = 0.856314 +/- 0.000000
Elapsed time = 0:04:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.349711
Epoch 1
Loss = 1.4432e+00, PNorm = 43.3275, GNorm = 0.9591, lr_0 = 8.7143e-04
Validation rmse = 1.272511
Epoch 2
Loss = 1.4066e+00, PNorm = 43.3627, GNorm = 0.7073, lr_0 = 9.1030e-04
Validation rmse = 1.276731
Epoch 3
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 500,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.377119
Epoch 1
Validation rmse = 1.332752
Epoch 2
Validation rmse = 1.305274
Epoch 3
Validation rmse = 1.290505
Epoch 4
Validation rmse = 1.278722
Epoch 5
Validation rmse = 1.271949
Epoch 6
Loss = 1.3948e+00, PNorm = 43.3537, GNorm = 0.7644, lr_0 = 3.7276e-04
Validation rmse = 1.265837
Epoch 7
Validation rmse = 1.261106
Epoch 8
Validation rmse = 1.258522
Epoch 9
Validation rmse = 1.255068
Epoch 10
Validation rmse = 1.252215
Epoch 11
Validation rmse = 1.250344
Epoch 12
Loss = 1.3150e+00, PNorm = 43.3712, GNorm = 0.4893, lr_0 = 1.3895e-04
Loss = 1.3241e+00, PNorm = 43.3721, GNorm = 0.4608, lr_0 = 1.2798e-04
Validation rmse = 1.248576
Epoch 13
Validation rmse = 1.246606
Epoch 14
Validation rmse = 1.244482
Epoch 15
Validation rmse = 1.242721
Epoch 16
Validation rmse = 1.240777
Epoch 17
Validation rmse = 1.238461
Epoch 18
Loss = 1.2847e+00, PNorm = 43.3807, GNorm = 0.3918, lr_0 = 1.0000e-04
Validation rmse = 1.235581
Epoch 19
Validation rmse = 1.232737
Epoch 20
Validation rmse = 1.230105
Epoch 21
Validation rmse = 1.227354
Epoch 22
Validation rmse = 1.225194
Epoch 23
Validation rmse = 1.222991
Epoch 24
Validation rmse = 1.221603
Epoch 25
Loss = 1.2178e+00, PNorm = 43.3911, GNorm = 0.5367, lr_0 = 1.0000e-04
Validation rmse = 1.219699
Epoch 26
Validation rmse = 1.216248
Epoch 27
Validation rmse = 1.212334
Epoch 28
Validation rmse = 1.208486
Epoch 29
Validation rmse = 1.205859
Model 0 best validation rmse = 1.205859 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.255488
Ensemble test rmse = 1.255488
1-fold cross validation
	Seed 0 ==> test rmse = 1.255488
Overall test rmse = 1.255488 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 500,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.377119
Epoch 1
Validation rmse = 1.332752
Epoch 2
Validation rmse = 1.305274
Epoch 3
Validation rmse = 1.290505
Epoch 4
Validation rmse = 1.278722
Epoch 5
Validation rmse = 1.271949
Epoch 6
Loss = 1.3948e+00, PNorm = 43.3537, GNorm = 0.7644, lr_0 = 3.7276e-04
Validation rmse = 1.265837
Epoch 7
Validation rmse = 1.261106
Epoch 8
Validation rmse = 1.258522
Epoch 9
Validation rmse = 1.255068
Epoch 10
Validation rmse = 1.252215
Epoch 11
Validation rmse = 1.250344
Epoch 12
Loss = 1.3150e+00, PNorm = 43.3712, GNorm = 0.4893, lr_0 = 1.3895e-04
Loss = 1.3241e+00, PNorm = 43.3721, GNorm = 0.4608, lr_0 = 1.2798e-04
Validation rmse = 1.248576
Epoch 13
Validation rmse = 1.246606
Epoch 14
Validation rmse = 1.244482
Epoch 15
Validation rmse = 1.242721
Epoch 16
Validation rmse = 1.240777
Epoch 17
Validation rmse = 1.238461
Epoch 18
Loss = 1.2847e+00, PNorm = 43.3807, GNorm = 0.3918, lr_0 = 1.0000e-04
Validation rmse = 1.235581
Epoch 19
Validation rmse = 1.232737
Epoch 20
Validation rmse = 1.230105
Epoch 21
Validation rmse = 1.227354
Epoch 22
Validation rmse = 1.225194
Epoch 23
Validation rmse = 1.222991
Epoch 24
Validation rmse = 1.221603
Epoch 25
Loss = 1.2178e+00, PNorm = 43.3911, GNorm = 0.5367, lr_0 = 1.0000e-04
Validation rmse = 1.219699
Epoch 26
Validation rmse = 1.216248
Epoch 27
Validation rmse = 1.212334
Epoch 28
Validation rmse = 1.208486
Epoch 29
Validation rmse = 1.205859
Model 0 best validation rmse = 1.205859 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.255488
Ensemble test rmse = 1.255488
1-fold cross validation
	Seed 0 ==> test rmse = 1.255488
Overall test rmse = 1.255488 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 500,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.506031
Epoch 1
Validation rmse = 1.463183
Epoch 2
Validation rmse = 1.443509
Epoch 3
Validation rmse = 1.434512
Epoch 4
Loss = 1.4225e+00, PNorm = 43.3592, GNorm = 0.8449, lr_0 = 6.6287e-04
Validation rmse = 1.429336
Epoch 5
Validation rmse = 1.424507
Epoch 6
Validation rmse = 1.410033
Epoch 7
Validation rmse = 1.392542
Epoch 8
Loss = 1.3151e+00, PNorm = 43.3959, GNorm = 0.3860, lr_0 = 4.0471e-04
Validation rmse = 1.376378
Epoch 9
Validation rmse = 1.366801
Epoch 10
Validation rmse = 1.352095
Epoch 11
Validation rmse = 1.342650
Epoch 12
Loss = 1.2573e+00, PNorm = 43.4222, GNorm = 0.4878, lr_0 = 2.3714e-04
Validation rmse = 1.333766
Epoch 13
Validation rmse = 1.326692
Epoch 14
Validation rmse = 1.320989
Epoch 15
Validation rmse = 1.313942
Epoch 16
Loss = 1.2227e+00, PNorm = 43.4393, GNorm = 0.4732, lr_0 = 1.4478e-04
Loss = 1.2054e+00, PNorm = 43.4405, GNorm = 0.4733, lr_0 = 1.3895e-04
Validation rmse = 1.308231
Epoch 17
Validation rmse = 1.302588
Epoch 18
Validation rmse = 1.297300
Epoch 19
Validation rmse = 1.292343
Epoch 20
Loss = 1.1970e+00, PNorm = 43.4525, GNorm = 0.6178, lr_0 = 1.0000e-04
Validation rmse = 1.287859
Epoch 21
Validation rmse = 1.281568
Epoch 22
Validation rmse = 1.274794
Epoch 23
Validation rmse = 1.269151
Epoch 24
Validation rmse = 1.264088
Epoch 25
Loss = 1.1434e+00, PNorm = 43.4654, GNorm = 0.8003, lr_0 = 1.0000e-04
Validation rmse = 1.258988
Epoch 26
Validation rmse = 1.250504
Epoch 27
Validation rmse = 1.244543
Epoch 28
Validation rmse = 1.237648
Epoch 29
Loss = 1.1457e+00, PNorm = 43.4783, GNorm = 0.4188, lr_0 = 1.0000e-04
Validation rmse = 1.232551
Model 0 best validation rmse = 1.232551 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.123491
Ensemble test rmse = 1.123491
1-fold cross validation
	Seed 0 ==> test rmse = 1.123491
Overall test rmse = 1.123491 +/- 0.000000
Elapsed time = 0:02:27
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 500,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.377119
Epoch 1
Validation rmse = 1.357804
Epoch 2
Validation rmse = 1.352296
Epoch 3
Validation rmse = 1.346831
Epoch 4
Validation rmse = 1.341197
Model 0 best validation rmse = 1.341197 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.428538
Ensemble test rmse = 1.428538
1-fold cross validation
	Seed 0 ==> test rmse = 1.428538
Overall test rmse = 1.428538 +/- 0.000000
Elapsed time = 0:00:16
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 500,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.506031
Epoch 1
Validation rmse = 1.472184
Epoch 2
Validation rmse = 1.460264
Epoch 3
Validation rmse = 1.455026
Epoch 4
Loss = 1.4254e+00, PNorm = 43.3301, GNorm = 0.9920, lr_0 = 1.0000e-04
Validation rmse = 1.450613
Model 0 best validation rmse = 1.450613 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.384657
Ensemble test rmse = 1.384657
1-fold cross validation
	Seed 0 ==> test rmse = 1.384657
Overall test rmse = 1.384657 +/- 0.000000
Elapsed time = 0:00:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 500,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.500184
Epoch 1
Validation rmse = 1.489406
Epoch 2
Validation rmse = 1.483903
Epoch 3
Validation rmse = 1.476896
Epoch 4
Validation rmse = 1.469364
Model 0 best validation rmse = 1.469364 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.216879
Ensemble test rmse = 1.216879
1-fold cross validation
	Seed 0 ==> test rmse = 1.216879
Overall test rmse = 1.216879 +/- 0.000000
Elapsed time = 0:00:17
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 1000,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 5,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.5160e+00, PNorm = 43.3250, GNorm = 12.4769, lr_0 = 1.0000e-04
Validation rmse = 1.421389
Epoch 1
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 1000,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 1,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.5160e+00, PNorm = 43.3250, GNorm = 12.4769, lr_0 = 1.0000e-04
Validation rmse = 1.421389
Model 0 best validation rmse = 1.421389 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.512130
Ensemble test rmse = 1.512130
1-fold cross validation
	Seed 0 ==> test rmse = 1.512130
Overall test rmse = 1.512130 +/- 0.000000
Elapsed time = 0:00:05
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 1000,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 1,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.6005e+00, PNorm = 43.3249, GNorm = 13.4173, lr_0 = 1.0000e-04
Validation rmse = 1.521009
Model 0 best validation rmse = 1.521009 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.276575
Ensemble test rmse = 1.276575
1-fold cross validation
	Seed 0 ==> test rmse = 1.276575
Overall test rmse = 1.276575 +/- 0.000000
Elapsed time = 0:00:05
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 1000,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 1,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.5160e+00, PNorm = 43.3250, GNorm = 12.4769, lr_0 = 1.0000e-04
Validation rmse = 1.421389
Model 0 best validation rmse = 1.421389 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.512130
Ensemble test rmse = 1.512130
1-fold cross validation
	Seed 0 ==> test rmse = 1.512130
Overall test rmse = 1.512130 +/- 0.000000
Elapsed time = 0:00:05
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 1000,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 1,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.6005e+00, PNorm = 43.3249, GNorm = 13.4173, lr_0 = 1.0000e-04
Validation rmse = 1.521009
Model 0 best validation rmse = 1.521009 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.276575
Ensemble test rmse = 1.276575
1-fold cross validation
	Seed 0 ==> test rmse = 1.276575
Overall test rmse = 1.276575 +/- 0.000000
Elapsed time = 0:00:05
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-a7971c61-fa44-44c2-9140-b665ed1a938a.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 1,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7249e+00, PNorm = 43.3214, GNorm = 1.2524, lr_0 = 4.3000e-04
Validation rmse = 1.315150
Model 0 best validation rmse = 1.315150 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.400568
Ensemble test rmse = 1.400568
1-fold cross validation
	Seed 0 ==> test rmse = 1.400568
Overall test rmse = 1.400568 +/- 0.000000
Elapsed time = 0:00:03
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9882, lr_0 = 3.0475e-04
Loss = 1.4487e+00, PNorm = 34.0770, GNorm = 2.0143, lr_0 = 3.2725e-04
Loss = 1.1911e+00, PNorm = 34.0840, GNorm = 1.1740, lr_0 = 3.4975e-04
Loss = 1.4932e+00, PNorm = 34.0957, GNorm = 6.5593, lr_0 = 3.7225e-04
Loss = 1.3794e+00, PNorm = 34.1087, GNorm = 0.8852, lr_0 = 3.9475e-04
Loss = 1.2898e+00, PNorm = 34.1164, GNorm = 4.6213, lr_0 = 4.1725e-04
Loss = 1.2109e+00, PNorm = 34.1213, GNorm = 2.4256, lr_0 = 4.3975e-04
Loss = 1.4010e+00, PNorm = 34.1327, GNorm = 0.9934, lr_0 = 4.6225e-04
Loss = 1.4221e+00, PNorm = 34.1504, GNorm = 3.0334, lr_0 = 4.8475e-04
Loss = 1.2919e+00, PNorm = 34.1722, GNorm = 7.2700, lr_0 = 5.0725e-04
Loss = 1.3147e+00, PNorm = 34.1872, GNorm = 1.4059, lr_0 = 5.2975e-04
Loss = 1.0992e+00, PNorm = 34.2060, GNorm = 3.0343, lr_0 = 5.5225e-04
Loss = 7.3647e-01, PNorm = 34.2073, GNorm = 2.2183, lr_0 = 5.5450e-04
Validation rmse = 1.228565
Epoch 1
Loss = 1.1035e+00, PNorm = 34.2178, GNorm = 0.8083, lr_0 = 5.7700e-04
Loss = 1.4086e+00, PNorm = 34.2342, GNorm = 3.4673, lr_0 = 5.9950e-04
Loss = 1.1778e+00, PNorm = 34.2537, GNorm = 6.5705, lr_0 = 6.2200e-04
Loss = 1.1835e+00, PNorm = 34.2683, GNorm = 1.2977, lr_0 = 6.4450e-04
Loss = 1.2701e+00, PNorm = 34.2781, GNorm = 3.0441, lr_0 = 6.6700e-04
Loss = 1.2216e+00, PNorm = 34.2933, GNorm = 2.4881, lr_0 = 6.8950e-04
Loss = 1.1830e+00, PNorm = 34.3136, GNorm = 2.1587, lr_0 = 7.1200e-04
Loss = 1.2696e+00, PNorm = 34.3316, GNorm = 3.4795, lr_0 = 7.3450e-04
Loss = 1.1937e+00, PNorm = 34.3557, GNorm = 1.1521, lr_0 = 7.5700e-04
Loss = 1.2716e+00, PNorm = 34.3925, GNorm = 1.0563, lr_0 = 7.7950e-04
Loss = 1.1571e+00, PNorm = 34.4235, GNorm = 1.6019, lr_0 = 8.0200e-04
Loss = 1.2267e+00, PNorm = 34.4478, GNorm = 2.2283, lr_0 = 8.2450e-04
Loss = 1.3329e+00, PNorm = 34.4910, GNorm = 2.1034, lr_0 = 8.4700e-04
Loss = 1.4345e+00, PNorm = 34.5301, GNorm = 2.6554, lr_0 = 8.6950e-04
Loss = 1.2190e+00, PNorm = 34.5841, GNorm = 1.0586, lr_0 = 8.9200e-04
Loss = 1.2721e+00, PNorm = 34.6209, GNorm = 1.0373, lr_0 = 9.1450e-04
Loss = 1.2486e+00, PNorm = 34.6479, GNorm = 0.9591, lr_0 = 9.3700e-04
Loss = 1.1593e+00, PNorm = 34.6723, GNorm = 0.9991, lr_0 = 9.5950e-04
Loss = 1.1604e+00, PNorm = 34.6951, GNorm = 1.6944, lr_0 = 9.8200e-04
Loss = 1.2010e+00, PNorm = 34.7291, GNorm = 0.9211, lr_0 = 9.9918e-04
Loss = 4.2419e+00, PNorm = 34.7331, GNorm = 22.6204, lr_0 = 9.9877e-04
Validation rmse = 1.193463
Epoch 2
Loss = 1.5146e+00, PNorm = 34.8104, GNorm = 0.6645, lr_0 = 9.9467e-04
Loss = 1.2917e+00, PNorm = 34.9008, GNorm = 0.9792, lr_0 = 9.9059e-04
Loss = 1.1051e+00, PNorm = 34.9722, GNorm = 2.6611, lr_0 = 9.8652e-04
Loss = 1.3402e+00, PNorm = 35.0072, GNorm = 0.5853, lr_0 = 9.8247e-04
Loss = 1.2180e+00, PNorm = 35.0421, GNorm = 0.4930, lr_0 = 9.7844e-04
Loss = 1.1982e+00, PNorm = 35.0778, GNorm = 0.8239, lr_0 = 9.7443e-04
Loss = 1.0388e+00, PNorm = 35.1088, GNorm = 2.0917, lr_0 = 9.7043e-04
Loss = 1.3339e+00, PNorm = 35.1236, GNorm = 0.6149, lr_0 = 9.6645e-04
Loss = 1.1695e+00, PNorm = 35.1395, GNorm = 0.7360, lr_0 = 9.6248e-04
Loss = 1.1769e+00, PNorm = 35.1685, GNorm = 1.1274, lr_0 = 9.5853e-04
Loss = 1.2304e+00, PNorm = 35.2005, GNorm = 1.4388, lr_0 = 9.5460e-04
Loss = 1.1664e+00, PNorm = 35.2186, GNorm = 0.7193, lr_0 = 9.5068e-04
Loss = 1.2385e+00, PNorm = 35.2376, GNorm = 0.5815, lr_0 = 9.4678e-04
Loss = 1.1599e+00, PNorm = 35.2644, GNorm = 0.5583, lr_0 = 9.4290e-04
Loss = 1.1996e+00, PNorm = 35.2887, GNorm = 1.2111, lr_0 = 9.3903e-04
Loss = 1.3188e+00, PNorm = 35.3134, GNorm = 0.7128, lr_0 = 9.3517e-04
Loss = 1.1022e+00, PNorm = 35.3355, GNorm = 0.6196, lr_0 = 9.3134e-04
Loss = 1.2089e+00, PNorm = 35.3632, GNorm = 0.4917, lr_0 = 9.2752e-04
Loss = 1.1087e+00, PNorm = 35.3869, GNorm = 1.7376, lr_0 = 9.2371e-04
Loss = 1.1120e+00, PNorm = 35.4222, GNorm = 1.6930, lr_0 = 9.1992e-04
Loss = 5.8828e-01, PNorm = 35.4253, GNorm = 1.2205, lr_0 = 9.1954e-04
Validation rmse = 1.088687
Epoch 3
Loss = 1.1848e+00, PNorm = 35.4498, GNorm = 0.5996, lr_0 = 9.1577e-04
Loss = 1.1060e+00, PNorm = 35.4875, GNorm = 1.9448, lr_0 = 9.1201e-04
Loss = 1.2364e+00, PNorm = 35.5095, GNorm = 0.9975, lr_0 = 9.0827e-04
Loss = 1.0764e+00, PNorm = 35.5281, GNorm = 1.8111, lr_0 = 9.0454e-04
Loss = 1.0768e+00, PNorm = 35.5440, GNorm = 0.4004, lr_0 = 9.0083e-04
Loss = 1.0941e+00, PNorm = 35.5762, GNorm = 1.1990, lr_0 = 8.9713e-04
Loss = 1.1529e+00, PNorm = 35.6026, GNorm = 0.7937, lr_0 = 8.9345e-04
Loss = 1.1493e+00, PNorm = 35.6427, GNorm = 3.8722, lr_0 = 8.8979e-04
Loss = 1.2392e+00, PNorm = 35.6647, GNorm = 0.8497, lr_0 = 8.8614e-04
Loss = 1.0839e+00, PNorm = 35.7057, GNorm = 2.4455, lr_0 = 8.8250e-04
Loss = 1.1231e+00, PNorm = 35.7390, GNorm = 1.6844, lr_0 = 8.7888e-04
Loss = 1.1837e+00, PNorm = 35.7809, GNorm = 0.9953, lr_0 = 8.7527e-04
Loss = 1.2221e+00, PNorm = 35.8077, GNorm = 0.6616, lr_0 = 8.7168e-04
Loss = 1.2044e+00, PNorm = 35.8256, GNorm = 0.8269, lr_0 = 8.6810e-04
Loss = 1.2286e+00, PNorm = 35.8475, GNorm = 1.1271, lr_0 = 8.6454e-04
Loss = 1.2385e+00, PNorm = 35.8732, GNorm = 1.4371, lr_0 = 8.6099e-04
Loss = 1.0407e+00, PNorm = 35.8923, GNorm = 0.8727, lr_0 = 8.5746e-04
Loss = 9.1811e-01, PNorm = 35.9220, GNorm = 1.9630, lr_0 = 8.5394e-04
Loss = 1.0693e+00, PNorm = 35.9442, GNorm = 1.0003, lr_0 = 8.5044e-04
Loss = 1.0823e+00, PNorm = 35.9659, GNorm = 1.8365, lr_0 = 8.4695e-04
Loss = 5.7143e-01, PNorm = 35.9688, GNorm = 1.5200, lr_0 = 8.4660e-04
Validation rmse = 1.056982
Epoch 4
Loss = 1.0066e+00, PNorm = 35.9875, GNorm = 0.8425, lr_0 = 8.4313e-04
Loss = 1.1815e+00, PNorm = 36.0111, GNorm = 0.9324, lr_0 = 8.3967e-04
Loss = 1.1621e+00, PNorm = 36.0546, GNorm = 0.6283, lr_0 = 8.3622e-04
Loss = 1.1740e+00, PNorm = 36.0974, GNorm = 1.3296, lr_0 = 8.3279e-04
Loss = 1.1783e+00, PNorm = 36.1382, GNorm = 0.6691, lr_0 = 8.2937e-04
Loss = 1.0845e+00, PNorm = 36.1749, GNorm = 2.8852, lr_0 = 8.2597e-04
Loss = 1.0773e+00, PNorm = 36.2172, GNorm = 1.6536, lr_0 = 8.2258e-04
Loss = 1.0906e+00, PNorm = 36.2507, GNorm = 1.0458, lr_0 = 8.1921e-04
Loss = 1.0977e+00, PNorm = 36.3044, GNorm = 1.8867, lr_0 = 8.1584e-04
Loss = 1.0780e+00, PNorm = 36.3263, GNorm = 1.4470, lr_0 = 8.1250e-04
Loss = 1.0939e+00, PNorm = 36.3516, GNorm = 0.7341, lr_0 = 8.0916e-04
Loss = 1.0119e+00, PNorm = 36.3771, GNorm = 1.2687, lr_0 = 8.0584e-04
Loss = 1.3193e+00, PNorm = 36.4104, GNorm = 2.4967, lr_0 = 8.0254e-04
Loss = 1.0798e+00, PNorm = 36.4430, GNorm = 0.9308, lr_0 = 7.9924e-04
Loss = 1.0147e+00, PNorm = 36.4957, GNorm = 1.5169, lr_0 = 7.9596e-04
Loss = 1.1605e+00, PNorm = 36.5170, GNorm = 2.5383, lr_0 = 7.9270e-04
Loss = 1.0587e+00, PNorm = 36.5461, GNorm = 1.0704, lr_0 = 7.8944e-04
Loss = 1.0217e+00, PNorm = 36.5801, GNorm = 1.4144, lr_0 = 7.8620e-04
Loss = 1.0267e+00, PNorm = 36.6097, GNorm = 1.4198, lr_0 = 7.8298e-04
Loss = 1.0808e+00, PNorm = 36.6392, GNorm = 2.1586, lr_0 = 7.7977e-04
Loss = 5.7109e-01, PNorm = 36.6414, GNorm = 3.1240, lr_0 = 7.7945e-04
Validation rmse = 1.020110
Epoch 5
Loss = 1.0342e+00, PNorm = 36.6873, GNorm = 0.8245, lr_0 = 7.7625e-04
Loss = 9.7604e-01, PNorm = 36.7206, GNorm = 1.2524, lr_0 = 7.7306e-04
Loss = 1.0360e+00, PNorm = 36.7517, GNorm = 1.7248, lr_0 = 7.6989e-04
Loss = 1.0997e+00, PNorm = 36.7835, GNorm = 0.7342, lr_0 = 7.6673e-04
Loss = 1.0925e+00, PNorm = 36.8267, GNorm = 3.0786, lr_0 = 7.6358e-04
Loss = 9.8653e-01, PNorm = 36.8639, GNorm = 1.6828, lr_0 = 7.6045e-04
Loss = 1.1499e+00, PNorm = 36.9024, GNorm = 1.1848, lr_0 = 7.5733e-04
Loss = 1.0597e+00, PNorm = 36.9355, GNorm = 0.8683, lr_0 = 7.5422e-04
Loss = 1.1261e+00, PNorm = 36.9625, GNorm = 2.7708, lr_0 = 7.5113e-04
Loss = 9.6466e-01, PNorm = 36.9863, GNorm = 0.8904, lr_0 = 7.4805e-04
Loss = 1.2126e+00, PNorm = 37.0135, GNorm = 2.5964, lr_0 = 7.4498e-04
Loss = 9.7462e-01, PNorm = 37.0500, GNorm = 1.3721, lr_0 = 7.4192e-04
Loss = 1.0539e+00, PNorm = 37.0770, GNorm = 0.9366, lr_0 = 7.3888e-04
Loss = 1.1808e+00, PNorm = 37.1064, GNorm = 3.9941, lr_0 = 7.3584e-04
Loss = 1.0591e+00, PNorm = 37.1347, GNorm = 1.2911, lr_0 = 7.3282e-04
Loss = 1.0124e+00, PNorm = 37.1648, GNorm = 1.2325, lr_0 = 7.2982e-04
Loss = 9.6937e-01, PNorm = 37.1797, GNorm = 0.9280, lr_0 = 7.2682e-04
Loss = 1.0509e+00, PNorm = 37.2058, GNorm = 1.4967, lr_0 = 7.2384e-04
Loss = 9.9035e-01, PNorm = 37.2491, GNorm = 2.8844, lr_0 = 7.2087e-04
Loss = 1.1722e+00, PNorm = 37.2947, GNorm = 0.7120, lr_0 = 7.1791e-04
Loss = 9.3833e-01, PNorm = 37.2977, GNorm = 5.4414, lr_0 = 7.1762e-04
Validation rmse = 1.018622
Epoch 6
Loss = 9.9146e-01, PNorm = 37.3320, GNorm = 2.2286, lr_0 = 7.1467e-04
Loss = 1.1441e+00, PNorm = 37.3340, GNorm = 1.8049, lr_0 = 7.1174e-04
Loss = 1.0390e+00, PNorm = 37.3580, GNorm = 1.1453, lr_0 = 7.0882e-04
Loss = 1.1090e+00, PNorm = 37.3969, GNorm = 2.1940, lr_0 = 7.0591e-04
Loss = 1.0520e+00, PNorm = 37.4323, GNorm = 3.0013, lr_0 = 7.0301e-04
Loss = 1.0138e+00, PNorm = 37.4749, GNorm = 1.0668, lr_0 = 7.0013e-04
Loss = 9.9047e-01, PNorm = 37.5065, GNorm = 1.2889, lr_0 = 6.9726e-04
Loss = 1.0300e+00, PNorm = 37.5378, GNorm = 2.1427, lr_0 = 6.9440e-04
Loss = 9.7413e-01, PNorm = 37.5683, GNorm = 2.8038, lr_0 = 6.9155e-04
Loss = 1.0085e+00, PNorm = 37.5830, GNorm = 0.8455, lr_0 = 6.8871e-04
Loss = 1.0163e+00, PNorm = 37.6082, GNorm = 2.8911, lr_0 = 6.8588e-04
Loss = 1.0625e+00, PNorm = 37.6344, GNorm = 1.8541, lr_0 = 6.8307e-04
Loss = 1.0557e+00, PNorm = 37.6618, GNorm = 1.2695, lr_0 = 6.8027e-04
Loss = 1.0015e+00, PNorm = 37.6957, GNorm = 1.3642, lr_0 = 6.7747e-04
Loss = 9.1231e-01, PNorm = 37.7232, GNorm = 1.4451, lr_0 = 6.7469e-04
Loss = 9.1784e-01, PNorm = 37.7604, GNorm = 2.3647, lr_0 = 6.7193e-04
Loss = 1.0703e+00, PNorm = 37.7836, GNorm = 2.7990, lr_0 = 6.6917e-04
Loss = 1.0733e+00, PNorm = 37.8025, GNorm = 1.0988, lr_0 = 6.6642e-04
Loss = 9.3329e-01, PNorm = 37.8374, GNorm = 1.4249, lr_0 = 6.6369e-04
Loss = 9.8350e-01, PNorm = 37.8669, GNorm = 1.5333, lr_0 = 6.6097e-04
Loss = 5.7697e-01, PNorm = 37.8698, GNorm = 1.5336, lr_0 = 6.6069e-04
Validation rmse = 0.946677
Epoch 7
Loss = 1.0754e+00, PNorm = 37.8982, GNorm = 1.6627, lr_0 = 6.5798e-04
Loss = 1.0335e+00, PNorm = 37.9276, GNorm = 1.4474, lr_0 = 6.5528e-04
Loss = 9.3271e-01, PNorm = 37.9537, GNorm = 1.4824, lr_0 = 6.5259e-04
Loss = 1.0158e+00, PNorm = 37.9835, GNorm = 3.8941, lr_0 = 6.4992e-04
Loss = 9.9914e-01, PNorm = 38.0089, GNorm = 2.7313, lr_0 = 6.4725e-04
Loss = 9.3670e-01, PNorm = 38.0302, GNorm = 2.0024, lr_0 = 6.4459e-04
Loss = 9.8655e-01, PNorm = 38.0799, GNorm = 4.6154, lr_0 = 6.4195e-04
Loss = 9.3051e-01, PNorm = 38.1215, GNorm = 3.5841, lr_0 = 6.3931e-04
Loss = 8.7997e-01, PNorm = 38.1625, GNorm = 2.6472, lr_0 = 6.3669e-04
Loss = 8.9268e-01, PNorm = 38.1893, GNorm = 1.0541, lr_0 = 6.3408e-04
Loss = 8.8866e-01, PNorm = 38.2296, GNorm = 2.7774, lr_0 = 6.3148e-04
Loss = 9.6192e-01, PNorm = 38.2580, GNorm = 2.4772, lr_0 = 6.2889e-04
Loss = 1.0219e+00, PNorm = 38.2836, GNorm = 2.7452, lr_0 = 6.2630e-04
Loss = 1.0262e+00, PNorm = 38.3115, GNorm = 1.4103, lr_0 = 6.2373e-04
Loss = 9.7314e-01, PNorm = 38.3427, GNorm = 3.3338, lr_0 = 6.2118e-04
Loss = 9.8830e-01, PNorm = 38.3695, GNorm = 1.1844, lr_0 = 6.1863e-04
Loss = 9.6157e-01, PNorm = 38.3861, GNorm = 2.6625, lr_0 = 6.1609e-04
Loss = 9.0939e-01, PNorm = 38.4107, GNorm = 2.4677, lr_0 = 6.1356e-04
Loss = 1.0713e+00, PNorm = 38.4445, GNorm = 1.5095, lr_0 = 6.1104e-04
Loss = 9.2941e-01, PNorm = 38.4723, GNorm = 1.7250, lr_0 = 6.0854e-04
Loss = 9.8304e-01, PNorm = 38.4738, GNorm = 6.7101, lr_0 = 6.0829e-04
Validation rmse = 0.945522
Epoch 8
Loss = 1.0174e+00, PNorm = 38.4956, GNorm = 1.3857, lr_0 = 6.0579e-04
Loss = 9.5840e-01, PNorm = 38.5228, GNorm = 3.0262, lr_0 = 6.0330e-04
Loss = 9.9667e-01, PNorm = 38.5496, GNorm = 3.3769, lr_0 = 6.0083e-04
Loss = 8.9801e-01, PNorm = 38.5824, GNorm = 1.2820, lr_0 = 5.9836e-04
Loss = 8.9125e-01, PNorm = 38.6092, GNorm = 2.4736, lr_0 = 5.9591e-04
Loss = 9.6314e-01, PNorm = 38.6301, GNorm = 4.2667, lr_0 = 5.9346e-04
Loss = 6.7865e-01, PNorm = 38.6516, GNorm = 2.3519, lr_0 = 5.9103e-04
Loss = 9.5595e-01, PNorm = 38.6954, GNorm = 7.2368, lr_0 = 5.8860e-04
Loss = 1.1142e+00, PNorm = 38.7293, GNorm = 1.4711, lr_0 = 5.8619e-04
Loss = 9.1621e-01, PNorm = 38.7613, GNorm = 1.3863, lr_0 = 5.8378e-04
Loss = 1.0670e+00, PNorm = 38.7838, GNorm = 2.0057, lr_0 = 5.8139e-04
Loss = 9.9535e-01, PNorm = 38.7970, GNorm = 1.3686, lr_0 = 5.7900e-04
Loss = 1.0033e+00, PNorm = 38.8207, GNorm = 0.9095, lr_0 = 5.7662e-04
Loss = 1.0167e+00, PNorm = 38.8545, GNorm = 2.2078, lr_0 = 5.7426e-04
Loss = 8.5919e-01, PNorm = 38.8707, GNorm = 4.7494, lr_0 = 5.7190e-04
Loss = 8.9420e-01, PNorm = 38.8852, GNorm = 3.6040, lr_0 = 5.6956e-04
Loss = 7.7937e-01, PNorm = 38.9126, GNorm = 1.6607, lr_0 = 5.6722e-04
Loss = 8.1401e-01, PNorm = 38.9428, GNorm = 2.6351, lr_0 = 5.6489e-04
Loss = 9.3360e-01, PNorm = 38.9727, GNorm = 3.8397, lr_0 = 5.6257e-04
Loss = 9.7156e-01, PNorm = 39.0020, GNorm = 2.4292, lr_0 = 5.6026e-04
Loss = 2.0099e+00, PNorm = 39.0068, GNorm = 3.9287, lr_0 = 5.6003e-04
Validation rmse = 0.887399
Epoch 9
Loss = 8.5356e-01, PNorm = 39.0458, GNorm = 3.0443, lr_0 = 5.5774e-04
Loss = 8.0636e-01, PNorm = 39.0762, GNorm = 2.8392, lr_0 = 5.5545e-04
Loss = 9.2046e-01, PNorm = 39.1016, GNorm = 5.6039, lr_0 = 5.5317e-04
Loss = 8.1595e-01, PNorm = 39.1149, GNorm = 2.6568, lr_0 = 5.5090e-04
Loss = 1.0102e+00, PNorm = 39.1316, GNorm = 2.3732, lr_0 = 5.4864e-04
Loss = 8.6706e-01, PNorm = 39.1492, GNorm = 1.6984, lr_0 = 5.4639e-04
Loss = 8.8835e-01, PNorm = 39.1773, GNorm = 2.0252, lr_0 = 5.4414e-04
Loss = 8.4800e-01, PNorm = 39.2047, GNorm = 4.8211, lr_0 = 5.4191e-04
Loss = 9.4847e-01, PNorm = 39.2220, GNorm = 3.5162, lr_0 = 5.3969e-04
Loss = 7.8804e-01, PNorm = 39.2472, GNorm = 2.5058, lr_0 = 5.3747e-04
Loss = 8.2312e-01, PNorm = 39.2784, GNorm = 3.4836, lr_0 = 5.3527e-04
Loss = 8.4021e-01, PNorm = 39.3074, GNorm = 3.1426, lr_0 = 5.3307e-04
Loss = 8.5616e-01, PNorm = 39.3404, GNorm = 3.3276, lr_0 = 5.3088e-04
Loss = 8.7734e-01, PNorm = 39.3584, GNorm = 2.8411, lr_0 = 5.2871e-04
Loss = 8.9217e-01, PNorm = 39.3871, GNorm = 1.3888, lr_0 = 5.2654e-04
Loss = 1.0085e+00, PNorm = 39.4262, GNorm = 3.6320, lr_0 = 5.2438e-04
Loss = 1.0589e+00, PNorm = 39.4594, GNorm = 2.6002, lr_0 = 5.2222e-04
Loss = 8.6040e-01, PNorm = 39.4851, GNorm = 2.9001, lr_0 = 5.2008e-04
Loss = 7.9519e-01, PNorm = 39.4983, GNorm = 1.4197, lr_0 = 5.1795e-04
Loss = 9.1927e-01, PNorm = 39.5171, GNorm = 3.3076, lr_0 = 5.1582e-04
Validation rmse = 0.891890
Epoch 10
Loss = 8.3578e-01, PNorm = 39.5490, GNorm = 3.8198, lr_0 = 5.1371e-04
Loss = 8.9218e-01, PNorm = 39.5696, GNorm = 3.9994, lr_0 = 5.1160e-04
Loss = 8.9796e-01, PNorm = 39.5968, GNorm = 1.9845, lr_0 = 5.0950e-04
Loss = 8.8645e-01, PNorm = 39.6200, GNorm = 1.8526, lr_0 = 5.0741e-04
Loss = 8.2344e-01, PNorm = 39.6455, GNorm = 1.6606, lr_0 = 5.0533e-04
Loss = 8.9535e-01, PNorm = 39.6653, GNorm = 2.1669, lr_0 = 5.0325e-04
Loss = 9.4837e-01, PNorm = 39.6890, GNorm = 4.1511, lr_0 = 5.0119e-04
Loss = 7.9721e-01, PNorm = 39.7109, GNorm = 2.4392, lr_0 = 4.9913e-04
Loss = 9.9844e-01, PNorm = 39.7419, GNorm = 1.7366, lr_0 = 4.9708e-04
Loss = 8.4003e-01, PNorm = 39.7681, GNorm = 1.6418, lr_0 = 4.9504e-04
Loss = 8.6284e-01, PNorm = 39.7887, GNorm = 2.3808, lr_0 = 4.9301e-04
Loss = 8.0514e-01, PNorm = 39.8230, GNorm = 2.3383, lr_0 = 4.9099e-04
Loss = 8.3309e-01, PNorm = 39.8400, GNorm = 2.6801, lr_0 = 4.8897e-04
Loss = 7.9106e-01, PNorm = 39.8517, GNorm = 6.5647, lr_0 = 4.8697e-04
Loss = 8.5354e-01, PNorm = 39.8748, GNorm = 1.0680, lr_0 = 4.8497e-04
Loss = 8.8548e-01, PNorm = 39.8985, GNorm = 1.8196, lr_0 = 4.8298e-04
Loss = 8.7741e-01, PNorm = 39.9175, GNorm = 1.5992, lr_0 = 4.8100e-04
Loss = 7.7429e-01, PNorm = 39.9319, GNorm = 2.3227, lr_0 = 4.7902e-04
Loss = 8.4639e-01, PNorm = 39.9537, GNorm = 2.1572, lr_0 = 4.7706e-04
Loss = 7.8239e-01, PNorm = 39.9759, GNorm = 3.9773, lr_0 = 4.7510e-04
Validation rmse = 0.815504
Epoch 11
Loss = 7.4981e-01, PNorm = 39.9961, GNorm = 2.3908, lr_0 = 4.7296e-04
Loss = 9.0535e-01, PNorm = 40.0141, GNorm = 3.1701, lr_0 = 4.7102e-04
Loss = 7.6110e-01, PNorm = 40.0515, GNorm = 1.7078, lr_0 = 4.6908e-04
Loss = 7.3829e-01, PNorm = 40.0775, GNorm = 5.4763, lr_0 = 4.6716e-04
Loss = 8.2807e-01, PNorm = 40.0980, GNorm = 5.1721, lr_0 = 4.6524e-04
Loss = 9.1875e-01, PNorm = 40.1238, GNorm = 3.2818, lr_0 = 4.6333e-04
Loss = 7.0711e-01, PNorm = 40.1467, GNorm = 1.4164, lr_0 = 4.6143e-04
Loss = 8.4758e-01, PNorm = 40.1677, GNorm = 2.0117, lr_0 = 4.5954e-04
Loss = 7.1166e-01, PNorm = 40.1837, GNorm = 3.7574, lr_0 = 4.5765e-04
Loss = 7.2067e-01, PNorm = 40.1999, GNorm = 1.9297, lr_0 = 4.5577e-04
Loss = 7.5650e-01, PNorm = 40.2154, GNorm = 2.5007, lr_0 = 4.5390e-04
Loss = 7.7014e-01, PNorm = 40.2375, GNorm = 4.1767, lr_0 = 4.5204e-04
Loss = 8.1857e-01, PNorm = 40.2582, GNorm = 2.0048, lr_0 = 4.5019e-04
Loss = 9.2795e-01, PNorm = 40.2785, GNorm = 1.7156, lr_0 = 4.4834e-04
Loss = 8.0201e-01, PNorm = 40.3006, GNorm = 2.1270, lr_0 = 4.4650e-04
Loss = 8.6698e-01, PNorm = 40.3168, GNorm = 3.6233, lr_0 = 4.4467e-04
Loss = 6.9157e-01, PNorm = 40.3311, GNorm = 4.3161, lr_0 = 4.4284e-04
Loss = 1.0284e+00, PNorm = 40.3536, GNorm = 1.9629, lr_0 = 4.4103e-04
Loss = 8.2950e-01, PNorm = 40.3767, GNorm = 1.8469, lr_0 = 4.3922e-04
Loss = 9.1172e-01, PNorm = 40.3942, GNorm = 2.6722, lr_0 = 4.3741e-04
Validation rmse = 0.778927
Epoch 12
Loss = 8.0170e-01, PNorm = 40.4173, GNorm = 3.8426, lr_0 = 4.3544e-04
Loss = 7.5344e-01, PNorm = 40.4384, GNorm = 2.2773, lr_0 = 4.3365e-04
Loss = 7.5335e-01, PNorm = 40.4568, GNorm = 12.8969, lr_0 = 4.3187e-04
Loss = 8.9833e-01, PNorm = 40.4699, GNorm = 1.7587, lr_0 = 4.3010e-04
Loss = 8.8579e-01, PNorm = 40.4819, GNorm = 1.7552, lr_0 = 4.2834e-04
Loss = 7.3585e-01, PNorm = 40.4963, GNorm = 5.3486, lr_0 = 4.2658e-04
Loss = 8.2315e-01, PNorm = 40.5193, GNorm = 3.8685, lr_0 = 4.2483e-04
Loss = 7.7309e-01, PNorm = 40.5460, GNorm = 4.1986, lr_0 = 4.2309e-04
Loss = 8.5996e-01, PNorm = 40.5647, GNorm = 3.8126, lr_0 = 4.2135e-04
Loss = 7.2072e-01, PNorm = 40.5802, GNorm = 2.0440, lr_0 = 4.1962e-04
Loss = 5.9838e-01, PNorm = 40.5931, GNorm = 2.4814, lr_0 = 4.1790e-04
Loss = 7.6237e-01, PNorm = 40.6162, GNorm = 2.6140, lr_0 = 4.1618e-04
Loss = 7.2870e-01, PNorm = 40.6235, GNorm = 2.8602, lr_0 = 4.1448e-04
Loss = 7.0675e-01, PNorm = 40.6293, GNorm = 2.4211, lr_0 = 4.1278e-04
Loss = 6.5114e-01, PNorm = 40.6477, GNorm = 2.9681, lr_0 = 4.1108e-04
Loss = 7.7546e-01, PNorm = 40.6623, GNorm = 2.0840, lr_0 = 4.0940e-04
Loss = 7.5698e-01, PNorm = 40.6806, GNorm = 2.5596, lr_0 = 4.0772e-04
Loss = 8.1805e-01, PNorm = 40.7056, GNorm = 2.1526, lr_0 = 4.0604e-04
Loss = 7.5831e-01, PNorm = 40.7202, GNorm = 2.9631, lr_0 = 4.0438e-04
Loss = 9.2589e-01, PNorm = 40.7297, GNorm = 4.8695, lr_0 = 4.0272e-04
Validation rmse = 0.766763
Epoch 13
Loss = 6.6184e-01, PNorm = 40.7516, GNorm = 2.6113, lr_0 = 4.0090e-04
Loss = 7.8616e-01, PNorm = 40.7747, GNorm = 2.1465, lr_0 = 3.9925e-04
Loss = 9.1121e-01, PNorm = 40.7918, GNorm = 1.8191, lr_0 = 3.9762e-04
Loss = 9.3160e-01, PNorm = 40.8070, GNorm = 3.8699, lr_0 = 3.9598e-04
Loss = 6.5031e-01, PNorm = 40.8171, GNorm = 3.8493, lr_0 = 3.9436e-04
Loss = 7.5104e-01, PNorm = 40.8311, GNorm = 3.8263, lr_0 = 3.9274e-04
Loss = 7.5224e-01, PNorm = 40.8529, GNorm = 3.6010, lr_0 = 3.9113e-04
Loss = 7.3021e-01, PNorm = 40.8707, GNorm = 3.5147, lr_0 = 3.8953e-04
Loss = 6.0976e-01, PNorm = 40.8863, GNorm = 3.6719, lr_0 = 3.8793e-04
Loss = 7.3682e-01, PNorm = 40.9013, GNorm = 7.3827, lr_0 = 3.8634e-04
Loss = 7.0772e-01, PNorm = 40.9188, GNorm = 3.7874, lr_0 = 3.8475e-04
Loss = 7.3191e-01, PNorm = 40.9335, GNorm = 2.7009, lr_0 = 3.8317e-04
Loss = 7.8557e-01, PNorm = 40.9465, GNorm = 3.8591, lr_0 = 3.8160e-04
Loss = 7.4770e-01, PNorm = 40.9617, GNorm = 2.7418, lr_0 = 3.8003e-04
Loss = 6.6275e-01, PNorm = 40.9772, GNorm = 1.9624, lr_0 = 3.7847e-04
Loss = 7.2008e-01, PNorm = 40.9915, GNorm = 6.5568, lr_0 = 3.7692e-04
Loss = 8.1428e-01, PNorm = 41.0030, GNorm = 6.3392, lr_0 = 3.7537e-04
Loss = 7.3704e-01, PNorm = 41.0115, GNorm = 3.7277, lr_0 = 3.7383e-04
Loss = 8.1607e-01, PNorm = 41.0208, GNorm = 1.5989, lr_0 = 3.7230e-04
Loss = 7.9841e-01, PNorm = 41.0343, GNorm = 2.1237, lr_0 = 3.7077e-04
Validation rmse = 0.734454
Epoch 14
Loss = 7.4297e-01, PNorm = 41.0481, GNorm = 2.5610, lr_0 = 3.6910e-04
Loss = 6.7299e-01, PNorm = 41.0649, GNorm = 2.4386, lr_0 = 3.6758e-04
Loss = 6.4974e-01, PNorm = 41.0811, GNorm = 3.4375, lr_0 = 3.6608e-04
Loss = 7.6016e-01, PNorm = 41.0932, GNorm = 3.0774, lr_0 = 3.6457e-04
Loss = 7.1508e-01, PNorm = 41.0997, GNorm = 2.4881, lr_0 = 3.6308e-04
Loss = 7.3586e-01, PNorm = 41.1161, GNorm = 1.9876, lr_0 = 3.6159e-04
Loss = 6.4224e-01, PNorm = 41.1324, GNorm = 5.5813, lr_0 = 3.6010e-04
Loss = 7.1202e-01, PNorm = 41.1477, GNorm = 3.8168, lr_0 = 3.5863e-04
Loss = 5.9287e-01, PNorm = 41.1539, GNorm = 4.8676, lr_0 = 3.5716e-04
Loss = 6.4577e-01, PNorm = 41.1675, GNorm = 2.3672, lr_0 = 3.5569e-04
Loss = 7.3894e-01, PNorm = 41.1815, GNorm = 4.2880, lr_0 = 3.5423e-04
Loss = 6.7180e-01, PNorm = 41.1912, GNorm = 3.3323, lr_0 = 3.5278e-04
Loss = 6.3356e-01, PNorm = 41.2085, GNorm = 5.2751, lr_0 = 3.5133e-04
Loss = 7.3084e-01, PNorm = 41.2232, GNorm = 3.2267, lr_0 = 3.4989e-04
Loss = 7.8906e-01, PNorm = 41.2340, GNorm = 2.2161, lr_0 = 3.4845e-04
Loss = 6.6922e-01, PNorm = 41.2490, GNorm = 1.9259, lr_0 = 3.4702e-04
Loss = 6.8450e-01, PNorm = 41.2668, GNorm = 8.5718, lr_0 = 3.4560e-04
Loss = 6.8791e-01, PNorm = 41.2847, GNorm = 13.1227, lr_0 = 3.4418e-04
Loss = 7.4227e-01, PNorm = 41.2989, GNorm = 2.5593, lr_0 = 3.4277e-04
Loss = 7.2042e-01, PNorm = 41.3104, GNorm = 1.6576, lr_0 = 3.4136e-04
Validation rmse = 0.809222
Epoch 15
Loss = 7.2204e-01, PNorm = 41.3324, GNorm = 3.5470, lr_0 = 3.3982e-04
Loss = 7.7353e-01, PNorm = 41.3492, GNorm = 1.8297, lr_0 = 3.3843e-04
Loss = 7.9293e-01, PNorm = 41.3624, GNorm = 4.5280, lr_0 = 3.3704e-04
Loss = 5.5263e-01, PNorm = 41.3789, GNorm = 2.9357, lr_0 = 3.3565e-04
Loss = 6.0945e-01, PNorm = 41.3946, GNorm = 4.3282, lr_0 = 3.3428e-04
Loss = 7.8865e-01, PNorm = 41.4071, GNorm = 4.0449, lr_0 = 3.3291e-04
Loss = 6.3675e-01, PNorm = 41.4185, GNorm = 4.2760, lr_0 = 3.3154e-04
Loss = 5.9558e-01, PNorm = 41.4271, GNorm = 3.5667, lr_0 = 3.3018e-04
Loss = 6.3197e-01, PNorm = 41.4405, GNorm = 2.6770, lr_0 = 3.2882e-04
Loss = 6.6331e-01, PNorm = 41.4466, GNorm = 3.1568, lr_0 = 3.2748e-04
Loss = 5.6876e-01, PNorm = 41.4601, GNorm = 3.6042, lr_0 = 3.2613e-04
Loss = 7.0455e-01, PNorm = 41.4659, GNorm = 2.2479, lr_0 = 3.2479e-04
Loss = 7.3257e-01, PNorm = 41.4723, GNorm = 2.0033, lr_0 = 3.2346e-04
Loss = 6.0045e-01, PNorm = 41.4841, GNorm = 2.2638, lr_0 = 3.2213e-04
Loss = 5.8562e-01, PNorm = 41.4960, GNorm = 5.1702, lr_0 = 3.2081e-04
Loss = 7.6680e-01, PNorm = 41.5061, GNorm = 4.0742, lr_0 = 3.1950e-04
Loss = 7.9908e-01, PNorm = 41.5167, GNorm = 3.5093, lr_0 = 3.1818e-04
Loss = 6.6247e-01, PNorm = 41.5282, GNorm = 2.7864, lr_0 = 3.1688e-04
Loss = 7.0615e-01, PNorm = 41.5416, GNorm = 4.5979, lr_0 = 3.1558e-04
Loss = 6.5874e-01, PNorm = 41.5562, GNorm = 2.6622, lr_0 = 3.1428e-04
Validation rmse = 0.705795
Epoch 16
Loss = 7.9032e-01, PNorm = 41.5755, GNorm = 4.8068, lr_0 = 3.1287e-04
Loss = 7.6104e-01, PNorm = 41.5883, GNorm = 3.5616, lr_0 = 3.1158e-04
Loss = 6.9412e-01, PNorm = 41.5994, GNorm = 2.3415, lr_0 = 3.1030e-04
Loss = 6.6655e-01, PNorm = 41.6139, GNorm = 3.6621, lr_0 = 3.0903e-04
Loss = 5.5691e-01, PNorm = 41.6286, GNorm = 4.4748, lr_0 = 3.0776e-04
Loss = 6.8569e-01, PNorm = 41.6428, GNorm = 3.7786, lr_0 = 3.0650e-04
Loss = 6.3945e-01, PNorm = 41.6550, GNorm = 2.2420, lr_0 = 3.0524e-04
Loss = 4.9332e-01, PNorm = 41.6675, GNorm = 2.8273, lr_0 = 3.0399e-04
Loss = 4.6625e-01, PNorm = 41.6831, GNorm = 6.9689, lr_0 = 3.0274e-04
Loss = 5.7025e-01, PNorm = 41.6948, GNorm = 5.8514, lr_0 = 3.0150e-04
Loss = 7.6404e-01, PNorm = 41.7010, GNorm = 2.8514, lr_0 = 3.0026e-04
Loss = 7.2794e-01, PNorm = 41.7053, GNorm = 2.8439, lr_0 = 2.9903e-04
Loss = 6.6173e-01, PNorm = 41.7107, GNorm = 2.4862, lr_0 = 2.9780e-04
Loss = 6.4192e-01, PNorm = 41.7194, GNorm = 4.4948, lr_0 = 2.9658e-04
Loss = 6.0863e-01, PNorm = 41.7317, GNorm = 5.0172, lr_0 = 2.9536e-04
Loss = 7.4508e-01, PNorm = 41.7372, GNorm = 3.6269, lr_0 = 2.9415e-04
Loss = 5.8594e-01, PNorm = 41.7484, GNorm = 3.6254, lr_0 = 2.9294e-04
Loss = 6.9398e-01, PNorm = 41.7627, GNorm = 2.3714, lr_0 = 2.9174e-04
Loss = 5.9055e-01, PNorm = 41.7754, GNorm = 3.2104, lr_0 = 2.9055e-04
Loss = 6.9040e-01, PNorm = 41.7885, GNorm = 3.9782, lr_0 = 2.8935e-04
Validation rmse = 0.712559
Epoch 17
Loss = 6.0644e-01, PNorm = 41.7982, GNorm = 4.9480, lr_0 = 2.8805e-04
Loss = 6.1937e-01, PNorm = 41.8025, GNorm = 3.5872, lr_0 = 2.8687e-04
Loss = 5.6440e-01, PNorm = 41.8140, GNorm = 3.0208, lr_0 = 2.8569e-04
Loss = 6.7177e-01, PNorm = 41.8250, GNorm = 4.1142, lr_0 = 2.8452e-04
Loss = 5.7847e-01, PNorm = 41.8338, GNorm = 2.2421, lr_0 = 2.8335e-04
Loss = 5.5540e-01, PNorm = 41.8409, GNorm = 6.6744, lr_0 = 2.8219e-04
Loss = 7.0615e-01, PNorm = 41.8482, GNorm = 6.3389, lr_0 = 2.8103e-04
Loss = 6.5288e-01, PNorm = 41.8531, GNorm = 4.7517, lr_0 = 2.7988e-04
Loss = 5.8384e-01, PNorm = 41.8620, GNorm = 3.9817, lr_0 = 2.7873e-04
Loss = 5.5435e-01, PNorm = 41.8701, GNorm = 2.5392, lr_0 = 2.7758e-04
Loss = 5.4117e-01, PNorm = 41.8837, GNorm = 3.8704, lr_0 = 2.7644e-04
Loss = 5.6684e-01, PNorm = 41.8956, GNorm = 4.3348, lr_0 = 2.7531e-04
Loss = 7.6953e-01, PNorm = 41.9101, GNorm = 5.2822, lr_0 = 2.7418e-04
Loss = 5.7237e-01, PNorm = 41.9211, GNorm = 3.2319, lr_0 = 2.7305e-04
Loss = 6.1013e-01, PNorm = 41.9303, GNorm = 5.1448, lr_0 = 2.7193e-04
Loss = 5.9574e-01, PNorm = 41.9397, GNorm = 3.6491, lr_0 = 2.7082e-04
Loss = 5.3656e-01, PNorm = 41.9438, GNorm = 7.6780, lr_0 = 2.6971e-04
Loss = 5.7508e-01, PNorm = 41.9496, GNorm = 2.4763, lr_0 = 2.6860e-04
Loss = 7.0760e-01, PNorm = 41.9648, GNorm = 5.1868, lr_0 = 2.6750e-04
Loss = 5.1335e-01, PNorm = 41.9779, GNorm = 5.4723, lr_0 = 2.6640e-04
Validation rmse = 0.700705
Epoch 18
Loss = 5.8160e-01, PNorm = 41.9914, GNorm = 4.0638, lr_0 = 2.6520e-04
Loss = 5.8062e-01, PNorm = 41.9986, GNorm = 4.0547, lr_0 = 2.6411e-04
Loss = 5.4702e-01, PNorm = 42.0060, GNorm = 6.8586, lr_0 = 2.6303e-04
Loss = 5.2730e-01, PNorm = 42.0197, GNorm = 7.4944, lr_0 = 2.6195e-04
Loss = 4.0696e-01, PNorm = 42.0310, GNorm = 4.8652, lr_0 = 2.6087e-04
Loss = 4.9648e-01, PNorm = 42.0386, GNorm = 11.2528, lr_0 = 2.5980e-04
Loss = 5.3066e-01, PNorm = 42.0479, GNorm = 12.0515, lr_0 = 2.5874e-04
Loss = 6.5372e-01, PNorm = 42.0570, GNorm = 4.1313, lr_0 = 2.5767e-04
Loss = 5.7889e-01, PNorm = 42.0660, GNorm = 8.4688, lr_0 = 2.5662e-04
Loss = 5.5086e-01, PNorm = 42.0734, GNorm = 2.9297, lr_0 = 2.5556e-04
Loss = 5.1946e-01, PNorm = 42.0830, GNorm = 3.6606, lr_0 = 2.5452e-04
Loss = 5.7918e-01, PNorm = 42.0929, GNorm = 3.4268, lr_0 = 2.5347e-04
Loss = 6.5172e-01, PNorm = 42.0991, GNorm = 4.7381, lr_0 = 2.5243e-04
Loss = 5.3613e-01, PNorm = 42.1061, GNorm = 4.0659, lr_0 = 2.5140e-04
Loss = 3.9562e-01, PNorm = 42.1169, GNorm = 3.2549, lr_0 = 2.5036e-04
Loss = 5.1243e-01, PNorm = 42.1231, GNorm = 4.8315, lr_0 = 2.4934e-04
Loss = 6.1040e-01, PNorm = 42.1325, GNorm = 3.9914, lr_0 = 2.4831e-04
Loss = 6.0450e-01, PNorm = 42.1418, GNorm = 6.4787, lr_0 = 2.4729e-04
Loss = 6.2690e-01, PNorm = 42.1503, GNorm = 3.9488, lr_0 = 2.4628e-04
Loss = 7.1963e-01, PNorm = 42.1581, GNorm = 2.6029, lr_0 = 2.4527e-04
Validation rmse = 0.692407
Epoch 19
Loss = 4.2332e-01, PNorm = 42.1713, GNorm = 7.4302, lr_0 = 2.4416e-04
Loss = 5.6146e-01, PNorm = 42.1787, GNorm = 4.8457, lr_0 = 2.4316e-04
Loss = 6.0675e-01, PNorm = 42.1874, GNorm = 7.1283, lr_0 = 2.4216e-04
Loss = 6.2774e-01, PNorm = 42.1948, GNorm = 2.8825, lr_0 = 2.4117e-04
Loss = 4.8940e-01, PNorm = 42.2041, GNorm = 3.6691, lr_0 = 2.4018e-04
Loss = 4.8090e-01, PNorm = 42.2100, GNorm = 5.6362, lr_0 = 2.3919e-04
Loss = 5.6407e-01, PNorm = 42.2166, GNorm = 10.2655, lr_0 = 2.3821e-04
Loss = 5.2628e-01, PNorm = 42.2232, GNorm = 4.3245, lr_0 = 2.3723e-04
Loss = 6.7894e-01, PNorm = 42.2312, GNorm = 9.0485, lr_0 = 2.3626e-04
Loss = 5.2368e-01, PNorm = 42.2409, GNorm = 4.0596, lr_0 = 2.3529e-04
Loss = 4.9621e-01, PNorm = 42.2487, GNorm = 3.2859, lr_0 = 2.3433e-04
Loss = 5.5528e-01, PNorm = 42.2579, GNorm = 3.3337, lr_0 = 2.3336e-04
Loss = 6.2308e-01, PNorm = 42.2674, GNorm = 4.1880, lr_0 = 2.3241e-04
Loss = 5.6858e-01, PNorm = 42.2739, GNorm = 4.4664, lr_0 = 2.3145e-04
Loss = 5.5142e-01, PNorm = 42.2786, GNorm = 3.8304, lr_0 = 2.3050e-04
Loss = 4.4493e-01, PNorm = 42.2849, GNorm = 3.5836, lr_0 = 2.2956e-04
Loss = 4.3534e-01, PNorm = 42.2906, GNorm = 7.0108, lr_0 = 2.2862e-04
Loss = 4.7982e-01, PNorm = 42.2965, GNorm = 9.3019, lr_0 = 2.2768e-04
Loss = 5.8861e-01, PNorm = 42.3078, GNorm = 8.2730, lr_0 = 2.2674e-04
Loss = 4.8968e-01, PNorm = 42.3213, GNorm = 3.2750, lr_0 = 2.2581e-04
Validation rmse = 0.686628
Epoch 20
Loss = 4.1374e-01, PNorm = 42.3306, GNorm = 4.3768, lr_0 = 2.2489e-04
Loss = 4.9620e-01, PNorm = 42.3415, GNorm = 12.8488, lr_0 = 2.2396e-04
Loss = 4.4470e-01, PNorm = 42.3476, GNorm = 6.1707, lr_0 = 2.2305e-04
Loss = 4.0715e-01, PNorm = 42.3548, GNorm = 8.9536, lr_0 = 2.2213e-04
Loss = 5.3861e-01, PNorm = 42.3637, GNorm = 4.0306, lr_0 = 2.2122e-04
Loss = 5.6977e-01, PNorm = 42.3717, GNorm = 3.3652, lr_0 = 2.2031e-04
Loss = 5.1929e-01, PNorm = 42.3761, GNorm = 5.3531, lr_0 = 2.1941e-04
Loss = 4.0123e-01, PNorm = 42.3793, GNorm = 3.4064, lr_0 = 2.1851e-04
Loss = 4.7444e-01, PNorm = 42.3874, GNorm = 6.2058, lr_0 = 2.1761e-04
Loss = 5.4743e-01, PNorm = 42.3920, GNorm = 6.9142, lr_0 = 2.1672e-04
Loss = 4.3463e-01, PNorm = 42.4017, GNorm = 6.0512, lr_0 = 2.1583e-04
Loss = 5.3336e-01, PNorm = 42.4093, GNorm = 4.5689, lr_0 = 2.1494e-04
Loss = 5.6598e-01, PNorm = 42.4153, GNorm = 5.3953, lr_0 = 2.1406e-04
Loss = 4.5227e-01, PNorm = 42.4220, GNorm = 4.1219, lr_0 = 2.1318e-04
Loss = 5.7789e-01, PNorm = 42.4263, GNorm = 3.1284, lr_0 = 2.1231e-04
Loss = 5.7866e-01, PNorm = 42.4308, GNorm = 8.7227, lr_0 = 2.1144e-04
Loss = 5.9854e-01, PNorm = 42.4386, GNorm = 4.4225, lr_0 = 2.1057e-04
Loss = 4.7654e-01, PNorm = 42.4457, GNorm = 4.9468, lr_0 = 2.0970e-04
Loss = 5.4338e-01, PNorm = 42.4522, GNorm = 4.1530, lr_0 = 2.0884e-04
Loss = 4.7331e-01, PNorm = 42.4618, GNorm = 4.8354, lr_0 = 2.0799e-04
Validation rmse = 0.698996
Epoch 21
Loss = 6.0395e-01, PNorm = 42.4731, GNorm = 6.1700, lr_0 = 2.0705e-04
Loss = 4.0288e-01, PNorm = 42.4813, GNorm = 3.9180, lr_0 = 2.0620e-04
Loss = 5.0531e-01, PNorm = 42.4898, GNorm = 5.0791, lr_0 = 2.0535e-04
Loss = 5.0181e-01, PNorm = 42.4976, GNorm = 4.7467, lr_0 = 2.0451e-04
Loss = 5.6461e-01, PNorm = 42.5023, GNorm = 3.1781, lr_0 = 2.0367e-04
Loss = 4.5009e-01, PNorm = 42.5086, GNorm = 6.9234, lr_0 = 2.0283e-04
Loss = 4.4630e-01, PNorm = 42.5148, GNorm = 3.8384, lr_0 = 2.0200e-04
Loss = 3.8321e-01, PNorm = 42.5248, GNorm = 4.6933, lr_0 = 2.0117e-04
Loss = 5.2156e-01, PNorm = 42.5330, GNorm = 7.1971, lr_0 = 2.0035e-04
Loss = 2.7137e-01, PNorm = 42.5405, GNorm = 4.6167, lr_0 = 1.9953e-04
Loss = 6.5508e-01, PNorm = 42.5482, GNorm = 6.0268, lr_0 = 1.9871e-04
Loss = 6.0812e-01, PNorm = 42.5497, GNorm = 8.0059, lr_0 = 1.9789e-04
Loss = 5.8456e-01, PNorm = 42.5506, GNorm = 4.1499, lr_0 = 1.9708e-04
Loss = 4.3966e-01, PNorm = 42.5565, GNorm = 3.8816, lr_0 = 1.9627e-04
Loss = 4.3316e-01, PNorm = 42.5652, GNorm = 7.7188, lr_0 = 1.9547e-04
Loss = 5.7399e-01, PNorm = 42.5735, GNorm = 4.0410, lr_0 = 1.9466e-04
Loss = 3.6592e-01, PNorm = 42.5808, GNorm = 6.4191, lr_0 = 1.9387e-04
Loss = 3.8212e-01, PNorm = 42.5890, GNorm = 4.7381, lr_0 = 1.9307e-04
Loss = 5.2345e-01, PNorm = 42.5924, GNorm = 7.3567, lr_0 = 1.9228e-04
Loss = 4.6840e-01, PNorm = 42.5986, GNorm = 2.6187, lr_0 = 1.9149e-04
Validation rmse = 0.694322
Epoch 22
Loss = 4.7134e-01, PNorm = 42.6039, GNorm = 3.4690, lr_0 = 1.9062e-04
Loss = 4.3318e-01, PNorm = 42.6094, GNorm = 6.8422, lr_0 = 1.8984e-04
Loss = 4.0329e-01, PNorm = 42.6175, GNorm = 3.0302, lr_0 = 1.8906e-04
Loss = 4.8942e-01, PNorm = 42.6262, GNorm = 6.9272, lr_0 = 1.8829e-04
Loss = 4.7689e-01, PNorm = 42.6340, GNorm = 6.1949, lr_0 = 1.8751e-04
Loss = 4.1576e-01, PNorm = 42.6393, GNorm = 6.9494, lr_0 = 1.8675e-04
Loss = 4.5475e-01, PNorm = 42.6451, GNorm = 7.4360, lr_0 = 1.8598e-04
Loss = 5.4488e-01, PNorm = 42.6527, GNorm = 6.2418, lr_0 = 1.8522e-04
Loss = 2.5688e-01, PNorm = 42.6585, GNorm = 3.3455, lr_0 = 1.8446e-04
Loss = 4.0680e-01, PNorm = 42.6622, GNorm = 6.0590, lr_0 = 1.8370e-04
Loss = 4.2382e-01, PNorm = 42.6658, GNorm = 6.0280, lr_0 = 1.8295e-04
Loss = 4.3157e-01, PNorm = 42.6683, GNorm = 5.4813, lr_0 = 1.8219e-04
Loss = 3.4441e-01, PNorm = 42.6757, GNorm = 4.9553, lr_0 = 1.8145e-04
Loss = 3.6487e-01, PNorm = 42.6811, GNorm = 6.0497, lr_0 = 1.8070e-04
Loss = 4.8878e-01, PNorm = 42.6860, GNorm = 7.9680, lr_0 = 1.7996e-04
Loss = 4.5482e-01, PNorm = 42.6910, GNorm = 6.3461, lr_0 = 1.7922e-04
Loss = 5.6651e-01, PNorm = 42.6929, GNorm = 3.4107, lr_0 = 1.7849e-04
Loss = 5.4308e-01, PNorm = 42.6941, GNorm = 3.2460, lr_0 = 1.7775e-04
Loss = 6.0456e-01, PNorm = 42.6968, GNorm = 3.5549, lr_0 = 1.7703e-04
Loss = 5.2137e-01, PNorm = 42.7024, GNorm = 2.6603, lr_0 = 1.7630e-04
Validation rmse = 0.684163
Epoch 23
Loss = 4.1957e-01, PNorm = 42.7086, GNorm = 6.5427, lr_0 = 1.7550e-04
Loss = 4.7394e-01, PNorm = 42.7131, GNorm = 7.2661, lr_0 = 1.7478e-04
Loss = 5.3788e-01, PNorm = 42.7183, GNorm = 4.7870, lr_0 = 1.7407e-04
Loss = 4.4944e-01, PNorm = 42.7251, GNorm = 6.7672, lr_0 = 1.7335e-04
Loss = 4.8389e-01, PNorm = 42.7318, GNorm = 5.1922, lr_0 = 1.7264e-04
Loss = 4.5046e-01, PNorm = 42.7394, GNorm = 6.0181, lr_0 = 1.7193e-04
Loss = 3.5656e-01, PNorm = 42.7463, GNorm = 3.8128, lr_0 = 1.7123e-04
Loss = 5.0092e-01, PNorm = 42.7495, GNorm = 10.3245, lr_0 = 1.7052e-04
Loss = 3.4062e-01, PNorm = 42.7530, GNorm = 4.9163, lr_0 = 1.6982e-04
Loss = 3.0748e-01, PNorm = 42.7584, GNorm = 12.7134, lr_0 = 1.6913e-04
Loss = 4.5177e-01, PNorm = 42.7639, GNorm = 3.2262, lr_0 = 1.6843e-04
Loss = 2.4816e-01, PNorm = 42.7685, GNorm = 4.1961, lr_0 = 1.6774e-04
Loss = 5.5019e-01, PNorm = 42.7731, GNorm = 5.6523, lr_0 = 1.6705e-04
Loss = 4.0124e-01, PNorm = 42.7783, GNorm = 5.7569, lr_0 = 1.6637e-04
Loss = 4.2060e-01, PNorm = 42.7812, GNorm = 11.0384, lr_0 = 1.6569e-04
Loss = 4.2263e-01, PNorm = 42.7863, GNorm = 3.4099, lr_0 = 1.6501e-04
Loss = 4.5189e-01, PNorm = 42.7899, GNorm = 5.8919, lr_0 = 1.6433e-04
Loss = 4.5487e-01, PNorm = 42.7951, GNorm = 4.8011, lr_0 = 1.6365e-04
Loss = 5.4438e-01, PNorm = 42.7977, GNorm = 6.4732, lr_0 = 1.6298e-04
Loss = 3.1376e-01, PNorm = 42.8010, GNorm = 6.5071, lr_0 = 1.6231e-04
Validation rmse = 0.686292
Epoch 24
Loss = 4.3791e-01, PNorm = 42.8104, GNorm = 8.7795, lr_0 = 1.6158e-04
Loss = 3.6751e-01, PNorm = 42.8154, GNorm = 5.9397, lr_0 = 1.6092e-04
Loss = 4.4024e-01, PNorm = 42.8201, GNorm = 5.3354, lr_0 = 1.6026e-04
Loss = 4.0570e-01, PNorm = 42.8274, GNorm = 5.3417, lr_0 = 1.5960e-04
Loss = 5.0503e-01, PNorm = 42.8334, GNorm = 17.8476, lr_0 = 1.5895e-04
Loss = 5.5874e-01, PNorm = 42.8369, GNorm = 3.3941, lr_0 = 1.5829e-04
Loss = 4.6848e-01, PNorm = 42.8414, GNorm = 3.0322, lr_0 = 1.5764e-04
Loss = 4.0294e-01, PNorm = 42.8465, GNorm = 3.0540, lr_0 = 1.5700e-04
Loss = 3.0357e-01, PNorm = 42.8511, GNorm = 5.9873, lr_0 = 1.5635e-04
Loss = 4.1313e-01, PNorm = 42.8559, GNorm = 4.1799, lr_0 = 1.5571e-04
Loss = 4.4901e-01, PNorm = 42.8590, GNorm = 9.5315, lr_0 = 1.5507e-04
Loss = 3.4379e-01, PNorm = 42.8610, GNorm = 5.4769, lr_0 = 1.5444e-04
Loss = 4.9052e-01, PNorm = 42.8640, GNorm = 5.7411, lr_0 = 1.5380e-04
Loss = 4.4380e-01, PNorm = 42.8730, GNorm = 2.9771, lr_0 = 1.5317e-04
Loss = 3.8496e-01, PNorm = 42.8798, GNorm = 25.9860, lr_0 = 1.5254e-04
Loss = 2.4110e-01, PNorm = 42.8865, GNorm = 8.8498, lr_0 = 1.5192e-04
Loss = 1.0910e-01, PNorm = 42.8924, GNorm = 3.4479, lr_0 = 1.5129e-04
Loss = 4.1056e-01, PNorm = 42.8981, GNorm = 10.7895, lr_0 = 1.5067e-04
Loss = 3.2664e-01, PNorm = 42.9040, GNorm = 9.8239, lr_0 = 1.5005e-04
Loss = 5.0513e-01, PNorm = 42.9087, GNorm = 5.9121, lr_0 = 1.4944e-04
Validation rmse = 0.690250
Epoch 25
Loss = 3.5578e-01, PNorm = 42.9155, GNorm = 9.2550, lr_0 = 1.4876e-04
Loss = 2.7416e-01, PNorm = 42.9218, GNorm = 6.8141, lr_0 = 1.4815e-04
Loss = 4.0301e-01, PNorm = 42.9268, GNorm = 8.6074, lr_0 = 1.4755e-04
Loss = 3.3822e-01, PNorm = 42.9306, GNorm = 5.0138, lr_0 = 1.4694e-04
Loss = 1.8114e-01, PNorm = 42.9337, GNorm = 11.1059, lr_0 = 1.4634e-04
Loss = 4.8160e-01, PNorm = 42.9326, GNorm = 5.3918, lr_0 = 1.4574e-04
Loss = 2.0170e-01, PNorm = 42.9336, GNorm = 3.1650, lr_0 = 1.4514e-04
Loss = 2.6356e-01, PNorm = 42.9375, GNorm = 7.2018, lr_0 = 1.4454e-04
Loss = 4.3139e-01, PNorm = 42.9426, GNorm = 28.5260, lr_0 = 1.4395e-04
Loss = 2.9899e-01, PNorm = 42.9480, GNorm = 4.2025, lr_0 = 1.4336e-04
Loss = 2.7438e-01, PNorm = 42.9538, GNorm = 6.2665, lr_0 = 1.4277e-04
Loss = 4.1251e-01, PNorm = 42.9600, GNorm = 13.6267, lr_0 = 1.4219e-04
Loss = 4.5908e-01, PNorm = 42.9645, GNorm = 6.4787, lr_0 = 1.4160e-04
Loss = 4.0241e-01, PNorm = 42.9694, GNorm = 4.4148, lr_0 = 1.4102e-04
Loss = 5.3871e-01, PNorm = 42.9726, GNorm = 10.9792, lr_0 = 1.4044e-04
Loss = 3.5720e-01, PNorm = 42.9742, GNorm = 6.5066, lr_0 = 1.3987e-04
Loss = 4.2277e-01, PNorm = 42.9786, GNorm = 5.5430, lr_0 = 1.3929e-04
Loss = 4.7631e-01, PNorm = 42.9821, GNorm = 5.5681, lr_0 = 1.3872e-04
Loss = 3.8558e-01, PNorm = 42.9852, GNorm = 6.2510, lr_0 = 1.3815e-04
Loss = 3.9076e-01, PNorm = 42.9893, GNorm = 4.7394, lr_0 = 1.3759e-04
Validation rmse = 0.685148
Epoch 26
Loss = 4.2748e-01, PNorm = 42.9960, GNorm = 4.5169, lr_0 = 1.3696e-04
Loss = 3.2768e-01, PNorm = 43.0017, GNorm = 4.6880, lr_0 = 1.3640e-04
Loss = 3.3464e-01, PNorm = 43.0050, GNorm = 8.0034, lr_0 = 1.3584e-04
Loss = 3.2685e-01, PNorm = 43.0084, GNorm = 5.8148, lr_0 = 1.3529e-04
Loss = 2.8005e-01, PNorm = 43.0126, GNorm = 4.3972, lr_0 = 1.3473e-04
Loss = 4.2469e-01, PNorm = 43.0182, GNorm = 6.1600, lr_0 = 1.3418e-04
Loss = 5.0321e-01, PNorm = 43.0208, GNorm = 6.2437, lr_0 = 1.3363e-04
Loss = 3.6060e-01, PNorm = 43.0244, GNorm = 3.3957, lr_0 = 1.3308e-04
Loss = 3.5320e-01, PNorm = 43.0289, GNorm = 7.2356, lr_0 = 1.3253e-04
Loss = 3.4852e-01, PNorm = 43.0322, GNorm = 7.9562, lr_0 = 1.3199e-04
Loss = 3.4538e-01, PNorm = 43.0356, GNorm = 4.5355, lr_0 = 1.3145e-04
Loss = 3.4871e-01, PNorm = 43.0394, GNorm = 6.9450, lr_0 = 1.3091e-04
Loss = 5.0162e-01, PNorm = 43.0440, GNorm = 4.8672, lr_0 = 1.3037e-04
Loss = 2.7242e-01, PNorm = 43.0481, GNorm = 8.4633, lr_0 = 1.2984e-04
Loss = 4.3217e-01, PNorm = 43.0512, GNorm = 4.4463, lr_0 = 1.2930e-04
Loss = 2.9749e-01, PNorm = 43.0536, GNorm = 3.7944, lr_0 = 1.2877e-04
Loss = 2.3441e-01, PNorm = 43.0565, GNorm = 6.5689, lr_0 = 1.2824e-04
Loss = 2.8270e-01, PNorm = 43.0610, GNorm = 12.9347, lr_0 = 1.2772e-04
Loss = 2.7022e-01, PNorm = 43.0647, GNorm = 9.4513, lr_0 = 1.2719e-04
Loss = 4.5593e-01, PNorm = 43.0672, GNorm = 5.3615, lr_0 = 1.2667e-04
Validation rmse = 0.688062
Epoch 27
Loss = 4.9425e-01, PNorm = 43.0710, GNorm = 4.7532, lr_0 = 1.2610e-04
Loss = 3.5604e-01, PNorm = 43.0752, GNorm = 5.3615, lr_0 = 1.2558e-04
Loss = 2.8307e-01, PNorm = 43.0796, GNorm = 6.6514, lr_0 = 1.2507e-04
Loss = 3.0275e-01, PNorm = 43.0838, GNorm = 4.5731, lr_0 = 1.2455e-04
Loss = 3.6747e-01, PNorm = 43.0891, GNorm = 5.0233, lr_0 = 1.2404e-04
Loss = 3.5674e-01, PNorm = 43.0949, GNorm = 6.2968, lr_0 = 1.2353e-04
Loss = 2.1689e-01, PNorm = 43.1010, GNorm = 4.8393, lr_0 = 1.2303e-04
Loss = 3.2211e-01, PNorm = 43.1070, GNorm = 3.9430, lr_0 = 1.2252e-04
Loss = 3.1824e-01, PNorm = 43.1106, GNorm = 6.5374, lr_0 = 1.2202e-04
Loss = 2.8496e-01, PNorm = 43.1143, GNorm = 6.3211, lr_0 = 1.2152e-04
Loss = 3.1462e-01, PNorm = 43.1167, GNorm = 8.1700, lr_0 = 1.2102e-04
Loss = 1.7679e-01, PNorm = 43.1201, GNorm = 5.3629, lr_0 = 1.2052e-04
Loss = 4.6657e-01, PNorm = 43.1218, GNorm = 13.6432, lr_0 = 1.2003e-04
Loss = 3.4168e-01, PNorm = 43.1238, GNorm = 5.5750, lr_0 = 1.1954e-04
Loss = 3.8959e-01, PNorm = 43.1279, GNorm = 11.8347, lr_0 = 1.1905e-04
Loss = 3.4121e-01, PNorm = 43.1319, GNorm = 7.1978, lr_0 = 1.1856e-04
Loss = 3.1101e-01, PNorm = 43.1332, GNorm = 11.8965, lr_0 = 1.1807e-04
Loss = 3.5991e-01, PNorm = 43.1327, GNorm = 10.4125, lr_0 = 1.1759e-04
Loss = 1.9958e-01, PNorm = 43.1337, GNorm = 9.0103, lr_0 = 1.1710e-04
Loss = 4.0973e-01, PNorm = 43.1348, GNorm = 5.6182, lr_0 = 1.1662e-04
Validation rmse = 0.695204
Epoch 28
Loss = 2.4662e-01, PNorm = 43.1387, GNorm = 7.7036, lr_0 = 1.1610e-04
Loss = 2.1911e-01, PNorm = 43.1414, GNorm = 8.3757, lr_0 = 1.1562e-04
Loss = 3.2274e-01, PNorm = 43.1481, GNorm = 9.9777, lr_0 = 1.1515e-04
Loss = 2.9675e-01, PNorm = 43.1545, GNorm = 7.5860, lr_0 = 1.1467e-04
Loss = 3.2964e-01, PNorm = 43.1579, GNorm = 5.3373, lr_0 = 1.1420e-04
Loss = 3.5293e-01, PNorm = 43.1612, GNorm = 5.5552, lr_0 = 1.1373e-04
Loss = 2.7082e-01, PNorm = 43.1643, GNorm = 8.6072, lr_0 = 1.1327e-04
Loss = 3.4673e-01, PNorm = 43.1670, GNorm = 8.6303, lr_0 = 1.1280e-04
Loss = 2.6083e-01, PNorm = 43.1700, GNorm = 13.8106, lr_0 = 1.1234e-04
Loss = 4.8332e-01, PNorm = 43.1735, GNorm = 10.8580, lr_0 = 1.1188e-04
Loss = 4.3835e-01, PNorm = 43.1771, GNorm = 5.3705, lr_0 = 1.1142e-04
Loss = 3.4645e-01, PNorm = 43.1799, GNorm = 11.0616, lr_0 = 1.1096e-04
Loss = 3.4806e-01, PNorm = 43.1832, GNorm = 7.5033, lr_0 = 1.1051e-04
Loss = 2.9516e-01, PNorm = 43.1869, GNorm = 7.6495, lr_0 = 1.1005e-04
Loss = 2.9378e-01, PNorm = 43.1885, GNorm = 5.3654, lr_0 = 1.0960e-04
Loss = 3.3746e-01, PNorm = 43.1903, GNorm = 12.5858, lr_0 = 1.0915e-04
Loss = 3.3507e-01, PNorm = 43.1929, GNorm = 6.9010, lr_0 = 1.0871e-04
Loss = 2.5745e-01, PNorm = 43.1957, GNorm = 4.5762, lr_0 = 1.0826e-04
Loss = 2.2911e-01, PNorm = 43.1988, GNorm = 6.8402, lr_0 = 1.0781e-04
Loss = 1.4206e-01, PNorm = 43.2013, GNorm = 6.8182, lr_0 = 1.0737e-04
Validation rmse = 0.688635
Epoch 29
Loss = 3.4026e-01, PNorm = 43.2044, GNorm = 6.9441, lr_0 = 1.0689e-04
Loss = 2.5240e-01, PNorm = 43.2081, GNorm = 15.0901, lr_0 = 1.0645e-04
Loss = 2.2420e-01, PNorm = 43.2112, GNorm = 7.1522, lr_0 = 1.0601e-04
Loss = 1.5836e-01, PNorm = 43.2137, GNorm = 5.4783, lr_0 = 1.0558e-04
Loss = 4.0591e-01, PNorm = 43.2165, GNorm = 6.4192, lr_0 = 1.0514e-04
Loss = 1.6504e-01, PNorm = 43.2208, GNorm = 7.9172, lr_0 = 1.0471e-04
Loss = 3.0343e-01, PNorm = 43.2260, GNorm = 13.5126, lr_0 = 1.0428e-04
Loss = 3.6240e-01, PNorm = 43.2303, GNorm = 9.3510, lr_0 = 1.0386e-04
Loss = 5.0826e-01, PNorm = 43.2311, GNorm = 4.8506, lr_0 = 1.0343e-04
Loss = 3.0278e-01, PNorm = 43.2332, GNorm = 4.9014, lr_0 = 1.0300e-04
Loss = 2.5929e-01, PNorm = 43.2361, GNorm = 10.4126, lr_0 = 1.0258e-04
Loss = 3.2243e-01, PNorm = 43.2396, GNorm = 9.1237, lr_0 = 1.0216e-04
Loss = 2.0853e-01, PNorm = 43.2447, GNorm = 4.4448, lr_0 = 1.0174e-04
Loss = 2.8846e-01, PNorm = 43.2473, GNorm = 7.0164, lr_0 = 1.0132e-04
Loss = 2.8851e-01, PNorm = 43.2482, GNorm = 10.0210, lr_0 = 1.0091e-04
Loss = 2.7784e-01, PNorm = 43.2509, GNorm = 4.9927, lr_0 = 1.0049e-04
Loss = 3.4677e-01, PNorm = 43.2554, GNorm = 5.2729, lr_0 = 1.0008e-04
Loss = 2.0876e-01, PNorm = 43.2609, GNorm = 4.7257, lr_0 = 1.0000e-04
Loss = 2.4221e-01, PNorm = 43.2668, GNorm = 9.7134, lr_0 = 1.0000e-04
Loss = 3.3012e-01, PNorm = 43.2672, GNorm = 5.0059, lr_0 = 1.0000e-04
Validation rmse = 0.682118
Model 0 best validation rmse = 0.682118 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.841524
Ensemble test rmse = 0.841524
1-fold cross validation
	Seed 0 ==> test rmse = 0.841524
Overall test rmse = 0.841524 +/- 0.000000
Elapsed time = 0:04:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 1,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7804e+00, PNorm = 43.2588, GNorm = 1.5326, lr_0 = 4.3000e-04
Validation rmse = 1.284306
Model 0 best validation rmse = 1.284306 on epoch 0
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 1.364820
Ensemble test rmse = 1.364820
1-fold cross validation
	Seed 0 ==> test rmse = 1.364820
Overall test rmse = 1.364820 +/- 0.000000
Elapsed time = 0:00:06
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7804e+00, PNorm = 43.2588, GNorm = 1.5326, lr_0 = 4.3000e-04
Validation rmse = 1.284306
Epoch 1
Loss = 1.4357e+00, PNorm = 43.2626, GNorm = 0.9985, lr_0 = 7.6000e-04
Loss = 1.3995e+00, PNorm = 43.2769, GNorm = 1.5045, lr_0 = 9.8910e-04
Validation rmse = 1.247114
Epoch 2
Loss = 1.3035e+00, PNorm = 43.3051, GNorm = 0.8098, lr_0 = 9.3633e-04
Validation rmse = 1.246525
Epoch 3
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7804e+00, PNorm = 43.2588, GNorm = 1.5326, lr_0 = 4.3000e-04
Validation rmse = 1.284306
Epoch 1
Loss = 1.4357e+00, PNorm = 43.2626, GNorm = 0.9985, lr_0 = 7.6000e-04
Loss = 1.3995e+00, PNorm = 43.2769, GNorm = 1.5045, lr_0 = 9.8910e-04
Validation rmse = 1.247114
Epoch 2
Loss = 1.3035e+00, PNorm = 43.3051, GNorm = 0.8098, lr_0 = 9.3633e-04
Validation rmse = 1.246525
Epoch 3
Loss = 1.2003e+00, PNorm = 43.3436, GNorm = 2.1816, lr_0 = 8.8638e-04
Loss = 1.1046e+00, PNorm = 43.3949, GNorm = 1.2993, lr_0 = 8.3909e-04
Validation rmse = 1.035407
Epoch 4
Loss = 9.3443e-01, PNorm = 43.4560, GNorm = 2.9238, lr_0 = 7.9433e-04
Validation rmse = 1.007708
Epoch 5
Loss = 1.0191e+00, PNorm = 43.5026, GNorm = 12.3191, lr_0 = 7.5195e-04
Loss = 8.8449e-01, PNorm = 43.5354, GNorm = 1.9469, lr_0 = 7.1184e-04
Validation rmse = 0.990051
Epoch 6
Loss = 8.7040e-01, PNorm = 43.5763, GNorm = 11.4833, lr_0 = 6.7386e-04
Loss = 7.9217e-01, PNorm = 43.6069, GNorm = 6.2708, lr_0 = 6.3791e-04
Validation rmse = 0.881871
Epoch 7
Loss = 7.3401e-01, PNorm = 43.6382, GNorm = 8.9640, lr_0 = 6.0388e-04
Validation rmse = 0.998305
Epoch 8
Loss = 8.1026e-01, PNorm = 43.6618, GNorm = 10.2219, lr_0 = 5.7167e-04
Loss = 6.9238e-01, PNorm = 43.6859, GNorm = 2.3903, lr_0 = 5.4117e-04
Validation rmse = 0.902731
Epoch 9
Loss = 6.3166e-01, PNorm = 43.7136, GNorm = 2.0829, lr_0 = 5.1230e-04
Validation rmse = 0.872563
Epoch 10
Loss = 5.4227e-01, PNorm = 43.7364, GNorm = 5.8488, lr_0 = 4.8497e-04
Loss = 6.0441e-01, PNorm = 43.7578, GNorm = 2.8231, lr_0 = 4.5910e-04
Validation rmse = 0.867031
Epoch 11
Loss = 6.5715e-01, PNorm = 43.7770, GNorm = 8.1809, lr_0 = 4.3461e-04
Loss = 6.4429e-01, PNorm = 43.7984, GNorm = 2.9016, lr_0 = 4.1142e-04
Validation rmse = 0.926205
Epoch 12
Loss = 5.9643e-01, PNorm = 43.8233, GNorm = 7.9199, lr_0 = 3.8947e-04
Validation rmse = 0.853772
Epoch 13
Loss = 6.0427e-01, PNorm = 43.8439, GNorm = 3.3711, lr_0 = 3.6869e-04
Loss = 5.9134e-01, PNorm = 43.8594, GNorm = 15.0060, lr_0 = 3.4903e-04
Validation rmse = 0.860987
Epoch 14
Loss = 5.3820e-01, PNorm = 43.8749, GNorm = 2.8954, lr_0 = 3.3041e-04
Validation rmse = 0.860188
Epoch 15
Loss = 4.6807e-01, PNorm = 43.8927, GNorm = 4.7596, lr_0 = 3.1278e-04
Loss = 5.3452e-01, PNorm = 43.9064, GNorm = 5.5974, lr_0 = 2.9609e-04
Validation rmse = 0.849252
Epoch 16
Loss = 5.1372e-01, PNorm = 43.9225, GNorm = 8.0376, lr_0 = 2.8030e-04
Loss = 5.2849e-01, PNorm = 43.9367, GNorm = 2.5357, lr_0 = 2.6534e-04
Validation rmse = 0.840483
Epoch 17
Loss = 5.1545e-01, PNorm = 43.9509, GNorm = 11.3461, lr_0 = 2.5119e-04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7804e+00, PNorm = 43.2588, GNorm = 1.5326, lr_0 = 4.3000e-04
Validation rmse = 1.284306
Epoch 1
Loss = 1.4357e+00, PNorm = 43.2626, GNorm = 0.9985, lr_0 = 7.6000e-04
Loss = 1.3995e+00, PNorm = 43.2769, GNorm = 1.5045, lr_0 = 9.8910e-04
Validation rmse = 1.247114
Epoch 2
Loss = 1.3035e+00, PNorm = 43.3051, GNorm = 0.8098, lr_0 = 9.3633e-04
Validation rmse = 1.246525
Epoch 3
Loss = 1.2003e+00, PNorm = 43.3436, GNorm = 2.1816, lr_0 = 8.8638e-04
Loss = 1.1046e+00, PNorm = 43.3949, GNorm = 1.2993, lr_0 = 8.3909e-04
Validation rmse = 1.035400
Epoch 4
Loss = 9.3445e-01, PNorm = 43.4560, GNorm = 2.9115, lr_0 = 7.9433e-04
Validation rmse = 1.006028
Epoch 5
Loss = 1.0169e+00, PNorm = 43.5028, GNorm = 12.2099, lr_0 = 7.5195e-04
Loss = 8.8500e-01, PNorm = 43.5358, GNorm = 1.9342, lr_0 = 7.1184e-04
Validation rmse = 0.991409
Epoch 6
Loss = 8.7063e-01, PNorm = 43.5767, GNorm = 11.2803, lr_0 = 6.7386e-04
Loss = 7.9212e-01, PNorm = 43.6072, GNorm = 6.4697, lr_0 = 6.3791e-04
Validation rmse = 0.881611
Epoch 7
Loss = 7.3242e-01, PNorm = 43.6384, GNorm = 9.3449, lr_0 = 6.0388e-04
Validation rmse = 1.001654
Epoch 8
Loss = 8.1089e-01, PNorm = 43.6624, GNorm = 10.1751, lr_0 = 5.7167e-04
Loss = 6.9358e-01, PNorm = 43.6859, GNorm = 2.3732, lr_0 = 5.4117e-04
Validation rmse = 0.896070
Epoch 9
Loss = 6.2712e-01, PNorm = 43.7134, GNorm = 2.1183, lr_0 = 5.1230e-04
Validation rmse = 0.871742
Epoch 10
Loss = 5.3493e-01, PNorm = 43.7361, GNorm = 4.9025, lr_0 = 4.8497e-04
Loss = 6.0371e-01, PNorm = 43.7580, GNorm = 3.0214, lr_0 = 4.5910e-04
Validation rmse = 0.869566
Epoch 11
Loss = 6.5051e-01, PNorm = 43.7784, GNorm = 6.7672, lr_0 = 4.3461e-04
Loss = 6.3396e-01, PNorm = 43.8010, GNorm = 3.3048, lr_0 = 4.1142e-04
Validation rmse = 0.914959
Epoch 12
Loss = 5.8944e-01, PNorm = 43.8265, GNorm = 10.0659, lr_0 = 3.8947e-04
Validation rmse = 0.856256
Epoch 13
Loss = 5.9935e-01, PNorm = 43.8458, GNorm = 3.8620, lr_0 = 3.6869e-04
Loss = 5.8631e-01, PNorm = 43.8607, GNorm = 15.0064, lr_0 = 3.4903e-04
Validation rmse = 0.864406
Epoch 14
Loss = 5.3588e-01, PNorm = 43.8763, GNorm = 2.4702, lr_0 = 3.3041e-04
Validation rmse = 0.858736
Epoch 15
Loss = 4.6184e-01, PNorm = 43.8945, GNorm = 5.0942, lr_0 = 3.1278e-04
Loss = 5.3536e-01, PNorm = 43.9086, GNorm = 4.9762, lr_0 = 2.9609e-04
Validation rmse = 0.849407
Epoch 16
Loss = 5.1278e-01, PNorm = 43.9250, GNorm = 9.0316, lr_0 = 2.8030e-04
Loss = 5.2604e-01, PNorm = 43.9392, GNorm = 2.8491, lr_0 = 2.6534e-04
Validation rmse = 0.840488
Epoch 17
Loss = 5.1597e-01, PNorm = 43.9535, GNorm = 12.1574, lr_0 = 2.5119e-04
Validation rmse = 0.854321
Epoch 18
Loss = 5.1226e-01, PNorm = 43.9657, GNorm = 12.8012, lr_0 = 2.3779e-04
Loss = 5.2184e-01, PNorm = 43.9770, GNorm = 6.0976, lr_0 = 2.2510e-04
Validation rmse = 0.867550
Epoch 19
Loss = 4.9426e-01, PNorm = 43.9900, GNorm = 4.0561, lr_0 = 2.1309e-04
Validation rmse = 0.835358
Epoch 20
Loss = 4.3971e-01, PNorm = 44.0002, GNorm = 3.5005, lr_0 = 2.0173e-04
Loss = 5.0026e-01, PNorm = 44.0122, GNorm = 14.5796, lr_0 = 1.9096e-04
Validation rmse = 0.837309
Epoch 21
Loss = 3.9231e-01, PNorm = 44.0216, GNorm = 7.4359, lr_0 = 1.8078e-04
Loss = 4.8588e-01, PNorm = 44.0307, GNorm = 3.0716, lr_0 = 1.7113e-04
Validation rmse = 0.838868
Epoch 22
Loss = 4.2216e-01, PNorm = 44.0417, GNorm = 3.0771, lr_0 = 1.6200e-04
Validation rmse = 0.838184
Epoch 23
Loss = 4.7570e-01, PNorm = 44.0492, GNorm = 3.9519, lr_0 = 1.5336e-04
Loss = 4.1586e-01, PNorm = 44.0574, GNorm = 3.9806, lr_0 = 1.4518e-04
Validation rmse = 0.836194
Epoch 24
Loss = 3.7560e-01, PNorm = 44.0654, GNorm = 6.2940, lr_0 = 1.3743e-04
Validation rmse = 0.837274
Epoch 25
Loss = 5.3377e-01, PNorm = 44.0729, GNorm = 3.6150, lr_0 = 1.3010e-04
Loss = 4.1904e-01, PNorm = 44.0800, GNorm = 4.0021, lr_0 = 1.2316e-04
Validation rmse = 0.835428
Epoch 26
Loss = 4.4406e-01, PNorm = 44.0863, GNorm = 13.3732, lr_0 = 1.1659e-04
Loss = 3.9879e-01, PNorm = 44.0941, GNorm = 2.8589, lr_0 = 1.1037e-04
Validation rmse = 0.856118
Epoch 27
Loss = 4.3351e-01, PNorm = 44.1008, GNorm = 10.8878, lr_0 = 1.0448e-04
Validation rmse = 0.831105
Epoch 28
Loss = 3.9131e-01, PNorm = 44.1064, GNorm = 14.3980, lr_0 = 1.0000e-04
Loss = 4.2959e-01, PNorm = 44.1124, GNorm = 19.9708, lr_0 = 1.0000e-04
Validation rmse = 0.853690
Epoch 29
Loss = 4.2648e-01, PNorm = 44.1172, GNorm = 16.8010, lr_0 = 1.0000e-04
Validation rmse = 0.830561
Model 0 best validation rmse = 0.830561 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.654096
Ensemble test rmse = 0.654096
1-fold cross validation
	Seed 0 ==> test rmse = 0.654096
Overall test rmse = 0.654096 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,049 | train size = 839 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8838e+00, PNorm = 43.2585, GNorm = 1.5457, lr_0 = 4.0937e-04
Validation rmse = 1.355042
Epoch 1
Loss = 1.4515e+00, PNorm = 43.2614, GNorm = 2.0681, lr_0 = 7.1875e-04
Loss = 1.3865e+00, PNorm = 43.2737, GNorm = 1.8841, lr_0 = 1.0000e-03
Validation rmse = 1.329433
Epoch 2
Loss = 1.3129e+00, PNorm = 43.2963, GNorm = 1.2457, lr_0 = 9.4990e-04
Loss = 1.2767e+00, PNorm = 43.3301, GNorm = 1.4368, lr_0 = 9.0231e-04
Validation rmse = 1.200051
Epoch 3
Loss = 1.1662e+00, PNorm = 43.3689, GNorm = 2.5607, lr_0 = 8.5711e-04
Validation rmse = 1.120080
Epoch 4
Loss = 1.0457e+00, PNorm = 43.4211, GNorm = 2.5476, lr_0 = 8.1417e-04
Loss = 1.0547e+00, PNorm = 43.4680, GNorm = 1.7224, lr_0 = 7.7338e-04
Validation rmse = 1.049777
Epoch 5
Loss = 9.7494e-01, PNorm = 43.5147, GNorm = 3.9662, lr_0 = 7.3087e-04
Loss = 9.1549e-01, PNorm = 43.5563, GNorm = 3.5248, lr_0 = 6.9425e-04
Validation rmse = 0.954571
Epoch 6
Loss = 8.8629e-01, PNorm = 43.5972, GNorm = 7.0339, lr_0 = 6.5947e-04
Validation rmse = 0.937451
Epoch 7
Loss = 8.4251e-01, PNorm = 43.6289, GNorm = 1.9316, lr_0 = 6.2643e-04
Loss = 8.4561e-01, PNorm = 43.6644, GNorm = 4.3364, lr_0 = 5.9505e-04
Validation rmse = 0.916418
Epoch 8
Loss = 6.7407e-01, PNorm = 43.6923, GNorm = 3.9996, lr_0 = 5.6524e-04
Loss = 7.9244e-01, PNorm = 43.7208, GNorm = 5.0245, lr_0 = 5.3692e-04
Validation rmse = 0.951164
Epoch 9
Loss = 6.9361e-01, PNorm = 43.7464, GNorm = 9.3233, lr_0 = 5.1002e-04
Validation rmse = 0.896532
Epoch 10
Loss = 7.7441e-01, PNorm = 43.7694, GNorm = 4.6761, lr_0 = 4.8199e-04
Loss = 6.7132e-01, PNorm = 43.7908, GNorm = 2.3967, lr_0 = 4.5784e-04
Validation rmse = 0.876216
Epoch 11
Loss = 6.3829e-01, PNorm = 43.8171, GNorm = 2.5263, lr_0 = 4.3490e-04
Loss = 6.6391e-01, PNorm = 43.8365, GNorm = 4.1705, lr_0 = 4.1312e-04
Validation rmse = 0.904633
Epoch 12
Loss = 5.9479e-01, PNorm = 43.8555, GNorm = 2.2788, lr_0 = 3.9242e-04
Validation rmse = 0.868953
Epoch 13
Loss = 6.2595e-01, PNorm = 43.8716, GNorm = 10.3451, lr_0 = 3.7276e-04
Loss = 6.9489e-01, PNorm = 43.8885, GNorm = 3.9489, lr_0 = 3.5408e-04
Validation rmse = 0.914105
Epoch 14
Loss = 5.8959e-01, PNorm = 43.9115, GNorm = 3.0761, lr_0 = 3.3462e-04
Loss = 5.9402e-01, PNorm = 43.9306, GNorm = 2.5220, lr_0 = 3.1786e-04
Validation rmse = 0.851999
Epoch 15
Loss = 5.6409e-01, PNorm = 43.9475, GNorm = 8.9790, lr_0 = 3.0193e-04
Validation rmse = 0.846977
Epoch 16
Loss = 5.5485e-01, PNorm = 43.9590, GNorm = 7.4159, lr_0 = 2.8681e-04
Loss = 5.7105e-01, PNorm = 43.9705, GNorm = 3.3324, lr_0 = 2.7244e-04
Validation rmse = 0.856929
Epoch 17
Loss = 5.5750e-01, PNorm = 43.9851, GNorm = 7.5275, lr_0 = 2.5879e-04
Loss = 5.5127e-01, PNorm = 43.9992, GNorm = 3.3658, lr_0 = 2.4582e-04
Validation rmse = 0.829789
Epoch 18
Loss = 5.4430e-01, PNorm = 44.0124, GNorm = 4.5409, lr_0 = 2.3351e-04
Validation rmse = 0.833128
Epoch 19
Loss = 5.8472e-01, PNorm = 44.0253, GNorm = 11.8640, lr_0 = 2.2067e-04
Loss = 5.6948e-01, PNorm = 44.0343, GNorm = 8.3742, lr_0 = 2.0962e-04
Validation rmse = 0.893091
Epoch 20
Loss = 5.4814e-01, PNorm = 44.0474, GNorm = 3.2462, lr_0 = 1.9912e-04
Loss = 4.8455e-01, PNorm = 44.0585, GNorm = 2.7710, lr_0 = 1.8914e-04
Validation rmse = 0.827301
Epoch 21
Loss = 4.5857e-01, PNorm = 44.0695, GNorm = 3.4533, lr_0 = 1.7967e-04
Validation rmse = 0.835887
Epoch 22
Loss = 3.7303e-01, PNorm = 44.0770, GNorm = 3.3403, lr_0 = 1.7066e-04
Loss = 4.5470e-01, PNorm = 44.0860, GNorm = 2.4989, lr_0 = 1.6211e-04
Validation rmse = 0.852270
Epoch 23
Loss = 4.3629e-01, PNorm = 44.0964, GNorm = 4.9086, lr_0 = 1.5320e-04
Loss = 4.7559e-01, PNorm = 44.1055, GNorm = 3.4158, lr_0 = 1.4553e-04
Validation rmse = 0.854410
Epoch 24
Loss = 4.5957e-01, PNorm = 44.1141, GNorm = 5.1354, lr_0 = 1.3824e-04
Validation rmse = 0.834055
Epoch 25
Loss = 5.6599e-01, PNorm = 44.1213, GNorm = 6.4659, lr_0 = 1.3131e-04
Loss = 4.2465e-01, PNorm = 44.1277, GNorm = 6.2821, lr_0 = 1.2473e-04
Validation rmse = 0.826444
Epoch 26
Loss = 4.3879e-01, PNorm = 44.1343, GNorm = 6.9293, lr_0 = 1.1848e-04
Loss = 4.6039e-01, PNorm = 44.1405, GNorm = 4.4291, lr_0 = 1.1255e-04
Validation rmse = 0.821185
Epoch 27
Loss = 4.3201e-01, PNorm = 44.1480, GNorm = 3.7472, lr_0 = 1.0691e-04
Validation rmse = 0.821447
Epoch 28
Loss = 4.1598e-01, PNorm = 44.1543, GNorm = 3.8290, lr_0 = 1.0103e-04
Loss = 3.9449e-01, PNorm = 44.1596, GNorm = 10.4900, lr_0 = 1.0000e-04
Validation rmse = 0.836864
Epoch 29
Loss = 4.0105e-01, PNorm = 44.1665, GNorm = 4.2732, lr_0 = 1.0000e-04
Loss = 4.5004e-01, PNorm = 44.1717, GNorm = 3.5235, lr_0 = 1.0000e-04
Validation rmse = 0.816775
Model 0 best validation rmse = 0.816775 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.663326
Ensemble test rmse = 0.663326
1-fold cross validation
	Seed 0 ==> test rmse = 0.663326
Overall test rmse = 0.663326 +/- 0.000000
Elapsed time = 0:01:27
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8435e+00, PNorm = 43.2611, GNorm = 1.5803, lr_0 = 3.9118e-04
Validation rmse = 1.221507
Epoch 1
Loss = 1.4661e+00, PNorm = 43.2624, GNorm = 1.4735, lr_0 = 6.8235e-04
Loss = 1.3972e+00, PNorm = 43.2711, GNorm = 1.0810, lr_0 = 9.4706e-04
Validation rmse = 1.202008
Epoch 2
Loss = 1.3407e+00, PNorm = 43.2899, GNorm = 2.7902, lr_0 = 9.6204e-04
Loss = 1.3074e+00, PNorm = 43.3155, GNorm = 3.6014, lr_0 = 9.1661e-04
Validation rmse = 1.082665
Epoch 3
Loss = 1.2319e+00, PNorm = 43.3565, GNorm = 2.2587, lr_0 = 8.6911e-04
Loss = 1.1026e+00, PNorm = 43.4013, GNorm = 2.8475, lr_0 = 8.2807e-04
Validation rmse = 0.961449
Epoch 4
Loss = 9.9816e-01, PNorm = 43.4529, GNorm = 3.4850, lr_0 = 7.8897e-04
Validation rmse = 1.123910
Epoch 5
Loss = 9.9714e-01, PNorm = 43.5002, GNorm = 2.0303, lr_0 = 7.4808e-04
Loss = 9.2208e-01, PNorm = 43.5455, GNorm = 3.6042, lr_0 = 7.1276e-04
Validation rmse = 0.882288
Epoch 6
Loss = 8.3653e-01, PNorm = 43.5809, GNorm = 1.8374, lr_0 = 6.7910e-04
Loss = 7.9759e-01, PNorm = 43.6189, GNorm = 5.8006, lr_0 = 6.4703e-04
Validation rmse = 0.757773
Epoch 7
Loss = 8.6926e-01, PNorm = 43.6485, GNorm = 3.6833, lr_0 = 6.1648e-04
Loss = 8.1028e-01, PNorm = 43.6765, GNorm = 4.0486, lr_0 = 5.8736e-04
Loss = 7.0058e-01, PNorm = 43.6793, GNorm = 2.0100, lr_0 = 5.8453e-04
Validation rmse = 0.785144
Epoch 8
Loss = 7.2331e-01, PNorm = 43.7094, GNorm = 3.1349, lr_0 = 5.5693e-04
Validation rmse = 0.839392
Epoch 9
Loss = 7.3498e-01, PNorm = 43.7405, GNorm = 9.0980, lr_0 = 5.3063e-04
Loss = 7.2713e-01, PNorm = 43.7656, GNorm = 9.9359, lr_0 = 5.0557e-04
Validation rmse = 0.732373
Epoch 10
Loss = 7.1016e-01, PNorm = 43.7844, GNorm = 4.3813, lr_0 = 4.7937e-04
Loss = 6.7133e-01, PNorm = 43.8091, GNorm = 5.4360, lr_0 = 4.5673e-04
Validation rmse = 0.813500
Epoch 11
Loss = 6.2094e-01, PNorm = 43.8348, GNorm = 6.3327, lr_0 = 4.3517e-04
Loss = 6.4717e-01, PNorm = 43.8568, GNorm = 5.6126, lr_0 = 4.1462e-04
Loss = 6.3557e-01, PNorm = 43.8582, GNorm = 6.9016, lr_0 = 4.1262e-04
Validation rmse = 0.736129
Epoch 12
Loss = 6.2175e-01, PNorm = 43.8753, GNorm = 10.5464, lr_0 = 3.9313e-04
Validation rmse = 0.736037
Epoch 13
Loss = 5.6589e-01, PNorm = 43.8935, GNorm = 2.1029, lr_0 = 3.7457e-04
Loss = 5.6475e-01, PNorm = 43.9120, GNorm = 3.3889, lr_0 = 3.5688e-04
Validation rmse = 0.730457
Epoch 14
Loss = 5.0061e-01, PNorm = 43.9288, GNorm = 2.5483, lr_0 = 3.4003e-04
Loss = 6.3840e-01, PNorm = 43.9453, GNorm = 14.0172, lr_0 = 3.2397e-04
Validation rmse = 0.780079
Epoch 15
Loss = 5.6827e-01, PNorm = 43.9586, GNorm = 3.7803, lr_0 = 3.0718e-04
Loss = 5.8409e-01, PNorm = 43.9758, GNorm = 7.7367, lr_0 = 2.9268e-04
Validation rmse = 0.747189
Epoch 16
Loss = 5.4785e-01, PNorm = 43.9967, GNorm = 6.2783, lr_0 = 2.7885e-04
Validation rmse = 0.742253
Epoch 17
Loss = 5.6077e-01, PNorm = 44.0110, GNorm = 3.8340, lr_0 = 2.6440e-04
Loss = 5.4015e-01, PNorm = 44.0211, GNorm = 10.8866, lr_0 = 2.5192e-04
Validation rmse = 0.709275
Epoch 18
Loss = 5.0950e-01, PNorm = 44.0346, GNorm = 2.4176, lr_0 = 2.4002e-04
Loss = 5.1241e-01, PNorm = 44.0493, GNorm = 4.4571, lr_0 = 2.2869e-04
Validation rmse = 0.708112
Epoch 19
Loss = 5.8175e-01, PNorm = 44.0623, GNorm = 9.4191, lr_0 = 2.1789e-04
Loss = 4.9058e-01, PNorm = 44.0725, GNorm = 2.8633, lr_0 = 2.0760e-04
Validation rmse = 0.692364
Epoch 20
Loss = 4.6166e-01, PNorm = 44.0849, GNorm = 6.1275, lr_0 = 1.9684e-04
Validation rmse = 0.691100
Epoch 21
Loss = 3.8353e-01, PNorm = 44.0963, GNorm = 6.0082, lr_0 = 1.8755e-04
Loss = 4.7604e-01, PNorm = 44.1073, GNorm = 10.5225, lr_0 = 1.7869e-04
Validation rmse = 0.700646
Epoch 22
Loss = 5.3810e-01, PNorm = 44.1178, GNorm = 7.9577, lr_0 = 1.6943e-04
Loss = 4.6984e-01, PNorm = 44.1272, GNorm = 2.9598, lr_0 = 1.6143e-04
Validation rmse = 0.739378
Epoch 23
Loss = 4.5046e-01, PNorm = 44.1368, GNorm = 3.7903, lr_0 = 1.5381e-04
Loss = 4.5727e-01, PNorm = 44.1451, GNorm = 8.9980, lr_0 = 1.4654e-04
Validation rmse = 0.722964
Epoch 24
Loss = 4.3469e-01, PNorm = 44.1535, GNorm = 3.6339, lr_0 = 1.3895e-04
Validation rmse = 0.695105
Epoch 25
Loss = 2.7327e-01, PNorm = 44.1600, GNorm = 5.3783, lr_0 = 1.3239e-04
Loss = 4.6848e-01, PNorm = 44.1663, GNorm = 9.7660, lr_0 = 1.2614e-04
Validation rmse = 0.687931
Epoch 26
Loss = 3.8077e-01, PNorm = 44.1723, GNorm = 6.4929, lr_0 = 1.2018e-04
Loss = 4.2790e-01, PNorm = 44.1798, GNorm = 7.2079, lr_0 = 1.1450e-04
Validation rmse = 0.692091
Epoch 27
Loss = 3.7707e-01, PNorm = 44.1856, GNorm = 2.9709, lr_0 = 1.0857e-04
Loss = 4.7324e-01, PNorm = 44.1910, GNorm = 5.4303, lr_0 = 1.0344e-04
Validation rmse = 0.684397
Epoch 28
Loss = 4.7644e-01, PNorm = 44.1968, GNorm = 7.9526, lr_0 = 1.0000e-04
Validation rmse = 0.695977
Epoch 29
Loss = 4.3177e-01, PNorm = 44.2031, GNorm = 3.4222, lr_0 = 1.0000e-04
Loss = 4.1563e-01, PNorm = 44.2091, GNorm = 3.1692, lr_0 = 1.0000e-04
Validation rmse = 0.698849
Model 0 best validation rmse = 0.684397 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.643713
Ensemble test rmse = 0.643713
1-fold cross validation
	Seed 0 ==> test rmse = 0.643713
Overall test rmse = 0.643713 +/- 0.000000
Elapsed time = 0:01:29
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,149 | train size = 919 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9921e+00, PNorm = 43.2571, GNorm = 1.1783, lr_0 = 3.7500e-04
Validation rmse = 1.251047
Epoch 1
Loss = 1.4548e+00, PNorm = 43.2577, GNorm = 1.0295, lr_0 = 6.5000e-04
Loss = 1.4145e+00, PNorm = 43.2651, GNorm = 0.7330, lr_0 = 9.0000e-04
Validation rmse = 1.186226
Epoch 2
Loss = 1.3680e+00, PNorm = 43.2859, GNorm = 4.9207, lr_0 = 9.6853e-04
Loss = 1.3210e+00, PNorm = 43.3144, GNorm = 2.0417, lr_0 = 9.2527e-04
Validation rmse = 1.076865
Epoch 3
Loss = 1.1926e+00, PNorm = 43.3476, GNorm = 1.0547, lr_0 = 8.8395e-04
Loss = 1.1562e+00, PNorm = 43.3910, GNorm = 2.1211, lr_0 = 8.4448e-04
Validation rmse = 0.958338
Epoch 4
Loss = 1.1819e+00, PNorm = 43.4478, GNorm = 5.8278, lr_0 = 8.0309e-04
Loss = 1.0280e+00, PNorm = 43.4911, GNorm = 2.2021, lr_0 = 7.6722e-04
Validation rmse = 0.913425
Epoch 5
Loss = 9.6304e-01, PNorm = 43.5424, GNorm = 6.3210, lr_0 = 7.2962e-04
Loss = 9.3310e-01, PNorm = 43.5812, GNorm = 2.1279, lr_0 = 6.9703e-04
Validation rmse = 0.890592
Epoch 6
Loss = 8.3764e-01, PNorm = 43.6174, GNorm = 4.7845, lr_0 = 6.6591e-04
Validation rmse = 0.799433
Epoch 7
Loss = 8.6900e-01, PNorm = 43.6534, GNorm = 4.5976, lr_0 = 6.3327e-04
Loss = 8.1383e-01, PNorm = 43.6908, GNorm = 6.5051, lr_0 = 6.0499e-04
Validation rmse = 0.831750
Epoch 8
Loss = 8.3151e-01, PNorm = 43.7188, GNorm = 11.3851, lr_0 = 5.7797e-04
Loss = 7.7075e-01, PNorm = 43.7496, GNorm = 4.6098, lr_0 = 5.5216e-04
Validation rmse = 0.757710
Epoch 9
Loss = 7.2672e-01, PNorm = 43.7803, GNorm = 10.4574, lr_0 = 5.2510e-04
Loss = 7.6193e-01, PNorm = 43.8051, GNorm = 3.4258, lr_0 = 5.0165e-04
Validation rmse = 0.721925
Epoch 10
Loss = 6.5001e-01, PNorm = 43.8328, GNorm = 2.5597, lr_0 = 4.7706e-04
Loss = 7.3336e-01, PNorm = 43.8591, GNorm = 2.8302, lr_0 = 4.5575e-04
Validation rmse = 0.708926
Epoch 11
Loss = 6.0732e-01, PNorm = 43.8855, GNorm = 3.7996, lr_0 = 4.3540e-04
Loss = 7.1966e-01, PNorm = 43.9094, GNorm = 3.5442, lr_0 = 4.1596e-04
Loss = 5.7395e-01, PNorm = 43.9114, GNorm = 4.9403, lr_0 = 4.1406e-04
Validation rmse = 0.775166
Epoch 12
Loss = 6.8835e-01, PNorm = 43.9301, GNorm = 2.9428, lr_0 = 3.9557e-04
Validation rmse = 0.739378
Epoch 13
Loss = 7.9223e-01, PNorm = 43.9535, GNorm = 8.7836, lr_0 = 3.7618e-04
Loss = 5.8333e-01, PNorm = 43.9722, GNorm = 3.1053, lr_0 = 3.5938e-04
Validation rmse = 0.701368
Epoch 14
Loss = 5.0421e-01, PNorm = 43.9898, GNorm = 4.1068, lr_0 = 3.4333e-04
Loss = 5.7202e-01, PNorm = 44.0092, GNorm = 5.4917, lr_0 = 3.2800e-04
Validation rmse = 0.689009
Epoch 15
Loss = 6.0647e-01, PNorm = 44.0278, GNorm = 7.8376, lr_0 = 3.1192e-04
Loss = 5.8741e-01, PNorm = 44.0467, GNorm = 5.0795, lr_0 = 2.9799e-04
Validation rmse = 0.702846
Epoch 16
Loss = 5.6678e-01, PNorm = 44.0613, GNorm = 3.0428, lr_0 = 2.8469e-04
Loss = 5.7272e-01, PNorm = 44.0772, GNorm = 6.2102, lr_0 = 2.7197e-04
Validation rmse = 0.708572
Epoch 17
Loss = 5.3565e-01, PNorm = 44.0912, GNorm = 4.1911, lr_0 = 2.5864e-04
Loss = 5.6209e-01, PNorm = 44.1050, GNorm = 3.9241, lr_0 = 2.4709e-04
Loss = 8.3904e-01, PNorm = 44.1066, GNorm = 18.9413, lr_0 = 2.4596e-04
Validation rmse = 0.689316
Epoch 18
Loss = 5.2594e-01, PNorm = 44.1194, GNorm = 5.2622, lr_0 = 2.3498e-04
Validation rmse = 0.686057
Epoch 19
Loss = 5.2966e-01, PNorm = 44.1331, GNorm = 3.1605, lr_0 = 2.2449e-04
Loss = 5.4199e-01, PNorm = 44.1457, GNorm = 10.9805, lr_0 = 2.1446e-04
Validation rmse = 0.690382
Epoch 20
Loss = 5.6701e-01, PNorm = 44.1570, GNorm = 10.8046, lr_0 = 2.0395e-04
Loss = 5.0955e-01, PNorm = 44.1668, GNorm = 18.8840, lr_0 = 1.9484e-04
Validation rmse = 0.713652
Epoch 21
Loss = 4.9154e-01, PNorm = 44.1782, GNorm = 2.9846, lr_0 = 1.8529e-04
Loss = 4.6227e-01, PNorm = 44.1894, GNorm = 4.3667, lr_0 = 1.7702e-04
Validation rmse = 0.700998
Epoch 22
Loss = 4.2182e-01, PNorm = 44.1997, GNorm = 5.5752, lr_0 = 1.6911e-04
Loss = 5.3631e-01, PNorm = 44.2103, GNorm = 2.9849, lr_0 = 1.6156e-04
Validation rmse = 0.691713
Epoch 23
Loss = 4.6960e-01, PNorm = 44.2177, GNorm = 4.0930, lr_0 = 1.5364e-04
Loss = 4.8606e-01, PNorm = 44.2264, GNorm = 9.4252, lr_0 = 1.4678e-04
Validation rmse = 0.684159
Epoch 24
Loss = 3.9723e-01, PNorm = 44.2364, GNorm = 3.7259, lr_0 = 1.4022e-04
Validation rmse = 0.687748
Epoch 25
Loss = 2.3076e-01, PNorm = 44.2446, GNorm = 3.6285, lr_0 = 1.3335e-04
Loss = 4.7123e-01, PNorm = 44.2510, GNorm = 4.4406, lr_0 = 1.2740e-04
Validation rmse = 0.693146
Epoch 26
Loss = 4.3875e-01, PNorm = 44.2577, GNorm = 3.0463, lr_0 = 1.2115e-04
Loss = 4.1936e-01, PNorm = 44.2645, GNorm = 7.4498, lr_0 = 1.1574e-04
Validation rmse = 0.681751
Epoch 27
Loss = 4.4431e-01, PNorm = 44.2709, GNorm = 14.0365, lr_0 = 1.1057e-04
Loss = 4.3696e-01, PNorm = 44.2769, GNorm = 8.3393, lr_0 = 1.0564e-04
Validation rmse = 0.693597
Epoch 28
Loss = 3.5621e-01, PNorm = 44.2822, GNorm = 7.5153, lr_0 = 1.0046e-04
Loss = 4.4928e-01, PNorm = 44.2879, GNorm = 6.7602, lr_0 = 1.0000e-04
Validation rmse = 0.688691
Epoch 29
Loss = 4.0414e-01, PNorm = 44.2935, GNorm = 3.1573, lr_0 = 1.0000e-04
Loss = 4.3576e-01, PNorm = 44.2991, GNorm = 7.3029, lr_0 = 1.0000e-04
Validation rmse = 0.685453
Model 0 best validation rmse = 0.681751 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.634810
Ensemble test rmse = 0.634810
1-fold cross validation
	Seed 0 ==> test rmse = 0.634810
Overall test rmse = 0.634810 +/- 0.000000
Elapsed time = 0:01:33
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8934e+00, PNorm = 43.2599, GNorm = 4.2435, lr_0 = 3.6053e-04
Validation rmse = 1.284498
Epoch 1
Loss = 1.4592e+00, PNorm = 43.2601, GNorm = 1.2446, lr_0 = 6.2105e-04
Loss = 1.3870e+00, PNorm = 43.2657, GNorm = 1.2005, lr_0 = 8.5789e-04
Validation rmse = 1.213587
Epoch 2
Loss = 1.3196e+00, PNorm = 43.2811, GNorm = 1.4020, lr_0 = 9.7859e-04
Loss = 1.2543e+00, PNorm = 43.3094, GNorm = 0.9791, lr_0 = 9.3714e-04
Validation rmse = 1.023615
Epoch 3
Loss = 1.1920e+00, PNorm = 43.3478, GNorm = 4.9836, lr_0 = 8.9357e-04
Loss = 1.1199e+00, PNorm = 43.3894, GNorm = 1.3637, lr_0 = 8.5572e-04
Validation rmse = 0.933027
Epoch 4
Loss = 1.0059e+00, PNorm = 43.4437, GNorm = 2.4853, lr_0 = 8.1593e-04
Loss = 1.0044e+00, PNorm = 43.4823, GNorm = 4.3753, lr_0 = 7.8137e-04
Validation rmse = 0.845163
Epoch 5
Loss = 9.5394e-01, PNorm = 43.5168, GNorm = 4.5857, lr_0 = 7.4504e-04
Loss = 9.5102e-01, PNorm = 43.5506, GNorm = 7.8431, lr_0 = 7.1348e-04
Validation rmse = 0.836012
Epoch 6
Loss = 8.8906e-01, PNorm = 43.5833, GNorm = 5.7572, lr_0 = 6.8326e-04
Loss = 8.6729e-01, PNorm = 43.6179, GNorm = 7.8478, lr_0 = 6.5432e-04
Validation rmse = 0.827626
Epoch 7
Loss = 7.7620e-01, PNorm = 43.6528, GNorm = 4.4273, lr_0 = 6.2390e-04
Loss = 7.8117e-01, PNorm = 43.6845, GNorm = 3.7826, lr_0 = 5.9747e-04
Validation rmse = 0.754582
Epoch 8
Loss = 7.3694e-01, PNorm = 43.7157, GNorm = 4.0721, lr_0 = 5.6969e-04
Loss = 7.4518e-01, PNorm = 43.7347, GNorm = 5.7272, lr_0 = 5.4556e-04
Validation rmse = 0.803513
Epoch 9
Loss = 7.5012e-01, PNorm = 43.7710, GNorm = 6.0911, lr_0 = 5.2019e-04
Loss = 7.1065e-01, PNorm = 43.7945, GNorm = 6.2312, lr_0 = 4.9816e-04
Validation rmse = 0.758633
Epoch 10
Loss = 7.0375e-01, PNorm = 43.8136, GNorm = 12.6262, lr_0 = 4.7500e-04
Loss = 6.8149e-01, PNorm = 43.8355, GNorm = 3.3022, lr_0 = 4.5488e-04
Loss = 4.3092e-01, PNorm = 43.8378, GNorm = 4.4842, lr_0 = 4.5291e-04
Validation rmse = 0.740387
Epoch 11
Loss = 6.5888e-01, PNorm = 43.8593, GNorm = 9.2137, lr_0 = 4.3373e-04
Loss = 7.1752e-01, PNorm = 43.8704, GNorm = 3.0762, lr_0 = 4.1536e-04
Validation rmse = 0.736837
Epoch 12
Loss = 6.0232e-01, PNorm = 43.8896, GNorm = 3.7483, lr_0 = 3.9776e-04
Validation rmse = 0.728651
Epoch 13
Loss = 5.7290e-01, PNorm = 43.9114, GNorm = 9.2185, lr_0 = 3.7927e-04
Loss = 6.0774e-01, PNorm = 43.9302, GNorm = 10.6374, lr_0 = 3.6320e-04
Validation rmse = 0.775777
Epoch 14
Loss = 7.8906e-01, PNorm = 43.9464, GNorm = 9.4886, lr_0 = 3.4632e-04
Loss = 5.7045e-01, PNorm = 43.9624, GNorm = 2.5494, lr_0 = 3.3165e-04
Validation rmse = 0.786217
Epoch 15
Loss = 6.4803e-01, PNorm = 43.9790, GNorm = 5.1186, lr_0 = 3.1623e-04
Loss = 6.3246e-01, PNorm = 43.9924, GNorm = 4.0929, lr_0 = 3.0283e-04
Validation rmse = 0.735726
Epoch 16
Loss = 5.9578e-01, PNorm = 44.0060, GNorm = 12.1273, lr_0 = 2.8875e-04
Loss = 5.7351e-01, PNorm = 44.0195, GNorm = 3.1467, lr_0 = 2.7652e-04
Validation rmse = 0.757069
Epoch 17
Loss = 5.4871e-01, PNorm = 44.0316, GNorm = 2.4748, lr_0 = 2.6481e-04
Loss = 6.0110e-01, PNorm = 44.0427, GNorm = 3.4163, lr_0 = 2.5359e-04
Validation rmse = 0.711029
Epoch 18
Loss = 5.4973e-01, PNorm = 44.0555, GNorm = 3.9866, lr_0 = 2.4180e-04
Loss = 5.6742e-01, PNorm = 44.0681, GNorm = 2.6574, lr_0 = 2.3156e-04
Validation rmse = 0.729112
Epoch 19
Loss = 5.5116e-01, PNorm = 44.0798, GNorm = 7.4699, lr_0 = 2.2079e-04
Loss = 4.9083e-01, PNorm = 44.0902, GNorm = 3.7817, lr_0 = 2.1144e-04
Validation rmse = 0.691890
Epoch 20
Loss = 4.8303e-01, PNorm = 44.1006, GNorm = 3.5377, lr_0 = 2.0161e-04
Loss = 5.2682e-01, PNorm = 44.1100, GNorm = 3.3555, lr_0 = 1.9307e-04
Validation rmse = 0.684454
Epoch 21
Loss = 4.7732e-01, PNorm = 44.1186, GNorm = 6.2588, lr_0 = 1.8409e-04
Loss = 5.1746e-01, PNorm = 44.1273, GNorm = 3.9436, lr_0 = 1.7630e-04
Validation rmse = 0.685927
Epoch 22
Loss = 5.0609e-01, PNorm = 44.1384, GNorm = 9.1844, lr_0 = 1.6810e-04
Loss = 5.0612e-01, PNorm = 44.1464, GNorm = 14.1770, lr_0 = 1.6098e-04
Validation rmse = 0.678704
Epoch 23
Loss = 4.8903e-01, PNorm = 44.1549, GNorm = 8.0239, lr_0 = 1.5416e-04
Loss = 4.9654e-01, PNorm = 44.1608, GNorm = 6.5628, lr_0 = 1.4763e-04
Loss = 9.1663e-01, PNorm = 44.1612, GNorm = 26.4186, lr_0 = 1.4699e-04
Validation rmse = 0.688933
Epoch 24
Loss = 5.5500e-01, PNorm = 44.1647, GNorm = 5.5014, lr_0 = 1.4077e-04
Validation rmse = 0.682688
Epoch 25
Loss = 5.5777e-01, PNorm = 44.1721, GNorm = 2.3650, lr_0 = 1.3422e-04
Loss = 4.8692e-01, PNorm = 44.1801, GNorm = 6.0379, lr_0 = 1.2854e-04
Validation rmse = 0.694082
Epoch 26
Loss = 4.7050e-01, PNorm = 44.1860, GNorm = 4.8605, lr_0 = 1.2256e-04
Loss = 4.6070e-01, PNorm = 44.1903, GNorm = 12.3775, lr_0 = 1.1737e-04
Validation rmse = 0.677362
Epoch 27
Loss = 4.5185e-01, PNorm = 44.1963, GNorm = 3.5720, lr_0 = 1.1191e-04
Loss = 4.7001e-01, PNorm = 44.2015, GNorm = 4.1574, lr_0 = 1.0717e-04
Validation rmse = 0.683477
Epoch 28
Loss = 4.1161e-01, PNorm = 44.2070, GNorm = 7.5580, lr_0 = 1.0263e-04
Loss = 4.3540e-01, PNorm = 44.2123, GNorm = 10.9386, lr_0 = 1.0000e-04
Validation rmse = 0.681624
Epoch 29
Loss = 4.2718e-01, PNorm = 44.2166, GNorm = 3.6331, lr_0 = 1.0000e-04
Loss = 4.4691e-01, PNorm = 44.2216, GNorm = 4.7118, lr_0 = 1.0000e-04
Validation rmse = 0.678762
Model 0 best validation rmse = 0.677362 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.688417
Ensemble test rmse = 0.688417
1-fold cross validation
	Seed 0 ==> test rmse = 0.688417
Overall test rmse = 0.688417 +/- 0.000000
Elapsed time = 0:01:39
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,249 | train size = 999 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0138e+00, PNorm = 43.2622, GNorm = 1.5766, lr_0 = 3.6053e-04
Validation rmse = 1.296211
Epoch 1
Loss = 1.4522e+00, PNorm = 43.2630, GNorm = 1.7708, lr_0 = 6.2105e-04
Loss = 1.3686e+00, PNorm = 43.2726, GNorm = 0.7915, lr_0 = 8.5789e-04
Validation rmse = 1.290151
Epoch 2
Loss = 1.3295e+00, PNorm = 43.2955, GNorm = 0.8685, lr_0 = 9.8284e-04
Loss = 1.2412e+00, PNorm = 43.3284, GNorm = 1.0809, lr_0 = 9.4120e-04
Validation rmse = 1.183694
Epoch 3
Loss = 1.1522e+00, PNorm = 43.3648, GNorm = 2.9798, lr_0 = 9.0134e-04
Loss = 1.1547e+00, PNorm = 43.4069, GNorm = 1.6210, lr_0 = 8.6316e-04
Validation rmse = 1.115505
Epoch 4
Loss = 1.1319e+00, PNorm = 43.4554, GNorm = 4.3348, lr_0 = 8.2660e-04
Loss = 9.4642e-01, PNorm = 43.5094, GNorm = 2.3751, lr_0 = 7.9158e-04
Validation rmse = 0.952165
Epoch 5
Loss = 9.4389e-01, PNorm = 43.5534, GNorm = 5.5060, lr_0 = 7.5805e-04
Loss = 8.9976e-01, PNorm = 43.5906, GNorm = 2.3025, lr_0 = 7.2594e-04
Validation rmse = 0.873979
Epoch 6
Loss = 7.1018e-01, PNorm = 43.6232, GNorm = 1.8226, lr_0 = 6.9519e-04
Loss = 8.2896e-01, PNorm = 43.6608, GNorm = 2.2032, lr_0 = 6.6575e-04
Validation rmse = 0.957613
Epoch 7
Loss = 7.3686e-01, PNorm = 43.6876, GNorm = 5.5057, lr_0 = 6.3755e-04
Loss = 8.2139e-01, PNorm = 43.7128, GNorm = 6.6204, lr_0 = 6.1054e-04
Validation rmse = 0.860019
Epoch 8
Loss = 6.4908e-01, PNorm = 43.7396, GNorm = 2.5017, lr_0 = 5.8468e-04
Loss = 7.6932e-01, PNorm = 43.7733, GNorm = 15.7368, lr_0 = 5.5991e-04
Validation rmse = 0.923972
Epoch 9
Loss = 8.0430e-01, PNorm = 43.7925, GNorm = 5.4327, lr_0 = 5.3620e-04
Loss = 7.5442e-01, PNorm = 43.8128, GNorm = 7.1957, lr_0 = 5.1348e-04
Validation rmse = 0.839472
Epoch 10
Loss = 4.6463e-01, PNorm = 43.8401, GNorm = 3.3643, lr_0 = 4.9173e-04
Loss = 6.4664e-01, PNorm = 43.8678, GNorm = 4.0494, lr_0 = 4.7090e-04
Validation rmse = 0.864948
Epoch 11
Loss = 6.2360e-01, PNorm = 43.8826, GNorm = 2.5801, lr_0 = 4.5096e-04
Loss = 6.1085e-01, PNorm = 43.9020, GNorm = 4.1861, lr_0 = 4.3186e-04
Validation rmse = 0.865155
Epoch 12
Loss = 5.2614e-01, PNorm = 43.9239, GNorm = 2.5329, lr_0 = 4.1356e-04
Loss = 6.0680e-01, PNorm = 43.9471, GNorm = 9.4127, lr_0 = 3.9604e-04
Validation rmse = 0.833906
Epoch 13
Loss = 5.3312e-01, PNorm = 43.9629, GNorm = 6.8701, lr_0 = 3.7927e-04
Loss = 5.5615e-01, PNorm = 43.9772, GNorm = 11.9731, lr_0 = 3.6320e-04
Validation rmse = 0.856617
Epoch 14
Loss = 6.4414e-01, PNorm = 43.9948, GNorm = 5.3620, lr_0 = 3.4782e-04
Loss = 6.0060e-01, PNorm = 44.0131, GNorm = 4.9198, lr_0 = 3.3309e-04
Validation rmse = 0.863744
Epoch 15
Loss = 4.9893e-01, PNorm = 44.0300, GNorm = 3.4560, lr_0 = 3.1898e-04
Loss = 5.2867e-01, PNorm = 44.0455, GNorm = 6.0660, lr_0 = 3.0547e-04
Validation rmse = 0.849954
Epoch 16
Loss = 4.9377e-01, PNorm = 44.0587, GNorm = 2.7786, lr_0 = 2.9253e-04
Loss = 5.4951e-01, PNorm = 44.0715, GNorm = 11.8593, lr_0 = 2.8014e-04
Validation rmse = 0.851488
Epoch 17
Loss = 4.8251e-01, PNorm = 44.0855, GNorm = 9.2673, lr_0 = 2.6827e-04
Loss = 5.7267e-01, PNorm = 44.0980, GNorm = 7.1974, lr_0 = 2.5691e-04
Validation rmse = 0.835891
Epoch 18
Loss = 5.6327e-01, PNorm = 44.1123, GNorm = 8.3861, lr_0 = 2.4602e-04
Loss = 5.1512e-01, PNorm = 44.1279, GNorm = 8.0648, lr_0 = 2.3560e-04
Validation rmse = 0.830547
Epoch 19
Loss = 7.0736e-01, PNorm = 44.1382, GNorm = 3.3523, lr_0 = 2.2562e-04
Loss = 4.8304e-01, PNorm = 44.1494, GNorm = 8.9159, lr_0 = 2.1607e-04
Validation rmse = 0.835737
Epoch 20
Loss = 4.0665e-01, PNorm = 44.1617, GNorm = 3.2854, lr_0 = 2.0691e-04
Loss = 5.1876e-01, PNorm = 44.1728, GNorm = 4.2015, lr_0 = 1.9815e-04
Validation rmse = 0.828193
Epoch 21
Loss = 3.8309e-01, PNorm = 44.1828, GNorm = 7.8212, lr_0 = 1.8976e-04
Loss = 4.4398e-01, PNorm = 44.1926, GNorm = 13.0926, lr_0 = 1.8172e-04
Validation rmse = 0.849456
Epoch 22
Loss = 5.7756e-01, PNorm = 44.2005, GNorm = 4.6401, lr_0 = 1.7402e-04
Loss = 4.4822e-01, PNorm = 44.2093, GNorm = 4.6399, lr_0 = 1.6665e-04
Validation rmse = 0.833615
Epoch 23
Loss = 6.8105e-01, PNorm = 44.2175, GNorm = 3.4782, lr_0 = 1.5959e-04
Loss = 4.2104e-01, PNorm = 44.2258, GNorm = 9.8645, lr_0 = 1.5283e-04
Validation rmse = 0.852886
Epoch 24
Loss = 4.6705e-01, PNorm = 44.2340, GNorm = 5.4758, lr_0 = 1.4636e-04
Loss = 4.7497e-01, PNorm = 44.2401, GNorm = 10.8475, lr_0 = 1.4016e-04
Validation rmse = 0.831966
Epoch 25
Loss = 4.1771e-01, PNorm = 44.2472, GNorm = 6.2157, lr_0 = 1.3422e-04
Loss = 4.3940e-01, PNorm = 44.2545, GNorm = 15.7097, lr_0 = 1.2854e-04
Validation rmse = 0.832093
Epoch 26
Loss = 5.1471e-01, PNorm = 44.2615, GNorm = 10.8304, lr_0 = 1.2309e-04
Loss = 4.5804e-01, PNorm = 44.2687, GNorm = 4.6209, lr_0 = 1.1788e-04
Validation rmse = 0.843391
Epoch 27
Loss = 2.9680e-01, PNorm = 44.2743, GNorm = 3.1507, lr_0 = 1.1288e-04
Loss = 4.4610e-01, PNorm = 44.2803, GNorm = 5.6462, lr_0 = 1.0810e-04
Validation rmse = 0.849275
Epoch 28
Loss = 4.5693e-01, PNorm = 44.2846, GNorm = 4.0036, lr_0 = 1.0352e-04
Loss = 4.1676e-01, PNorm = 44.2896, GNorm = 8.1917, lr_0 = 1.0000e-04
Validation rmse = 0.839024
Epoch 29
Loss = 3.5785e-01, PNorm = 44.2956, GNorm = 3.3989, lr_0 = 1.0000e-04
Loss = 3.9714e-01, PNorm = 44.3018, GNorm = 8.0756, lr_0 = 1.0000e-04
Validation rmse = 0.846901
Model 0 best validation rmse = 0.828193 on epoch 20
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.735185
Ensemble test rmse = 0.735185
1-fold cross validation
	Seed 0 ==> test rmse = 0.735185
Overall test rmse = 0.735185 +/- 0.000000
Elapsed time = 0:01:40
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0108e+00, PNorm = 43.2615, GNorm = 1.7764, lr_0 = 3.4750e-04
Loss = 1.4443e+00, PNorm = 43.2627, GNorm = 1.5213, lr_0 = 5.7250e-04
Loss = 1.3635e+00, PNorm = 43.2630, GNorm = 1.4662, lr_0 = 5.9500e-04
Validation rmse = 1.433524
Epoch 1
Loss = 1.3820e+00, PNorm = 43.2708, GNorm = 1.8509, lr_0 = 8.2000e-04
Loss = 1.3551e+00, PNorm = 43.2852, GNorm = 0.8470, lr_0 = 9.9181e-04
Validation rmse = 1.334819
Epoch 2
Loss = 1.2535e+00, PNorm = 43.3086, GNorm = 0.9529, lr_0 = 9.5186e-04
Loss = 1.1891e+00, PNorm = 43.3452, GNorm = 1.3592, lr_0 = 9.1351e-04
Validation rmse = 1.195294
Epoch 3
Loss = 1.1580e+00, PNorm = 43.3887, GNorm = 1.8784, lr_0 = 8.7671e-04
Loss = 1.0308e+00, PNorm = 43.4424, GNorm = 1.7995, lr_0 = 8.4140e-04
Validation rmse = 0.950459
Epoch 4
Loss = 1.0075e+00, PNorm = 43.4840, GNorm = 5.3347, lr_0 = 8.0750e-04
Loss = 9.1061e-01, PNorm = 43.5268, GNorm = 3.9320, lr_0 = 7.7497e-04
Validation rmse = 0.906457
Epoch 5
Loss = 8.3113e-01, PNorm = 43.5710, GNorm = 9.2165, lr_0 = 7.4070e-04
Loss = 8.4670e-01, PNorm = 43.6076, GNorm = 6.3187, lr_0 = 7.1086e-04
Validation rmse = 0.918813
Epoch 6
Loss = 8.3324e-01, PNorm = 43.6407, GNorm = 5.1920, lr_0 = 6.8223e-04
Loss = 9.2883e-01, PNorm = 43.6662, GNorm = 4.2196, lr_0 = 6.5474e-04
Validation rmse = 1.031236
Epoch 7
Loss = 9.1708e-01, PNorm = 43.6944, GNorm = 2.2938, lr_0 = 6.2837e-04
Loss = 8.4016e-01, PNorm = 43.7244, GNorm = 1.7620, lr_0 = 6.0306e-04
Validation rmse = 0.902953
Epoch 8
Loss = 7.6460e-01, PNorm = 43.7586, GNorm = 6.7755, lr_0 = 5.7876e-04
Loss = 7.5930e-01, PNorm = 43.7872, GNorm = 2.4067, lr_0 = 5.5545e-04
Validation rmse = 0.839268
Epoch 9
Loss = 7.4240e-01, PNorm = 43.8087, GNorm = 4.7220, lr_0 = 5.3307e-04
Loss = 7.1793e-01, PNorm = 43.8301, GNorm = 8.4899, lr_0 = 5.1160e-04
Validation rmse = 0.838436
Epoch 10
Loss = 6.9399e-01, PNorm = 43.8524, GNorm = 2.8460, lr_0 = 4.8897e-04
Loss = 6.5124e-01, PNorm = 43.8708, GNorm = 3.6842, lr_0 = 4.6928e-04
Validation rmse = 0.852930
Epoch 11
Loss = 7.5135e-01, PNorm = 43.8878, GNorm = 4.2443, lr_0 = 4.5037e-04
Loss = 6.2559e-01, PNorm = 43.9122, GNorm = 6.7646, lr_0 = 4.3223e-04
Validation rmse = 0.804190
Epoch 12
Loss = 6.0293e-01, PNorm = 43.9312, GNorm = 4.6603, lr_0 = 4.1482e-04
Loss = 6.2533e-01, PNorm = 43.9531, GNorm = 3.3574, lr_0 = 3.9811e-04
Loss = 6.8067e-01, PNorm = 43.9652, GNorm = 2.2556, lr_0 = 3.8207e-04
Validation rmse = 0.827821
Epoch 13
Loss = 6.2928e-01, PNorm = 43.9834, GNorm = 6.1021, lr_0 = 3.6668e-04
Loss = 6.0285e-01, PNorm = 43.9989, GNorm = 3.0985, lr_0 = 3.5191e-04
Loss = 5.1148e-01, PNorm = 44.0007, GNorm = 5.3352, lr_0 = 3.5046e-04
Validation rmse = 0.834999
Epoch 14
Loss = 5.8534e-01, PNorm = 44.0208, GNorm = 11.1040, lr_0 = 3.3635e-04
Loss = 6.4562e-01, PNorm = 44.0350, GNorm = 13.3219, lr_0 = 3.2280e-04
Validation rmse = 0.807215
Epoch 15
Loss = 6.3246e-01, PNorm = 44.0489, GNorm = 7.7048, lr_0 = 3.0979e-04
Loss = 6.2994e-01, PNorm = 44.0649, GNorm = 7.9200, lr_0 = 2.9731e-04
Validation rmse = 0.815304
Epoch 16
Loss = 5.5329e-01, PNorm = 44.0797, GNorm = 4.8033, lr_0 = 2.8534e-04
Loss = 5.7172e-01, PNorm = 44.0952, GNorm = 4.1204, lr_0 = 2.7384e-04
Validation rmse = 0.804017
Epoch 17
Loss = 5.2565e-01, PNorm = 44.1055, GNorm = 4.2937, lr_0 = 2.6281e-04
Loss = 5.6809e-01, PNorm = 44.1186, GNorm = 7.5097, lr_0 = 2.5222e-04
Validation rmse = 0.794670
Epoch 18
Loss = 5.2032e-01, PNorm = 44.1318, GNorm = 4.4081, lr_0 = 2.4206e-04
Loss = 5.1508e-01, PNorm = 44.1445, GNorm = 5.8492, lr_0 = 2.3231e-04
Validation rmse = 0.781409
Epoch 19
Loss = 5.3560e-01, PNorm = 44.1566, GNorm = 3.0653, lr_0 = 2.2204e-04
Loss = 5.3739e-01, PNorm = 44.1675, GNorm = 3.4556, lr_0 = 2.1309e-04
Validation rmse = 0.788879
Epoch 20
Loss = 4.7392e-01, PNorm = 44.1773, GNorm = 7.1133, lr_0 = 2.0451e-04
Loss = 4.7863e-01, PNorm = 44.1885, GNorm = 13.9645, lr_0 = 1.9627e-04
Validation rmse = 0.785984
Epoch 21
Loss = 5.1416e-01, PNorm = 44.1983, GNorm = 6.2477, lr_0 = 1.8836e-04
Loss = 4.8549e-01, PNorm = 44.2084, GNorm = 4.8661, lr_0 = 1.8078e-04
Validation rmse = 0.771824
Epoch 22
Loss = 4.2534e-01, PNorm = 44.2171, GNorm = 8.8468, lr_0 = 1.7349e-04
Loss = 5.2010e-01, PNorm = 44.2255, GNorm = 2.5652, lr_0 = 1.6651e-04
Validation rmse = 0.781883
Epoch 23
Loss = 3.5499e-01, PNorm = 44.2337, GNorm = 2.6382, lr_0 = 1.5914e-04
Loss = 5.5969e-01, PNorm = 44.2407, GNorm = 12.5723, lr_0 = 1.5273e-04
Validation rmse = 0.778432
Epoch 24
Loss = 4.8625e-01, PNorm = 44.2493, GNorm = 4.1904, lr_0 = 1.4658e-04
Loss = 4.7063e-01, PNorm = 44.2573, GNorm = 4.3864, lr_0 = 1.4067e-04
Validation rmse = 0.773565
Epoch 25
Loss = 4.0328e-01, PNorm = 44.2650, GNorm = 3.0827, lr_0 = 1.3501e-04
Loss = 4.5940e-01, PNorm = 44.2722, GNorm = 4.3953, lr_0 = 1.2957e-04
Loss = 4.8196e-01, PNorm = 44.2794, GNorm = 3.3561, lr_0 = 1.2435e-04
Validation rmse = 0.770612
Epoch 26
Loss = 4.9515e-01, PNorm = 44.2852, GNorm = 4.0868, lr_0 = 1.1934e-04
Loss = 4.1297e-01, PNorm = 44.2906, GNorm = 3.5746, lr_0 = 1.1453e-04
Validation rmse = 0.782764
Epoch 27
Loss = 4.6780e-01, PNorm = 44.2967, GNorm = 3.8832, lr_0 = 1.0992e-04
Loss = 4.1959e-01, PNorm = 44.3024, GNorm = 2.9657, lr_0 = 1.0549e-04
Validation rmse = 0.776079
Epoch 28
Loss = 3.8868e-01, PNorm = 44.3094, GNorm = 3.1912, lr_0 = 1.0083e-04
Loss = 4.9839e-01, PNorm = 44.3149, GNorm = 4.8970, lr_0 = 1.0000e-04
Validation rmse = 0.779536
Epoch 29
Loss = 4.6862e-01, PNorm = 44.3196, GNorm = 2.3813, lr_0 = 1.0000e-04
Loss = 4.3955e-01, PNorm = 44.3252, GNorm = 19.4660, lr_0 = 1.0000e-04
Validation rmse = 0.766429
Model 0 best validation rmse = 0.766429 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.704261
Ensemble test rmse = 0.704261
1-fold cross validation
	Seed 0 ==> test rmse = 0.704261
Overall test rmse = 0.704261 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,349 | train size = 1,079 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7880e+00, PNorm = 43.2598, GNorm = 2.1248, lr_0 = 3.3571e-04
Loss = 1.4462e+00, PNorm = 43.2585, GNorm = 1.2508, lr_0 = 5.5000e-04
Validation rmse = 1.433008
Epoch 1
Loss = 1.3943e+00, PNorm = 43.2658, GNorm = 1.3414, lr_0 = 7.8571e-04
Loss = 1.3078e+00, PNorm = 43.2836, GNorm = 0.8287, lr_0 = 1.0000e-03
Validation rmse = 1.287295
Epoch 2
Loss = 1.1760e+00, PNorm = 43.3131, GNorm = 1.0718, lr_0 = 9.6160e-04
Loss = 1.1814e+00, PNorm = 43.3537, GNorm = 1.2792, lr_0 = 9.2467e-04
Validation rmse = 1.082370
Epoch 3
Loss = 1.0653e+00, PNorm = 43.4120, GNorm = 1.3633, lr_0 = 8.8568e-04
Loss = 1.0464e+00, PNorm = 43.4608, GNorm = 6.0248, lr_0 = 8.5167e-04
Validation rmse = 0.907592
Epoch 4
Loss = 8.7029e-01, PNorm = 43.5110, GNorm = 4.5113, lr_0 = 8.1896e-04
Loss = 9.6421e-01, PNorm = 43.5466, GNorm = 5.3315, lr_0 = 7.8751e-04
Validation rmse = 0.892914
Epoch 5
Loss = 7.7552e-01, PNorm = 43.5841, GNorm = 3.6132, lr_0 = 7.5431e-04
Loss = 8.5754e-01, PNorm = 43.6190, GNorm = 5.3371, lr_0 = 7.2534e-04
Validation rmse = 0.860431
Epoch 6
Loss = 8.2874e-01, PNorm = 43.6510, GNorm = 5.9634, lr_0 = 6.9749e-04
Loss = 8.2587e-01, PNorm = 43.6762, GNorm = 1.8082, lr_0 = 6.7070e-04
Loss = 8.3679e-01, PNorm = 43.7097, GNorm = 5.1896, lr_0 = 6.4495e-04
Validation rmse = 0.845843
Epoch 7
Loss = 7.5883e-01, PNorm = 43.7405, GNorm = 12.6352, lr_0 = 6.2018e-04
Loss = 7.4139e-01, PNorm = 43.7712, GNorm = 3.8206, lr_0 = 5.9636e-04
Validation rmse = 0.806030
Epoch 8
Loss = 7.1911e-01, PNorm = 43.8027, GNorm = 1.6500, lr_0 = 5.7122e-04
Loss = 7.2067e-01, PNorm = 43.8230, GNorm = 14.0383, lr_0 = 5.4928e-04
Validation rmse = 0.807426
Epoch 9
Loss = 8.6227e-01, PNorm = 43.8446, GNorm = 14.4962, lr_0 = 5.2819e-04
Loss = 7.4879e-01, PNorm = 43.8658, GNorm = 5.6146, lr_0 = 5.0790e-04
Validation rmse = 0.796495
Epoch 10
Loss = 7.0543e-01, PNorm = 43.8882, GNorm = 2.3761, lr_0 = 4.8649e-04
Loss = 6.5929e-01, PNorm = 43.9147, GNorm = 2.6677, lr_0 = 4.6781e-04
Validation rmse = 0.809607
Epoch 11
Loss = 5.8714e-01, PNorm = 43.9352, GNorm = 5.3988, lr_0 = 4.4984e-04
Loss = 6.8995e-01, PNorm = 43.9500, GNorm = 2.7777, lr_0 = 4.3257e-04
Validation rmse = 0.797948
Epoch 12
Loss = 6.2439e-01, PNorm = 43.9706, GNorm = 6.1533, lr_0 = 4.1433e-04
Loss = 5.9612e-01, PNorm = 43.9917, GNorm = 3.9071, lr_0 = 3.9842e-04
Loss = 6.5810e-01, PNorm = 44.0104, GNorm = 14.1300, lr_0 = 3.8312e-04
Validation rmse = 0.871149
Epoch 13
Loss = 6.2197e-01, PNorm = 44.0264, GNorm = 3.1002, lr_0 = 3.6841e-04
Loss = 6.0108e-01, PNorm = 44.0422, GNorm = 7.5228, lr_0 = 3.5426e-04
Validation rmse = 0.756036
Epoch 14
Loss = 5.5147e-01, PNorm = 44.0630, GNorm = 9.6025, lr_0 = 3.4065e-04
Loss = 6.3316e-01, PNorm = 44.0787, GNorm = 4.1467, lr_0 = 3.2757e-04
Validation rmse = 0.779146
Epoch 15
Loss = 5.5464e-01, PNorm = 44.0948, GNorm = 10.6441, lr_0 = 3.1376e-04
Loss = 6.8367e-01, PNorm = 44.1081, GNorm = 6.1388, lr_0 = 3.0171e-04
Validation rmse = 0.805273
Epoch 16
Loss = 6.5424e-01, PNorm = 44.1222, GNorm = 11.6836, lr_0 = 2.9012e-04
Loss = 5.4409e-01, PNorm = 44.1376, GNorm = 3.2983, lr_0 = 2.7898e-04
Validation rmse = 0.786506
Epoch 17
Loss = 5.1988e-01, PNorm = 44.1565, GNorm = 3.5520, lr_0 = 2.6722e-04
Loss = 5.2675e-01, PNorm = 44.1702, GNorm = 3.9906, lr_0 = 2.5696e-04
Validation rmse = 0.789451
Epoch 18
Loss = 4.8215e-01, PNorm = 44.1849, GNorm = 9.9316, lr_0 = 2.4709e-04
Loss = 5.0488e-01, PNorm = 44.1962, GNorm = 8.8756, lr_0 = 2.3760e-04
Loss = 5.6190e-01, PNorm = 44.2088, GNorm = 4.3265, lr_0 = 2.2848e-04
Validation rmse = 0.786401
Epoch 19
Loss = 4.9244e-01, PNorm = 44.2216, GNorm = 5.6864, lr_0 = 2.1970e-04
Loss = 4.6422e-01, PNorm = 44.2320, GNorm = 5.9833, lr_0 = 2.1127e-04
Validation rmse = 0.788749
Epoch 20
Loss = 4.4049e-01, PNorm = 44.2433, GNorm = 2.8019, lr_0 = 2.0236e-04
Loss = 5.1929e-01, PNorm = 44.2526, GNorm = 6.1904, lr_0 = 1.9459e-04
Validation rmse = 0.792956
Epoch 21
Loss = 4.9084e-01, PNorm = 44.2625, GNorm = 3.9603, lr_0 = 1.8712e-04
Loss = 4.7387e-01, PNorm = 44.2731, GNorm = 5.1553, lr_0 = 1.7993e-04
Validation rmse = 0.821494
Epoch 22
Loss = 5.1143e-01, PNorm = 44.2824, GNorm = 19.1147, lr_0 = 1.7234e-04
Loss = 4.8315e-01, PNorm = 44.2909, GNorm = 3.9606, lr_0 = 1.6572e-04
Validation rmse = 0.765472
Epoch 23
Loss = 5.2847e-01, PNorm = 44.3005, GNorm = 6.0909, lr_0 = 1.5936e-04
Loss = 3.9625e-01, PNorm = 44.3103, GNorm = 13.4374, lr_0 = 1.5324e-04
Validation rmse = 0.776511
Epoch 24
Loss = 4.2336e-01, PNorm = 44.3181, GNorm = 9.2985, lr_0 = 1.4678e-04
Loss = 4.8289e-01, PNorm = 44.3258, GNorm = 6.7889, lr_0 = 1.4114e-04
Validation rmse = 0.784246
Epoch 25
Loss = 3.4343e-01, PNorm = 44.3312, GNorm = 3.3081, lr_0 = 1.3572e-04
Loss = 4.3556e-01, PNorm = 44.3374, GNorm = 3.4304, lr_0 = 1.3051e-04
Loss = 4.4150e-01, PNorm = 44.3436, GNorm = 9.2006, lr_0 = 1.2550e-04
Validation rmse = 0.775337
Epoch 26
Loss = 4.1749e-01, PNorm = 44.3508, GNorm = 10.0041, lr_0 = 1.2068e-04
Loss = 4.6600e-01, PNorm = 44.3574, GNorm = 5.0718, lr_0 = 1.1604e-04
Validation rmse = 0.764409
Epoch 27
Loss = 4.4525e-01, PNorm = 44.3642, GNorm = 3.3716, lr_0 = 1.1115e-04
Loss = 4.3820e-01, PNorm = 44.3692, GNorm = 2.7749, lr_0 = 1.0688e-04
Validation rmse = 0.794529
Epoch 28
Loss = 4.2145e-01, PNorm = 44.3746, GNorm = 4.8782, lr_0 = 1.0278e-04
Loss = 4.1655e-01, PNorm = 44.3801, GNorm = 4.7764, lr_0 = 1.0000e-04
Validation rmse = 0.782247
Epoch 29
Loss = 4.4719e-01, PNorm = 44.3854, GNorm = 12.8215, lr_0 = 1.0000e-04
Loss = 4.2905e-01, PNorm = 44.3914, GNorm = 3.6213, lr_0 = 1.0000e-04
Validation rmse = 0.771532
Model 0 best validation rmse = 0.756036 on epoch 13
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.713570
Ensemble test rmse = 0.713570
1-fold cross validation
	Seed 0 ==> test rmse = 0.713570
Overall test rmse = 0.713570 +/- 0.000000
Elapsed time = 0:01:46
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0369e+00, PNorm = 43.2605, GNorm = 1.2721, lr_0 = 3.2500e-04
Loss = 1.4469e+00, PNorm = 43.2596, GNorm = 1.4201, lr_0 = 5.2955e-04
Validation rmse = 1.398802
Epoch 1
Loss = 1.4036e+00, PNorm = 43.2654, GNorm = 1.3685, lr_0 = 7.5455e-04
Loss = 1.3425e+00, PNorm = 43.2798, GNorm = 1.6652, lr_0 = 9.5909e-04
Validation rmse = 1.319069
Epoch 2
Loss = 1.2195e+00, PNorm = 43.3078, GNorm = 0.8524, lr_0 = 9.6692e-04
Loss = 1.2254e+00, PNorm = 43.3410, GNorm = 3.8454, lr_0 = 9.3144e-04
Validation rmse = 1.176534
Epoch 3
Loss = 1.1366e+00, PNorm = 43.3834, GNorm = 2.4254, lr_0 = 8.9727e-04
Loss = 1.0749e+00, PNorm = 43.4312, GNorm = 2.7381, lr_0 = 8.6435e-04
Validation rmse = 0.964619
Epoch 4
Loss = 1.0714e+00, PNorm = 43.4841, GNorm = 1.8811, lr_0 = 8.2953e-04
Loss = 9.5767e-01, PNorm = 43.5323, GNorm = 7.1178, lr_0 = 7.9909e-04
Loss = 8.8952e-01, PNorm = 43.5691, GNorm = 1.8535, lr_0 = 7.6977e-04
Validation rmse = 0.928400
Epoch 5
Loss = 8.4248e-01, PNorm = 43.6113, GNorm = 4.8440, lr_0 = 7.3877e-04
Loss = 8.8252e-01, PNorm = 43.6466, GNorm = 3.2345, lr_0 = 7.1166e-04
Validation rmse = 0.877120
Epoch 6
Loss = 8.3102e-01, PNorm = 43.6751, GNorm = 6.0561, lr_0 = 6.8555e-04
Loss = 7.7356e-01, PNorm = 43.6997, GNorm = 2.9727, lr_0 = 6.6040e-04
Validation rmse = 0.877793
Epoch 7
Loss = 7.4602e-01, PNorm = 43.7338, GNorm = 3.8726, lr_0 = 6.3379e-04
Loss = 7.3056e-01, PNorm = 43.7578, GNorm = 4.2730, lr_0 = 6.1054e-04
Validation rmse = 0.923340
Epoch 8
Loss = 7.4597e-01, PNorm = 43.7898, GNorm = 10.3836, lr_0 = 5.8814e-04
Loss = 7.5510e-01, PNorm = 43.8241, GNorm = 4.9096, lr_0 = 5.6656e-04
Loss = 7.4359e-01, PNorm = 43.8448, GNorm = 8.2945, lr_0 = 5.4577e-04
Validation rmse = 0.840859
Epoch 9
Loss = 6.9847e-01, PNorm = 43.8634, GNorm = 2.7489, lr_0 = 5.2379e-04
Loss = 7.2448e-01, PNorm = 43.8844, GNorm = 5.6985, lr_0 = 5.0457e-04
Validation rmse = 0.893005
Epoch 10
Loss = 6.8244e-01, PNorm = 43.9055, GNorm = 6.2043, lr_0 = 4.8424e-04
Loss = 6.5742e-01, PNorm = 43.9266, GNorm = 3.1941, lr_0 = 4.6648e-04
Validation rmse = 0.848730
Epoch 11
Loss = 6.0749e-01, PNorm = 43.9452, GNorm = 2.0250, lr_0 = 4.4936e-04
Loss = 6.4407e-01, PNorm = 43.9643, GNorm = 2.0804, lr_0 = 4.3288e-04
Validation rmse = 0.844872
Epoch 12
Loss = 7.5722e-01, PNorm = 43.9807, GNorm = 4.6897, lr_0 = 4.1544e-04
Loss = 6.0814e-01, PNorm = 44.0024, GNorm = 2.5369, lr_0 = 4.0020e-04
Loss = 6.1268e-01, PNorm = 44.0191, GNorm = 9.7006, lr_0 = 3.8551e-04
Loss = 4.9630e-01, PNorm = 44.0201, GNorm = 3.8295, lr_0 = 3.8407e-04
Validation rmse = 0.805720
Epoch 13
Loss = 5.9131e-01, PNorm = 44.0377, GNorm = 3.8888, lr_0 = 3.6998e-04
Loss = 5.3321e-01, PNorm = 44.0551, GNorm = 4.5694, lr_0 = 3.5641e-04
Validation rmse = 0.806825
Epoch 14
Loss = 5.6565e-01, PNorm = 44.0702, GNorm = 11.7666, lr_0 = 3.4333e-04
Loss = 5.6794e-01, PNorm = 44.0829, GNorm = 7.3454, lr_0 = 3.3074e-04
Validation rmse = 0.795751
Epoch 15
Loss = 6.1228e-01, PNorm = 44.0930, GNorm = 6.3319, lr_0 = 3.1741e-04
Loss = 5.8493e-01, PNorm = 44.1069, GNorm = 4.3203, lr_0 = 3.0577e-04
Validation rmse = 0.834043
Epoch 16
Loss = 5.7018e-01, PNorm = 44.1219, GNorm = 6.4243, lr_0 = 2.9455e-04
Loss = 5.1836e-01, PNorm = 44.1353, GNorm = 2.7150, lr_0 = 2.8374e-04
Loss = 6.2681e-01, PNorm = 44.1481, GNorm = 9.6440, lr_0 = 2.7333e-04
Loss = 8.3215e-01, PNorm = 44.1492, GNorm = 22.5095, lr_0 = 2.7231e-04
Validation rmse = 0.818778
Epoch 17
Loss = 5.3852e-01, PNorm = 44.1601, GNorm = 4.5285, lr_0 = 2.6232e-04
Loss = 5.9998e-01, PNorm = 44.1720, GNorm = 6.8954, lr_0 = 2.5270e-04
Validation rmse = 0.822790
Epoch 18
Loss = 5.0054e-01, PNorm = 44.1853, GNorm = 4.3469, lr_0 = 2.4252e-04
Loss = 4.6517e-01, PNorm = 44.1972, GNorm = 5.9766, lr_0 = 2.3362e-04
Validation rmse = 0.802678
Epoch 19
Loss = 4.8436e-01, PNorm = 44.2091, GNorm = 4.4779, lr_0 = 2.2505e-04
Loss = 5.1373e-01, PNorm = 44.2194, GNorm = 6.7707, lr_0 = 2.1679e-04
Validation rmse = 0.796978
Epoch 20
Loss = 5.6131e-01, PNorm = 44.2301, GNorm = 7.7285, lr_0 = 2.0806e-04
Loss = 4.6021e-01, PNorm = 44.2382, GNorm = 4.5483, lr_0 = 2.0042e-04
Validation rmse = 0.808128
Epoch 21
Loss = 3.4219e-01, PNorm = 44.2479, GNorm = 9.4317, lr_0 = 1.9235e-04
Loss = 5.1755e-01, PNorm = 44.2576, GNorm = 5.0480, lr_0 = 1.8529e-04
Loss = 4.9154e-01, PNorm = 44.2675, GNorm = 3.6723, lr_0 = 1.7849e-04
Validation rmse = 0.792214
Epoch 22
Loss = 4.8635e-01, PNorm = 44.2734, GNorm = 3.1941, lr_0 = 1.7195e-04
Loss = 4.6107e-01, PNorm = 44.2824, GNorm = 5.4578, lr_0 = 1.6564e-04
Validation rmse = 0.788111
Epoch 23
Loss = 4.1384e-01, PNorm = 44.2904, GNorm = 3.8069, lr_0 = 1.5896e-04
Loss = 4.4437e-01, PNorm = 44.3000, GNorm = 5.9894, lr_0 = 1.5313e-04
Validation rmse = 0.792200
Epoch 24
Loss = 3.5807e-01, PNorm = 44.3058, GNorm = 3.7248, lr_0 = 1.4751e-04
Loss = 4.3404e-01, PNorm = 44.3132, GNorm = 14.7547, lr_0 = 1.4210e-04
Validation rmse = 0.786959
Epoch 25
Loss = 7.9000e-01, PNorm = 44.3192, GNorm = 9.9768, lr_0 = 1.3638e-04
Loss = 4.5197e-01, PNorm = 44.3261, GNorm = 6.1448, lr_0 = 1.3137e-04
Loss = 4.3274e-01, PNorm = 44.3325, GNorm = 8.6437, lr_0 = 1.2655e-04
Validation rmse = 0.790991
Epoch 26
Loss = 4.1988e-01, PNorm = 44.3388, GNorm = 4.7483, lr_0 = 1.2146e-04
Loss = 4.6729e-01, PNorm = 44.3433, GNorm = 5.0801, lr_0 = 1.1700e-04
Validation rmse = 0.797838
Epoch 27
Loss = 3.5297e-01, PNorm = 44.3497, GNorm = 3.4921, lr_0 = 1.1271e-04
Loss = 4.6419e-01, PNorm = 44.3556, GNorm = 4.7159, lr_0 = 1.0857e-04
Validation rmse = 0.788479
Epoch 28
Loss = 4.2571e-01, PNorm = 44.3610, GNorm = 4.4191, lr_0 = 1.0420e-04
Loss = 3.9814e-01, PNorm = 44.3656, GNorm = 6.2389, lr_0 = 1.0037e-04
Validation rmse = 0.786695
Epoch 29
Loss = 5.5139e-01, PNorm = 44.3702, GNorm = 6.7930, lr_0 = 1.0000e-04
Loss = 4.4032e-01, PNorm = 44.3756, GNorm = 5.2765, lr_0 = 1.0000e-04
Loss = 3.8351e-01, PNorm = 44.3810, GNorm = 3.4591, lr_0 = 1.0000e-04
Validation rmse = 0.811821
Model 0 best validation rmse = 0.786695 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.688063
Ensemble test rmse = 0.688063
1-fold cross validation
	Seed 0 ==> test rmse = 0.688063
Overall test rmse = 0.688063 +/- 0.000000
Elapsed time = 0:01:50
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,449 | train size = 1,159 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7816e+00, PNorm = 43.2601, GNorm = 1.7372, lr_0 = 3.1522e-04
Loss = 1.4388e+00, PNorm = 43.2590, GNorm = 2.0754, lr_0 = 5.1087e-04
Validation rmse = 1.404206
Epoch 1
Loss = 1.3950e+00, PNorm = 43.2648, GNorm = 1.5212, lr_0 = 7.2609e-04
Loss = 1.3058e+00, PNorm = 43.2782, GNorm = 1.1303, lr_0 = 9.2174e-04
Validation rmse = 1.273516
Epoch 2
Loss = 1.1569e+00, PNorm = 43.3114, GNorm = 2.4487, lr_0 = 9.7528e-04
Loss = 1.1559e+00, PNorm = 43.3559, GNorm = 1.4772, lr_0 = 9.4103e-04
Validation rmse = 1.189330
Epoch 3
Loss = 1.0081e+00, PNorm = 43.4102, GNorm = 3.7634, lr_0 = 9.0474e-04
Loss = 1.0528e+00, PNorm = 43.4598, GNorm = 1.2164, lr_0 = 8.7296e-04
Loss = 9.5998e-01, PNorm = 43.5149, GNorm = 1.5111, lr_0 = 8.4230e-04
Validation rmse = 0.946639
Epoch 4
Loss = 8.7094e-01, PNorm = 43.5691, GNorm = 5.5225, lr_0 = 8.0981e-04
Loss = 9.0968e-01, PNorm = 43.6104, GNorm = 5.2970, lr_0 = 7.8137e-04
Validation rmse = 1.003710
Epoch 5
Loss = 9.4387e-01, PNorm = 43.6505, GNorm = 6.9562, lr_0 = 7.5124e-04
Loss = 8.7955e-01, PNorm = 43.6790, GNorm = 2.4259, lr_0 = 7.2485e-04
Validation rmse = 0.900208
Epoch 6
Loss = 7.1871e-01, PNorm = 43.7169, GNorm = 9.1648, lr_0 = 6.9939e-04
Loss = 7.7757e-01, PNorm = 43.7520, GNorm = 5.1459, lr_0 = 6.7483e-04
Loss = 8.0214e-01, PNorm = 43.7843, GNorm = 5.1226, lr_0 = 6.5113e-04
Validation rmse = 0.859453
Epoch 7
Loss = 7.5640e-01, PNorm = 43.8118, GNorm = 7.2863, lr_0 = 6.2601e-04
Loss = 7.5622e-01, PNorm = 43.8380, GNorm = 5.4367, lr_0 = 6.0403e-04
Validation rmse = 0.866433
Epoch 8
Loss = 7.2297e-01, PNorm = 43.8715, GNorm = 3.3345, lr_0 = 5.8073e-04
Loss = 6.8031e-01, PNorm = 43.9020, GNorm = 3.4746, lr_0 = 5.6033e-04
Validation rmse = 0.875228
Epoch 9
Loss = 6.4184e-01, PNorm = 43.9264, GNorm = 4.0884, lr_0 = 5.3872e-04
Loss = 6.3492e-01, PNorm = 43.9490, GNorm = 4.5209, lr_0 = 5.1980e-04
Loss = 6.7646e-01, PNorm = 43.9743, GNorm = 4.2641, lr_0 = 5.0155e-04
Validation rmse = 0.869391
Epoch 10
Loss = 6.1091e-01, PNorm = 43.9953, GNorm = 6.1066, lr_0 = 4.8220e-04
Loss = 6.5148e-01, PNorm = 44.0156, GNorm = 6.8059, lr_0 = 4.6527e-04
Validation rmse = 0.824763
Epoch 11
Loss = 6.2382e-01, PNorm = 44.0368, GNorm = 2.2055, lr_0 = 4.4732e-04
Loss = 6.3991e-01, PNorm = 44.0621, GNorm = 3.8863, lr_0 = 4.3161e-04
Validation rmse = 0.832700
Epoch 12
Loss = 6.0027e-01, PNorm = 44.0830, GNorm = 9.7653, lr_0 = 4.1645e-04
Loss = 5.8967e-01, PNorm = 44.1032, GNorm = 3.9158, lr_0 = 4.0183e-04
Loss = 5.9719e-01, PNorm = 44.1174, GNorm = 2.9082, lr_0 = 3.8771e-04
Validation rmse = 0.843354
Epoch 13
Loss = 5.4744e-01, PNorm = 44.1375, GNorm = 9.5746, lr_0 = 3.7276e-04
Loss = 6.1746e-01, PNorm = 44.1551, GNorm = 4.0820, lr_0 = 3.5967e-04
Validation rmse = 0.800299
Epoch 14
Loss = 4.8368e-01, PNorm = 44.1707, GNorm = 2.9185, lr_0 = 3.4580e-04
Loss = 5.5352e-01, PNorm = 44.1903, GNorm = 4.9385, lr_0 = 3.3365e-04
Validation rmse = 0.839481
Epoch 15
Loss = 5.2104e-01, PNorm = 44.2043, GNorm = 7.5294, lr_0 = 3.2078e-04
Loss = 5.8538e-01, PNorm = 44.2195, GNorm = 9.5052, lr_0 = 3.0952e-04
Loss = 5.2230e-01, PNorm = 44.2342, GNorm = 8.4191, lr_0 = 2.9865e-04
Loss = 5.5784e-01, PNorm = 44.2358, GNorm = 14.3794, lr_0 = 2.9758e-04
Validation rmse = 0.815409
Epoch 16
Loss = 5.0366e-01, PNorm = 44.2487, GNorm = 6.9064, lr_0 = 2.8713e-04
Loss = 5.5498e-01, PNorm = 44.2646, GNorm = 8.2901, lr_0 = 2.7704e-04
Validation rmse = 0.822035
Epoch 17
Loss = 5.5746e-01, PNorm = 44.2773, GNorm = 12.2852, lr_0 = 2.6731e-04
Loss = 5.3356e-01, PNorm = 44.2910, GNorm = 3.7874, lr_0 = 2.5792e-04
Validation rmse = 0.839032
Epoch 18
Loss = 5.5783e-01, PNorm = 44.3035, GNorm = 4.7258, lr_0 = 2.4798e-04
Loss = 5.1250e-01, PNorm = 44.3160, GNorm = 3.9398, lr_0 = 2.3927e-04
Loss = 4.7998e-01, PNorm = 44.3286, GNorm = 4.1890, lr_0 = 2.3086e-04
Loss = 5.5065e-01, PNorm = 44.3297, GNorm = 10.6782, lr_0 = 2.3004e-04
Validation rmse = 0.813856
Epoch 19
Loss = 4.3579e-01, PNorm = 44.3435, GNorm = 10.2651, lr_0 = 2.2196e-04
Loss = 5.1132e-01, PNorm = 44.3535, GNorm = 7.9283, lr_0 = 2.1416e-04
Validation rmse = 0.813174
Epoch 20
Loss = 4.0342e-01, PNorm = 44.3611, GNorm = 4.0825, lr_0 = 2.0590e-04
Loss = 4.8543e-01, PNorm = 44.3722, GNorm = 4.3681, lr_0 = 1.9867e-04
Validation rmse = 0.831772
Epoch 21
Loss = 4.6123e-01, PNorm = 44.3829, GNorm = 6.9325, lr_0 = 1.9101e-04
Loss = 4.7476e-01, PNorm = 44.3937, GNorm = 5.5610, lr_0 = 1.8430e-04
Validation rmse = 0.822528
Epoch 22
Loss = 4.6011e-01, PNorm = 44.4021, GNorm = 9.2225, lr_0 = 1.7719e-04
Loss = 4.3539e-01, PNorm = 44.4100, GNorm = 4.4674, lr_0 = 1.7097e-04
Loss = 4.8090e-01, PNorm = 44.4190, GNorm = 11.9599, lr_0 = 1.6496e-04
Validation rmse = 0.804788
Epoch 23
Loss = 4.5210e-01, PNorm = 44.4254, GNorm = 8.4839, lr_0 = 1.5917e-04
Loss = 4.6747e-01, PNorm = 44.4320, GNorm = 6.7658, lr_0 = 1.5358e-04
Validation rmse = 0.798616
Epoch 24
Loss = 4.2660e-01, PNorm = 44.4416, GNorm = 2.5147, lr_0 = 1.4766e-04
Loss = 4.5068e-01, PNorm = 44.4509, GNorm = 3.4943, lr_0 = 1.4247e-04
Validation rmse = 0.786915
Epoch 25
Loss = 1.8978e-01, PNorm = 44.4579, GNorm = 6.0617, lr_0 = 1.3698e-04
Loss = 4.9730e-01, PNorm = 44.4632, GNorm = 6.8396, lr_0 = 1.3217e-04
Loss = 4.5364e-01, PNorm = 44.4678, GNorm = 7.8550, lr_0 = 1.2752e-04
Validation rmse = 0.815839
Epoch 26
Loss = 4.8253e-01, PNorm = 44.4732, GNorm = 3.6587, lr_0 = 1.2261e-04
Loss = 3.7636e-01, PNorm = 44.4801, GNorm = 3.4390, lr_0 = 1.1830e-04
Validation rmse = 0.794066
Epoch 27
Loss = 3.9123e-01, PNorm = 44.4874, GNorm = 5.7693, lr_0 = 1.1374e-04
Loss = 4.4736e-01, PNorm = 44.4938, GNorm = 3.1953, lr_0 = 1.0974e-04
Validation rmse = 0.790343
Epoch 28
Loss = 3.1338e-01, PNorm = 44.4984, GNorm = 3.7286, lr_0 = 1.0589e-04
Loss = 3.8915e-01, PNorm = 44.5024, GNorm = 8.8184, lr_0 = 1.0217e-04
Loss = 4.2902e-01, PNorm = 44.5073, GNorm = 3.3287, lr_0 = 1.0000e-04
Validation rmse = 0.799601
Epoch 29
Loss = 4.2142e-01, PNorm = 44.5132, GNorm = 8.2912, lr_0 = 1.0000e-04
Loss = 3.7699e-01, PNorm = 44.5185, GNorm = 9.2076, lr_0 = 1.0000e-04
Validation rmse = 0.792712
Model 0 best validation rmse = 0.786915 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.669626
Ensemble test rmse = 0.669626
1-fold cross validation
	Seed 0 ==> test rmse = 0.669626
Overall test rmse = 0.669626 +/- 0.000000
Elapsed time = 1:21:50
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9426e+00, PNorm = 43.2610, GNorm = 3.6960, lr_0 = 3.1522e-04
Loss = 1.4147e+00, PNorm = 43.2614, GNorm = 1.7797, lr_0 = 5.1087e-04
Validation rmse = 1.435417
Epoch 1
Loss = 1.3776e+00, PNorm = 43.2677, GNorm = 1.0470, lr_0 = 7.2609e-04
Loss = 1.3514e+00, PNorm = 43.2781, GNorm = 0.7913, lr_0 = 9.2174e-04
Validation rmse = 1.326025
Epoch 2
Loss = 1.2951e+00, PNorm = 43.3021, GNorm = 0.9218, lr_0 = 9.7878e-04
Loss = 1.2138e+00, PNorm = 43.3390, GNorm = 1.4013, lr_0 = 9.4440e-04
Loss = 1.1789e+00, PNorm = 43.3754, GNorm = 1.4608, lr_0 = 9.1123e-04
Validation rmse = 1.266061
Epoch 3
Loss = 1.1056e+00, PNorm = 43.4205, GNorm = 1.2980, lr_0 = 8.7922e-04
Loss = 1.0854e+00, PNorm = 43.4698, GNorm = 1.4709, lr_0 = 8.4834e-04
Validation rmse = 1.019424
Epoch 4
Loss = 9.7855e-01, PNorm = 43.5139, GNorm = 4.0080, lr_0 = 8.1855e-04
Loss = 9.2530e-01, PNorm = 43.5611, GNorm = 2.9085, lr_0 = 7.8980e-04
Validation rmse = 0.958977
Epoch 5
Loss = 6.8746e-01, PNorm = 43.6049, GNorm = 4.7900, lr_0 = 7.6206e-04
Loss = 8.4009e-01, PNorm = 43.6439, GNorm = 4.7778, lr_0 = 7.3529e-04
Loss = 8.2075e-01, PNorm = 43.6815, GNorm = 4.1270, lr_0 = 7.0947e-04
Validation rmse = 0.904766
Epoch 6
Loss = 7.8088e-01, PNorm = 43.7130, GNorm = 4.5752, lr_0 = 6.8455e-04
Loss = 8.5919e-01, PNorm = 43.7419, GNorm = 9.4182, lr_0 = 6.6050e-04
Validation rmse = 0.984586
Epoch 7
Loss = 8.5440e-01, PNorm = 43.7687, GNorm = 9.0459, lr_0 = 6.3731e-04
Loss = 8.3157e-01, PNorm = 43.8029, GNorm = 2.4897, lr_0 = 6.1492e-04
Loss = 7.9303e-01, PNorm = 43.8370, GNorm = 2.2970, lr_0 = 5.9332e-04
Validation rmse = 0.889615
Epoch 8
Loss = 6.6267e-01, PNorm = 43.8653, GNorm = 2.7045, lr_0 = 5.7248e-04
Loss = 7.3252e-01, PNorm = 43.8908, GNorm = 1.8445, lr_0 = 5.5238e-04
Validation rmse = 0.864281
Epoch 9
Loss = 7.1553e-01, PNorm = 43.9155, GNorm = 10.7678, lr_0 = 5.3298e-04
Loss = 6.7564e-01, PNorm = 43.9402, GNorm = 11.1207, lr_0 = 5.1426e-04
Validation rmse = 0.856590
Epoch 10
Loss = 5.1744e-01, PNorm = 43.9613, GNorm = 2.3051, lr_0 = 4.9619e-04
Loss = 5.7134e-01, PNorm = 43.9897, GNorm = 2.6104, lr_0 = 4.7877e-04
Loss = 6.5817e-01, PNorm = 44.0109, GNorm = 2.9833, lr_0 = 4.6195e-04
Validation rmse = 0.895783
Epoch 11
Loss = 5.9179e-01, PNorm = 44.0288, GNorm = 4.2370, lr_0 = 4.4573e-04
Loss = 6.1882e-01, PNorm = 44.0460, GNorm = 15.9259, lr_0 = 4.3007e-04
Validation rmse = 0.851774
Epoch 12
Loss = 6.3882e-01, PNorm = 44.0676, GNorm = 8.8434, lr_0 = 4.1497e-04
Loss = 5.8148e-01, PNorm = 44.0865, GNorm = 7.7190, lr_0 = 4.0039e-04
Loss = 6.0932e-01, PNorm = 44.1061, GNorm = 5.1698, lr_0 = 3.8633e-04
Validation rmse = 0.849838
Epoch 13
Loss = 5.5610e-01, PNorm = 44.1266, GNorm = 8.0342, lr_0 = 3.7276e-04
Loss = 5.9192e-01, PNorm = 44.1458, GNorm = 5.7455, lr_0 = 3.5967e-04
Validation rmse = 0.856088
Epoch 14
Loss = 5.6228e-01, PNorm = 44.1625, GNorm = 3.5477, lr_0 = 3.4703e-04
Loss = 5.3012e-01, PNorm = 44.1783, GNorm = 2.8930, lr_0 = 3.3485e-04
Validation rmse = 0.823042
Epoch 15
Loss = 5.6016e-01, PNorm = 44.1953, GNorm = 7.7969, lr_0 = 3.2308e-04
Loss = 5.1406e-01, PNorm = 44.2111, GNorm = 3.7219, lr_0 = 3.1174e-04
Loss = 5.3647e-01, PNorm = 44.2257, GNorm = 3.9476, lr_0 = 3.0079e-04
Validation rmse = 0.832107
Epoch 16
Loss = 5.6699e-01, PNorm = 44.2397, GNorm = 8.6547, lr_0 = 2.9022e-04
Loss = 5.3044e-01, PNorm = 44.2500, GNorm = 3.3797, lr_0 = 2.8003e-04
Validation rmse = 0.836797
Epoch 17
Loss = 5.6543e-01, PNorm = 44.2642, GNorm = 8.2762, lr_0 = 2.7019e-04
Loss = 4.4635e-01, PNorm = 44.2803, GNorm = 4.1214, lr_0 = 2.6070e-04
Loss = 5.5934e-01, PNorm = 44.2909, GNorm = 12.5128, lr_0 = 2.5155e-04
Validation rmse = 0.835638
Epoch 18
Loss = 5.4685e-01, PNorm = 44.3016, GNorm = 13.4392, lr_0 = 2.4271e-04
Loss = 5.4842e-01, PNorm = 44.3131, GNorm = 8.6330, lr_0 = 2.3419e-04
Validation rmse = 0.841457
Epoch 19
Loss = 4.8108e-01, PNorm = 44.3230, GNorm = 2.9021, lr_0 = 2.2596e-04
Loss = 4.6955e-01, PNorm = 44.3368, GNorm = 12.2495, lr_0 = 2.1803e-04
Validation rmse = 0.826940
Epoch 20
Loss = 5.2989e-01, PNorm = 44.3447, GNorm = 6.7394, lr_0 = 2.1037e-04
Loss = 4.8781e-01, PNorm = 44.3547, GNorm = 3.1549, lr_0 = 2.0298e-04
Loss = 4.4507e-01, PNorm = 44.3640, GNorm = 4.1875, lr_0 = 1.9585e-04
Validation rmse = 0.824566
Epoch 21
Loss = 4.7195e-01, PNorm = 44.3723, GNorm = 4.0076, lr_0 = 1.8897e-04
Loss = 4.4482e-01, PNorm = 44.3808, GNorm = 4.1820, lr_0 = 1.8233e-04
Validation rmse = 0.823777
Epoch 22
Loss = 4.2382e-01, PNorm = 44.3896, GNorm = 10.8677, lr_0 = 1.7593e-04
Loss = 4.0767e-01, PNorm = 44.3989, GNorm = 11.8622, lr_0 = 1.6975e-04
Loss = 4.8337e-01, PNorm = 44.4055, GNorm = 5.0250, lr_0 = 1.6379e-04
Validation rmse = 0.820648
Epoch 23
Loss = 4.2029e-01, PNorm = 44.4140, GNorm = 13.3669, lr_0 = 1.5804e-04
Loss = 4.7060e-01, PNorm = 44.4197, GNorm = 6.0058, lr_0 = 1.5249e-04
Validation rmse = 0.827752
Epoch 24
Loss = 4.1497e-01, PNorm = 44.4261, GNorm = 8.5786, lr_0 = 1.4713e-04
Loss = 4.6102e-01, PNorm = 44.4347, GNorm = 12.0911, lr_0 = 1.4196e-04
Validation rmse = 0.824412
Epoch 25
Loss = 3.3288e-01, PNorm = 44.4407, GNorm = 3.3137, lr_0 = 1.3698e-04
Loss = 4.9224e-01, PNorm = 44.4445, GNorm = 6.2660, lr_0 = 1.3217e-04
Loss = 4.5506e-01, PNorm = 44.4515, GNorm = 7.4239, lr_0 = 1.2752e-04
Validation rmse = 0.834448
Epoch 26
Loss = 4.8663e-01, PNorm = 44.4576, GNorm = 4.9570, lr_0 = 1.2304e-04
Loss = 4.1403e-01, PNorm = 44.4644, GNorm = 6.7066, lr_0 = 1.1872e-04
Validation rmse = 0.819442
Epoch 27
Loss = 5.4479e-01, PNorm = 44.4680, GNorm = 4.2718, lr_0 = 1.1455e-04
Loss = 2.9903e-01, PNorm = 44.4734, GNorm = 4.9089, lr_0 = 1.1053e-04
Loss = 4.8283e-01, PNorm = 44.4791, GNorm = 4.9215, lr_0 = 1.0665e-04
Validation rmse = 0.816503
Epoch 28
Loss = 4.1916e-01, PNorm = 44.4830, GNorm = 4.3593, lr_0 = 1.0290e-04
Loss = 3.6819e-01, PNorm = 44.4880, GNorm = 8.7959, lr_0 = 1.0000e-04
Validation rmse = 0.814239
Epoch 29
Loss = 3.7723e-01, PNorm = 44.4920, GNorm = 15.5012, lr_0 = 1.0000e-04
Loss = 4.3525e-01, PNorm = 44.4959, GNorm = 3.5598, lr_0 = 1.0000e-04
Validation rmse = 0.815167
Model 0 best validation rmse = 0.814239 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.645879
Ensemble test rmse = 0.645879
1-fold cross validation
	Seed 0 ==> test rmse = 0.645879
Overall test rmse = 0.645879 +/- 0.000000
Elapsed time = 0:26:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9083e+00, PNorm = 43.2600, GNorm = 1.5451, lr_0 = 4.3000e-04
Validation rmse = 1.369945
Epoch 1
Loss = 1.4359e+00, PNorm = 43.2644, GNorm = 1.4772, lr_0 = 7.6000e-04
Loss = 1.4152e+00, PNorm = 43.2796, GNorm = 0.8518, lr_0 = 9.8910e-04
Validation rmse = 1.290842
Epoch 2
Loss = 1.3155e+00, PNorm = 43.3037, GNorm = 1.4012, lr_0 = 9.3633e-04
Validation rmse = 1.202598
Epoch 3
Loss = 1.3082e+00, PNorm = 43.3363, GNorm = 1.0761, lr_0 = 8.8638e-04
Loss = 1.1528e+00, PNorm = 43.3730, GNorm = 1.0367, lr_0 = 8.3909e-04
Validation rmse = 1.078739
Epoch 4
Loss = 1.0986e+00, PNorm = 43.4102, GNorm = 1.6018, lr_0 = 7.9433e-04
Validation rmse = 1.054488
Epoch 5
Loss = 1.2133e+00, PNorm = 43.4494, GNorm = 9.2207, lr_0 = 7.5195e-04
Loss = 1.0056e+00, PNorm = 43.4898, GNorm = 4.4772, lr_0 = 7.1184e-04
Validation rmse = 0.937357
Epoch 6
Loss = 9.9996e-01, PNorm = 43.5279, GNorm = 4.2762, lr_0 = 6.7386e-04
Loss = 9.3722e-01, PNorm = 43.5629, GNorm = 1.9819, lr_0 = 6.3791e-04
Validation rmse = 0.966099
Epoch 7
Loss = 8.9395e-01, PNorm = 43.6012, GNorm = 6.1168, lr_0 = 6.0388e-04
Validation rmse = 0.888075
Epoch 8
Loss = 7.5776e-01, PNorm = 43.6335, GNorm = 3.1121, lr_0 = 5.7167e-04
Loss = 7.5117e-01, PNorm = 43.6667, GNorm = 7.1144, lr_0 = 5.4117e-04
Validation rmse = 0.842003
Epoch 9
Loss = 7.7116e-01, PNorm = 43.6955, GNorm = 3.8389, lr_0 = 5.1230e-04
Validation rmse = 0.822488
Epoch 10
Loss = 6.9275e-01, PNorm = 43.7232, GNorm = 1.8885, lr_0 = 4.8497e-04
Loss = 6.6220e-01, PNorm = 43.7523, GNorm = 4.2989, lr_0 = 4.5910e-04
Validation rmse = 0.839168
Epoch 11
Loss = 6.5164e-01, PNorm = 43.7815, GNorm = 3.6363, lr_0 = 4.3461e-04
Loss = 6.6836e-01, PNorm = 43.7997, GNorm = 3.1131, lr_0 = 4.1142e-04
Validation rmse = 0.829046
Epoch 12
Loss = 6.5351e-01, PNorm = 43.8219, GNorm = 4.5378, lr_0 = 3.8947e-04
Validation rmse = 0.842835
Epoch 13
Loss = 5.7227e-01, PNorm = 43.8424, GNorm = 2.9052, lr_0 = 3.6869e-04
Loss = 5.7237e-01, PNorm = 43.8652, GNorm = 8.9093, lr_0 = 3.4903e-04
Validation rmse = 0.803995
Epoch 14
Loss = 6.1402e-01, PNorm = 43.8805, GNorm = 7.1807, lr_0 = 3.3041e-04
Validation rmse = 0.801350
Epoch 15
Loss = 3.9914e-01, PNorm = 43.8959, GNorm = 12.5140, lr_0 = 3.1278e-04
Loss = 6.1358e-01, PNorm = 43.9113, GNorm = 8.9315, lr_0 = 2.9609e-04
Validation rmse = 0.814838
Epoch 16
Loss = 5.4697e-01, PNorm = 43.9245, GNorm = 3.3169, lr_0 = 2.8030e-04
Loss = 6.0064e-01, PNorm = 43.9385, GNorm = 13.4595, lr_0 = 2.6534e-04
Validation rmse = 0.827197
Epoch 17
Loss = 5.4981e-01, PNorm = 43.9517, GNorm = 15.2950, lr_0 = 2.5119e-04
Validation rmse = 0.801827
Epoch 18
Loss = 6.4895e-01, PNorm = 43.9619, GNorm = 8.4887, lr_0 = 2.3779e-04
Loss = 5.5529e-01, PNorm = 43.9730, GNorm = 3.6031, lr_0 = 2.2510e-04
Validation rmse = 0.807659
Epoch 19
Loss = 4.9319e-01, PNorm = 43.9855, GNorm = 6.5133, lr_0 = 2.1309e-04
Validation rmse = 0.824664
Epoch 20
Loss = 3.2857e-01, PNorm = 43.9957, GNorm = 4.1434, lr_0 = 2.0173e-04
Loss = 4.6633e-01, PNorm = 44.0042, GNorm = 3.8354, lr_0 = 1.9096e-04
Validation rmse = 0.843927
Epoch 21
Loss = 4.8288e-01, PNorm = 44.0137, GNorm = 2.4592, lr_0 = 1.8078e-04
Loss = 4.8163e-01, PNorm = 44.0212, GNorm = 6.8314, lr_0 = 1.7113e-04
Validation rmse = 0.786158
Epoch 22
Loss = 4.4960e-01, PNorm = 44.0310, GNorm = 3.0954, lr_0 = 1.6200e-04
Validation rmse = 0.804651
Epoch 23
Loss = 2.9807e-01, PNorm = 44.0400, GNorm = 5.1895, lr_0 = 1.5336e-04
Loss = 4.7920e-01, PNorm = 44.0452, GNorm = 9.8014, lr_0 = 1.4518e-04
Validation rmse = 0.786963
Epoch 24
Loss = 4.2559e-01, PNorm = 44.0535, GNorm = 5.7993, lr_0 = 1.3743e-04
Validation rmse = 0.820206
Epoch 25
Loss = 4.9781e-01, PNorm = 44.0598, GNorm = 4.3279, lr_0 = 1.3010e-04
Loss = 3.9171e-01, PNorm = 44.0662, GNorm = 4.4266, lr_0 = 1.2316e-04
Validation rmse = 0.785692
Epoch 26
Loss = 4.5673e-01, PNorm = 44.0710, GNorm = 3.5610, lr_0 = 1.1659e-04
Loss = 3.9647e-01, PNorm = 44.0772, GNorm = 7.5962, lr_0 = 1.1037e-04
Validation rmse = 0.817745
Epoch 27
Loss = 4.6282e-01, PNorm = 44.0824, GNorm = 4.2687, lr_0 = 1.0448e-04
Validation rmse = 0.789445
Epoch 28
Loss = 3.2537e-01, PNorm = 44.0868, GNorm = 9.4904, lr_0 = 1.0000e-04
Loss = 4.1820e-01, PNorm = 44.0921, GNorm = 3.4211, lr_0 = 1.0000e-04
Validation rmse = 0.799352
Epoch 29
Loss = 3.8163e-01, PNorm = 44.0971, GNorm = 3.9130, lr_0 = 1.0000e-04
Validation rmse = 0.805109
Model 0 best validation rmse = 0.785692 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.627215
Ensemble test rmse = 0.627215
1-fold cross validation
	Seed 0 ==> test rmse = 0.627215
Overall test rmse = 0.627215 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,049 | train size = 839 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9366e+00, PNorm = 43.2575, GNorm = 1.7580, lr_0 = 4.0937e-04
Validation rmse = 1.263063
Epoch 1
Loss = 1.4436e+00, PNorm = 43.2572, GNorm = 1.6893, lr_0 = 7.1875e-04
Loss = 1.3882e+00, PNorm = 43.2678, GNorm = 1.1576, lr_0 = 1.0000e-03
Validation rmse = 1.165344
Epoch 2
Loss = 1.3081e+00, PNorm = 43.2923, GNorm = 1.1327, lr_0 = 9.4990e-04
Loss = 1.2283e+00, PNorm = 43.3244, GNorm = 2.0569, lr_0 = 9.0231e-04
Validation rmse = 1.043672
Epoch 3
Loss = 1.1699e+00, PNorm = 43.3630, GNorm = 1.2375, lr_0 = 8.5711e-04
Validation rmse = 0.927481
Epoch 4
Loss = 1.1251e+00, PNorm = 43.4046, GNorm = 4.8128, lr_0 = 8.1417e-04
Loss = 1.0528e+00, PNorm = 43.4433, GNorm = 5.1851, lr_0 = 7.7338e-04
Validation rmse = 0.895714
Epoch 5
Loss = 9.6087e-01, PNorm = 43.4885, GNorm = 3.1294, lr_0 = 7.3087e-04
Loss = 9.0616e-01, PNorm = 43.5336, GNorm = 3.4513, lr_0 = 6.9425e-04
Validation rmse = 0.945491
Epoch 6
Loss = 8.5705e-01, PNorm = 43.5721, GNorm = 6.7113, lr_0 = 6.5947e-04
Validation rmse = 0.810735
Epoch 7
Loss = 8.1720e-01, PNorm = 43.6127, GNorm = 11.2223, lr_0 = 6.2643e-04
Loss = 7.8712e-01, PNorm = 43.6477, GNorm = 6.6228, lr_0 = 5.9505e-04
Validation rmse = 0.809082
Epoch 8
Loss = 7.3663e-01, PNorm = 43.6835, GNorm = 3.3440, lr_0 = 5.6524e-04
Loss = 7.3191e-01, PNorm = 43.7107, GNorm = 13.9766, lr_0 = 5.3692e-04
Validation rmse = 0.795448
Epoch 9
Loss = 6.7755e-01, PNorm = 43.7417, GNorm = 4.5721, lr_0 = 5.1002e-04
Validation rmse = 0.773511
Epoch 10
Loss = 6.6512e-01, PNorm = 43.7704, GNorm = 12.2541, lr_0 = 4.8199e-04
Loss = 6.5568e-01, PNorm = 43.7926, GNorm = 3.1803, lr_0 = 4.5784e-04
Validation rmse = 0.780104
Epoch 11
Loss = 6.0003e-01, PNorm = 43.8158, GNorm = 5.7128, lr_0 = 4.3490e-04
Loss = 6.2044e-01, PNorm = 43.8369, GNorm = 3.9342, lr_0 = 4.1312e-04
Validation rmse = 0.789317
Epoch 12
Loss = 6.0585e-01, PNorm = 43.8586, GNorm = 11.9617, lr_0 = 3.9242e-04
Validation rmse = 0.805615
Epoch 13
Loss = 5.4928e-01, PNorm = 43.8748, GNorm = 8.8365, lr_0 = 3.7276e-04
Loss = 6.3319e-01, PNorm = 43.8954, GNorm = 6.1524, lr_0 = 3.5408e-04
Validation rmse = 0.774958
Epoch 14
Loss = 5.5817e-01, PNorm = 43.9160, GNorm = 14.1399, lr_0 = 3.3462e-04
Loss = 5.6346e-01, PNorm = 43.9286, GNorm = 7.0351, lr_0 = 3.1786e-04
Validation rmse = 0.768834
Epoch 15
Loss = 4.9755e-01, PNorm = 43.9441, GNorm = 3.7936, lr_0 = 3.0193e-04
Validation rmse = 0.754884
Epoch 16
Loss = 5.6798e-01, PNorm = 43.9574, GNorm = 7.6318, lr_0 = 2.8681e-04
Loss = 4.8563e-01, PNorm = 43.9718, GNorm = 7.4652, lr_0 = 2.7244e-04
Validation rmse = 0.748994
Epoch 17
Loss = 5.3520e-01, PNorm = 43.9828, GNorm = 3.6529, lr_0 = 2.5879e-04
Loss = 4.7100e-01, PNorm = 43.9937, GNorm = 5.8609, lr_0 = 2.4582e-04
Validation rmse = 0.753706
Epoch 18
Loss = 4.9487e-01, PNorm = 44.0038, GNorm = 10.7222, lr_0 = 2.3351e-04
Validation rmse = 0.738630
Epoch 19
Loss = 3.7824e-01, PNorm = 44.0164, GNorm = 8.5458, lr_0 = 2.2067e-04
Loss = 4.5901e-01, PNorm = 44.0275, GNorm = 7.2284, lr_0 = 2.0962e-04
Validation rmse = 0.750396
Epoch 20
Loss = 4.7162e-01, PNorm = 44.0348, GNorm = 5.7895, lr_0 = 1.9912e-04
Loss = 4.0859e-01, PNorm = 44.0453, GNorm = 5.4771, lr_0 = 1.8914e-04
Validation rmse = 0.728878
Epoch 21
Loss = 4.2811e-01, PNorm = 44.0532, GNorm = 12.5314, lr_0 = 1.7967e-04
Validation rmse = 0.733747
Epoch 22
Loss = 4.9831e-01, PNorm = 44.0610, GNorm = 5.7207, lr_0 = 1.7066e-04
Loss = 4.9572e-01, PNorm = 44.0674, GNorm = 3.3844, lr_0 = 1.6211e-04
Validation rmse = 0.735967
Epoch 23
Loss = 3.6069e-01, PNorm = 44.0751, GNorm = 2.7184, lr_0 = 1.5320e-04
Loss = 4.3236e-01, PNorm = 44.0829, GNorm = 3.3784, lr_0 = 1.4553e-04
Validation rmse = 0.735257
Epoch 24
Loss = 4.2483e-01, PNorm = 44.0900, GNorm = 6.0761, lr_0 = 1.3824e-04
Validation rmse = 0.727008
Epoch 25
Loss = 5.1396e-01, PNorm = 44.0952, GNorm = 13.1807, lr_0 = 1.3131e-04
Loss = 3.7952e-01, PNorm = 44.1000, GNorm = 10.4943, lr_0 = 1.2473e-04
Validation rmse = 0.727638
Epoch 26
Loss = 2.9328e-01, PNorm = 44.1067, GNorm = 11.0915, lr_0 = 1.1848e-04
Loss = 4.3645e-01, PNorm = 44.1127, GNorm = 6.6470, lr_0 = 1.1255e-04
Validation rmse = 0.733706
Epoch 27
Loss = 3.8716e-01, PNorm = 44.1183, GNorm = 8.5172, lr_0 = 1.0691e-04
Validation rmse = 0.724634
Epoch 28
Loss = 3.7952e-01, PNorm = 44.1233, GNorm = 7.7691, lr_0 = 1.0103e-04
Loss = 3.9951e-01, PNorm = 44.1270, GNorm = 5.7121, lr_0 = 1.0000e-04
Validation rmse = 0.721774
Epoch 29
Loss = 3.9811e-01, PNorm = 44.1307, GNorm = 5.9533, lr_0 = 1.0000e-04
Loss = 3.8092e-01, PNorm = 44.1360, GNorm = 4.0602, lr_0 = 1.0000e-04
Validation rmse = 0.725277
Model 0 best validation rmse = 0.721774 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.741466
Ensemble test rmse = 0.741466
1-fold cross validation
	Seed 0 ==> test rmse = 0.741466
Overall test rmse = 0.741466 +/- 0.000000
Elapsed time = 0:01:26
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9739e+00, PNorm = 43.2599, GNorm = 1.1873, lr_0 = 3.9118e-04
Validation rmse = 1.304064
Epoch 1
Loss = 1.4157e+00, PNorm = 43.2618, GNorm = 2.3560, lr_0 = 6.8235e-04
Loss = 1.3884e+00, PNorm = 43.2720, GNorm = 1.6033, lr_0 = 9.4706e-04
Validation rmse = 1.200744
Epoch 2
Loss = 1.3423e+00, PNorm = 43.2929, GNorm = 0.8140, lr_0 = 9.6204e-04
Loss = 1.2348e+00, PNorm = 43.3253, GNorm = 3.4683, lr_0 = 9.1661e-04
Validation rmse = 1.105928
Epoch 3
Loss = 1.1348e+00, PNorm = 43.3650, GNorm = 5.1395, lr_0 = 8.6911e-04
Loss = 1.0981e+00, PNorm = 43.4074, GNorm = 2.0153, lr_0 = 8.2807e-04
Validation rmse = 0.926742
Epoch 4
Loss = 9.6137e-01, PNorm = 43.4558, GNorm = 8.4839, lr_0 = 7.8897e-04
Validation rmse = 0.940847
Epoch 5
Loss = 8.9614e-01, PNorm = 43.4984, GNorm = 3.1358, lr_0 = 7.4808e-04
Loss = 8.7520e-01, PNorm = 43.5352, GNorm = 5.0964, lr_0 = 7.1276e-04
Validation rmse = 0.822658
Epoch 6
Loss = 8.1742e-01, PNorm = 43.5750, GNorm = 8.9320, lr_0 = 6.7910e-04
Loss = 9.5078e-01, PNorm = 43.6051, GNorm = 5.5365, lr_0 = 6.4703e-04
Validation rmse = 0.880566
Epoch 7
Loss = 9.1533e-01, PNorm = 43.6300, GNorm = 3.0300, lr_0 = 6.1648e-04
Loss = 7.6182e-01, PNorm = 43.6591, GNorm = 3.7761, lr_0 = 5.8736e-04
Loss = 7.1468e-01, PNorm = 43.6624, GNorm = 9.8339, lr_0 = 5.8453e-04
Validation rmse = 0.786403
Epoch 8
Loss = 6.8197e-01, PNorm = 43.6932, GNorm = 6.9655, lr_0 = 5.5693e-04
Validation rmse = 0.775327
Epoch 9
Loss = 6.3063e-01, PNorm = 43.7138, GNorm = 3.1394, lr_0 = 5.3063e-04
Loss = 6.6327e-01, PNorm = 43.7374, GNorm = 4.6497, lr_0 = 5.0557e-04
Validation rmse = 0.760131
Epoch 10
Loss = 5.5968e-01, PNorm = 43.7593, GNorm = 6.0004, lr_0 = 4.7937e-04
Loss = 7.1945e-01, PNorm = 43.7792, GNorm = 4.8101, lr_0 = 4.5673e-04
Validation rmse = 0.783046
Epoch 11
Loss = 5.9310e-01, PNorm = 43.8000, GNorm = 4.0474, lr_0 = 4.3517e-04
Loss = 6.2282e-01, PNorm = 43.8155, GNorm = 11.4833, lr_0 = 4.1462e-04
Loss = 6.8619e-01, PNorm = 43.8171, GNorm = 5.5388, lr_0 = 4.1262e-04
Validation rmse = 0.767497
Epoch 12
Loss = 6.1548e-01, PNorm = 43.8340, GNorm = 11.2537, lr_0 = 3.9313e-04
Validation rmse = 0.739191
Epoch 13
Loss = 6.6412e-01, PNorm = 43.8501, GNorm = 5.6373, lr_0 = 3.7457e-04
Loss = 6.0704e-01, PNorm = 43.8702, GNorm = 17.6656, lr_0 = 3.5688e-04
Validation rmse = 0.788501
Epoch 14
Loss = 5.5522e-01, PNorm = 43.8822, GNorm = 5.7366, lr_0 = 3.4003e-04
Loss = 6.1890e-01, PNorm = 43.8944, GNorm = 10.5982, lr_0 = 3.2397e-04
Validation rmse = 0.768488
Epoch 15
Loss = 5.6146e-01, PNorm = 43.9097, GNorm = 10.3895, lr_0 = 3.0718e-04
Loss = 5.5104e-01, PNorm = 43.9225, GNorm = 7.0402, lr_0 = 2.9268e-04
Validation rmse = 0.742512
Epoch 16
Loss = 5.6092e-01, PNorm = 43.9343, GNorm = 9.0191, lr_0 = 2.7885e-04
Validation rmse = 0.756482
Epoch 17
Loss = 6.2201e-01, PNorm = 43.9487, GNorm = 11.9029, lr_0 = 2.6440e-04
Loss = 4.7674e-01, PNorm = 43.9588, GNorm = 4.9133, lr_0 = 2.5192e-04
Validation rmse = 0.783600
Epoch 18
Loss = 5.2489e-01, PNorm = 43.9702, GNorm = 5.4499, lr_0 = 2.4002e-04
Loss = 5.7357e-01, PNorm = 43.9797, GNorm = 10.0419, lr_0 = 2.2869e-04
Validation rmse = 0.725336
Epoch 19
Loss = 4.5917e-01, PNorm = 43.9884, GNorm = 8.5730, lr_0 = 2.1789e-04
Loss = 5.2754e-01, PNorm = 43.9984, GNorm = 3.7739, lr_0 = 2.0760e-04
Validation rmse = 0.720380
Epoch 20
Loss = 4.4764e-01, PNorm = 44.0090, GNorm = 3.9559, lr_0 = 1.9684e-04
Validation rmse = 0.718185
Epoch 21
Loss = 3.4107e-01, PNorm = 44.0154, GNorm = 3.8368, lr_0 = 1.8755e-04
Loss = 5.1028e-01, PNorm = 44.0230, GNorm = 8.2314, lr_0 = 1.7869e-04
Validation rmse = 0.723588
Epoch 22
Loss = 4.4091e-01, PNorm = 44.0313, GNorm = 13.8003, lr_0 = 1.6943e-04
Loss = 4.9494e-01, PNorm = 44.0372, GNorm = 3.8412, lr_0 = 1.6143e-04
Validation rmse = 0.706718
Epoch 23
Loss = 3.9300e-01, PNorm = 44.0440, GNorm = 3.1100, lr_0 = 1.5381e-04
Loss = 4.4692e-01, PNorm = 44.0515, GNorm = 4.1137, lr_0 = 1.4654e-04
Validation rmse = 0.709614
Epoch 24
Loss = 4.0513e-01, PNorm = 44.0578, GNorm = 12.9746, lr_0 = 1.3895e-04
Validation rmse = 0.705279
Epoch 25
Loss = 3.4270e-01, PNorm = 44.0630, GNorm = 8.3374, lr_0 = 1.3239e-04
Loss = 4.1347e-01, PNorm = 44.0675, GNorm = 5.7620, lr_0 = 1.2614e-04
Validation rmse = 0.704589
Epoch 26
Loss = 4.3524e-01, PNorm = 44.0732, GNorm = 9.9790, lr_0 = 1.2018e-04
Loss = 3.9644e-01, PNorm = 44.0787, GNorm = 8.3148, lr_0 = 1.1450e-04
Validation rmse = 0.712138
Epoch 27
Loss = 4.2400e-01, PNorm = 44.0837, GNorm = 10.0431, lr_0 = 1.0857e-04
Loss = 4.2786e-01, PNorm = 44.0888, GNorm = 8.3812, lr_0 = 1.0344e-04
Validation rmse = 0.710845
Epoch 28
Loss = 4.0290e-01, PNorm = 44.0938, GNorm = 3.8600, lr_0 = 1.0000e-04
Validation rmse = 0.701885
Epoch 29
Loss = 3.0060e-01, PNorm = 44.0977, GNorm = 7.4821, lr_0 = 1.0000e-04
Loss = 4.0429e-01, PNorm = 44.1024, GNorm = 6.3101, lr_0 = 1.0000e-04
Validation rmse = 0.703554
Model 0 best validation rmse = 0.701885 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.665779
Ensemble test rmse = 0.665779
1-fold cross validation
	Seed 0 ==> test rmse = 0.665779
Overall test rmse = 0.665779 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,149 | train size = 919 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9154e+00, PNorm = 43.2604, GNorm = 1.1324, lr_0 = 3.7500e-04
Validation rmse = 1.282522
Epoch 1
Loss = 1.3767e+00, PNorm = 43.2619, GNorm = 1.4714, lr_0 = 6.5000e-04
Loss = 1.3689e+00, PNorm = 43.2725, GNorm = 1.0451, lr_0 = 9.0000e-04
Validation rmse = 1.256114
Epoch 2
Loss = 1.2751e+00, PNorm = 43.2979, GNorm = 0.7921, lr_0 = 9.6853e-04
Loss = 1.2458e+00, PNorm = 43.3329, GNorm = 2.1345, lr_0 = 9.2527e-04
Validation rmse = 1.100296
Epoch 3
Loss = 1.0426e+00, PNorm = 43.3755, GNorm = 3.1246, lr_0 = 8.8395e-04
Loss = 1.1369e+00, PNorm = 43.4232, GNorm = 6.8318, lr_0 = 8.4448e-04
Validation rmse = 0.998030
Epoch 4
Loss = 9.9089e-01, PNorm = 43.4749, GNorm = 7.3118, lr_0 = 8.0309e-04
Loss = 9.7627e-01, PNorm = 43.5191, GNorm = 4.4933, lr_0 = 7.6722e-04
Validation rmse = 0.880752
Epoch 5
Loss = 9.4220e-01, PNorm = 43.5549, GNorm = 7.2509, lr_0 = 7.2962e-04
Loss = 9.8647e-01, PNorm = 43.5925, GNorm = 2.6963, lr_0 = 6.9703e-04
Validation rmse = 0.905583
Epoch 6
Loss = 8.3350e-01, PNorm = 43.6257, GNorm = 8.2850, lr_0 = 6.6591e-04
Validation rmse = 0.865307
Epoch 7
Loss = 8.0143e-01, PNorm = 43.6671, GNorm = 2.5820, lr_0 = 6.3327e-04
Loss = 7.9856e-01, PNorm = 43.6991, GNorm = 3.1757, lr_0 = 6.0499e-04
Validation rmse = 0.902430
Epoch 8
Loss = 7.5245e-01, PNorm = 43.7269, GNorm = 2.4224, lr_0 = 5.7797e-04
Loss = 7.2474e-01, PNorm = 43.7578, GNorm = 4.4738, lr_0 = 5.5216e-04
Validation rmse = 0.836057
Epoch 9
Loss = 6.9531e-01, PNorm = 43.7809, GNorm = 3.3979, lr_0 = 5.2510e-04
Loss = 6.7497e-01, PNorm = 43.8109, GNorm = 6.3097, lr_0 = 5.0165e-04
Validation rmse = 0.866935
Epoch 10
Loss = 6.7134e-01, PNorm = 43.8331, GNorm = 5.7077, lr_0 = 4.7706e-04
Loss = 6.1700e-01, PNorm = 43.8576, GNorm = 2.9604, lr_0 = 4.5575e-04
Validation rmse = 0.802545
Epoch 11
Loss = 5.9357e-01, PNorm = 43.8827, GNorm = 13.8537, lr_0 = 4.3540e-04
Loss = 6.7069e-01, PNorm = 43.8946, GNorm = 8.2028, lr_0 = 4.1596e-04
Loss = 4.8772e-01, PNorm = 43.8954, GNorm = 9.3717, lr_0 = 4.1406e-04
Validation rmse = 0.801535
Epoch 12
Loss = 6.2605e-01, PNorm = 43.9105, GNorm = 3.0684, lr_0 = 3.9557e-04
Validation rmse = 0.801361
Epoch 13
Loss = 4.7176e-01, PNorm = 43.9356, GNorm = 8.4975, lr_0 = 3.7618e-04
Loss = 6.6728e-01, PNorm = 43.9506, GNorm = 6.2564, lr_0 = 3.5938e-04
Validation rmse = 0.847578
Epoch 14
Loss = 5.4602e-01, PNorm = 43.9633, GNorm = 2.2423, lr_0 = 3.4333e-04
Loss = 5.1841e-01, PNorm = 43.9801, GNorm = 9.1917, lr_0 = 3.2800e-04
Validation rmse = 0.792402
Epoch 15
Loss = 5.5691e-01, PNorm = 43.9964, GNorm = 5.8201, lr_0 = 3.1192e-04
Loss = 4.8238e-01, PNorm = 44.0095, GNorm = 5.1911, lr_0 = 2.9799e-04
Validation rmse = 0.765955
Epoch 16
Loss = 4.8888e-01, PNorm = 44.0168, GNorm = 11.1647, lr_0 = 2.8469e-04
Loss = 5.3081e-01, PNorm = 44.0273, GNorm = 4.0628, lr_0 = 2.7197e-04
Validation rmse = 0.785356
Epoch 17
Loss = 4.9626e-01, PNorm = 44.0400, GNorm = 2.9171, lr_0 = 2.5864e-04
Loss = 4.8080e-01, PNorm = 44.0521, GNorm = 6.3294, lr_0 = 2.4709e-04
Loss = 6.4407e-01, PNorm = 44.0527, GNorm = 16.8572, lr_0 = 2.4596e-04
Validation rmse = 0.780139
Epoch 18
Loss = 4.9312e-01, PNorm = 44.0614, GNorm = 3.3042, lr_0 = 2.3498e-04
Validation rmse = 0.764215
Epoch 19
Loss = 5.4060e-01, PNorm = 44.0707, GNorm = 3.6083, lr_0 = 2.2449e-04
Loss = 4.7242e-01, PNorm = 44.0787, GNorm = 3.6549, lr_0 = 2.1446e-04
Validation rmse = 0.761902
Epoch 20
Loss = 3.3762e-01, PNorm = 44.0901, GNorm = 10.5083, lr_0 = 2.0395e-04
Loss = 4.9150e-01, PNorm = 44.0975, GNorm = 8.4513, lr_0 = 1.9484e-04
Validation rmse = 0.795638
Epoch 21
Loss = 4.5575e-01, PNorm = 44.1061, GNorm = 3.2390, lr_0 = 1.8529e-04
Loss = 4.3738e-01, PNorm = 44.1143, GNorm = 4.9249, lr_0 = 1.7702e-04
Validation rmse = 0.752708
Epoch 22
Loss = 4.0976e-01, PNorm = 44.1193, GNorm = 4.8395, lr_0 = 1.6911e-04
Loss = 4.1082e-01, PNorm = 44.1249, GNorm = 3.4123, lr_0 = 1.6156e-04
Validation rmse = 0.753011
Epoch 23
Loss = 4.7690e-01, PNorm = 44.1345, GNorm = 22.0305, lr_0 = 1.5364e-04
Loss = 5.0419e-01, PNorm = 44.1392, GNorm = 6.3173, lr_0 = 1.4678e-04
Validation rmse = 0.750193
Epoch 24
Loss = 3.7650e-01, PNorm = 44.1449, GNorm = 3.1791, lr_0 = 1.4022e-04
Validation rmse = 0.748579
Epoch 25
Loss = 2.4723e-01, PNorm = 44.1519, GNorm = 6.4396, lr_0 = 1.3335e-04
Loss = 4.4958e-01, PNorm = 44.1574, GNorm = 6.7754, lr_0 = 1.2740e-04
Validation rmse = 0.744855
Epoch 26
Loss = 4.3304e-01, PNorm = 44.1631, GNorm = 4.1303, lr_0 = 1.2115e-04
Loss = 3.6124e-01, PNorm = 44.1687, GNorm = 5.8650, lr_0 = 1.1574e-04
Validation rmse = 0.741038
Epoch 27
Loss = 4.3606e-01, PNorm = 44.1706, GNorm = 5.5881, lr_0 = 1.1057e-04
Loss = 3.9520e-01, PNorm = 44.1739, GNorm = 8.8482, lr_0 = 1.0564e-04
Validation rmse = 0.757841
Epoch 28
Loss = 4.1694e-01, PNorm = 44.1798, GNorm = 8.7608, lr_0 = 1.0046e-04
Loss = 3.3810e-01, PNorm = 44.1847, GNorm = 10.8909, lr_0 = 1.0000e-04
Validation rmse = 0.739273
Epoch 29
Loss = 3.5372e-01, PNorm = 44.1883, GNorm = 3.3442, lr_0 = 1.0000e-04
Loss = 3.9444e-01, PNorm = 44.1914, GNorm = 6.1812, lr_0 = 1.0000e-04
Validation rmse = 0.754938
Model 0 best validation rmse = 0.739273 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.669221
Ensemble test rmse = 0.669221
1-fold cross validation
	Seed 0 ==> test rmse = 0.669221
Overall test rmse = 0.669221 +/- 0.000000
Elapsed time = 0:01:32
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9292e+00, PNorm = 43.2610, GNorm = 1.9712, lr_0 = 3.6053e-04
Validation rmse = 1.269048
Epoch 1
Loss = 1.5084e+00, PNorm = 43.2643, GNorm = 1.6249, lr_0 = 6.2105e-04
Loss = 1.3950e+00, PNorm = 43.2737, GNorm = 1.2819, lr_0 = 8.5789e-04
Validation rmse = 1.238394
Epoch 2
Loss = 1.3825e+00, PNorm = 43.2955, GNorm = 1.4807, lr_0 = 9.7859e-04
Loss = 1.2016e+00, PNorm = 43.3238, GNorm = 1.1256, lr_0 = 9.3714e-04
Validation rmse = 1.039428
Epoch 3
Loss = 1.0097e+00, PNorm = 43.3719, GNorm = 2.5850, lr_0 = 8.9357e-04
Loss = 1.0502e+00, PNorm = 43.4248, GNorm = 4.4844, lr_0 = 8.5572e-04
Validation rmse = 1.026061
Epoch 4
Loss = 9.6118e-01, PNorm = 43.4789, GNorm = 5.3564, lr_0 = 8.1593e-04
Loss = 9.2181e-01, PNorm = 43.5190, GNorm = 3.3677, lr_0 = 7.8137e-04
Validation rmse = 0.867638
Epoch 5
Loss = 8.4290e-01, PNorm = 43.5619, GNorm = 8.6418, lr_0 = 7.4504e-04
Loss = 8.1859e-01, PNorm = 43.5975, GNorm = 2.2031, lr_0 = 7.1348e-04
Validation rmse = 0.798211
Epoch 6
Loss = 7.9917e-01, PNorm = 43.6211, GNorm = 2.7866, lr_0 = 6.8326e-04
Loss = 8.5910e-01, PNorm = 43.6475, GNorm = 2.2061, lr_0 = 6.5432e-04
Validation rmse = 0.787050
Epoch 7
Loss = 7.5323e-01, PNorm = 43.6774, GNorm = 5.9208, lr_0 = 6.2390e-04
Loss = 7.6249e-01, PNorm = 43.6990, GNorm = 2.6588, lr_0 = 5.9747e-04
Validation rmse = 0.735927
Epoch 8
Loss = 6.9600e-01, PNorm = 43.7358, GNorm = 9.3171, lr_0 = 5.6969e-04
Loss = 6.9725e-01, PNorm = 43.7614, GNorm = 7.3876, lr_0 = 5.4556e-04
Validation rmse = 0.731382
Epoch 9
Loss = 7.1185e-01, PNorm = 43.7840, GNorm = 3.7908, lr_0 = 5.2019e-04
Loss = 6.9724e-01, PNorm = 43.8029, GNorm = 6.0776, lr_0 = 4.9816e-04
Validation rmse = 0.831543
Epoch 10
Loss = 7.1502e-01, PNorm = 43.8332, GNorm = 10.2795, lr_0 = 4.7500e-04
Loss = 6.7321e-01, PNorm = 43.8499, GNorm = 7.8041, lr_0 = 4.5488e-04
Loss = 8.3633e-01, PNorm = 43.8516, GNorm = 8.2563, lr_0 = 4.5291e-04
Validation rmse = 0.711942
Epoch 11
Loss = 5.7937e-01, PNorm = 43.8699, GNorm = 3.0077, lr_0 = 4.3373e-04
Loss = 6.1352e-01, PNorm = 43.8824, GNorm = 15.9292, lr_0 = 4.1536e-04
Validation rmse = 0.678190
Epoch 12
Loss = 6.0425e-01, PNorm = 43.8962, GNorm = 3.1559, lr_0 = 3.9776e-04
Validation rmse = 0.689977
Epoch 13
Loss = 4.6922e-01, PNorm = 43.9100, GNorm = 8.4225, lr_0 = 3.7927e-04
Loss = 5.0068e-01, PNorm = 43.9224, GNorm = 4.3416, lr_0 = 3.6320e-04
Validation rmse = 0.678313
Epoch 14
Loss = 5.2319e-01, PNorm = 43.9388, GNorm = 5.2235, lr_0 = 3.4632e-04
Loss = 5.3596e-01, PNorm = 43.9527, GNorm = 2.7568, lr_0 = 3.3165e-04
Validation rmse = 0.676162
Epoch 15
Loss = 7.8645e-01, PNorm = 43.9653, GNorm = 21.7831, lr_0 = 3.1623e-04
Loss = 5.9379e-01, PNorm = 43.9764, GNorm = 10.7332, lr_0 = 3.0283e-04
Validation rmse = 0.694853
Epoch 16
Loss = 5.2176e-01, PNorm = 43.9859, GNorm = 3.5523, lr_0 = 2.8875e-04
Loss = 5.5954e-01, PNorm = 43.9964, GNorm = 5.0170, lr_0 = 2.7652e-04
Validation rmse = 0.693545
Epoch 17
Loss = 4.4347e-01, PNorm = 44.0075, GNorm = 2.9688, lr_0 = 2.6481e-04
Loss = 4.9480e-01, PNorm = 44.0170, GNorm = 16.6500, lr_0 = 2.5359e-04
Validation rmse = 0.669086
Epoch 18
Loss = 4.7096e-01, PNorm = 44.0279, GNorm = 9.3683, lr_0 = 2.4180e-04
Loss = 5.1302e-01, PNorm = 44.0369, GNorm = 4.0509, lr_0 = 2.3156e-04
Validation rmse = 0.822690
Epoch 19
Loss = 6.2352e-01, PNorm = 44.0448, GNorm = 15.1711, lr_0 = 2.2079e-04
Loss = 5.1487e-01, PNorm = 44.0523, GNorm = 6.7956, lr_0 = 2.1144e-04
Validation rmse = 0.755284
Epoch 20
Loss = 4.9323e-01, PNorm = 44.0608, GNorm = 11.0908, lr_0 = 2.0161e-04
Loss = 5.3084e-01, PNorm = 44.0679, GNorm = 10.5929, lr_0 = 1.9307e-04
Validation rmse = 0.697539
Epoch 21
Loss = 4.4951e-01, PNorm = 44.0752, GNorm = 4.4012, lr_0 = 1.8409e-04
Loss = 4.6693e-01, PNorm = 44.0814, GNorm = 5.1689, lr_0 = 1.7630e-04
Validation rmse = 0.754523
Epoch 22
Loss = 5.0750e-01, PNorm = 44.0902, GNorm = 7.7086, lr_0 = 1.6810e-04
Loss = 4.4471e-01, PNorm = 44.0952, GNorm = 6.3230, lr_0 = 1.6098e-04
Validation rmse = 0.684301
Epoch 23
Loss = 4.2315e-01, PNorm = 44.0997, GNorm = 13.5315, lr_0 = 1.5416e-04
Loss = 4.5195e-01, PNorm = 44.1053, GNorm = 3.1746, lr_0 = 1.4763e-04
Loss = 6.0289e-01, PNorm = 44.1058, GNorm = 11.0376, lr_0 = 1.4699e-04
Validation rmse = 0.677072
Epoch 24
Loss = 4.6312e-01, PNorm = 44.1105, GNorm = 4.2337, lr_0 = 1.4077e-04
Validation rmse = 0.684251
Epoch 25
Loss = 4.9297e-01, PNorm = 44.1161, GNorm = 4.0753, lr_0 = 1.3422e-04
Loss = 4.3200e-01, PNorm = 44.1216, GNorm = 8.3521, lr_0 = 1.2854e-04
Validation rmse = 0.666762
Epoch 26
Loss = 4.2151e-01, PNorm = 44.1250, GNorm = 6.1816, lr_0 = 1.2256e-04
Loss = 4.1034e-01, PNorm = 44.1291, GNorm = 4.1769, lr_0 = 1.1737e-04
Validation rmse = 0.683019
Epoch 27
Loss = 4.9327e-01, PNorm = 44.1331, GNorm = 7.6120, lr_0 = 1.1191e-04
Loss = 4.0457e-01, PNorm = 44.1383, GNorm = 3.4355, lr_0 = 1.0717e-04
Validation rmse = 0.695492
Epoch 28
Loss = 5.0201e-01, PNorm = 44.1420, GNorm = 8.9354, lr_0 = 1.0263e-04
Loss = 3.8205e-01, PNorm = 44.1457, GNorm = 5.9611, lr_0 = 1.0000e-04
Validation rmse = 0.697067
Epoch 29
Loss = 4.7521e-01, PNorm = 44.1499, GNorm = 3.2862, lr_0 = 1.0000e-04
Loss = 3.8370e-01, PNorm = 44.1531, GNorm = 4.9899, lr_0 = 1.0000e-04
Validation rmse = 0.703704
Model 0 best validation rmse = 0.666762 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.676439
Ensemble test rmse = 0.676439
1-fold cross validation
	Seed 0 ==> test rmse = 0.676439
Overall test rmse = 0.676439 +/- 0.000000
Elapsed time = 0:01:36
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,249 | train size = 999 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8374e+00, PNorm = 43.2598, GNorm = 1.1621, lr_0 = 3.6053e-04
Validation rmse = 1.252684
Epoch 1
Loss = 1.4541e+00, PNorm = 43.2616, GNorm = 1.5570, lr_0 = 6.2105e-04
Loss = 1.3747e+00, PNorm = 43.2714, GNorm = 1.6629, lr_0 = 8.5789e-04
Validation rmse = 1.164639
Epoch 2
Loss = 1.3282e+00, PNorm = 43.2901, GNorm = 0.9067, lr_0 = 9.8284e-04
Loss = 1.3121e+00, PNorm = 43.3200, GNorm = 2.2644, lr_0 = 9.4120e-04
Validation rmse = 1.074329
Epoch 3
Loss = 1.0438e+00, PNorm = 43.3562, GNorm = 2.1440, lr_0 = 9.0134e-04
Loss = 1.1086e+00, PNorm = 43.4008, GNorm = 5.0077, lr_0 = 8.6316e-04
Validation rmse = 0.983573
Epoch 4
Loss = 1.0134e+00, PNorm = 43.4516, GNorm = 6.8455, lr_0 = 8.2660e-04
Loss = 1.0198e+00, PNorm = 43.4980, GNorm = 1.4727, lr_0 = 7.9158e-04
Validation rmse = 0.844172
Epoch 5
Loss = 8.2503e-01, PNorm = 43.5463, GNorm = 4.2960, lr_0 = 7.5805e-04
Loss = 8.6742e-01, PNorm = 43.5883, GNorm = 1.5828, lr_0 = 7.2594e-04
Validation rmse = 0.833101
Epoch 6
Loss = 8.5403e-01, PNorm = 43.6292, GNorm = 3.3645, lr_0 = 6.9519e-04
Loss = 8.4288e-01, PNorm = 43.6684, GNorm = 2.7758, lr_0 = 6.6575e-04
Validation rmse = 0.772860
Epoch 7
Loss = 8.6114e-01, PNorm = 43.6995, GNorm = 2.5074, lr_0 = 6.3755e-04
Loss = 7.5824e-01, PNorm = 43.7312, GNorm = 2.0858, lr_0 = 6.1054e-04
Validation rmse = 0.791997
Epoch 8
Loss = 6.2483e-01, PNorm = 43.7612, GNorm = 3.4717, lr_0 = 5.8468e-04
Loss = 6.8011e-01, PNorm = 43.7951, GNorm = 7.8007, lr_0 = 5.5991e-04
Validation rmse = 0.780448
Epoch 9
Loss = 6.4649e-01, PNorm = 43.8136, GNorm = 3.9203, lr_0 = 5.3620e-04
Loss = 7.7691e-01, PNorm = 43.8353, GNorm = 2.1666, lr_0 = 5.1348e-04
Validation rmse = 0.756931
Epoch 10
Loss = 5.4310e-01, PNorm = 43.8602, GNorm = 2.2381, lr_0 = 4.9173e-04
Loss = 6.1371e-01, PNorm = 43.8909, GNorm = 13.9540, lr_0 = 4.7090e-04
Validation rmse = 0.698197
Epoch 11
Loss = 6.6638e-01, PNorm = 43.9080, GNorm = 3.4062, lr_0 = 4.5096e-04
Loss = 6.2240e-01, PNorm = 43.9264, GNorm = 7.7029, lr_0 = 4.3186e-04
Validation rmse = 0.698451
Epoch 12
Loss = 5.4783e-01, PNorm = 43.9461, GNorm = 4.8092, lr_0 = 4.1356e-04
Loss = 5.5596e-01, PNorm = 43.9631, GNorm = 3.6515, lr_0 = 3.9604e-04
Validation rmse = 0.683974
Epoch 13
Loss = 6.6490e-01, PNorm = 43.9841, GNorm = 3.3922, lr_0 = 3.7927e-04
Loss = 5.5473e-01, PNorm = 43.9978, GNorm = 4.4712, lr_0 = 3.6320e-04
Validation rmse = 0.686472
Epoch 14
Loss = 5.6249e-01, PNorm = 44.0143, GNorm = 3.2203, lr_0 = 3.4782e-04
Loss = 5.5647e-01, PNorm = 44.0285, GNorm = 4.0781, lr_0 = 3.3309e-04
Validation rmse = 0.742317
Epoch 15
Loss = 6.4851e-01, PNorm = 44.0435, GNorm = 9.1512, lr_0 = 3.1898e-04
Loss = 5.3815e-01, PNorm = 44.0605, GNorm = 4.9095, lr_0 = 3.0547e-04
Validation rmse = 0.690971
Epoch 16
Loss = 4.5667e-01, PNorm = 44.0733, GNorm = 2.2734, lr_0 = 2.9253e-04
Loss = 4.9578e-01, PNorm = 44.0853, GNorm = 2.5150, lr_0 = 2.8014e-04
Validation rmse = 0.683551
Epoch 17
Loss = 5.0252e-01, PNorm = 44.0963, GNorm = 3.1267, lr_0 = 2.6827e-04
Loss = 4.8266e-01, PNorm = 44.1085, GNorm = 10.9707, lr_0 = 2.5691e-04
Validation rmse = 0.701591
Epoch 18
Loss = 4.0606e-01, PNorm = 44.1198, GNorm = 3.3877, lr_0 = 2.4602e-04
Loss = 4.4368e-01, PNorm = 44.1309, GNorm = 3.4396, lr_0 = 2.3560e-04
Validation rmse = 0.689263
Epoch 19
Loss = 4.7315e-01, PNorm = 44.1401, GNorm = 6.2439, lr_0 = 2.2562e-04
Loss = 5.5546e-01, PNorm = 44.1475, GNorm = 3.4016, lr_0 = 2.1607e-04
Validation rmse = 0.692167
Epoch 20
Loss = 2.9099e-01, PNorm = 44.1571, GNorm = 3.1767, lr_0 = 2.0691e-04
Loss = 4.6184e-01, PNorm = 44.1688, GNorm = 5.5569, lr_0 = 1.9815e-04
Validation rmse = 0.687117
Epoch 21
Loss = 5.9555e-01, PNorm = 44.1752, GNorm = 8.5193, lr_0 = 1.8976e-04
Loss = 4.3910e-01, PNorm = 44.1821, GNorm = 3.8030, lr_0 = 1.8172e-04
Validation rmse = 0.690069
Epoch 22
Loss = 3.8970e-01, PNorm = 44.1908, GNorm = 5.2223, lr_0 = 1.7402e-04
Loss = 4.4388e-01, PNorm = 44.1980, GNorm = 3.4648, lr_0 = 1.6665e-04
Validation rmse = 0.686008
Epoch 23
Loss = 3.2526e-01, PNorm = 44.2057, GNorm = 3.7055, lr_0 = 1.5959e-04
Loss = 4.5277e-01, PNorm = 44.2130, GNorm = 5.8388, lr_0 = 1.5283e-04
Validation rmse = 0.677268
Epoch 24
Loss = 3.6094e-01, PNorm = 44.2201, GNorm = 2.7571, lr_0 = 1.4636e-04
Loss = 3.7206e-01, PNorm = 44.2282, GNorm = 5.1757, lr_0 = 1.4016e-04
Validation rmse = 0.688356
Epoch 25
Loss = 5.4924e-01, PNorm = 44.2326, GNorm = 3.5752, lr_0 = 1.3422e-04
Loss = 4.3524e-01, PNorm = 44.2360, GNorm = 2.7750, lr_0 = 1.2854e-04
Validation rmse = 0.680327
Epoch 26
Loss = 2.9348e-01, PNorm = 44.2423, GNorm = 5.0056, lr_0 = 1.2309e-04
Loss = 3.7322e-01, PNorm = 44.2494, GNorm = 10.7639, lr_0 = 1.1788e-04
Validation rmse = 0.695982
Epoch 27
Loss = 5.6533e-01, PNorm = 44.2531, GNorm = 4.5459, lr_0 = 1.1288e-04
Loss = 3.6812e-01, PNorm = 44.2569, GNorm = 5.1439, lr_0 = 1.0810e-04
Validation rmse = 0.679280
Epoch 28
Loss = 6.1656e-01, PNorm = 44.2617, GNorm = 5.2794, lr_0 = 1.0352e-04
Loss = 3.6273e-01, PNorm = 44.2662, GNorm = 10.3577, lr_0 = 1.0000e-04
Validation rmse = 0.688694
Epoch 29
Loss = 3.4826e-01, PNorm = 44.2714, GNorm = 8.3138, lr_0 = 1.0000e-04
Loss = 3.6787e-01, PNorm = 44.2761, GNorm = 9.0398, lr_0 = 1.0000e-04
Validation rmse = 0.695615
Model 0 best validation rmse = 0.677268 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.662222
Ensemble test rmse = 0.662222
1-fold cross validation
	Seed 0 ==> test rmse = 0.662222
Overall test rmse = 0.662222 +/- 0.000000
Elapsed time = 0:01:40
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8855e+00, PNorm = 43.2600, GNorm = 2.8105, lr_0 = 3.4750e-04
Loss = 1.4495e+00, PNorm = 43.2604, GNorm = 1.4196, lr_0 = 5.7250e-04
Loss = 1.4770e+00, PNorm = 43.2607, GNorm = 1.1592, lr_0 = 5.9500e-04
Validation rmse = 1.354080
Epoch 1
Loss = 1.3979e+00, PNorm = 43.2683, GNorm = 1.1791, lr_0 = 8.2000e-04
Loss = 1.3202e+00, PNorm = 43.2868, GNorm = 1.5211, lr_0 = 9.9181e-04
Validation rmse = 1.292517
Epoch 2
Loss = 1.2391e+00, PNorm = 43.3131, GNorm = 1.0887, lr_0 = 9.5186e-04
Loss = 1.2237e+00, PNorm = 43.3459, GNorm = 1.5709, lr_0 = 9.1351e-04
Validation rmse = 1.125824
Epoch 3
Loss = 1.1541e+00, PNorm = 43.3873, GNorm = 2.5481, lr_0 = 8.7671e-04
Loss = 1.0709e+00, PNorm = 43.4357, GNorm = 3.6705, lr_0 = 8.4140e-04
Validation rmse = 0.924216
Epoch 4
Loss = 1.0083e+00, PNorm = 43.4807, GNorm = 1.4102, lr_0 = 8.0750e-04
Loss = 1.0116e+00, PNorm = 43.5267, GNorm = 6.5389, lr_0 = 7.7497e-04
Validation rmse = 0.827439
Epoch 5
Loss = 9.0856e-01, PNorm = 43.5741, GNorm = 7.5649, lr_0 = 7.4070e-04
Loss = 8.9533e-01, PNorm = 43.6113, GNorm = 5.3656, lr_0 = 7.1086e-04
Validation rmse = 0.863998
Epoch 6
Loss = 8.7515e-01, PNorm = 43.6459, GNorm = 4.0933, lr_0 = 6.8223e-04
Loss = 8.2996e-01, PNorm = 43.6850, GNorm = 8.2935, lr_0 = 6.5474e-04
Validation rmse = 0.740632
Epoch 7
Loss = 7.8210e-01, PNorm = 43.7088, GNorm = 2.6906, lr_0 = 6.2837e-04
Loss = 7.4986e-01, PNorm = 43.7405, GNorm = 5.2073, lr_0 = 6.0306e-04
Validation rmse = 0.764069
Epoch 8
Loss = 6.4536e-01, PNorm = 43.7735, GNorm = 2.6319, lr_0 = 5.7876e-04
Loss = 8.2690e-01, PNorm = 43.7918, GNorm = 2.7266, lr_0 = 5.5545e-04
Validation rmse = 0.790595
Epoch 9
Loss = 8.1979e-01, PNorm = 43.8117, GNorm = 4.4883, lr_0 = 5.3307e-04
Loss = 7.3299e-01, PNorm = 43.8421, GNorm = 2.9790, lr_0 = 5.1160e-04
Validation rmse = 0.688131
Epoch 10
Loss = 6.2935e-01, PNorm = 43.8677, GNorm = 6.5795, lr_0 = 4.8897e-04
Loss = 6.4540e-01, PNorm = 43.8890, GNorm = 8.8720, lr_0 = 4.6928e-04
Validation rmse = 0.692818
Epoch 11
Loss = 6.5667e-01, PNorm = 43.9071, GNorm = 6.4236, lr_0 = 4.5037e-04
Loss = 6.2566e-01, PNorm = 43.9303, GNorm = 6.4586, lr_0 = 4.3223e-04
Validation rmse = 0.707075
Epoch 12
Loss = 5.9361e-01, PNorm = 43.9483, GNorm = 6.1558, lr_0 = 4.1482e-04
Loss = 5.7932e-01, PNorm = 43.9660, GNorm = 3.1652, lr_0 = 3.9811e-04
Loss = 6.4445e-01, PNorm = 43.9819, GNorm = 3.4180, lr_0 = 3.8207e-04
Validation rmse = 0.673195
Epoch 13
Loss = 5.5895e-01, PNorm = 43.9979, GNorm = 4.1425, lr_0 = 3.6668e-04
Loss = 6.0996e-01, PNorm = 44.0131, GNorm = 3.2132, lr_0 = 3.5191e-04
Loss = 5.3641e-01, PNorm = 44.0147, GNorm = 3.1416, lr_0 = 3.5046e-04
Validation rmse = 0.686850
Epoch 14
Loss = 5.7487e-01, PNorm = 44.0327, GNorm = 3.7267, lr_0 = 3.3635e-04
Loss = 5.3068e-01, PNorm = 44.0456, GNorm = 4.1155, lr_0 = 3.2280e-04
Validation rmse = 0.666799
Epoch 15
Loss = 5.6257e-01, PNorm = 44.0545, GNorm = 6.4101, lr_0 = 3.0979e-04
Loss = 5.3219e-01, PNorm = 44.0685, GNorm = 10.8704, lr_0 = 2.9731e-04
Validation rmse = 0.687179
Epoch 16
Loss = 4.8999e-01, PNorm = 44.0818, GNorm = 6.8327, lr_0 = 2.8534e-04
Loss = 5.7766e-01, PNorm = 44.0929, GNorm = 4.1278, lr_0 = 2.7384e-04
Validation rmse = 0.657161
Epoch 17
Loss = 5.7360e-01, PNorm = 44.1056, GNorm = 6.0325, lr_0 = 2.6281e-04
Loss = 4.8273e-01, PNorm = 44.1194, GNorm = 4.2908, lr_0 = 2.5222e-04
Validation rmse = 0.655066
Epoch 18
Loss = 4.3808e-01, PNorm = 44.1278, GNorm = 3.3282, lr_0 = 2.4206e-04
Loss = 5.1351e-01, PNorm = 44.1362, GNorm = 5.8256, lr_0 = 2.3231e-04
Validation rmse = 0.655227
Epoch 19
Loss = 4.9211e-01, PNorm = 44.1488, GNorm = 7.8742, lr_0 = 2.2204e-04
Loss = 4.4576e-01, PNorm = 44.1601, GNorm = 8.9903, lr_0 = 2.1309e-04
Validation rmse = 0.636443
Epoch 20
Loss = 4.6705e-01, PNorm = 44.1678, GNorm = 3.3630, lr_0 = 2.0451e-04
Loss = 4.6165e-01, PNorm = 44.1756, GNorm = 7.3735, lr_0 = 1.9627e-04
Validation rmse = 0.674410
Epoch 21
Loss = 4.6679e-01, PNorm = 44.1819, GNorm = 11.3050, lr_0 = 1.8836e-04
Loss = 4.7560e-01, PNorm = 44.1895, GNorm = 3.6016, lr_0 = 1.8078e-04
Validation rmse = 0.650229
Epoch 22
Loss = 4.7120e-01, PNorm = 44.1969, GNorm = 11.4171, lr_0 = 1.7349e-04
Loss = 4.3467e-01, PNorm = 44.2060, GNorm = 3.7977, lr_0 = 1.6651e-04
Validation rmse = 0.658561
Epoch 23
Loss = 5.3477e-01, PNorm = 44.2130, GNorm = 7.6205, lr_0 = 1.5914e-04
Loss = 3.9321e-01, PNorm = 44.2203, GNorm = 3.6744, lr_0 = 1.5273e-04
Validation rmse = 0.647605
Epoch 24
Loss = 2.3956e-01, PNorm = 44.2260, GNorm = 5.5118, lr_0 = 1.4658e-04
Loss = 4.7895e-01, PNorm = 44.2300, GNorm = 4.9261, lr_0 = 1.4067e-04
Validation rmse = 0.657189
Epoch 25
Loss = 3.1956e-01, PNorm = 44.2363, GNorm = 9.7741, lr_0 = 1.3501e-04
Loss = 3.8833e-01, PNorm = 44.2421, GNorm = 9.8917, lr_0 = 1.2957e-04
Loss = 5.1127e-01, PNorm = 44.2477, GNorm = 8.3980, lr_0 = 1.2435e-04
Validation rmse = 0.633884
Epoch 26
Loss = 3.8578e-01, PNorm = 44.2520, GNorm = 4.4913, lr_0 = 1.1934e-04
Loss = 4.4375e-01, PNorm = 44.2576, GNorm = 8.6759, lr_0 = 1.1453e-04
Validation rmse = 0.639613
Epoch 27
Loss = 4.3133e-01, PNorm = 44.2620, GNorm = 3.0504, lr_0 = 1.0992e-04
Loss = 3.9679e-01, PNorm = 44.2664, GNorm = 7.6731, lr_0 = 1.0549e-04
Validation rmse = 0.648301
Epoch 28
Loss = 3.4687e-01, PNorm = 44.2717, GNorm = 6.3295, lr_0 = 1.0083e-04
Loss = 4.6306e-01, PNorm = 44.2754, GNorm = 6.4898, lr_0 = 1.0000e-04
Validation rmse = 0.637690
Epoch 29
Loss = 4.7400e-01, PNorm = 44.2774, GNorm = 8.7279, lr_0 = 1.0000e-04
Loss = 3.7517e-01, PNorm = 44.2817, GNorm = 5.7400, lr_0 = 1.0000e-04
Validation rmse = 0.639875
Model 0 best validation rmse = 0.633884 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.669917
Ensemble test rmse = 0.669917
1-fold cross validation
	Seed 0 ==> test rmse = 0.669917
Overall test rmse = 0.669917 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,349 | train size = 1,079 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9237e+00, PNorm = 43.2590, GNorm = 1.4555, lr_0 = 3.3571e-04
Loss = 1.4510e+00, PNorm = 43.2587, GNorm = 1.6232, lr_0 = 5.5000e-04
Validation rmse = 1.298522
Epoch 1
Loss = 1.3982e+00, PNorm = 43.2652, GNorm = 1.1980, lr_0 = 7.8571e-04
Loss = 1.3424e+00, PNorm = 43.2823, GNorm = 1.9772, lr_0 = 1.0000e-03
Validation rmse = 1.246821
Epoch 2
Loss = 1.2423e+00, PNorm = 43.3084, GNorm = 1.4624, lr_0 = 9.6160e-04
Loss = 1.2092e+00, PNorm = 43.3437, GNorm = 1.8151, lr_0 = 9.2467e-04
Validation rmse = 1.019762
Epoch 3
Loss = 1.0826e+00, PNorm = 43.3878, GNorm = 5.7134, lr_0 = 8.8568e-04
Loss = 1.0927e+00, PNorm = 43.4354, GNorm = 2.1843, lr_0 = 8.5167e-04
Validation rmse = 0.837209
Epoch 4
Loss = 9.5693e-01, PNorm = 43.4886, GNorm = 6.2924, lr_0 = 8.1896e-04
Loss = 9.3142e-01, PNorm = 43.5296, GNorm = 3.5372, lr_0 = 7.8751e-04
Validation rmse = 0.790550
Epoch 5
Loss = 9.5505e-01, PNorm = 43.5676, GNorm = 12.1297, lr_0 = 7.5431e-04
Loss = 9.7307e-01, PNorm = 43.5960, GNorm = 4.6730, lr_0 = 7.2534e-04
Validation rmse = 0.807348
Epoch 6
Loss = 8.5156e-01, PNorm = 43.6334, GNorm = 2.6922, lr_0 = 6.9749e-04
Loss = 8.2059e-01, PNorm = 43.6735, GNorm = 3.1520, lr_0 = 6.7070e-04
Loss = 7.9427e-01, PNorm = 43.7018, GNorm = 5.5729, lr_0 = 6.4495e-04
Validation rmse = 0.723287
Epoch 7
Loss = 8.3524e-01, PNorm = 43.7247, GNorm = 9.3051, lr_0 = 6.2018e-04
Loss = 7.9388e-01, PNorm = 43.7529, GNorm = 4.1975, lr_0 = 5.9636e-04
Validation rmse = 0.714445
Epoch 8
Loss = 7.5428e-01, PNorm = 43.7794, GNorm = 2.9597, lr_0 = 5.7122e-04
Loss = 6.9119e-01, PNorm = 43.8040, GNorm = 3.9767, lr_0 = 5.4928e-04
Validation rmse = 0.718137
Epoch 9
Loss = 6.2659e-01, PNorm = 43.8318, GNorm = 3.1997, lr_0 = 5.2819e-04
Loss = 6.6706e-01, PNorm = 43.8548, GNorm = 5.4661, lr_0 = 5.0790e-04
Validation rmse = 0.689576
Epoch 10
Loss = 7.1641e-01, PNorm = 43.8782, GNorm = 5.3039, lr_0 = 4.8649e-04
Loss = 6.7431e-01, PNorm = 43.9033, GNorm = 6.4138, lr_0 = 4.6781e-04
Validation rmse = 0.719702
Epoch 11
Loss = 5.5203e-01, PNorm = 43.9220, GNorm = 3.3317, lr_0 = 4.4984e-04
Loss = 6.4247e-01, PNorm = 43.9470, GNorm = 13.4497, lr_0 = 4.3257e-04
Validation rmse = 0.688810
Epoch 12
Loss = 7.3224e-01, PNorm = 43.9632, GNorm = 2.9183, lr_0 = 4.1433e-04
Loss = 5.9695e-01, PNorm = 43.9791, GNorm = 3.3184, lr_0 = 3.9842e-04
Loss = 6.2256e-01, PNorm = 43.9957, GNorm = 5.3844, lr_0 = 3.8312e-04
Validation rmse = 0.758282
Epoch 13
Loss = 6.4850e-01, PNorm = 44.0118, GNorm = 8.8697, lr_0 = 3.6841e-04
Loss = 6.4034e-01, PNorm = 44.0291, GNorm = 10.2243, lr_0 = 3.5426e-04
Validation rmse = 0.677787
Epoch 14
Loss = 5.9971e-01, PNorm = 44.0475, GNorm = 6.9949, lr_0 = 3.4065e-04
Loss = 6.0036e-01, PNorm = 44.0634, GNorm = 3.0601, lr_0 = 3.2757e-04
Validation rmse = 0.654112
Epoch 15
Loss = 5.6124e-01, PNorm = 44.0801, GNorm = 3.0607, lr_0 = 3.1376e-04
Loss = 5.3652e-01, PNorm = 44.0917, GNorm = 2.1101, lr_0 = 3.0171e-04
Validation rmse = 0.658470
Epoch 16
Loss = 4.9561e-01, PNorm = 44.1024, GNorm = 3.3156, lr_0 = 2.9012e-04
Loss = 5.4920e-01, PNorm = 44.1145, GNorm = 13.4801, lr_0 = 2.7898e-04
Validation rmse = 0.672676
Epoch 17
Loss = 5.5423e-01, PNorm = 44.1244, GNorm = 7.0078, lr_0 = 2.6722e-04
Loss = 5.1197e-01, PNorm = 44.1390, GNorm = 9.8804, lr_0 = 2.5696e-04
Validation rmse = 0.656530
Epoch 18
Loss = 4.5637e-01, PNorm = 44.1482, GNorm = 3.5953, lr_0 = 2.4709e-04
Loss = 4.9971e-01, PNorm = 44.1601, GNorm = 8.3985, lr_0 = 2.3760e-04
Loss = 4.9398e-01, PNorm = 44.1689, GNorm = 7.8478, lr_0 = 2.2848e-04
Validation rmse = 0.646663
Epoch 19
Loss = 4.8391e-01, PNorm = 44.1774, GNorm = 10.1117, lr_0 = 2.1970e-04
Loss = 4.9247e-01, PNorm = 44.1879, GNorm = 7.5410, lr_0 = 2.1127e-04
Validation rmse = 0.656621
Epoch 20
Loss = 5.2490e-01, PNorm = 44.1987, GNorm = 7.4728, lr_0 = 2.0236e-04
Loss = 4.6771e-01, PNorm = 44.2075, GNorm = 18.8383, lr_0 = 1.9459e-04
Validation rmse = 0.716748
Epoch 21
Loss = 5.5963e-01, PNorm = 44.2129, GNorm = 17.8092, lr_0 = 1.8712e-04
Loss = 5.3155e-01, PNorm = 44.2201, GNorm = 8.4346, lr_0 = 1.7993e-04
Validation rmse = 0.645339
Epoch 22
Loss = 3.7814e-01, PNorm = 44.2298, GNorm = 3.6891, lr_0 = 1.7234e-04
Loss = 4.7151e-01, PNorm = 44.2387, GNorm = 7.0585, lr_0 = 1.6572e-04
Validation rmse = 0.639709
Epoch 23
Loss = 3.5072e-01, PNorm = 44.2460, GNorm = 3.6785, lr_0 = 1.5936e-04
Loss = 4.8038e-01, PNorm = 44.2514, GNorm = 5.9289, lr_0 = 1.5324e-04
Validation rmse = 0.643846
Epoch 24
Loss = 3.4906e-01, PNorm = 44.2581, GNorm = 4.8426, lr_0 = 1.4678e-04
Loss = 4.2688e-01, PNorm = 44.2652, GNorm = 5.7763, lr_0 = 1.4114e-04
Validation rmse = 0.645020
Epoch 25
Loss = 4.8343e-01, PNorm = 44.2705, GNorm = 2.6726, lr_0 = 1.3572e-04
Loss = 4.0175e-01, PNorm = 44.2765, GNorm = 4.7246, lr_0 = 1.3051e-04
Loss = 4.5582e-01, PNorm = 44.2826, GNorm = 6.3737, lr_0 = 1.2550e-04
Validation rmse = 0.638360
Epoch 26
Loss = 3.8180e-01, PNorm = 44.2890, GNorm = 3.5324, lr_0 = 1.2068e-04
Loss = 4.4048e-01, PNorm = 44.2932, GNorm = 4.6055, lr_0 = 1.1604e-04
Validation rmse = 0.639198
Epoch 27
Loss = 3.7834e-01, PNorm = 44.2973, GNorm = 3.9869, lr_0 = 1.1115e-04
Loss = 4.4571e-01, PNorm = 44.3025, GNorm = 4.1975, lr_0 = 1.0688e-04
Validation rmse = 0.637718
Epoch 28
Loss = 4.3989e-01, PNorm = 44.3063, GNorm = 6.5295, lr_0 = 1.0278e-04
Loss = 3.9049e-01, PNorm = 44.3105, GNorm = 3.6540, lr_0 = 1.0000e-04
Validation rmse = 0.658617
Epoch 29
Loss = 4.2806e-01, PNorm = 44.3157, GNorm = 3.3976, lr_0 = 1.0000e-04
Loss = 4.6880e-01, PNorm = 44.3193, GNorm = 8.8993, lr_0 = 1.0000e-04
Validation rmse = 0.636882
Model 0 best validation rmse = 0.636882 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.649620
Ensemble test rmse = 0.649620
1-fold cross validation
	Seed 0 ==> test rmse = 0.649620
Overall test rmse = 0.649620 +/- 0.000000
Elapsed time = 0:01:51
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.2195e+00, PNorm = 43.2604, GNorm = 2.1026, lr_0 = 3.2500e-04
Loss = 1.4585e+00, PNorm = 43.2590, GNorm = 1.7077, lr_0 = 5.2955e-04
Validation rmse = 1.391257
Epoch 1
Loss = 1.4325e+00, PNorm = 43.2622, GNorm = 1.2535, lr_0 = 7.5455e-04
Loss = 1.3541e+00, PNorm = 43.2737, GNorm = 2.0038, lr_0 = 9.5909e-04
Validation rmse = 1.265926
Epoch 2
Loss = 1.3173e+00, PNorm = 43.3008, GNorm = 2.2022, lr_0 = 9.6692e-04
Loss = 1.1942e+00, PNorm = 43.3367, GNorm = 2.9288, lr_0 = 9.3144e-04
Validation rmse = 1.067288
Epoch 3
Loss = 1.0700e+00, PNorm = 43.3731, GNorm = 2.3847, lr_0 = 8.9727e-04
Loss = 1.0821e+00, PNorm = 43.4253, GNorm = 10.8038, lr_0 = 8.6435e-04
Validation rmse = 0.889081
Epoch 4
Loss = 8.8846e-01, PNorm = 43.4749, GNorm = 2.1845, lr_0 = 8.2953e-04
Loss = 9.6961e-01, PNorm = 43.5097, GNorm = 4.1159, lr_0 = 7.9909e-04
Loss = 9.8072e-01, PNorm = 43.5467, GNorm = 3.2630, lr_0 = 7.6977e-04
Validation rmse = 0.810839
Epoch 5
Loss = 8.9839e-01, PNorm = 43.5877, GNorm = 11.3084, lr_0 = 7.3877e-04
Loss = 8.5737e-01, PNorm = 43.6249, GNorm = 9.4810, lr_0 = 7.1166e-04
Validation rmse = 0.879634
Epoch 6
Loss = 8.6092e-01, PNorm = 43.6525, GNorm = 2.4828, lr_0 = 6.8555e-04
Loss = 8.5497e-01, PNorm = 43.6782, GNorm = 1.9157, lr_0 = 6.6040e-04
Validation rmse = 0.771190
Epoch 7
Loss = 8.2303e-01, PNorm = 43.7119, GNorm = 2.1767, lr_0 = 6.3379e-04
Loss = 8.0774e-01, PNorm = 43.7379, GNorm = 6.4952, lr_0 = 6.1054e-04
Validation rmse = 0.765286
Epoch 8
Loss = 8.2306e-01, PNorm = 43.7587, GNorm = 8.0883, lr_0 = 5.8814e-04
Loss = 7.2531e-01, PNorm = 43.7840, GNorm = 2.9121, lr_0 = 5.6656e-04
Loss = 7.1449e-01, PNorm = 43.8058, GNorm = 5.1546, lr_0 = 5.4577e-04
Validation rmse = 0.773135
Epoch 9
Loss = 6.7344e-01, PNorm = 43.8249, GNorm = 12.3963, lr_0 = 5.2379e-04
Loss = 7.7791e-01, PNorm = 43.8404, GNorm = 2.0385, lr_0 = 5.0457e-04
Validation rmse = 0.727103
Epoch 10
Loss = 6.2895e-01, PNorm = 43.8610, GNorm = 6.3026, lr_0 = 4.8424e-04
Loss = 6.7187e-01, PNorm = 43.8836, GNorm = 3.4074, lr_0 = 4.6648e-04
Validation rmse = 0.728911
Epoch 11
Loss = 5.9848e-01, PNorm = 43.9047, GNorm = 3.5384, lr_0 = 4.4936e-04
Loss = 6.2181e-01, PNorm = 43.9238, GNorm = 5.5250, lr_0 = 4.3288e-04
Validation rmse = 0.783071
Epoch 12
Loss = 6.3960e-01, PNorm = 43.9362, GNorm = 9.1030, lr_0 = 4.1544e-04
Loss = 6.7256e-01, PNorm = 43.9515, GNorm = 2.3142, lr_0 = 4.0020e-04
Loss = 7.5168e-01, PNorm = 43.9685, GNorm = 8.3518, lr_0 = 3.8551e-04
Loss = 7.0381e-01, PNorm = 43.9704, GNorm = 14.8942, lr_0 = 3.8407e-04
Validation rmse = 0.755840
Epoch 13
Loss = 6.8065e-01, PNorm = 43.9875, GNorm = 11.3962, lr_0 = 3.6998e-04
Loss = 6.5041e-01, PNorm = 44.0036, GNorm = 5.1479, lr_0 = 3.5641e-04
Validation rmse = 0.707058
Epoch 14
Loss = 5.4425e-01, PNorm = 44.0179, GNorm = 6.2390, lr_0 = 3.4333e-04
Loss = 6.2431e-01, PNorm = 44.0332, GNorm = 10.4751, lr_0 = 3.3074e-04
Validation rmse = 0.703864
Epoch 15
Loss = 5.6985e-01, PNorm = 44.0463, GNorm = 14.9871, lr_0 = 3.1741e-04
Loss = 5.9583e-01, PNorm = 44.0600, GNorm = 5.7354, lr_0 = 3.0577e-04
Validation rmse = 0.686336
Epoch 16
Loss = 4.7707e-01, PNorm = 44.0698, GNorm = 6.9740, lr_0 = 2.9455e-04
Loss = 5.9114e-01, PNorm = 44.0792, GNorm = 3.7983, lr_0 = 2.8374e-04
Loss = 6.4274e-01, PNorm = 44.0868, GNorm = 13.6628, lr_0 = 2.7333e-04
Loss = 4.1473e-01, PNorm = 44.0879, GNorm = 3.4573, lr_0 = 2.7231e-04
Validation rmse = 0.749703
Epoch 17
Loss = 5.7655e-01, PNorm = 44.0975, GNorm = 2.9887, lr_0 = 2.6232e-04
Loss = 5.5383e-01, PNorm = 44.1084, GNorm = 4.2643, lr_0 = 2.5270e-04
Validation rmse = 0.694512
Epoch 18
Loss = 4.6121e-01, PNorm = 44.1192, GNorm = 5.3373, lr_0 = 2.4252e-04
Loss = 5.2961e-01, PNorm = 44.1295, GNorm = 12.4309, lr_0 = 2.3362e-04
Validation rmse = 0.672288
Epoch 19
Loss = 4.7777e-01, PNorm = 44.1371, GNorm = 6.1978, lr_0 = 2.2505e-04
Loss = 5.1458e-01, PNorm = 44.1445, GNorm = 4.6767, lr_0 = 2.1679e-04
Validation rmse = 0.671962
Epoch 20
Loss = 4.4646e-01, PNorm = 44.1539, GNorm = 5.7879, lr_0 = 2.0806e-04
Loss = 5.5135e-01, PNorm = 44.1629, GNorm = 12.5326, lr_0 = 2.0042e-04
Validation rmse = 0.659544
Epoch 21
Loss = 6.1565e-01, PNorm = 44.1716, GNorm = 5.1635, lr_0 = 1.9235e-04
Loss = 4.9464e-01, PNorm = 44.1801, GNorm = 2.8587, lr_0 = 1.8529e-04
Loss = 4.1612e-01, PNorm = 44.1871, GNorm = 2.9596, lr_0 = 1.7849e-04
Validation rmse = 0.695614
Epoch 22
Loss = 5.1996e-01, PNorm = 44.1922, GNorm = 18.1984, lr_0 = 1.7195e-04
Loss = 5.2410e-01, PNorm = 44.1972, GNorm = 14.5220, lr_0 = 1.6564e-04
Validation rmse = 0.686805
Epoch 23
Loss = 4.9441e-01, PNorm = 44.2052, GNorm = 9.6608, lr_0 = 1.5896e-04
Loss = 4.7963e-01, PNorm = 44.2114, GNorm = 4.6018, lr_0 = 1.5313e-04
Validation rmse = 0.662910
Epoch 24
Loss = 4.1763e-01, PNorm = 44.2174, GNorm = 8.4049, lr_0 = 1.4751e-04
Loss = 5.3612e-01, PNorm = 44.2231, GNorm = 11.2559, lr_0 = 1.4210e-04
Validation rmse = 0.672392
Epoch 25
Loss = 3.6756e-01, PNorm = 44.2284, GNorm = 4.7568, lr_0 = 1.3638e-04
Loss = 4.4139e-01, PNorm = 44.2344, GNorm = 6.0812, lr_0 = 1.3137e-04
Loss = 4.6916e-01, PNorm = 44.2396, GNorm = 3.7008, lr_0 = 1.2655e-04
Validation rmse = 0.668851
Epoch 26
Loss = 3.7785e-01, PNorm = 44.2445, GNorm = 7.2802, lr_0 = 1.2146e-04
Loss = 4.4439e-01, PNorm = 44.2497, GNorm = 7.5862, lr_0 = 1.1700e-04
Validation rmse = 0.660585
Epoch 27
Loss = 3.9646e-01, PNorm = 44.2536, GNorm = 6.1037, lr_0 = 1.1271e-04
Loss = 4.4902e-01, PNorm = 44.2573, GNorm = 12.2670, lr_0 = 1.0857e-04
Validation rmse = 0.662931
Epoch 28
Loss = 4.5787e-01, PNorm = 44.2610, GNorm = 3.4572, lr_0 = 1.0420e-04
Loss = 4.2363e-01, PNorm = 44.2652, GNorm = 5.8237, lr_0 = 1.0037e-04
Validation rmse = 0.663514
Epoch 29
Loss = 5.7880e-01, PNorm = 44.2689, GNorm = 11.4692, lr_0 = 1.0000e-04
Loss = 3.7980e-01, PNorm = 44.2720, GNorm = 4.2863, lr_0 = 1.0000e-04
Loss = 4.5235e-01, PNorm = 44.2761, GNorm = 5.9606, lr_0 = 1.0000e-04
Validation rmse = 0.659866
Model 0 best validation rmse = 0.659544 on epoch 20
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.646264
Ensemble test rmse = 0.646264
1-fold cross validation
	Seed 0 ==> test rmse = 0.646264
Overall test rmse = 0.646264 +/- 0.000000
Elapsed time = 0:01:51
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,449 | train size = 1,159 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8539e+00, PNorm = 43.2607, GNorm = 1.4878, lr_0 = 3.1522e-04
Loss = 1.4411e+00, PNorm = 43.2611, GNorm = 1.2324, lr_0 = 5.1087e-04
Validation rmse = 1.332040
Epoch 1
Loss = 1.4087e+00, PNorm = 43.2711, GNorm = 0.8347, lr_0 = 7.2609e-04
Loss = 1.3091e+00, PNorm = 43.2909, GNorm = 1.1346, lr_0 = 9.2174e-04
Validation rmse = 1.176839
Epoch 2
Loss = 1.2535e+00, PNorm = 43.3218, GNorm = 1.9200, lr_0 = 9.7528e-04
Loss = 1.2158e+00, PNorm = 43.3569, GNorm = 2.7248, lr_0 = 9.4103e-04
Validation rmse = 0.901891
Epoch 3
Loss = 1.0294e+00, PNorm = 43.4182, GNorm = 4.2578, lr_0 = 9.0474e-04
Loss = 1.0486e+00, PNorm = 43.4658, GNorm = 3.3243, lr_0 = 8.7296e-04
Loss = 9.6689e-01, PNorm = 43.5118, GNorm = 2.7997, lr_0 = 8.4230e-04
Validation rmse = 0.832860
Epoch 4
Loss = 9.8211e-01, PNorm = 43.5556, GNorm = 4.5023, lr_0 = 8.0981e-04
Loss = 9.2889e-01, PNorm = 43.5939, GNorm = 3.2052, lr_0 = 7.8137e-04
Validation rmse = 0.778107
Epoch 5
Loss = 9.4689e-01, PNorm = 43.6323, GNorm = 2.0700, lr_0 = 7.5124e-04
Loss = 9.4649e-01, PNorm = 43.6704, GNorm = 2.0829, lr_0 = 7.2485e-04
Validation rmse = 0.761986
Epoch 6
Loss = 7.0585e-01, PNorm = 43.6995, GNorm = 2.1302, lr_0 = 6.9939e-04
Loss = 8.4062e-01, PNorm = 43.7355, GNorm = 1.9191, lr_0 = 6.7483e-04
Loss = 7.3522e-01, PNorm = 43.7613, GNorm = 4.9443, lr_0 = 6.5113e-04
Validation rmse = 0.735201
Epoch 7
Loss = 8.0084e-01, PNorm = 43.7855, GNorm = 2.6320, lr_0 = 6.2601e-04
Loss = 7.5557e-01, PNorm = 43.8124, GNorm = 3.7261, lr_0 = 6.0403e-04
Validation rmse = 0.706922
Epoch 8
Loss = 6.5635e-01, PNorm = 43.8425, GNorm = 6.6698, lr_0 = 5.8073e-04
Loss = 7.1917e-01, PNorm = 43.8653, GNorm = 4.3447, lr_0 = 5.6033e-04
Validation rmse = 0.690864
Epoch 9
Loss = 6.0489e-01, PNorm = 43.8843, GNorm = 6.5075, lr_0 = 5.3872e-04
Loss = 6.6917e-01, PNorm = 43.9037, GNorm = 3.5209, lr_0 = 5.1980e-04
Loss = 6.7534e-01, PNorm = 43.9231, GNorm = 5.1654, lr_0 = 5.0155e-04
Validation rmse = 0.675466
Epoch 10
Loss = 7.1433e-01, PNorm = 43.9475, GNorm = 3.0322, lr_0 = 4.8220e-04
Loss = 6.2021e-01, PNorm = 43.9702, GNorm = 2.4475, lr_0 = 4.6527e-04
Validation rmse = 0.681177
Epoch 11
Loss = 6.2792e-01, PNorm = 43.9950, GNorm = 5.1969, lr_0 = 4.4732e-04
Loss = 5.8690e-01, PNorm = 44.0157, GNorm = 4.6501, lr_0 = 4.3161e-04
Validation rmse = 0.646525
Epoch 12
Loss = 5.3460e-01, PNorm = 44.0301, GNorm = 3.7983, lr_0 = 4.1645e-04
Loss = 5.6895e-01, PNorm = 44.0465, GNorm = 7.2900, lr_0 = 4.0183e-04
Loss = 5.7310e-01, PNorm = 44.0585, GNorm = 5.3528, lr_0 = 3.8771e-04
Validation rmse = 0.650528
Epoch 13
Loss = 5.6201e-01, PNorm = 44.0779, GNorm = 1.9315, lr_0 = 3.7276e-04
Loss = 5.2541e-01, PNorm = 44.0945, GNorm = 5.6131, lr_0 = 3.5967e-04
Validation rmse = 0.646198
Epoch 14
Loss = 5.2216e-01, PNorm = 44.1088, GNorm = 2.9659, lr_0 = 3.4580e-04
Loss = 5.1158e-01, PNorm = 44.1244, GNorm = 11.5833, lr_0 = 3.3365e-04
Validation rmse = 0.658274
Epoch 15
Loss = 4.8861e-01, PNorm = 44.1382, GNorm = 4.0683, lr_0 = 3.2078e-04
Loss = 5.0780e-01, PNorm = 44.1518, GNorm = 6.2730, lr_0 = 3.0952e-04
Loss = 5.7164e-01, PNorm = 44.1612, GNorm = 16.5199, lr_0 = 2.9865e-04
Loss = 4.1127e-01, PNorm = 44.1620, GNorm = 14.2103, lr_0 = 2.9758e-04
Validation rmse = 0.639639
Epoch 16
Loss = 5.4494e-01, PNorm = 44.1703, GNorm = 3.3400, lr_0 = 2.8713e-04
Loss = 5.0769e-01, PNorm = 44.1851, GNorm = 9.2840, lr_0 = 2.7704e-04
Validation rmse = 0.639336
Epoch 17
Loss = 4.9593e-01, PNorm = 44.1947, GNorm = 3.3838, lr_0 = 2.6731e-04
Loss = 5.1206e-01, PNorm = 44.2041, GNorm = 10.0529, lr_0 = 2.5792e-04
Validation rmse = 0.623020
Epoch 18
Loss = 6.1307e-01, PNorm = 44.2164, GNorm = 3.3032, lr_0 = 2.4798e-04
Loss = 4.7509e-01, PNorm = 44.2256, GNorm = 6.6897, lr_0 = 2.3927e-04
Loss = 4.9010e-01, PNorm = 44.2347, GNorm = 14.9514, lr_0 = 2.3086e-04
Loss = 6.4006e-01, PNorm = 44.2351, GNorm = 13.1278, lr_0 = 2.3004e-04
Validation rmse = 0.660812
Epoch 19
Loss = 5.4153e-01, PNorm = 44.2405, GNorm = 2.5284, lr_0 = 2.2196e-04
Loss = 5.5317e-01, PNorm = 44.2485, GNorm = 8.9391, lr_0 = 2.1416e-04
Validation rmse = 0.678270
Epoch 20
Loss = 5.1825e-01, PNorm = 44.2587, GNorm = 6.6170, lr_0 = 2.0590e-04
Loss = 4.6718e-01, PNorm = 44.2677, GNorm = 8.9988, lr_0 = 1.9867e-04
Validation rmse = 0.631480
Epoch 21
Loss = 4.3347e-01, PNorm = 44.2760, GNorm = 2.8994, lr_0 = 1.9101e-04
Loss = 4.8498e-01, PNorm = 44.2828, GNorm = 4.5382, lr_0 = 1.8430e-04
Validation rmse = 0.652752
Epoch 22
Loss = 3.4872e-01, PNorm = 44.2877, GNorm = 2.9975, lr_0 = 1.7719e-04
Loss = 4.4614e-01, PNorm = 44.2943, GNorm = 4.0849, lr_0 = 1.7097e-04
Loss = 4.7476e-01, PNorm = 44.3011, GNorm = 3.0956, lr_0 = 1.6496e-04
Validation rmse = 0.638905
Epoch 23
Loss = 3.9433e-01, PNorm = 44.3097, GNorm = 4.0056, lr_0 = 1.5917e-04
Loss = 4.7784e-01, PNorm = 44.3148, GNorm = 3.8949, lr_0 = 1.5358e-04
Validation rmse = 0.628525
Epoch 24
Loss = 3.0539e-01, PNorm = 44.3201, GNorm = 3.3163, lr_0 = 1.4766e-04
Loss = 5.0162e-01, PNorm = 44.3267, GNorm = 3.5245, lr_0 = 1.4247e-04
Validation rmse = 0.624834
Epoch 25
Loss = 4.7587e-01, PNorm = 44.3315, GNorm = 6.5584, lr_0 = 1.3698e-04
Loss = 4.1260e-01, PNorm = 44.3362, GNorm = 2.4071, lr_0 = 1.3217e-04
Loss = 4.4093e-01, PNorm = 44.3411, GNorm = 5.4587, lr_0 = 1.2752e-04
Validation rmse = 0.631244
Epoch 26
Loss = 4.0648e-01, PNorm = 44.3453, GNorm = 5.3754, lr_0 = 1.2261e-04
Loss = 4.6315e-01, PNorm = 44.3495, GNorm = 6.5089, lr_0 = 1.1830e-04
Validation rmse = 0.630062
Epoch 27
Loss = 4.7562e-01, PNorm = 44.3547, GNorm = 9.9541, lr_0 = 1.1374e-04
Loss = 4.3164e-01, PNorm = 44.3591, GNorm = 4.2277, lr_0 = 1.0974e-04
Validation rmse = 0.628852
Epoch 28
Loss = 4.6453e-01, PNorm = 44.3639, GNorm = 10.1686, lr_0 = 1.0589e-04
Loss = 3.9724e-01, PNorm = 44.3667, GNorm = 3.2747, lr_0 = 1.0217e-04
Loss = 4.1736e-01, PNorm = 44.3706, GNorm = 14.4451, lr_0 = 1.0000e-04
Validation rmse = 0.626200
Epoch 29
Loss = 4.0848e-01, PNorm = 44.3756, GNorm = 5.1081, lr_0 = 1.0000e-04
Loss = 4.9221e-01, PNorm = 44.3783, GNorm = 10.0669, lr_0 = 1.0000e-04
Validation rmse = 0.633646
Model 0 best validation rmse = 0.623020 on epoch 17
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.674537
Ensemble test rmse = 0.674537
1-fold cross validation
	Seed 0 ==> test rmse = 0.674537
Overall test rmse = 0.674537 +/- 0.000000
Elapsed time = 0:01:56
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9862e+00, PNorm = 43.2622, GNorm = 2.4964, lr_0 = 3.1522e-04
Loss = 1.4427e+00, PNorm = 43.2623, GNorm = 2.0931, lr_0 = 5.1087e-04
Validation rmse = 1.351853
Epoch 1
Loss = 1.3594e+00, PNorm = 43.2681, GNorm = 0.8809, lr_0 = 7.2609e-04
Loss = 1.3191e+00, PNorm = 43.2807, GNorm = 1.8290, lr_0 = 9.2174e-04
Validation rmse = 1.180597
Epoch 2
Loss = 1.1874e+00, PNorm = 43.3071, GNorm = 0.8163, lr_0 = 9.7878e-04
Loss = 1.1966e+00, PNorm = 43.3407, GNorm = 2.8694, lr_0 = 9.4440e-04
Loss = 1.1584e+00, PNorm = 43.3800, GNorm = 3.5256, lr_0 = 9.1123e-04
Validation rmse = 0.950510
Epoch 3
Loss = 1.0069e+00, PNorm = 43.4299, GNorm = 3.3072, lr_0 = 8.7922e-04
Loss = 1.0543e+00, PNorm = 43.4643, GNorm = 8.1254, lr_0 = 8.4834e-04
Validation rmse = 0.827525
Epoch 4
Loss = 1.0198e+00, PNorm = 43.5007, GNorm = 1.5304, lr_0 = 8.1855e-04
Loss = 9.4299e-01, PNorm = 43.5453, GNorm = 5.7308, lr_0 = 7.8980e-04
Validation rmse = 0.797264
Epoch 5
Loss = 8.1715e-01, PNorm = 43.5849, GNorm = 3.8351, lr_0 = 7.6206e-04
Loss = 8.2809e-01, PNorm = 43.6152, GNorm = 3.1256, lr_0 = 7.3529e-04
Loss = 8.8000e-01, PNorm = 43.6478, GNorm = 3.4023, lr_0 = 7.0947e-04
Validation rmse = 0.809362
Epoch 6
Loss = 8.3314e-01, PNorm = 43.6858, GNorm = 6.8223, lr_0 = 6.8455e-04
Loss = 8.4751e-01, PNorm = 43.7091, GNorm = 7.8717, lr_0 = 6.6050e-04
Validation rmse = 0.788914
Epoch 7
Loss = 8.3796e-01, PNorm = 43.7337, GNorm = 2.4109, lr_0 = 6.3731e-04
Loss = 7.4162e-01, PNorm = 43.7656, GNorm = 4.8268, lr_0 = 6.1492e-04
Loss = 7.3824e-01, PNorm = 43.7976, GNorm = 3.6598, lr_0 = 5.9332e-04
Validation rmse = 0.720551
Epoch 8
Loss = 7.8337e-01, PNorm = 43.8226, GNorm = 2.4487, lr_0 = 5.7248e-04
Loss = 7.1278e-01, PNorm = 43.8466, GNorm = 6.2005, lr_0 = 5.5238e-04
Validation rmse = 0.710542
Epoch 9
Loss = 6.5953e-01, PNorm = 43.8712, GNorm = 9.6159, lr_0 = 5.3298e-04
Loss = 6.3519e-01, PNorm = 43.8948, GNorm = 5.0676, lr_0 = 5.1426e-04
Validation rmse = 0.694675
Epoch 10
Loss = 5.4117e-01, PNorm = 43.9165, GNorm = 2.4080, lr_0 = 4.9619e-04
Loss = 6.3035e-01, PNorm = 43.9404, GNorm = 5.1389, lr_0 = 4.7877e-04
Loss = 6.2166e-01, PNorm = 43.9585, GNorm = 3.2703, lr_0 = 4.6195e-04
Validation rmse = 0.674182
Epoch 11
Loss = 5.6203e-01, PNorm = 43.9795, GNorm = 9.3782, lr_0 = 4.4573e-04
Loss = 5.9357e-01, PNorm = 44.0031, GNorm = 4.8044, lr_0 = 4.3007e-04
Validation rmse = 0.677328
Epoch 12
Loss = 4.8539e-01, PNorm = 44.0204, GNorm = 5.1335, lr_0 = 4.1497e-04
Loss = 6.0151e-01, PNorm = 44.0356, GNorm = 8.4848, lr_0 = 4.0039e-04
Loss = 6.1893e-01, PNorm = 44.0552, GNorm = 3.5822, lr_0 = 3.8633e-04
Validation rmse = 0.664023
Epoch 13
Loss = 5.7353e-01, PNorm = 44.0749, GNorm = 12.6267, lr_0 = 3.7276e-04
Loss = 5.1376e-01, PNorm = 44.0885, GNorm = 2.7199, lr_0 = 3.5967e-04
Validation rmse = 0.662224
Epoch 14
Loss = 5.3183e-01, PNorm = 44.0999, GNorm = 2.2418, lr_0 = 3.4703e-04
Loss = 5.6895e-01, PNorm = 44.1136, GNorm = 4.3865, lr_0 = 3.3485e-04
Validation rmse = 0.666903
Epoch 15
Loss = 5.8086e-01, PNorm = 44.1299, GNorm = 5.1768, lr_0 = 3.2308e-04
Loss = 5.6087e-01, PNorm = 44.1453, GNorm = 5.6553, lr_0 = 3.1174e-04
Loss = 4.7947e-01, PNorm = 44.1595, GNorm = 11.2548, lr_0 = 3.0079e-04
Validation rmse = 0.644095
Epoch 16
Loss = 4.9356e-01, PNorm = 44.1682, GNorm = 2.8499, lr_0 = 2.9022e-04
Loss = 5.1915e-01, PNorm = 44.1796, GNorm = 7.6350, lr_0 = 2.8003e-04
Validation rmse = 0.663284
Epoch 17
Loss = 4.3456e-01, PNorm = 44.1922, GNorm = 3.4902, lr_0 = 2.7019e-04
Loss = 5.1868e-01, PNorm = 44.2051, GNorm = 6.3830, lr_0 = 2.6070e-04
Loss = 4.8848e-01, PNorm = 44.2148, GNorm = 8.8399, lr_0 = 2.5155e-04
Validation rmse = 0.667762
Epoch 18
Loss = 4.4842e-01, PNorm = 44.2258, GNorm = 4.3699, lr_0 = 2.4271e-04
Loss = 4.7232e-01, PNorm = 44.2347, GNorm = 6.3989, lr_0 = 2.3419e-04
Validation rmse = 0.656947
Epoch 19
Loss = 4.0181e-01, PNorm = 44.2451, GNorm = 3.9574, lr_0 = 2.2596e-04
Loss = 4.7554e-01, PNorm = 44.2550, GNorm = 6.0707, lr_0 = 2.1803e-04
Validation rmse = 0.660740
Epoch 20
Loss = 6.2421e-01, PNorm = 44.2610, GNorm = 7.9476, lr_0 = 2.1037e-04
Loss = 4.7203e-01, PNorm = 44.2675, GNorm = 3.5615, lr_0 = 2.0298e-04
Loss = 4.5696e-01, PNorm = 44.2774, GNorm = 13.0226, lr_0 = 1.9585e-04
Validation rmse = 0.659350
Epoch 21
Loss = 4.6142e-01, PNorm = 44.2842, GNorm = 2.8828, lr_0 = 1.8897e-04
Loss = 4.3540e-01, PNorm = 44.2905, GNorm = 5.1030, lr_0 = 1.8233e-04
Validation rmse = 0.646884
Epoch 22
Loss = 4.1708e-01, PNorm = 44.2994, GNorm = 9.7119, lr_0 = 1.7593e-04
Loss = 4.1185e-01, PNorm = 44.3066, GNorm = 11.4267, lr_0 = 1.6975e-04
Loss = 4.4820e-01, PNorm = 44.3139, GNorm = 5.6901, lr_0 = 1.6379e-04
Validation rmse = 0.634323
Epoch 23
Loss = 3.6650e-01, PNorm = 44.3191, GNorm = 3.1070, lr_0 = 1.5804e-04
Loss = 5.0447e-01, PNorm = 44.3249, GNorm = 8.4341, lr_0 = 1.5249e-04
Validation rmse = 0.679983
Epoch 24
Loss = 4.4046e-01, PNorm = 44.3302, GNorm = 5.4884, lr_0 = 1.4713e-04
Loss = 4.3940e-01, PNorm = 44.3365, GNorm = 4.4658, lr_0 = 1.4196e-04
Validation rmse = 0.676033
Epoch 25
Loss = 5.4521e-01, PNorm = 44.3416, GNorm = 8.8300, lr_0 = 1.3698e-04
Loss = 4.0190e-01, PNorm = 44.3478, GNorm = 3.1495, lr_0 = 1.3217e-04
Loss = 4.6523e-01, PNorm = 44.3522, GNorm = 10.9727, lr_0 = 1.2752e-04
Validation rmse = 0.643695
Epoch 26
Loss = 4.1972e-01, PNorm = 44.3557, GNorm = 8.7860, lr_0 = 1.2304e-04
Loss = 3.9736e-01, PNorm = 44.3605, GNorm = 8.3431, lr_0 = 1.1872e-04
Validation rmse = 0.645152
Epoch 27
Loss = 3.4051e-01, PNorm = 44.3657, GNorm = 8.4955, lr_0 = 1.1455e-04
Loss = 4.0378e-01, PNorm = 44.3703, GNorm = 8.4519, lr_0 = 1.1053e-04
Loss = 4.3043e-01, PNorm = 44.3736, GNorm = 9.8770, lr_0 = 1.0665e-04
Validation rmse = 0.640397
Epoch 28
Loss = 4.1646e-01, PNorm = 44.3771, GNorm = 3.5110, lr_0 = 1.0290e-04
Loss = 3.8020e-01, PNorm = 44.3813, GNorm = 11.3313, lr_0 = 1.0000e-04
Validation rmse = 0.648988
Epoch 29
Loss = 4.0136e-01, PNorm = 44.3857, GNorm = 7.7325, lr_0 = 1.0000e-04
Loss = 3.8850e-01, PNorm = 44.3891, GNorm = 3.4018, lr_0 = 1.0000e-04
Validation rmse = 0.646380
Model 0 best validation rmse = 0.634323 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.644651
Ensemble test rmse = 0.644651
1-fold cross validation
	Seed 0 ==> test rmse = 0.644651
Overall test rmse = 0.644651 +/- 0.000000
Elapsed time = 0:02:10
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9731e+00, PNorm = 43.2590, GNorm = 2.3800, lr_0 = 4.3000e-04
Validation rmse = 1.274124
Epoch 1
Loss = 1.4776e+00, PNorm = 43.2626, GNorm = 1.4865, lr_0 = 7.6000e-04
Loss = 1.4247e+00, PNorm = 43.2765, GNorm = 1.3433, lr_0 = 9.8910e-04
Validation rmse = 1.137355
Epoch 2
Loss = 1.3310e+00, PNorm = 43.2976, GNorm = 0.8734, lr_0 = 9.3633e-04
Validation rmse = 1.072906
Epoch 3
Loss = 1.1866e+00, PNorm = 43.3250, GNorm = 0.8771, lr_0 = 8.8638e-04
Loss = 1.2607e+00, PNorm = 43.3586, GNorm = 2.9838, lr_0 = 8.3909e-04
Validation rmse = 0.983507
Epoch 4
Loss = 1.1585e+00, PNorm = 43.3971, GNorm = 3.6664, lr_0 = 7.9433e-04
Validation rmse = 0.920052
Epoch 5
Loss = 9.9389e-01, PNorm = 43.4428, GNorm = 3.5397, lr_0 = 7.5195e-04
Loss = 1.0487e+00, PNorm = 43.4878, GNorm = 4.6485, lr_0 = 7.1184e-04
Validation rmse = 0.838112
Epoch 6
Loss = 9.4423e-01, PNorm = 43.5294, GNorm = 2.2331, lr_0 = 6.7386e-04
Loss = 9.7586e-01, PNorm = 43.5691, GNorm = 3.7560, lr_0 = 6.3791e-04
Validation rmse = 0.834486
Epoch 7
Loss = 8.9966e-01, PNorm = 43.6069, GNorm = 4.1054, lr_0 = 6.0388e-04
Validation rmse = 0.798202
Epoch 8
Loss = 8.4141e-01, PNorm = 43.6464, GNorm = 3.0837, lr_0 = 5.7167e-04
Loss = 8.1447e-01, PNorm = 43.6825, GNorm = 1.8262, lr_0 = 5.4117e-04
Validation rmse = 0.877652
Epoch 9
Loss = 8.6071e-01, PNorm = 43.7122, GNorm = 5.5576, lr_0 = 5.1230e-04
Validation rmse = 0.776964
Epoch 10
Loss = 6.5947e-01, PNorm = 43.7410, GNorm = 3.1203, lr_0 = 4.8497e-04
Loss = 6.8866e-01, PNorm = 43.7660, GNorm = 6.3873, lr_0 = 4.5910e-04
Validation rmse = 0.812532
Epoch 11
Loss = 7.7084e-01, PNorm = 43.7873, GNorm = 7.9059, lr_0 = 4.3461e-04
Loss = 7.3992e-01, PNorm = 43.8098, GNorm = 3.7084, lr_0 = 4.1142e-04
Validation rmse = 0.733233
Epoch 12
Loss = 6.8113e-01, PNorm = 43.8322, GNorm = 11.0386, lr_0 = 3.8947e-04
Validation rmse = 0.702377
Epoch 13
Loss = 6.2493e-01, PNorm = 43.8487, GNorm = 5.4712, lr_0 = 3.6869e-04
Loss = 6.7498e-01, PNorm = 43.8655, GNorm = 7.7276, lr_0 = 3.4903e-04
Validation rmse = 0.754814
Epoch 14
Loss = 7.3329e-01, PNorm = 43.8841, GNorm = 2.4082, lr_0 = 3.3041e-04
Validation rmse = 0.714564
Epoch 15
Loss = 4.8978e-01, PNorm = 43.8999, GNorm = 5.2536, lr_0 = 3.1278e-04
Loss = 5.8340e-01, PNorm = 43.9175, GNorm = 12.2610, lr_0 = 2.9609e-04
Validation rmse = 0.714723
Epoch 16
Loss = 5.8109e-01, PNorm = 43.9297, GNorm = 4.5914, lr_0 = 2.8030e-04
Loss = 5.9273e-01, PNorm = 43.9429, GNorm = 7.8934, lr_0 = 2.6534e-04
Validation rmse = 0.746651
Epoch 17
Loss = 5.9663e-01, PNorm = 43.9544, GNorm = 4.5768, lr_0 = 2.5119e-04
Validation rmse = 0.762959
Epoch 18
Loss = 5.7619e-01, PNorm = 43.9661, GNorm = 5.7595, lr_0 = 2.3779e-04
Loss = 5.4245e-01, PNorm = 43.9784, GNorm = 6.9272, lr_0 = 2.2510e-04
Validation rmse = 0.707867
Epoch 19
Loss = 4.6977e-01, PNorm = 43.9890, GNorm = 7.6933, lr_0 = 2.1309e-04
Validation rmse = 0.716300
Epoch 20
Loss = 6.6458e-01, PNorm = 43.9989, GNorm = 5.9033, lr_0 = 2.0173e-04
Loss = 5.0894e-01, PNorm = 44.0092, GNorm = 5.5260, lr_0 = 1.9096e-04
Validation rmse = 0.698619
Epoch 21
Loss = 4.7779e-01, PNorm = 44.0173, GNorm = 9.1481, lr_0 = 1.8078e-04
Loss = 5.0493e-01, PNorm = 44.0256, GNorm = 5.2034, lr_0 = 1.7113e-04
Validation rmse = 0.705794
Epoch 22
Loss = 4.3472e-01, PNorm = 44.0362, GNorm = 5.9399, lr_0 = 1.6200e-04
Validation rmse = 0.708818
Epoch 23
Loss = 4.2268e-01, PNorm = 44.0424, GNorm = 11.2827, lr_0 = 1.5336e-04
Loss = 5.0790e-01, PNorm = 44.0479, GNorm = 7.1946, lr_0 = 1.4518e-04
Validation rmse = 0.703643
Epoch 24
Loss = 4.8471e-01, PNorm = 44.0544, GNorm = 3.3553, lr_0 = 1.3743e-04
Validation rmse = 0.697865
Epoch 25
Loss = 4.3007e-01, PNorm = 44.0611, GNorm = 4.7837, lr_0 = 1.3010e-04
Loss = 4.3070e-01, PNorm = 44.0680, GNorm = 4.7785, lr_0 = 1.2316e-04
Validation rmse = 0.699277
Epoch 26
Loss = 4.2699e-01, PNorm = 44.0734, GNorm = 6.9595, lr_0 = 1.1659e-04
Loss = 4.4589e-01, PNorm = 44.0794, GNorm = 9.2448, lr_0 = 1.1037e-04
Validation rmse = 0.705869
Epoch 27
Loss = 4.7084e-01, PNorm = 44.0838, GNorm = 6.6450, lr_0 = 1.0448e-04
Validation rmse = 0.699437
Epoch 28
Loss = 4.5640e-01, PNorm = 44.0885, GNorm = 6.9448, lr_0 = 1.0000e-04
Loss = 4.2175e-01, PNorm = 44.0944, GNorm = 5.3902, lr_0 = 1.0000e-04
Validation rmse = 0.698844
Epoch 29
Loss = 4.1397e-01, PNorm = 44.0985, GNorm = 4.4125, lr_0 = 1.0000e-04
Validation rmse = 0.698341
Model 0 best validation rmse = 0.697865 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.822041
Ensemble test rmse = 0.822041
1-fold cross validation
	Seed 0 ==> test rmse = 0.822041
Overall test rmse = 0.822041 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,049 | train size = 839 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9324e+00, PNorm = 43.2594, GNorm = 1.7052, lr_0 = 4.0937e-04
Validation rmse = 1.207474
Epoch 1
Loss = 1.4868e+00, PNorm = 43.2628, GNorm = 1.4835, lr_0 = 7.1875e-04
Loss = 1.4134e+00, PNorm = 43.2762, GNorm = 1.5763, lr_0 = 1.0000e-03
Validation rmse = 1.171599
Epoch 2
Loss = 1.2877e+00, PNorm = 43.2937, GNorm = 2.1172, lr_0 = 9.4990e-04
Loss = 1.3152e+00, PNorm = 43.3152, GNorm = 4.7144, lr_0 = 9.0231e-04
Validation rmse = 1.255056
Epoch 3
Loss = 1.2560e+00, PNorm = 43.3424, GNorm = 1.2876, lr_0 = 8.5711e-04
Validation rmse = 1.042771
Epoch 4
Loss = 1.2031e+00, PNorm = 43.3727, GNorm = 0.8321, lr_0 = 8.1417e-04
Loss = 1.0925e+00, PNorm = 43.4105, GNorm = 1.2567, lr_0 = 7.7338e-04
Validation rmse = 0.984738
Epoch 5
Loss = 1.0493e+00, PNorm = 43.4601, GNorm = 1.3800, lr_0 = 7.3087e-04
Loss = 9.7281e-01, PNorm = 43.5057, GNorm = 1.8624, lr_0 = 6.9425e-04
Validation rmse = 0.891469
Epoch 6
Loss = 9.0983e-01, PNorm = 43.5505, GNorm = 3.3640, lr_0 = 6.5947e-04
Validation rmse = 0.827868
Epoch 7
Loss = 8.9716e-01, PNorm = 43.5918, GNorm = 4.9791, lr_0 = 6.2643e-04
Loss = 8.8586e-01, PNorm = 43.6294, GNorm = 3.3810, lr_0 = 5.9505e-04
Validation rmse = 0.837165
Epoch 8
Loss = 8.0066e-01, PNorm = 43.6698, GNorm = 6.9875, lr_0 = 5.6524e-04
Loss = 8.1690e-01, PNorm = 43.7046, GNorm = 2.9703, lr_0 = 5.3692e-04
Validation rmse = 0.790725
Epoch 9
Loss = 7.1745e-01, PNorm = 43.7328, GNorm = 4.5696, lr_0 = 5.1002e-04
Validation rmse = 0.705148
Epoch 10
Loss = 7.3779e-01, PNorm = 43.7667, GNorm = 10.8623, lr_0 = 4.8199e-04
Loss = 7.6264e-01, PNorm = 43.7928, GNorm = 4.6699, lr_0 = 4.5784e-04
Validation rmse = 0.726920
Epoch 11
Loss = 6.4089e-01, PNorm = 43.8202, GNorm = 3.4901, lr_0 = 4.3490e-04
Loss = 6.8476e-01, PNorm = 43.8459, GNorm = 14.9407, lr_0 = 4.1312e-04
Validation rmse = 0.718200
Epoch 12
Loss = 6.3974e-01, PNorm = 43.8655, GNorm = 2.9950, lr_0 = 3.9242e-04
Validation rmse = 0.690838
Epoch 13
Loss = 4.8088e-01, PNorm = 43.8903, GNorm = 5.2537, lr_0 = 3.7276e-04
Loss = 6.1877e-01, PNorm = 43.9128, GNorm = 6.4132, lr_0 = 3.5408e-04
Validation rmse = 0.695496
Epoch 14
Loss = 6.5109e-01, PNorm = 43.9318, GNorm = 6.3049, lr_0 = 3.3462e-04
Loss = 5.7254e-01, PNorm = 43.9513, GNorm = 5.0916, lr_0 = 3.1786e-04
Validation rmse = 0.686908
Epoch 15
Loss = 5.1566e-01, PNorm = 43.9692, GNorm = 5.1523, lr_0 = 3.0193e-04
Validation rmse = 0.669699
Epoch 16
Loss = 5.9684e-01, PNorm = 43.9848, GNorm = 8.4872, lr_0 = 2.8681e-04
Loss = 5.0305e-01, PNorm = 43.9985, GNorm = 7.6263, lr_0 = 2.7244e-04
Validation rmse = 0.682432
Epoch 17
Loss = 5.8944e-01, PNorm = 44.0119, GNorm = 10.2939, lr_0 = 2.5879e-04
Loss = 5.7334e-01, PNorm = 44.0235, GNorm = 11.4202, lr_0 = 2.4582e-04
Validation rmse = 0.658669
Epoch 18
Loss = 5.4308e-01, PNorm = 44.0350, GNorm = 5.4656, lr_0 = 2.3351e-04
Validation rmse = 0.655817
Epoch 19
Loss = 4.6994e-01, PNorm = 44.0485, GNorm = 9.6575, lr_0 = 2.2067e-04
Loss = 4.6542e-01, PNorm = 44.0609, GNorm = 12.9810, lr_0 = 2.0962e-04
Validation rmse = 0.644665
Epoch 20
Loss = 4.6843e-01, PNorm = 44.0702, GNorm = 6.3787, lr_0 = 1.9912e-04
Loss = 4.9765e-01, PNorm = 44.0815, GNorm = 15.8544, lr_0 = 1.8914e-04
Validation rmse = 0.639855
Epoch 21
Loss = 4.1578e-01, PNorm = 44.0902, GNorm = 5.1124, lr_0 = 1.7967e-04
Validation rmse = 0.636053
Epoch 22
Loss = 2.8986e-01, PNorm = 44.0988, GNorm = 5.6875, lr_0 = 1.7066e-04
Loss = 4.6055e-01, PNorm = 44.1081, GNorm = 2.8767, lr_0 = 1.6211e-04
Validation rmse = 0.644583
Epoch 23
Loss = 4.1936e-01, PNorm = 44.1158, GNorm = 8.5294, lr_0 = 1.5320e-04
Loss = 4.5855e-01, PNorm = 44.1234, GNorm = 4.0701, lr_0 = 1.4553e-04
Validation rmse = 0.649016
Epoch 24
Loss = 4.3469e-01, PNorm = 44.1298, GNorm = 10.5103, lr_0 = 1.3824e-04
Validation rmse = 0.644027
Epoch 25
Loss = 5.8503e-01, PNorm = 44.1351, GNorm = 13.5021, lr_0 = 1.3131e-04
Loss = 4.1124e-01, PNorm = 44.1421, GNorm = 5.5866, lr_0 = 1.2473e-04
Validation rmse = 0.628710
Epoch 26
Loss = 3.5262e-01, PNorm = 44.1483, GNorm = 3.3318, lr_0 = 1.1848e-04
Loss = 4.3433e-01, PNorm = 44.1542, GNorm = 12.5297, lr_0 = 1.1255e-04
Validation rmse = 0.629120
Epoch 27
Loss = 4.0441e-01, PNorm = 44.1593, GNorm = 3.4462, lr_0 = 1.0691e-04
Validation rmse = 0.630021
Epoch 28
Loss = 3.0780e-01, PNorm = 44.1646, GNorm = 3.7913, lr_0 = 1.0103e-04
Loss = 3.8381e-01, PNorm = 44.1692, GNorm = 8.9699, lr_0 = 1.0000e-04
Validation rmse = 0.628067
Epoch 29
Loss = 4.7178e-01, PNorm = 44.1734, GNorm = 7.8506, lr_0 = 1.0000e-04
Loss = 4.0264e-01, PNorm = 44.1783, GNorm = 8.9457, lr_0 = 1.0000e-04
Validation rmse = 0.643100
Model 0 best validation rmse = 0.628067 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.797335
Ensemble test rmse = 0.797335
1-fold cross validation
	Seed 0 ==> test rmse = 0.797335
Overall test rmse = 0.797335 +/- 0.000000
Elapsed time = 0:01:33
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0102e+00, PNorm = 43.2606, GNorm = 1.0424, lr_0 = 3.9118e-04
Validation rmse = 1.317489
Epoch 1
Loss = 1.4778e+00, PNorm = 43.2633, GNorm = 1.5042, lr_0 = 6.8235e-04
Loss = 1.4160e+00, PNorm = 43.2729, GNorm = 2.0650, lr_0 = 9.4706e-04
Validation rmse = 1.259154
Epoch 2
Loss = 1.2360e+00, PNorm = 43.2941, GNorm = 1.9730, lr_0 = 9.6204e-04
Loss = 1.2733e+00, PNorm = 43.3195, GNorm = 1.4749, lr_0 = 9.1661e-04
Validation rmse = 1.159192
Epoch 3
Loss = 1.1775e+00, PNorm = 43.3570, GNorm = 1.4654, lr_0 = 8.6911e-04
Loss = 1.1720e+00, PNorm = 43.3967, GNorm = 1.9900, lr_0 = 8.2807e-04
Validation rmse = 1.039829
Epoch 4
Loss = 1.0730e+00, PNorm = 43.4379, GNorm = 6.0701, lr_0 = 7.8897e-04
Validation rmse = 0.971949
Epoch 5
Loss = 8.9922e-01, PNorm = 43.4830, GNorm = 1.4796, lr_0 = 7.4808e-04
Loss = 9.5939e-01, PNorm = 43.5285, GNorm = 5.9237, lr_0 = 7.1276e-04
Validation rmse = 1.018840
Epoch 6
Loss = 9.3124e-01, PNorm = 43.5645, GNorm = 1.3910, lr_0 = 6.7910e-04
Loss = 8.9188e-01, PNorm = 43.6075, GNorm = 3.2358, lr_0 = 6.4703e-04
Validation rmse = 0.873643
Epoch 7
Loss = 8.4905e-01, PNorm = 43.6479, GNorm = 2.0396, lr_0 = 6.1648e-04
Loss = 7.6214e-01, PNorm = 43.6862, GNorm = 1.8886, lr_0 = 5.8736e-04
Loss = 8.8252e-01, PNorm = 43.6895, GNorm = 4.2248, lr_0 = 5.8453e-04
Validation rmse = 0.855967
Epoch 8
Loss = 7.7187e-01, PNorm = 43.7268, GNorm = 13.6132, lr_0 = 5.5693e-04
Validation rmse = 0.982877
Epoch 9
Loss = 7.1400e-01, PNorm = 43.7574, GNorm = 9.9285, lr_0 = 5.3063e-04
Loss = 7.7112e-01, PNorm = 43.7883, GNorm = 2.2766, lr_0 = 5.0557e-04
Validation rmse = 0.922675
Epoch 10
Loss = 7.7387e-01, PNorm = 43.8168, GNorm = 3.9599, lr_0 = 4.7937e-04
Loss = 6.9792e-01, PNorm = 43.8401, GNorm = 4.3900, lr_0 = 4.5673e-04
Validation rmse = 0.845282
Epoch 11
Loss = 6.8513e-01, PNorm = 43.8663, GNorm = 4.9214, lr_0 = 4.3517e-04
Loss = 6.7621e-01, PNorm = 43.8911, GNorm = 11.4298, lr_0 = 4.1462e-04
Loss = 9.5628e-01, PNorm = 43.8937, GNorm = 5.7942, lr_0 = 4.1262e-04
Validation rmse = 0.808579
Epoch 12
Loss = 6.9481e-01, PNorm = 43.9126, GNorm = 6.1600, lr_0 = 3.9313e-04
Validation rmse = 0.825082
Epoch 13
Loss = 6.4200e-01, PNorm = 43.9319, GNorm = 4.9817, lr_0 = 3.7457e-04
Loss = 5.5916e-01, PNorm = 43.9550, GNorm = 5.3754, lr_0 = 3.5688e-04
Validation rmse = 0.797274
Epoch 14
Loss = 6.4607e-01, PNorm = 43.9711, GNorm = 3.9674, lr_0 = 3.4003e-04
Loss = 5.5946e-01, PNorm = 43.9895, GNorm = 11.5939, lr_0 = 3.2397e-04
Validation rmse = 0.834448
Epoch 15
Loss = 5.6010e-01, PNorm = 44.0036, GNorm = 19.8251, lr_0 = 3.0718e-04
Loss = 6.0689e-01, PNorm = 44.0161, GNorm = 4.0327, lr_0 = 2.9268e-04
Validation rmse = 0.785264
Epoch 16
Loss = 5.6862e-01, PNorm = 44.0304, GNorm = 2.4726, lr_0 = 2.7885e-04
Validation rmse = 0.856400
Epoch 17
Loss = 4.4600e-01, PNorm = 44.0465, GNorm = 6.5626, lr_0 = 2.6440e-04
Loss = 5.3005e-01, PNorm = 44.0623, GNorm = 7.0574, lr_0 = 2.5192e-04
Validation rmse = 0.776614
Epoch 18
Loss = 5.2719e-01, PNorm = 44.0732, GNorm = 7.5498, lr_0 = 2.4002e-04
Loss = 5.1285e-01, PNorm = 44.0852, GNorm = 12.9460, lr_0 = 2.2869e-04
Validation rmse = 0.826787
Epoch 19
Loss = 5.7376e-01, PNorm = 44.0947, GNorm = 5.0709, lr_0 = 2.1789e-04
Loss = 4.4437e-01, PNorm = 44.1064, GNorm = 3.0904, lr_0 = 2.0760e-04
Validation rmse = 0.791364
Epoch 20
Loss = 4.4996e-01, PNorm = 44.1161, GNorm = 3.5135, lr_0 = 1.9684e-04
Validation rmse = 0.778853
Epoch 21
Loss = 6.0575e-01, PNorm = 44.1259, GNorm = 2.9109, lr_0 = 1.8755e-04
Loss = 4.5118e-01, PNorm = 44.1357, GNorm = 5.6222, lr_0 = 1.7869e-04
Validation rmse = 0.760238
Epoch 22
Loss = 4.4704e-01, PNorm = 44.1448, GNorm = 4.0544, lr_0 = 1.6943e-04
Loss = 4.6368e-01, PNorm = 44.1548, GNorm = 14.2542, lr_0 = 1.6143e-04
Validation rmse = 0.824034
Epoch 23
Loss = 4.1640e-01, PNorm = 44.1618, GNorm = 7.4561, lr_0 = 1.5381e-04
Loss = 4.5916e-01, PNorm = 44.1692, GNorm = 11.8131, lr_0 = 1.4654e-04
Validation rmse = 0.770573
Epoch 24
Loss = 4.6214e-01, PNorm = 44.1769, GNorm = 12.4718, lr_0 = 1.3895e-04
Validation rmse = 0.759738
Epoch 25
Loss = 3.4057e-01, PNorm = 44.1840, GNorm = 4.3163, lr_0 = 1.3239e-04
Loss = 4.6688e-01, PNorm = 44.1895, GNorm = 7.1205, lr_0 = 1.2614e-04
Validation rmse = 0.812836
Epoch 26
Loss = 4.2559e-01, PNorm = 44.1951, GNorm = 8.2464, lr_0 = 1.2018e-04
Loss = 4.4837e-01, PNorm = 44.2011, GNorm = 3.3952, lr_0 = 1.1450e-04
Validation rmse = 0.763063
Epoch 27
Loss = 3.9900e-01, PNorm = 44.2084, GNorm = 6.9896, lr_0 = 1.0857e-04
Loss = 4.0887e-01, PNorm = 44.2142, GNorm = 3.8472, lr_0 = 1.0344e-04
Validation rmse = 0.800050
Epoch 28
Loss = 3.9113e-01, PNorm = 44.2185, GNorm = 7.8796, lr_0 = 1.0000e-04
Validation rmse = 0.763536
Epoch 29
Loss = 5.7206e-01, PNorm = 44.2239, GNorm = 3.9023, lr_0 = 1.0000e-04
Loss = 4.0657e-01, PNorm = 44.2292, GNorm = 11.7107, lr_0 = 1.0000e-04
Validation rmse = 0.769264
Model 0 best validation rmse = 0.759738 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.535061
Ensemble test rmse = 0.535061
1-fold cross validation
	Seed 0 ==> test rmse = 0.535061
Overall test rmse = 0.535061 +/- 0.000000
Elapsed time = 0:01:38
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,149 | train size = 919 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9764e+00, PNorm = 43.2610, GNorm = 2.6027, lr_0 = 3.7500e-04
Validation rmse = 1.163938
Epoch 1
Loss = 1.4639e+00, PNorm = 43.2617, GNorm = 1.6071, lr_0 = 6.5000e-04
Loss = 1.4281e+00, PNorm = 43.2690, GNorm = 0.9267, lr_0 = 9.0000e-04
Validation rmse = 1.116075
Epoch 2
Loss = 1.3244e+00, PNorm = 43.2844, GNorm = 1.3627, lr_0 = 9.6853e-04
Loss = 1.2907e+00, PNorm = 43.3052, GNorm = 1.5364, lr_0 = 9.2527e-04
Validation rmse = 1.035387
Epoch 3
Loss = 1.3104e+00, PNorm = 43.3327, GNorm = 1.7005, lr_0 = 8.8395e-04
Loss = 1.2057e+00, PNorm = 43.3649, GNorm = 3.6885, lr_0 = 8.4448e-04
Validation rmse = 0.976603
Epoch 4
Loss = 1.1187e+00, PNorm = 43.4077, GNorm = 2.2372, lr_0 = 8.0309e-04
Loss = 1.0538e+00, PNorm = 43.4568, GNorm = 5.7537, lr_0 = 7.6722e-04
Validation rmse = 1.017973
Epoch 5
Loss = 1.0598e+00, PNorm = 43.4982, GNorm = 1.8930, lr_0 = 7.2962e-04
Loss = 1.0077e+00, PNorm = 43.5430, GNorm = 1.8136, lr_0 = 6.9703e-04
Validation rmse = 0.855152
Epoch 6
Loss = 8.9134e-01, PNorm = 43.5879, GNorm = 3.8461, lr_0 = 6.6591e-04
Validation rmse = 0.856511
Epoch 7
Loss = 7.7517e-01, PNorm = 43.6360, GNorm = 4.1019, lr_0 = 6.3327e-04
Loss = 8.3809e-01, PNorm = 43.6825, GNorm = 2.3557, lr_0 = 6.0499e-04
Validation rmse = 0.907173
Epoch 8
Loss = 8.3227e-01, PNorm = 43.7171, GNorm = 4.8608, lr_0 = 5.7797e-04
Loss = 7.9404e-01, PNorm = 43.7555, GNorm = 8.5456, lr_0 = 5.5216e-04
Validation rmse = 0.810068
Epoch 9
Loss = 7.4498e-01, PNorm = 43.7880, GNorm = 2.7991, lr_0 = 5.2510e-04
Loss = 6.8284e-01, PNorm = 43.8185, GNorm = 4.8081, lr_0 = 5.0165e-04
Validation rmse = 0.825996
Epoch 10
Loss = 6.9622e-01, PNorm = 43.8486, GNorm = 3.1685, lr_0 = 4.7706e-04
Loss = 7.7612e-01, PNorm = 43.8704, GNorm = 7.8469, lr_0 = 4.5575e-04
Validation rmse = 0.777693
Epoch 11
Loss = 6.2486e-01, PNorm = 43.8957, GNorm = 2.6880, lr_0 = 4.3540e-04
Loss = 7.0676e-01, PNorm = 43.9223, GNorm = 2.7052, lr_0 = 4.1596e-04
Loss = 7.9462e-01, PNorm = 43.9244, GNorm = 7.2018, lr_0 = 4.1406e-04
Validation rmse = 0.760643
Epoch 12
Loss = 6.0574e-01, PNorm = 43.9457, GNorm = 2.6598, lr_0 = 3.9557e-04
Validation rmse = 0.788219
Epoch 13
Loss = 4.7308e-01, PNorm = 43.9687, GNorm = 4.1575, lr_0 = 3.7618e-04
Loss = 6.2944e-01, PNorm = 43.9861, GNorm = 7.0051, lr_0 = 3.5938e-04
Validation rmse = 0.741397
Epoch 14
Loss = 5.2149e-01, PNorm = 44.0017, GNorm = 4.9486, lr_0 = 3.4333e-04
Loss = 5.8346e-01, PNorm = 44.0204, GNorm = 7.7330, lr_0 = 3.2800e-04
Validation rmse = 0.750879
Epoch 15
Loss = 5.7108e-01, PNorm = 44.0420, GNorm = 9.5396, lr_0 = 3.1192e-04
Loss = 5.3679e-01, PNorm = 44.0549, GNorm = 2.9623, lr_0 = 2.9799e-04
Validation rmse = 0.742195
Epoch 16
Loss = 5.3459e-01, PNorm = 44.0684, GNorm = 7.8016, lr_0 = 2.8469e-04
Loss = 5.3425e-01, PNorm = 44.0820, GNorm = 14.9021, lr_0 = 2.7197e-04
Validation rmse = 0.739825
Epoch 17
Loss = 4.6764e-01, PNorm = 44.0953, GNorm = 3.5684, lr_0 = 2.5864e-04
Loss = 4.9562e-01, PNorm = 44.1098, GNorm = 9.4247, lr_0 = 2.4709e-04
Loss = 1.1371e+00, PNorm = 44.1101, GNorm = 11.0337, lr_0 = 2.4596e-04
Validation rmse = 0.745314
Epoch 18
Loss = 4.6786e-01, PNorm = 44.1187, GNorm = 8.9249, lr_0 = 2.3498e-04
Validation rmse = 0.732840
Epoch 19
Loss = 4.3646e-01, PNorm = 44.1289, GNorm = 7.7334, lr_0 = 2.2449e-04
Loss = 4.7756e-01, PNorm = 44.1411, GNorm = 5.9709, lr_0 = 2.1446e-04
Validation rmse = 0.739157
Epoch 20
Loss = 3.7225e-01, PNorm = 44.1508, GNorm = 4.9333, lr_0 = 2.0395e-04
Loss = 5.0796e-01, PNorm = 44.1580, GNorm = 3.6082, lr_0 = 1.9484e-04
Validation rmse = 0.739192
Epoch 21
Loss = 4.9765e-01, PNorm = 44.1667, GNorm = 11.5400, lr_0 = 1.8529e-04
Loss = 4.8115e-01, PNorm = 44.1751, GNorm = 3.4136, lr_0 = 1.7702e-04
Validation rmse = 0.724214
Epoch 22
Loss = 3.7833e-01, PNorm = 44.1847, GNorm = 3.6485, lr_0 = 1.6911e-04
Loss = 4.7254e-01, PNorm = 44.1925, GNorm = 7.5642, lr_0 = 1.6156e-04
Validation rmse = 0.726059
Epoch 23
Loss = 3.6831e-01, PNorm = 44.2007, GNorm = 5.3740, lr_0 = 1.5364e-04
Loss = 4.8049e-01, PNorm = 44.2071, GNorm = 8.8759, lr_0 = 1.4678e-04
Validation rmse = 0.751175
Epoch 24
Loss = 4.7082e-01, PNorm = 44.2124, GNorm = 9.2592, lr_0 = 1.4022e-04
Validation rmse = 0.724131
Epoch 25
Loss = 4.9576e-01, PNorm = 44.2205, GNorm = 6.4160, lr_0 = 1.3335e-04
Loss = 4.1943e-01, PNorm = 44.2268, GNorm = 5.4008, lr_0 = 1.2740e-04
Validation rmse = 0.722929
Epoch 26
Loss = 3.6638e-01, PNorm = 44.2336, GNorm = 7.9478, lr_0 = 1.2115e-04
Loss = 3.9619e-01, PNorm = 44.2392, GNorm = 11.4315, lr_0 = 1.1574e-04
Validation rmse = 0.723946
Epoch 27
Loss = 4.2008e-01, PNorm = 44.2424, GNorm = 3.8014, lr_0 = 1.1057e-04
Loss = 3.9062e-01, PNorm = 44.2474, GNorm = 4.6996, lr_0 = 1.0564e-04
Validation rmse = 0.723928
Epoch 28
Loss = 3.3940e-01, PNorm = 44.2537, GNorm = 5.5890, lr_0 = 1.0046e-04
Loss = 4.2395e-01, PNorm = 44.2581, GNorm = 10.0958, lr_0 = 1.0000e-04
Validation rmse = 0.723251
Epoch 29
Loss = 3.3301e-01, PNorm = 44.2635, GNorm = 7.6873, lr_0 = 1.0000e-04
Loss = 4.2324e-01, PNorm = 44.2676, GNorm = 3.0162, lr_0 = 1.0000e-04
Validation rmse = 0.726768
Model 0 best validation rmse = 0.722929 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.644510
Ensemble test rmse = 0.644510
1-fold cross validation
	Seed 0 ==> test rmse = 0.644510
Overall test rmse = 0.644510 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9775e+00, PNorm = 43.2610, GNorm = 1.2239, lr_0 = 3.6053e-04
Validation rmse = 1.215558
Epoch 1
Loss = 1.4475e+00, PNorm = 43.2600, GNorm = 1.8706, lr_0 = 6.2105e-04
Loss = 1.4175e+00, PNorm = 43.2658, GNorm = 1.5984, lr_0 = 8.5789e-04
Validation rmse = 1.069616
Epoch 2
Loss = 1.3008e+00, PNorm = 43.2811, GNorm = 1.9647, lr_0 = 9.7859e-04
Loss = 1.2633e+00, PNorm = 43.3072, GNorm = 1.2256, lr_0 = 9.3714e-04
Validation rmse = 0.950993
Epoch 3
Loss = 1.2327e+00, PNorm = 43.3458, GNorm = 3.7101, lr_0 = 8.9357e-04
Loss = 1.0788e+00, PNorm = 43.3888, GNorm = 1.8967, lr_0 = 8.5572e-04
Validation rmse = 0.856269
Epoch 4
Loss = 1.0645e+00, PNorm = 43.4415, GNorm = 4.3969, lr_0 = 8.1593e-04
Loss = 9.5675e-01, PNorm = 43.4895, GNorm = 1.4856, lr_0 = 7.8137e-04
Validation rmse = 0.759531
Epoch 5
Loss = 8.5624e-01, PNorm = 43.5345, GNorm = 4.2115, lr_0 = 7.4504e-04
Loss = 9.4484e-01, PNorm = 43.5728, GNorm = 7.2046, lr_0 = 7.1348e-04
Validation rmse = 0.711735
Epoch 6
Loss = 8.0077e-01, PNorm = 43.6164, GNorm = 4.3530, lr_0 = 6.8326e-04
Loss = 8.4852e-01, PNorm = 43.6559, GNorm = 2.7592, lr_0 = 6.5432e-04
Validation rmse = 0.730815
Epoch 7
Loss = 7.6310e-01, PNorm = 43.6841, GNorm = 5.6302, lr_0 = 6.2390e-04
Loss = 8.1946e-01, PNorm = 43.7181, GNorm = 10.8625, lr_0 = 5.9747e-04
Validation rmse = 0.646588
Epoch 8
Loss = 7.5458e-01, PNorm = 43.7549, GNorm = 10.7332, lr_0 = 5.6969e-04
Loss = 7.0635e-01, PNorm = 43.7839, GNorm = 2.2334, lr_0 = 5.4556e-04
Validation rmse = 0.607950
Epoch 9
Loss = 6.6514e-01, PNorm = 43.8149, GNorm = 9.3509, lr_0 = 5.2019e-04
Loss = 7.0863e-01, PNorm = 43.8396, GNorm = 2.4752, lr_0 = 4.9816e-04
Validation rmse = 0.666633
Epoch 10
Loss = 6.5446e-01, PNorm = 43.8641, GNorm = 3.3854, lr_0 = 4.7500e-04
Loss = 6.9461e-01, PNorm = 43.8844, GNorm = 3.2812, lr_0 = 4.5488e-04
Loss = 5.5580e-01, PNorm = 43.8873, GNorm = 7.7842, lr_0 = 4.5291e-04
Validation rmse = 0.619881
Epoch 11
Loss = 6.2660e-01, PNorm = 43.9153, GNorm = 3.2070, lr_0 = 4.3373e-04
Loss = 6.5834e-01, PNorm = 43.9328, GNorm = 8.5689, lr_0 = 4.1536e-04
Validation rmse = 0.637669
Epoch 12
Loss = 6.1870e-01, PNorm = 43.9506, GNorm = 2.3967, lr_0 = 3.9776e-04
Validation rmse = 0.626498
Epoch 13
Loss = 5.7656e-01, PNorm = 43.9722, GNorm = 5.6491, lr_0 = 3.7927e-04
Loss = 5.2645e-01, PNorm = 43.9913, GNorm = 2.3875, lr_0 = 3.6320e-04
Validation rmse = 0.638718
Epoch 14
Loss = 6.0452e-01, PNorm = 44.0103, GNorm = 4.8636, lr_0 = 3.4632e-04
Loss = 5.8061e-01, PNorm = 44.0269, GNorm = 6.4130, lr_0 = 3.3165e-04
Validation rmse = 0.623680
Epoch 15
Loss = 5.5215e-01, PNorm = 44.0403, GNorm = 7.1939, lr_0 = 3.1623e-04
Loss = 5.8740e-01, PNorm = 44.0559, GNorm = 7.0040, lr_0 = 3.0283e-04
Validation rmse = 0.600830
Epoch 16
Loss = 5.6275e-01, PNorm = 44.0709, GNorm = 5.3362, lr_0 = 2.8875e-04
Loss = 5.3395e-01, PNorm = 44.0865, GNorm = 2.9127, lr_0 = 2.7652e-04
Validation rmse = 0.608962
Epoch 17
Loss = 5.3101e-01, PNorm = 44.0997, GNorm = 6.4900, lr_0 = 2.6481e-04
Loss = 4.8535e-01, PNorm = 44.1111, GNorm = 3.4188, lr_0 = 2.5359e-04
Validation rmse = 0.605307
Epoch 18
Loss = 5.2104e-01, PNorm = 44.1208, GNorm = 4.9725, lr_0 = 2.4180e-04
Loss = 4.4144e-01, PNorm = 44.1315, GNorm = 2.9417, lr_0 = 2.3156e-04
Validation rmse = 0.606601
Epoch 19
Loss = 4.7466e-01, PNorm = 44.1450, GNorm = 9.4022, lr_0 = 2.2079e-04
Loss = 4.7370e-01, PNorm = 44.1546, GNorm = 4.0659, lr_0 = 2.1144e-04
Validation rmse = 0.589202
Epoch 20
Loss = 4.3009e-01, PNorm = 44.1641, GNorm = 5.3458, lr_0 = 2.0161e-04
Loss = 5.1746e-01, PNorm = 44.1739, GNorm = 3.4432, lr_0 = 1.9307e-04
Validation rmse = 0.584439
Epoch 21
Loss = 4.1732e-01, PNorm = 44.1824, GNorm = 4.2424, lr_0 = 1.8409e-04
Loss = 5.0459e-01, PNorm = 44.1908, GNorm = 13.4172, lr_0 = 1.7630e-04
Validation rmse = 0.602112
Epoch 22
Loss = 4.0622e-01, PNorm = 44.2016, GNorm = 6.7093, lr_0 = 1.6810e-04
Loss = 5.0064e-01, PNorm = 44.2102, GNorm = 4.8353, lr_0 = 1.6098e-04
Validation rmse = 0.582831
Epoch 23
Loss = 4.0765e-01, PNorm = 44.2161, GNorm = 4.0119, lr_0 = 1.5416e-04
Loss = 4.7924e-01, PNorm = 44.2230, GNorm = 4.1310, lr_0 = 1.4763e-04
Loss = 2.6077e-01, PNorm = 44.2235, GNorm = 10.1127, lr_0 = 1.4699e-04
Validation rmse = 0.592119
Epoch 24
Loss = 4.0673e-01, PNorm = 44.2310, GNorm = 7.0364, lr_0 = 1.4077e-04
Validation rmse = 0.589838
Epoch 25
Loss = 2.7784e-01, PNorm = 44.2369, GNorm = 3.1099, lr_0 = 1.3422e-04
Loss = 4.0703e-01, PNorm = 44.2432, GNorm = 14.1930, lr_0 = 1.2854e-04
Validation rmse = 0.599315
Epoch 26
Loss = 3.3904e-01, PNorm = 44.2481, GNorm = 3.2934, lr_0 = 1.2256e-04
Loss = 4.2567e-01, PNorm = 44.2529, GNorm = 10.6749, lr_0 = 1.1737e-04
Validation rmse = 0.599102
Epoch 27
Loss = 3.4559e-01, PNorm = 44.2602, GNorm = 3.3200, lr_0 = 1.1191e-04
Loss = 3.9855e-01, PNorm = 44.2650, GNorm = 3.2692, lr_0 = 1.0717e-04
Validation rmse = 0.596042
Epoch 28
Loss = 3.6370e-01, PNorm = 44.2689, GNorm = 11.5628, lr_0 = 1.0263e-04
Loss = 4.2857e-01, PNorm = 44.2732, GNorm = 3.3859, lr_0 = 1.0000e-04
Validation rmse = 0.584239
Epoch 29
Loss = 3.1942e-01, PNorm = 44.2781, GNorm = 6.4024, lr_0 = 1.0000e-04
Loss = 3.9594e-01, PNorm = 44.2825, GNorm = 3.8964, lr_0 = 1.0000e-04
Validation rmse = 0.594433
Model 0 best validation rmse = 0.582831 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.572048
Ensemble test rmse = 0.572048
1-fold cross validation
	Seed 0 ==> test rmse = 0.572048
Overall test rmse = 0.572048 +/- 0.000000
Elapsed time = 0:01:48
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,249 | train size = 999 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0834e+00, PNorm = 43.2584, GNorm = 1.3497, lr_0 = 3.6053e-04
Validation rmse = 1.315472
Epoch 1
Loss = 1.5528e+00, PNorm = 43.2587, GNorm = 0.9499, lr_0 = 6.2105e-04
Loss = 1.4217e+00, PNorm = 43.2646, GNorm = 1.4249, lr_0 = 8.5789e-04
Validation rmse = 1.221776
Epoch 2
Loss = 1.2355e+00, PNorm = 43.2793, GNorm = 1.5425, lr_0 = 9.8284e-04
Loss = 1.3070e+00, PNorm = 43.3016, GNorm = 2.5566, lr_0 = 9.4120e-04
Validation rmse = 1.090397
Epoch 3
Loss = 1.1656e+00, PNorm = 43.3332, GNorm = 1.2762, lr_0 = 9.0134e-04
Loss = 1.1378e+00, PNorm = 43.3763, GNorm = 2.3332, lr_0 = 8.6316e-04
Validation rmse = 1.021812
Epoch 4
Loss = 1.0515e+00, PNorm = 43.4141, GNorm = 1.9071, lr_0 = 8.2660e-04
Loss = 1.0273e+00, PNorm = 43.4606, GNorm = 1.0939, lr_0 = 7.9158e-04
Validation rmse = 0.964753
Epoch 5
Loss = 9.8612e-01, PNorm = 43.5115, GNorm = 5.9985, lr_0 = 7.5805e-04
Loss = 9.1660e-01, PNorm = 43.5558, GNorm = 3.5074, lr_0 = 7.2594e-04
Validation rmse = 0.906739
Epoch 6
Loss = 8.8120e-01, PNorm = 43.6004, GNorm = 7.8347, lr_0 = 6.9519e-04
Loss = 8.9822e-01, PNorm = 43.6431, GNorm = 1.8691, lr_0 = 6.6575e-04
Validation rmse = 0.827089
Epoch 7
Loss = 7.2238e-01, PNorm = 43.6772, GNorm = 4.2185, lr_0 = 6.3755e-04
Loss = 7.9696e-01, PNorm = 43.7104, GNorm = 2.6131, lr_0 = 6.1054e-04
Validation rmse = 0.827675
Epoch 8
Loss = 6.8513e-01, PNorm = 43.7390, GNorm = 3.9306, lr_0 = 5.8468e-04
Loss = 7.4070e-01, PNorm = 43.7698, GNorm = 2.0934, lr_0 = 5.5991e-04
Validation rmse = 0.763471
Epoch 9
Loss = 5.6891e-01, PNorm = 43.7999, GNorm = 2.7057, lr_0 = 5.3620e-04
Loss = 7.7309e-01, PNorm = 43.8261, GNorm = 7.7842, lr_0 = 5.1348e-04
Validation rmse = 0.782501
Epoch 10
Loss = 6.5314e-01, PNorm = 43.8471, GNorm = 2.8403, lr_0 = 4.9173e-04
Loss = 6.7914e-01, PNorm = 43.8727, GNorm = 6.8193, lr_0 = 4.7090e-04
Validation rmse = 0.776854
Epoch 11
Loss = 6.0849e-01, PNorm = 43.8996, GNorm = 2.5324, lr_0 = 4.5096e-04
Loss = 6.4886e-01, PNorm = 43.9213, GNorm = 3.3844, lr_0 = 4.3186e-04
Validation rmse = 0.760494
Epoch 12
Loss = 6.0821e-01, PNorm = 43.9387, GNorm = 3.8455, lr_0 = 4.1356e-04
Loss = 6.2638e-01, PNorm = 43.9538, GNorm = 8.6644, lr_0 = 3.9604e-04
Validation rmse = 0.751414
Epoch 13
Loss = 4.8765e-01, PNorm = 43.9713, GNorm = 4.6596, lr_0 = 3.7927e-04
Loss = 6.0332e-01, PNorm = 43.9893, GNorm = 10.3129, lr_0 = 3.6320e-04
Validation rmse = 0.712843
Epoch 14
Loss = 6.1148e-01, PNorm = 44.0083, GNorm = 4.7833, lr_0 = 3.4782e-04
Loss = 5.3939e-01, PNorm = 44.0245, GNorm = 3.6759, lr_0 = 3.3309e-04
Validation rmse = 0.734353
Epoch 15
Loss = 4.0084e-01, PNorm = 44.0376, GNorm = 3.7664, lr_0 = 3.1898e-04
Loss = 5.4402e-01, PNorm = 44.0520, GNorm = 6.6322, lr_0 = 3.0547e-04
Validation rmse = 0.709051
Epoch 16
Loss = 5.3662e-01, PNorm = 44.0676, GNorm = 4.6516, lr_0 = 2.9253e-04
Loss = 5.2446e-01, PNorm = 44.0810, GNorm = 5.3708, lr_0 = 2.8014e-04
Validation rmse = 0.703741
Epoch 17
Loss = 4.4088e-01, PNorm = 44.0911, GNorm = 8.9642, lr_0 = 2.6827e-04
Loss = 5.1406e-01, PNorm = 44.1054, GNorm = 3.4137, lr_0 = 2.5691e-04
Validation rmse = 0.705919
Epoch 18
Loss = 5.5640e-01, PNorm = 44.1134, GNorm = 7.9138, lr_0 = 2.4602e-04
Loss = 5.3806e-01, PNorm = 44.1242, GNorm = 4.5385, lr_0 = 2.3560e-04
Validation rmse = 0.698112
Epoch 19
Loss = 6.7329e-01, PNorm = 44.1345, GNorm = 3.4597, lr_0 = 2.2562e-04
Loss = 5.3839e-01, PNorm = 44.1443, GNorm = 2.6090, lr_0 = 2.1607e-04
Validation rmse = 0.695711
Epoch 20
Loss = 3.6239e-01, PNorm = 44.1556, GNorm = 2.8342, lr_0 = 2.0691e-04
Loss = 4.3452e-01, PNorm = 44.1662, GNorm = 3.3303, lr_0 = 1.9815e-04
Validation rmse = 0.692028
Epoch 21
Loss = 2.8752e-01, PNorm = 44.1743, GNorm = 7.4252, lr_0 = 1.8976e-04
Loss = 4.7154e-01, PNorm = 44.1827, GNorm = 7.1318, lr_0 = 1.8172e-04
Validation rmse = 0.687712
Epoch 22
Loss = 2.9712e-01, PNorm = 44.1909, GNorm = 2.3253, lr_0 = 1.7402e-04
Loss = 4.3744e-01, PNorm = 44.1982, GNorm = 5.9808, lr_0 = 1.6665e-04
Validation rmse = 0.681983
Epoch 23
Loss = 3.6937e-01, PNorm = 44.2051, GNorm = 4.4461, lr_0 = 1.5959e-04
Loss = 4.5682e-01, PNorm = 44.2132, GNorm = 2.5138, lr_0 = 1.5283e-04
Validation rmse = 0.688835
Epoch 24
Loss = 3.4153e-01, PNorm = 44.2194, GNorm = 4.6519, lr_0 = 1.4636e-04
Loss = 4.9079e-01, PNorm = 44.2252, GNorm = 8.5633, lr_0 = 1.4016e-04
Validation rmse = 0.695491
Epoch 25
Loss = 4.9565e-01, PNorm = 44.2310, GNorm = 4.6518, lr_0 = 1.3422e-04
Loss = 4.6070e-01, PNorm = 44.2375, GNorm = 4.0088, lr_0 = 1.2854e-04
Validation rmse = 0.680175
Epoch 26
Loss = 3.7768e-01, PNorm = 44.2442, GNorm = 5.5676, lr_0 = 1.2309e-04
Loss = 4.3168e-01, PNorm = 44.2501, GNorm = 5.8567, lr_0 = 1.1788e-04
Validation rmse = 0.685629
Epoch 27
Loss = 4.7351e-01, PNorm = 44.2549, GNorm = 5.3754, lr_0 = 1.1288e-04
Loss = 4.0788e-01, PNorm = 44.2604, GNorm = 12.9655, lr_0 = 1.0810e-04
Validation rmse = 0.675330
Epoch 28
Loss = 6.5454e-01, PNorm = 44.2646, GNorm = 7.0121, lr_0 = 1.0352e-04
Loss = 3.7542e-01, PNorm = 44.2684, GNorm = 9.1736, lr_0 = 1.0000e-04
Validation rmse = 0.686741
Epoch 29
Loss = 4.4769e-01, PNorm = 44.2730, GNorm = 7.2570, lr_0 = 1.0000e-04
Loss = 4.0392e-01, PNorm = 44.2779, GNorm = 7.0390, lr_0 = 1.0000e-04
Validation rmse = 0.678344
Model 0 best validation rmse = 0.675330 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.574773
Ensemble test rmse = 0.574773
1-fold cross validation
	Seed 0 ==> test rmse = 0.574773
Overall test rmse = 0.574773 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9737e+00, PNorm = 43.2570, GNorm = 1.0677, lr_0 = 3.4750e-04
Loss = 1.4833e+00, PNorm = 43.2551, GNorm = 2.1175, lr_0 = 5.7250e-04
Loss = 1.4447e+00, PNorm = 43.2553, GNorm = 1.6391, lr_0 = 5.9500e-04
Validation rmse = 1.303670
Epoch 1
Loss = 1.4226e+00, PNorm = 43.2611, GNorm = 0.9254, lr_0 = 8.2000e-04
Loss = 1.3302e+00, PNorm = 43.2744, GNorm = 0.7822, lr_0 = 9.9181e-04
Validation rmse = 1.133288
Epoch 2
Loss = 1.2941e+00, PNorm = 43.2987, GNorm = 1.6487, lr_0 = 9.5186e-04
Loss = 1.2131e+00, PNorm = 43.3318, GNorm = 1.7365, lr_0 = 9.1351e-04
Validation rmse = 1.090918
Epoch 3
Loss = 1.1728e+00, PNorm = 43.3695, GNorm = 1.0807, lr_0 = 8.7671e-04
Loss = 1.0532e+00, PNorm = 43.4179, GNorm = 4.1683, lr_0 = 8.4140e-04
Validation rmse = 0.928853
Epoch 4
Loss = 9.2547e-01, PNorm = 43.4705, GNorm = 2.3485, lr_0 = 8.0750e-04
Loss = 9.9223e-01, PNorm = 43.5152, GNorm = 1.7037, lr_0 = 7.7497e-04
Validation rmse = 0.874974
Epoch 5
Loss = 8.9328e-01, PNorm = 43.5615, GNorm = 2.5421, lr_0 = 7.4070e-04
Loss = 8.6345e-01, PNorm = 43.6073, GNorm = 6.2949, lr_0 = 7.1086e-04
Validation rmse = 0.807148
Epoch 6
Loss = 8.2067e-01, PNorm = 43.6457, GNorm = 5.7653, lr_0 = 6.8223e-04
Loss = 7.8415e-01, PNorm = 43.6868, GNorm = 4.7871, lr_0 = 6.5474e-04
Validation rmse = 0.773795
Epoch 7
Loss = 7.2592e-01, PNorm = 43.7202, GNorm = 2.1632, lr_0 = 6.2837e-04
Loss = 7.5007e-01, PNorm = 43.7522, GNorm = 4.3704, lr_0 = 6.0306e-04
Validation rmse = 0.738776
Epoch 8
Loss = 7.5573e-01, PNorm = 43.7803, GNorm = 2.0518, lr_0 = 5.7876e-04
Loss = 6.9729e-01, PNorm = 43.8125, GNorm = 4.3778, lr_0 = 5.5545e-04
Validation rmse = 0.736440
Epoch 9
Loss = 7.3822e-01, PNorm = 43.8417, GNorm = 10.6654, lr_0 = 5.3307e-04
Loss = 6.7126e-01, PNorm = 43.8688, GNorm = 5.7127, lr_0 = 5.1160e-04
Validation rmse = 0.788756
Epoch 10
Loss = 7.5142e-01, PNorm = 43.8916, GNorm = 4.8883, lr_0 = 4.8897e-04
Loss = 6.9890e-01, PNorm = 43.9135, GNorm = 5.4427, lr_0 = 4.6928e-04
Validation rmse = 0.709102
Epoch 11
Loss = 5.2277e-01, PNorm = 43.9367, GNorm = 3.2777, lr_0 = 4.5037e-04
Loss = 6.2627e-01, PNorm = 43.9639, GNorm = 2.4551, lr_0 = 4.3223e-04
Validation rmse = 0.699080
Epoch 12
Loss = 4.9384e-01, PNorm = 43.9847, GNorm = 2.6369, lr_0 = 4.1482e-04
Loss = 5.9577e-01, PNorm = 44.0094, GNorm = 10.6396, lr_0 = 3.9811e-04
Loss = 6.2863e-01, PNorm = 44.0221, GNorm = 6.4182, lr_0 = 3.8207e-04
Validation rmse = 0.702175
Epoch 13
Loss = 5.4600e-01, PNorm = 44.0384, GNorm = 3.9292, lr_0 = 3.6668e-04
Loss = 6.2266e-01, PNorm = 44.0549, GNorm = 3.8133, lr_0 = 3.5191e-04
Loss = 6.3543e-01, PNorm = 44.0567, GNorm = 6.6808, lr_0 = 3.5046e-04
Validation rmse = 0.668704
Epoch 14
Loss = 5.5619e-01, PNorm = 44.0761, GNorm = 9.2109, lr_0 = 3.3635e-04
Loss = 5.4512e-01, PNorm = 44.0893, GNorm = 4.5335, lr_0 = 3.2280e-04
Validation rmse = 0.680508
Epoch 15
Loss = 5.0636e-01, PNorm = 44.1025, GNorm = 7.8725, lr_0 = 3.0979e-04
Loss = 5.5093e-01, PNorm = 44.1162, GNorm = 3.2972, lr_0 = 2.9731e-04
Validation rmse = 0.651583
Epoch 16
Loss = 4.8832e-01, PNorm = 44.1331, GNorm = 3.1718, lr_0 = 2.8534e-04
Loss = 5.4120e-01, PNorm = 44.1452, GNorm = 3.1291, lr_0 = 2.7384e-04
Validation rmse = 0.693901
Epoch 17
Loss = 5.8416e-01, PNorm = 44.1522, GNorm = 8.3730, lr_0 = 2.6281e-04
Loss = 6.1221e-01, PNorm = 44.1649, GNorm = 5.1218, lr_0 = 2.5222e-04
Validation rmse = 0.681468
Epoch 18
Loss = 4.4945e-01, PNorm = 44.1774, GNorm = 4.0808, lr_0 = 2.4206e-04
Loss = 5.8271e-01, PNorm = 44.1897, GNorm = 7.1686, lr_0 = 2.3231e-04
Validation rmse = 0.674346
Epoch 19
Loss = 5.6887e-01, PNorm = 44.1997, GNorm = 3.1635, lr_0 = 2.2204e-04
Loss = 4.7493e-01, PNorm = 44.2105, GNorm = 3.1724, lr_0 = 2.1309e-04
Validation rmse = 0.655888
Epoch 20
Loss = 4.8430e-01, PNorm = 44.2195, GNorm = 5.1602, lr_0 = 2.0451e-04
Loss = 4.3209e-01, PNorm = 44.2295, GNorm = 6.0359, lr_0 = 1.9627e-04
Validation rmse = 0.687803
Epoch 21
Loss = 5.6192e-01, PNorm = 44.2348, GNorm = 3.7670, lr_0 = 1.8836e-04
Loss = 5.2057e-01, PNorm = 44.2425, GNorm = 4.5481, lr_0 = 1.8078e-04
Validation rmse = 0.667643
Epoch 22
Loss = 5.0354e-01, PNorm = 44.2500, GNorm = 4.6945, lr_0 = 1.7349e-04
Loss = 4.6404e-01, PNorm = 44.2587, GNorm = 2.9583, lr_0 = 1.6651e-04
Validation rmse = 0.651844
Epoch 23
Loss = 4.4210e-01, PNorm = 44.2687, GNorm = 3.4914, lr_0 = 1.5914e-04
Loss = 4.4946e-01, PNorm = 44.2751, GNorm = 3.0632, lr_0 = 1.5273e-04
Validation rmse = 0.642565
Epoch 24
Loss = 5.0175e-01, PNorm = 44.2820, GNorm = 7.7799, lr_0 = 1.4658e-04
Loss = 4.7443e-01, PNorm = 44.2892, GNorm = 3.4670, lr_0 = 1.4067e-04
Validation rmse = 0.646933
Epoch 25
Loss = 5.8589e-01, PNorm = 44.2943, GNorm = 6.6274, lr_0 = 1.3501e-04
Loss = 4.2905e-01, PNorm = 44.2992, GNorm = 2.6254, lr_0 = 1.2957e-04
Loss = 4.2800e-01, PNorm = 44.3070, GNorm = 15.2824, lr_0 = 1.2435e-04
Validation rmse = 0.656829
Epoch 26
Loss = 4.0071e-01, PNorm = 44.3137, GNorm = 7.8462, lr_0 = 1.1934e-04
Loss = 4.4492e-01, PNorm = 44.3189, GNorm = 6.4645, lr_0 = 1.1453e-04
Validation rmse = 0.638689
Epoch 27
Loss = 3.9281e-01, PNorm = 44.3235, GNorm = 3.4192, lr_0 = 1.0992e-04
Loss = 4.0079e-01, PNorm = 44.3288, GNorm = 10.5274, lr_0 = 1.0549e-04
Validation rmse = 0.642533
Epoch 28
Loss = 4.4443e-01, PNorm = 44.3328, GNorm = 4.0879, lr_0 = 1.0083e-04
Loss = 3.7662e-01, PNorm = 44.3378, GNorm = 4.2453, lr_0 = 1.0000e-04
Validation rmse = 0.645143
Epoch 29
Loss = 4.0883e-01, PNorm = 44.3422, GNorm = 9.9479, lr_0 = 1.0000e-04
Loss = 4.4248e-01, PNorm = 44.3476, GNorm = 4.7371, lr_0 = 1.0000e-04
Validation rmse = 0.639962
Model 0 best validation rmse = 0.638689 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.551484
Ensemble test rmse = 0.551484
1-fold cross validation
	Seed 0 ==> test rmse = 0.551484
Overall test rmse = 0.551484 +/- 0.000000
Elapsed time = 0:01:56
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,349 | train size = 1,079 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9796e+00, PNorm = 43.2597, GNorm = 1.2262, lr_0 = 3.3571e-04
Loss = 1.4644e+00, PNorm = 43.2566, GNorm = 1.5300, lr_0 = 5.5000e-04
Validation rmse = 1.357802
Epoch 1
Loss = 1.3922e+00, PNorm = 43.2604, GNorm = 1.0391, lr_0 = 7.8571e-04
Loss = 1.3498e+00, PNorm = 43.2719, GNorm = 3.1948, lr_0 = 1.0000e-03
Validation rmse = 1.237795
Epoch 2
Loss = 1.3208e+00, PNorm = 43.2910, GNorm = 0.8853, lr_0 = 9.6160e-04
Loss = 1.2394e+00, PNorm = 43.3194, GNorm = 1.8146, lr_0 = 9.2467e-04
Validation rmse = 1.098924
Epoch 3
Loss = 1.1424e+00, PNorm = 43.3625, GNorm = 1.5852, lr_0 = 8.8568e-04
Loss = 1.0925e+00, PNorm = 43.4094, GNorm = 3.2024, lr_0 = 8.5167e-04
Validation rmse = 1.037225
Epoch 4
Loss = 1.0371e+00, PNorm = 43.4606, GNorm = 6.0313, lr_0 = 8.1896e-04
Loss = 9.2676e-01, PNorm = 43.5117, GNorm = 1.4562, lr_0 = 7.8751e-04
Validation rmse = 0.907563
Epoch 5
Loss = 9.6668e-01, PNorm = 43.5647, GNorm = 6.5614, lr_0 = 7.5431e-04
Loss = 8.7712e-01, PNorm = 43.6050, GNorm = 2.2017, lr_0 = 7.2534e-04
Validation rmse = 0.865562
Epoch 6
Loss = 9.7881e-01, PNorm = 43.6449, GNorm = 5.1882, lr_0 = 6.9749e-04
Loss = 8.0560e-01, PNorm = 43.6862, GNorm = 1.9457, lr_0 = 6.7070e-04
Loss = 8.8332e-01, PNorm = 43.7220, GNorm = 6.0233, lr_0 = 6.4495e-04
Validation rmse = 0.854908
Epoch 7
Loss = 7.5191e-01, PNorm = 43.7547, GNorm = 2.3825, lr_0 = 6.2018e-04
Loss = 7.8283e-01, PNorm = 43.7903, GNorm = 7.2787, lr_0 = 5.9636e-04
Validation rmse = 0.786974
Epoch 8
Loss = 7.2554e-01, PNorm = 43.8219, GNorm = 3.5190, lr_0 = 5.7122e-04
Loss = 7.3851e-01, PNorm = 43.8487, GNorm = 4.9825, lr_0 = 5.4928e-04
Validation rmse = 0.787722
Epoch 9
Loss = 6.6522e-01, PNorm = 43.8797, GNorm = 3.1709, lr_0 = 5.2819e-04
Loss = 7.0400e-01, PNorm = 43.9054, GNorm = 5.2136, lr_0 = 5.0790e-04
Validation rmse = 0.787094
Epoch 10
Loss = 7.1450e-01, PNorm = 43.9269, GNorm = 5.1388, lr_0 = 4.8649e-04
Loss = 6.3222e-01, PNorm = 43.9524, GNorm = 4.0605, lr_0 = 4.6781e-04
Validation rmse = 0.781807
Epoch 11
Loss = 5.8305e-01, PNorm = 43.9772, GNorm = 2.0772, lr_0 = 4.4984e-04
Loss = 6.7989e-01, PNorm = 44.0038, GNorm = 2.3267, lr_0 = 4.3257e-04
Validation rmse = 0.752848
Epoch 12
Loss = 5.3348e-01, PNorm = 44.0244, GNorm = 6.7390, lr_0 = 4.1433e-04
Loss = 6.7163e-01, PNorm = 44.0436, GNorm = 4.1046, lr_0 = 3.9842e-04
Loss = 5.6738e-01, PNorm = 44.0638, GNorm = 4.0156, lr_0 = 3.8312e-04
Validation rmse = 0.777628
Epoch 13
Loss = 5.9296e-01, PNorm = 44.0800, GNorm = 3.2625, lr_0 = 3.6841e-04
Loss = 5.9865e-01, PNorm = 44.0968, GNorm = 13.5602, lr_0 = 3.5426e-04
Validation rmse = 0.748198
Epoch 14
Loss = 5.5577e-01, PNorm = 44.1171, GNorm = 3.1313, lr_0 = 3.4065e-04
Loss = 5.8596e-01, PNorm = 44.1340, GNorm = 4.4222, lr_0 = 3.2757e-04
Validation rmse = 0.751192
Epoch 15
Loss = 5.8030e-01, PNorm = 44.1494, GNorm = 10.4664, lr_0 = 3.1376e-04
Loss = 5.7581e-01, PNorm = 44.1629, GNorm = 10.7596, lr_0 = 3.0171e-04
Validation rmse = 0.730693
Epoch 16
Loss = 5.2092e-01, PNorm = 44.1791, GNorm = 6.9681, lr_0 = 2.9012e-04
Loss = 5.1513e-01, PNorm = 44.1950, GNorm = 3.4820, lr_0 = 2.7898e-04
Validation rmse = 0.730265
Epoch 17
Loss = 5.0149e-01, PNorm = 44.2082, GNorm = 2.9731, lr_0 = 2.6722e-04
Loss = 5.3003e-01, PNorm = 44.2193, GNorm = 3.2391, lr_0 = 2.5696e-04
Validation rmse = 0.728958
Epoch 18
Loss = 4.1518e-01, PNorm = 44.2315, GNorm = 4.6923, lr_0 = 2.4709e-04
Loss = 5.1802e-01, PNorm = 44.2458, GNorm = 3.5671, lr_0 = 2.3760e-04
Loss = 4.7659e-01, PNorm = 44.2550, GNorm = 10.0515, lr_0 = 2.2848e-04
Validation rmse = 0.729627
Epoch 19
Loss = 4.7415e-01, PNorm = 44.2636, GNorm = 9.1642, lr_0 = 2.1970e-04
Loss = 5.3413e-01, PNorm = 44.2760, GNorm = 7.1375, lr_0 = 2.1127e-04
Validation rmse = 0.724134
Epoch 20
Loss = 5.2635e-01, PNorm = 44.2848, GNorm = 9.2056, lr_0 = 2.0236e-04
Loss = 5.3186e-01, PNorm = 44.2950, GNorm = 10.5104, lr_0 = 1.9459e-04
Validation rmse = 0.723080
Epoch 21
Loss = 4.2081e-01, PNorm = 44.3041, GNorm = 7.5799, lr_0 = 1.8712e-04
Loss = 4.3958e-01, PNorm = 44.3148, GNorm = 4.6963, lr_0 = 1.7993e-04
Validation rmse = 0.730896
Epoch 22
Loss = 4.2079e-01, PNorm = 44.3216, GNorm = 5.2274, lr_0 = 1.7234e-04
Loss = 4.5874e-01, PNorm = 44.3289, GNorm = 4.0906, lr_0 = 1.6572e-04
Validation rmse = 0.721998
Epoch 23
Loss = 4.8421e-01, PNorm = 44.3363, GNorm = 2.5818, lr_0 = 1.5936e-04
Loss = 4.5170e-01, PNorm = 44.3438, GNorm = 4.1006, lr_0 = 1.5324e-04
Validation rmse = 0.716743
Epoch 24
Loss = 5.3701e-01, PNorm = 44.3509, GNorm = 4.3009, lr_0 = 1.4678e-04
Loss = 3.9907e-01, PNorm = 44.3568, GNorm = 6.0589, lr_0 = 1.4114e-04
Validation rmse = 0.734950
Epoch 25
Loss = 3.0138e-01, PNorm = 44.3629, GNorm = 3.7410, lr_0 = 1.3572e-04
Loss = 4.1820e-01, PNorm = 44.3692, GNorm = 7.0309, lr_0 = 1.3051e-04
Loss = 5.0603e-01, PNorm = 44.3741, GNorm = 3.7096, lr_0 = 1.2550e-04
Validation rmse = 0.721557
Epoch 26
Loss = 4.2194e-01, PNorm = 44.3783, GNorm = 3.5810, lr_0 = 1.2068e-04
Loss = 4.1353e-01, PNorm = 44.3836, GNorm = 2.4582, lr_0 = 1.1604e-04
Validation rmse = 0.715680
Epoch 27
Loss = 3.7243e-01, PNorm = 44.3904, GNorm = 4.2204, lr_0 = 1.1115e-04
Loss = 4.5053e-01, PNorm = 44.3959, GNorm = 5.2911, lr_0 = 1.0688e-04
Validation rmse = 0.723664
Epoch 28
Loss = 3.7885e-01, PNorm = 44.3992, GNorm = 4.9951, lr_0 = 1.0278e-04
Loss = 4.0951e-01, PNorm = 44.4032, GNorm = 4.0387, lr_0 = 1.0000e-04
Validation rmse = 0.714212
Epoch 29
Loss = 3.5932e-01, PNorm = 44.4082, GNorm = 3.4525, lr_0 = 1.0000e-04
Loss = 4.2212e-01, PNorm = 44.4127, GNorm = 3.5009, lr_0 = 1.0000e-04
Validation rmse = 0.714044
Model 0 best validation rmse = 0.714044 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.547237
Ensemble test rmse = 0.547237
1-fold cross validation
	Seed 0 ==> test rmse = 0.547237
Overall test rmse = 0.547237 +/- 0.000000
Elapsed time = 0:02:02
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0480e+00, PNorm = 43.2607, GNorm = 2.2073, lr_0 = 3.2500e-04
Loss = 1.4653e+00, PNorm = 43.2570, GNorm = 1.7794, lr_0 = 5.2955e-04
Validation rmse = 1.284656
Epoch 1
Loss = 1.4144e+00, PNorm = 43.2603, GNorm = 1.2611, lr_0 = 7.5455e-04
Loss = 1.3459e+00, PNorm = 43.2702, GNorm = 1.3387, lr_0 = 9.5909e-04
Validation rmse = 1.123504
Epoch 2
Loss = 1.2263e+00, PNorm = 43.2917, GNorm = 1.6705, lr_0 = 9.6692e-04
Loss = 1.2699e+00, PNorm = 43.3234, GNorm = 2.9280, lr_0 = 9.3144e-04
Validation rmse = 1.108719
Epoch 3
Loss = 1.1981e+00, PNorm = 43.3621, GNorm = 1.2846, lr_0 = 8.9727e-04
Loss = 1.1556e+00, PNorm = 43.4081, GNorm = 1.1931, lr_0 = 8.6435e-04
Validation rmse = 0.945347
Epoch 4
Loss = 9.7167e-01, PNorm = 43.4636, GNorm = 2.0649, lr_0 = 8.2953e-04
Loss = 1.0012e+00, PNorm = 43.5164, GNorm = 2.0253, lr_0 = 7.9909e-04
Loss = 9.6100e-01, PNorm = 43.5671, GNorm = 4.5347, lr_0 = 7.6977e-04
Validation rmse = 0.874477
Epoch 5
Loss = 8.9174e-01, PNorm = 43.6212, GNorm = 2.3145, lr_0 = 7.3877e-04
Loss = 9.0881e-01, PNorm = 43.6673, GNorm = 9.7075, lr_0 = 7.1166e-04
Validation rmse = 0.910240
Epoch 6
Loss = 9.0463e-01, PNorm = 43.7150, GNorm = 6.5585, lr_0 = 6.8555e-04
Loss = 8.8324e-01, PNorm = 43.7565, GNorm = 2.7267, lr_0 = 6.6040e-04
Validation rmse = 0.794673
Epoch 7
Loss = 7.4900e-01, PNorm = 43.7997, GNorm = 4.2626, lr_0 = 6.3379e-04
Loss = 7.5251e-01, PNorm = 43.8365, GNorm = 4.7814, lr_0 = 6.1054e-04
Validation rmse = 0.766020
Epoch 8
Loss = 7.0624e-01, PNorm = 43.8681, GNorm = 5.5489, lr_0 = 5.8814e-04
Loss = 6.6749e-01, PNorm = 43.8983, GNorm = 2.4766, lr_0 = 5.6656e-04
Loss = 7.7363e-01, PNorm = 43.9260, GNorm = 3.7007, lr_0 = 5.4577e-04
Validation rmse = 0.755056
Epoch 9
Loss = 7.1114e-01, PNorm = 43.9604, GNorm = 4.7305, lr_0 = 5.2379e-04
Loss = 7.0737e-01, PNorm = 43.9849, GNorm = 1.8373, lr_0 = 5.0457e-04
Validation rmse = 0.756442
Epoch 10
Loss = 6.2881e-01, PNorm = 44.0162, GNorm = 3.1523, lr_0 = 4.8424e-04
Loss = 6.2761e-01, PNorm = 44.0417, GNorm = 4.9857, lr_0 = 4.6648e-04
Validation rmse = 0.732227
Epoch 11
Loss = 6.3915e-01, PNorm = 44.0585, GNorm = 6.0373, lr_0 = 4.4936e-04
Loss = 7.1170e-01, PNorm = 44.0750, GNorm = 7.0425, lr_0 = 4.3288e-04
Validation rmse = 0.767165
Epoch 12
Loss = 7.2862e-01, PNorm = 44.1012, GNorm = 1.9428, lr_0 = 4.1544e-04
Loss = 5.8515e-01, PNorm = 44.1247, GNorm = 4.4898, lr_0 = 4.0020e-04
Loss = 6.4004e-01, PNorm = 44.1439, GNorm = 7.6783, lr_0 = 3.8551e-04
Loss = 4.6736e-01, PNorm = 44.1453, GNorm = 3.7033, lr_0 = 3.8407e-04
Validation rmse = 0.728293
Epoch 13
Loss = 6.1704e-01, PNorm = 44.1629, GNorm = 2.5796, lr_0 = 3.6998e-04
Loss = 5.5795e-01, PNorm = 44.1823, GNorm = 2.5733, lr_0 = 3.5641e-04
Validation rmse = 0.711646
Epoch 14
Loss = 4.9823e-01, PNorm = 44.2006, GNorm = 3.7451, lr_0 = 3.4333e-04
Loss = 5.7000e-01, PNorm = 44.2162, GNorm = 4.1160, lr_0 = 3.3074e-04
Validation rmse = 0.719074
Epoch 15
Loss = 5.8846e-01, PNorm = 44.2263, GNorm = 3.6412, lr_0 = 3.1741e-04
Loss = 5.5335e-01, PNorm = 44.2421, GNorm = 2.8714, lr_0 = 3.0577e-04
Validation rmse = 0.693992
Epoch 16
Loss = 5.4071e-01, PNorm = 44.2593, GNorm = 9.9846, lr_0 = 2.9455e-04
Loss = 4.4817e-01, PNorm = 44.2747, GNorm = 2.8996, lr_0 = 2.8374e-04
Loss = 5.7015e-01, PNorm = 44.2837, GNorm = 6.1102, lr_0 = 2.7333e-04
Loss = 4.9312e-01, PNorm = 44.2849, GNorm = 3.5604, lr_0 = 2.7231e-04
Validation rmse = 0.716580
Epoch 17
Loss = 5.0739e-01, PNorm = 44.2985, GNorm = 3.6880, lr_0 = 2.6232e-04
Loss = 4.9710e-01, PNorm = 44.3127, GNorm = 3.9756, lr_0 = 2.5270e-04
Validation rmse = 0.701000
Epoch 18
Loss = 5.1859e-01, PNorm = 44.3256, GNorm = 11.5002, lr_0 = 2.4252e-04
Loss = 4.9969e-01, PNorm = 44.3365, GNorm = 3.9199, lr_0 = 2.3362e-04
Validation rmse = 0.720085
Epoch 19
Loss = 5.3137e-01, PNorm = 44.3470, GNorm = 3.4977, lr_0 = 2.2505e-04
Loss = 4.7026e-01, PNorm = 44.3575, GNorm = 4.4693, lr_0 = 2.1679e-04
Validation rmse = 0.695603
Epoch 20
Loss = 4.1725e-01, PNorm = 44.3693, GNorm = 3.3242, lr_0 = 2.0806e-04
Loss = 4.5355e-01, PNorm = 44.3781, GNorm = 5.1368, lr_0 = 2.0042e-04
Validation rmse = 0.705563
Epoch 21
Loss = 4.6238e-01, PNorm = 44.3868, GNorm = 3.3530, lr_0 = 1.9235e-04
Loss = 3.8716e-01, PNorm = 44.3969, GNorm = 3.4175, lr_0 = 1.8529e-04
Loss = 4.9236e-01, PNorm = 44.4062, GNorm = 6.1395, lr_0 = 1.7849e-04
Validation rmse = 0.699038
Epoch 22
Loss = 4.8693e-01, PNorm = 44.4151, GNorm = 4.4778, lr_0 = 1.7195e-04
Loss = 3.9351e-01, PNorm = 44.4243, GNorm = 3.4193, lr_0 = 1.6564e-04
Validation rmse = 0.702508
Epoch 23
Loss = 4.2367e-01, PNorm = 44.4291, GNorm = 5.5033, lr_0 = 1.5896e-04
Loss = 3.9938e-01, PNorm = 44.4355, GNorm = 5.2512, lr_0 = 1.5313e-04
Validation rmse = 0.702430
Epoch 24
Loss = 4.1447e-01, PNorm = 44.4438, GNorm = 10.7439, lr_0 = 1.4751e-04
Loss = 4.1627e-01, PNorm = 44.4504, GNorm = 3.3731, lr_0 = 1.4210e-04
Validation rmse = 0.699168
Epoch 25
Loss = 4.7503e-01, PNorm = 44.4564, GNorm = 6.0475, lr_0 = 1.3638e-04
Loss = 4.8682e-01, PNorm = 44.4634, GNorm = 8.0288, lr_0 = 1.3137e-04
Loss = 3.7024e-01, PNorm = 44.4691, GNorm = 7.3770, lr_0 = 1.2655e-04
Validation rmse = 0.699741
Epoch 26
Loss = 3.7761e-01, PNorm = 44.4753, GNorm = 3.6693, lr_0 = 1.2146e-04
Loss = 4.0160e-01, PNorm = 44.4809, GNorm = 4.8180, lr_0 = 1.1700e-04
Validation rmse = 0.698800
Epoch 27
Loss = 3.3151e-01, PNorm = 44.4856, GNorm = 7.8524, lr_0 = 1.1271e-04
Loss = 4.6856e-01, PNorm = 44.4900, GNorm = 9.5675, lr_0 = 1.0857e-04
Validation rmse = 0.693347
Epoch 28
Loss = 3.6831e-01, PNorm = 44.4959, GNorm = 3.0225, lr_0 = 1.0420e-04
Loss = 4.2626e-01, PNorm = 44.5008, GNorm = 4.2720, lr_0 = 1.0037e-04
Validation rmse = 0.693806
Epoch 29
Loss = 3.0427e-01, PNorm = 44.5052, GNorm = 6.9612, lr_0 = 1.0000e-04
Loss = 3.9449e-01, PNorm = 44.5100, GNorm = 3.2282, lr_0 = 1.0000e-04
Loss = 3.6742e-01, PNorm = 44.5144, GNorm = 8.6590, lr_0 = 1.0000e-04
Validation rmse = 0.695151
Model 0 best validation rmse = 0.693347 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.575440
Ensemble test rmse = 0.575440
1-fold cross validation
	Seed 0 ==> test rmse = 0.575440
Overall test rmse = 0.575440 +/- 0.000000
Elapsed time = 0:02:04
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,449 | train size = 1,159 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9741e+00, PNorm = 43.2595, GNorm = 6.0920, lr_0 = 3.1522e-04
Loss = 1.4946e+00, PNorm = 43.2568, GNorm = 1.9541, lr_0 = 5.1087e-04
Validation rmse = 1.273208
Epoch 1
Loss = 1.4273e+00, PNorm = 43.2589, GNorm = 0.8697, lr_0 = 7.2609e-04
Loss = 1.3394e+00, PNorm = 43.2709, GNorm = 1.5231, lr_0 = 9.2174e-04
Validation rmse = 1.157603
Epoch 2
Loss = 1.3328e+00, PNorm = 43.2977, GNorm = 2.9853, lr_0 = 9.7528e-04
Loss = 1.2420e+00, PNorm = 43.3353, GNorm = 2.1934, lr_0 = 9.4103e-04
Validation rmse = 1.083635
Epoch 3
Loss = 1.2476e+00, PNorm = 43.3851, GNorm = 4.8370, lr_0 = 9.0474e-04
Loss = 1.0771e+00, PNorm = 43.4366, GNorm = 4.3174, lr_0 = 8.7296e-04
Loss = 1.0010e+00, PNorm = 43.4989, GNorm = 1.2617, lr_0 = 8.4230e-04
Validation rmse = 0.895883
Epoch 4
Loss = 9.7009e-01, PNorm = 43.5645, GNorm = 1.9145, lr_0 = 8.0981e-04
Loss = 8.6766e-01, PNorm = 43.6122, GNorm = 8.4905, lr_0 = 7.8137e-04
Validation rmse = 0.820759
Epoch 5
Loss = 8.6752e-01, PNorm = 43.6600, GNorm = 2.4053, lr_0 = 7.5124e-04
Loss = 9.0911e-01, PNorm = 43.6987, GNorm = 3.7743, lr_0 = 7.2485e-04
Validation rmse = 1.033988
Epoch 6
Loss = 1.0464e+00, PNorm = 43.7348, GNorm = 8.6834, lr_0 = 6.9939e-04
Loss = 9.2697e-01, PNorm = 43.7663, GNorm = 2.6899, lr_0 = 6.7483e-04
Loss = 8.3806e-01, PNorm = 43.8024, GNorm = 1.7320, lr_0 = 6.5113e-04
Validation rmse = 0.798382
Epoch 7
Loss = 7.8826e-01, PNorm = 43.8440, GNorm = 2.2766, lr_0 = 6.2601e-04
Loss = 7.2751e-01, PNorm = 43.8735, GNorm = 3.0256, lr_0 = 6.0403e-04
Validation rmse = 0.822711
Epoch 8
Loss = 6.4696e-01, PNorm = 43.9030, GNorm = 5.0880, lr_0 = 5.8073e-04
Loss = 7.2618e-01, PNorm = 43.9310, GNorm = 4.5547, lr_0 = 5.6033e-04
Validation rmse = 0.746418
Epoch 9
Loss = 7.6895e-01, PNorm = 43.9624, GNorm = 8.3165, lr_0 = 5.3872e-04
Loss = 6.7312e-01, PNorm = 43.9884, GNorm = 5.6600, lr_0 = 5.1980e-04
Loss = 7.0794e-01, PNorm = 44.0149, GNorm = 12.2679, lr_0 = 5.0155e-04
Validation rmse = 0.741660
Epoch 10
Loss = 6.6010e-01, PNorm = 44.0378, GNorm = 5.1502, lr_0 = 4.8220e-04
Loss = 6.0295e-01, PNorm = 44.0604, GNorm = 4.1602, lr_0 = 4.6527e-04
Validation rmse = 0.692967
Epoch 11
Loss = 5.9749e-01, PNorm = 44.0843, GNorm = 10.4454, lr_0 = 4.4732e-04
Loss = 6.5212e-01, PNorm = 44.1017, GNorm = 10.3815, lr_0 = 4.3161e-04
Validation rmse = 0.733534
Epoch 12
Loss = 4.7091e-01, PNorm = 44.1186, GNorm = 2.2910, lr_0 = 4.1645e-04
Loss = 5.8182e-01, PNorm = 44.1410, GNorm = 4.6148, lr_0 = 4.0183e-04
Loss = 6.4443e-01, PNorm = 44.1578, GNorm = 3.5713, lr_0 = 3.8771e-04
Validation rmse = 0.784096
Epoch 13
Loss = 6.0600e-01, PNorm = 44.1778, GNorm = 2.6634, lr_0 = 3.7276e-04
Loss = 5.1493e-01, PNorm = 44.1952, GNorm = 4.5083, lr_0 = 3.5967e-04
Validation rmse = 0.693645
Epoch 14
Loss = 5.8180e-01, PNorm = 44.2104, GNorm = 3.5917, lr_0 = 3.4580e-04
Loss = 5.2252e-01, PNorm = 44.2240, GNorm = 5.8588, lr_0 = 3.3365e-04
Validation rmse = 0.691026
Epoch 15
Loss = 5.2527e-01, PNorm = 44.2431, GNorm = 13.0350, lr_0 = 3.2078e-04
Loss = 5.4390e-01, PNorm = 44.2594, GNorm = 2.6646, lr_0 = 3.0952e-04
Loss = 5.0570e-01, PNorm = 44.2704, GNorm = 9.1417, lr_0 = 2.9865e-04
Loss = 1.0524e-01, PNorm = 44.2712, GNorm = 5.5949, lr_0 = 2.9758e-04
Validation rmse = 0.702716
Epoch 16
Loss = 5.0578e-01, PNorm = 44.2844, GNorm = 11.9476, lr_0 = 2.8713e-04
Loss = 5.1189e-01, PNorm = 44.2947, GNorm = 2.1225, lr_0 = 2.7704e-04
Validation rmse = 0.677794
Epoch 17
Loss = 4.2362e-01, PNorm = 44.3081, GNorm = 8.2831, lr_0 = 2.6731e-04
Loss = 4.8640e-01, PNorm = 44.3216, GNorm = 8.2190, lr_0 = 2.5792e-04
Validation rmse = 0.693688
Epoch 18
Loss = 5.9291e-01, PNorm = 44.3307, GNorm = 9.0151, lr_0 = 2.4798e-04
Loss = 4.9961e-01, PNorm = 44.3430, GNorm = 2.8524, lr_0 = 2.3927e-04
Loss = 4.2390e-01, PNorm = 44.3558, GNorm = 7.2400, lr_0 = 2.3086e-04
Loss = 1.2364e-02, PNorm = 44.3569, GNorm = 4.9085, lr_0 = 2.3004e-04
Validation rmse = 0.686486
Epoch 19
Loss = 4.4901e-01, PNorm = 44.3649, GNorm = 3.5334, lr_0 = 2.2196e-04
Loss = 4.5559e-01, PNorm = 44.3761, GNorm = 4.6660, lr_0 = 2.1416e-04
Validation rmse = 0.664734
Epoch 20
Loss = 4.4475e-01, PNorm = 44.3877, GNorm = 6.2145, lr_0 = 2.0590e-04
Loss = 4.5799e-01, PNorm = 44.3956, GNorm = 3.1063, lr_0 = 1.9867e-04
Validation rmse = 0.685060
Epoch 21
Loss = 3.4533e-01, PNorm = 44.4015, GNorm = 2.8817, lr_0 = 1.9101e-04
Loss = 4.1531e-01, PNorm = 44.4098, GNorm = 6.0367, lr_0 = 1.8430e-04
Validation rmse = 0.688728
Epoch 22
Loss = 3.9725e-01, PNorm = 44.4199, GNorm = 4.8408, lr_0 = 1.7719e-04
Loss = 4.1379e-01, PNorm = 44.4280, GNorm = 4.2097, lr_0 = 1.7097e-04
Loss = 4.2123e-01, PNorm = 44.4378, GNorm = 4.4048, lr_0 = 1.6496e-04
Validation rmse = 0.668001
Epoch 23
Loss = 4.0187e-01, PNorm = 44.4425, GNorm = 4.4796, lr_0 = 1.5917e-04
Loss = 4.0386e-01, PNorm = 44.4488, GNorm = 3.7042, lr_0 = 1.5358e-04
Validation rmse = 0.667967
Epoch 24
Loss = 4.2679e-01, PNorm = 44.4553, GNorm = 5.7985, lr_0 = 1.4766e-04
Loss = 4.1378e-01, PNorm = 44.4623, GNorm = 2.9719, lr_0 = 1.4247e-04
Validation rmse = 0.670682
Epoch 25
Loss = 4.8612e-01, PNorm = 44.4691, GNorm = 4.7931, lr_0 = 1.3698e-04
Loss = 4.0103e-01, PNorm = 44.4750, GNorm = 2.9517, lr_0 = 1.3217e-04
Loss = 3.7474e-01, PNorm = 44.4826, GNorm = 4.3430, lr_0 = 1.2752e-04
Validation rmse = 0.665066
Epoch 26
Loss = 4.0145e-01, PNorm = 44.4888, GNorm = 3.1441, lr_0 = 1.2261e-04
Loss = 4.2975e-01, PNorm = 44.4923, GNorm = 5.0433, lr_0 = 1.1830e-04
Validation rmse = 0.664134
Epoch 27
Loss = 3.6260e-01, PNorm = 44.4991, GNorm = 5.4779, lr_0 = 1.1374e-04
Loss = 4.0202e-01, PNorm = 44.5054, GNorm = 5.2076, lr_0 = 1.0974e-04
Validation rmse = 0.675606
Epoch 28
Loss = 5.4782e-01, PNorm = 44.5101, GNorm = 4.1354, lr_0 = 1.0589e-04
Loss = 4.4471e-01, PNorm = 44.5126, GNorm = 10.6981, lr_0 = 1.0217e-04
Loss = 3.6970e-01, PNorm = 44.5177, GNorm = 10.4038, lr_0 = 1.0000e-04
Validation rmse = 0.667586
Epoch 29
Loss = 4.0826e-01, PNorm = 44.5237, GNorm = 5.1839, lr_0 = 1.0000e-04
Loss = 3.4384e-01, PNorm = 44.5280, GNorm = 7.1410, lr_0 = 1.0000e-04
Validation rmse = 0.661144
Model 0 best validation rmse = 0.661144 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.545780
Ensemble test rmse = 0.545780
1-fold cross validation
	Seed 0 ==> test rmse = 0.545780
Overall test rmse = 0.545780 +/- 0.000000
Elapsed time = 0:02:03
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9847e+00, PNorm = 43.2612, GNorm = 1.5839, lr_0 = 3.1522e-04
Loss = 1.4760e+00, PNorm = 43.2583, GNorm = 1.5299, lr_0 = 5.1087e-04
Validation rmse = 1.335528
Epoch 1
Loss = 1.3801e+00, PNorm = 43.2635, GNorm = 1.2553, lr_0 = 7.2609e-04
Loss = 1.3650e+00, PNorm = 43.2740, GNorm = 1.4969, lr_0 = 9.2174e-04
Validation rmse = 1.133652
Epoch 2
Loss = 1.2887e+00, PNorm = 43.2950, GNorm = 2.7876, lr_0 = 9.7878e-04
Loss = 1.2075e+00, PNorm = 43.3309, GNorm = 3.2120, lr_0 = 9.4440e-04
Loss = 1.1862e+00, PNorm = 43.3674, GNorm = 3.7306, lr_0 = 9.1123e-04
Validation rmse = 1.013000
Epoch 3
Loss = 1.0940e+00, PNorm = 43.4130, GNorm = 0.9683, lr_0 = 8.7922e-04
Loss = 1.0073e+00, PNorm = 43.4700, GNorm = 3.2634, lr_0 = 8.4834e-04
Validation rmse = 0.862703
Epoch 4
Loss = 9.4413e-01, PNorm = 43.5270, GNorm = 3.8223, lr_0 = 8.1855e-04
Loss = 9.2257e-01, PNorm = 43.5772, GNorm = 5.2393, lr_0 = 7.8980e-04
Validation rmse = 0.878477
Epoch 5
Loss = 9.4637e-01, PNorm = 43.6231, GNorm = 4.2047, lr_0 = 7.6206e-04
Loss = 8.8680e-01, PNorm = 43.6649, GNorm = 4.9776, lr_0 = 7.3529e-04
Loss = 7.8835e-01, PNorm = 43.7058, GNorm = 7.8073, lr_0 = 7.0947e-04
Validation rmse = 0.748490
Epoch 6
Loss = 7.5867e-01, PNorm = 43.7444, GNorm = 8.1499, lr_0 = 6.8455e-04
Loss = 8.1295e-01, PNorm = 43.7756, GNorm = 2.2895, lr_0 = 6.6050e-04
Validation rmse = 0.731870
Epoch 7
Loss = 6.8974e-01, PNorm = 43.8100, GNorm = 10.3362, lr_0 = 6.3731e-04
Loss = 7.6251e-01, PNorm = 43.8420, GNorm = 2.2209, lr_0 = 6.1492e-04
Loss = 6.9627e-01, PNorm = 43.8660, GNorm = 1.8786, lr_0 = 5.9332e-04
Validation rmse = 0.738305
Epoch 8
Loss = 6.7367e-01, PNorm = 43.8959, GNorm = 6.8419, lr_0 = 5.7248e-04
Loss = 6.9096e-01, PNorm = 43.9226, GNorm = 2.0689, lr_0 = 5.5238e-04
Validation rmse = 0.711392
Epoch 9
Loss = 6.5702e-01, PNorm = 43.9465, GNorm = 11.4791, lr_0 = 5.3298e-04
Loss = 6.8494e-01, PNorm = 43.9695, GNorm = 8.9220, lr_0 = 5.1426e-04
Validation rmse = 0.713208
Epoch 10
Loss = 7.1508e-01, PNorm = 43.9886, GNorm = 3.3547, lr_0 = 4.9619e-04
Loss = 5.9535e-01, PNorm = 44.0152, GNorm = 4.2303, lr_0 = 4.7877e-04
Loss = 5.8330e-01, PNorm = 44.0346, GNorm = 9.3521, lr_0 = 4.6195e-04
Validation rmse = 0.693447
Epoch 11
Loss = 5.6722e-01, PNorm = 44.0604, GNorm = 10.9723, lr_0 = 4.4573e-04
Loss = 5.8192e-01, PNorm = 44.0785, GNorm = 2.4040, lr_0 = 4.3007e-04
Validation rmse = 0.676357
Epoch 12
Loss = 5.0464e-01, PNorm = 44.0976, GNorm = 10.1529, lr_0 = 4.1497e-04
Loss = 6.0765e-01, PNorm = 44.1177, GNorm = 3.2536, lr_0 = 4.0039e-04
Loss = 5.6974e-01, PNorm = 44.1364, GNorm = 2.4333, lr_0 = 3.8633e-04
Validation rmse = 0.672919
Epoch 13
Loss = 5.3188e-01, PNorm = 44.1547, GNorm = 6.2969, lr_0 = 3.7276e-04
Loss = 5.5978e-01, PNorm = 44.1662, GNorm = 2.4708, lr_0 = 3.5967e-04
Validation rmse = 0.671208
Epoch 14
Loss = 5.8063e-01, PNorm = 44.1880, GNorm = 4.8405, lr_0 = 3.4703e-04
Loss = 4.9917e-01, PNorm = 44.2062, GNorm = 5.1643, lr_0 = 3.3485e-04
Validation rmse = 0.698555
Epoch 15
Loss = 6.4271e-01, PNorm = 44.2201, GNorm = 9.1413, lr_0 = 3.2308e-04
Loss = 4.7032e-01, PNorm = 44.2359, GNorm = 3.3403, lr_0 = 3.1174e-04
Loss = 5.1346e-01, PNorm = 44.2481, GNorm = 4.9629, lr_0 = 3.0079e-04
Validation rmse = 0.672859
Epoch 16
Loss = 5.2409e-01, PNorm = 44.2605, GNorm = 5.2973, lr_0 = 2.9022e-04
Loss = 4.7790e-01, PNorm = 44.2728, GNorm = 4.2620, lr_0 = 2.8003e-04
Validation rmse = 0.645624
Epoch 17
Loss = 5.4098e-01, PNorm = 44.2886, GNorm = 5.7413, lr_0 = 2.7019e-04
Loss = 5.4699e-01, PNorm = 44.2980, GNorm = 4.9878, lr_0 = 2.6070e-04
Loss = 5.3282e-01, PNorm = 44.3081, GNorm = 5.8893, lr_0 = 2.5155e-04
Validation rmse = 0.673472
Epoch 18
Loss = 4.6093e-01, PNorm = 44.3229, GNorm = 17.1982, lr_0 = 2.4271e-04
Loss = 4.9741e-01, PNorm = 44.3325, GNorm = 7.8765, lr_0 = 2.3419e-04
Validation rmse = 0.649249
Epoch 19
Loss = 3.5107e-01, PNorm = 44.3401, GNorm = 7.5090, lr_0 = 2.2596e-04
Loss = 4.1799e-01, PNorm = 44.3507, GNorm = 10.2787, lr_0 = 2.1803e-04
Validation rmse = 0.658827
Epoch 20
Loss = 5.9438e-01, PNorm = 44.3600, GNorm = 8.4340, lr_0 = 2.1037e-04
Loss = 4.4105e-01, PNorm = 44.3694, GNorm = 6.8353, lr_0 = 2.0298e-04
Loss = 4.2429e-01, PNorm = 44.3779, GNorm = 6.2294, lr_0 = 1.9585e-04
Validation rmse = 0.644540
Epoch 21
Loss = 4.5251e-01, PNorm = 44.3874, GNorm = 9.5019, lr_0 = 1.8897e-04
Loss = 5.0582e-01, PNorm = 44.3941, GNorm = 3.0508, lr_0 = 1.8233e-04
Validation rmse = 0.658110
Epoch 22
Loss = 3.5265e-01, PNorm = 44.4019, GNorm = 4.5469, lr_0 = 1.7593e-04
Loss = 4.4694e-01, PNorm = 44.4119, GNorm = 3.7593, lr_0 = 1.6975e-04
Loss = 4.0341e-01, PNorm = 44.4186, GNorm = 5.6686, lr_0 = 1.6379e-04
Validation rmse = 0.645672
Epoch 23
Loss = 4.0139e-01, PNorm = 44.4244, GNorm = 3.5377, lr_0 = 1.5804e-04
Loss = 4.2258e-01, PNorm = 44.4308, GNorm = 5.6031, lr_0 = 1.5249e-04
Validation rmse = 0.640289
Epoch 24
Loss = 3.6737e-01, PNorm = 44.4395, GNorm = 11.9586, lr_0 = 1.4713e-04
Loss = 4.0564e-01, PNorm = 44.4480, GNorm = 4.3590, lr_0 = 1.4196e-04
Validation rmse = 0.637308
Epoch 25
Loss = 4.5845e-01, PNorm = 44.4529, GNorm = 3.6090, lr_0 = 1.3698e-04
Loss = 3.7148e-01, PNorm = 44.4574, GNorm = 5.8714, lr_0 = 1.3217e-04
Loss = 4.1537e-01, PNorm = 44.4625, GNorm = 3.2248, lr_0 = 1.2752e-04
Validation rmse = 0.630807
Epoch 26
Loss = 4.0225e-01, PNorm = 44.4698, GNorm = 3.7934, lr_0 = 1.2304e-04
Loss = 4.1440e-01, PNorm = 44.4754, GNorm = 5.6483, lr_0 = 1.1872e-04
Validation rmse = 0.645062
Epoch 27
Loss = 4.1763e-01, PNorm = 44.4792, GNorm = 3.4934, lr_0 = 1.1455e-04
Loss = 3.7769e-01, PNorm = 44.4843, GNorm = 6.3308, lr_0 = 1.1053e-04
Loss = 3.6020e-01, PNorm = 44.4896, GNorm = 3.9771, lr_0 = 1.0665e-04
Validation rmse = 0.638848
Epoch 28
Loss = 3.6714e-01, PNorm = 44.4952, GNorm = 9.3703, lr_0 = 1.0290e-04
Loss = 3.5671e-01, PNorm = 44.5001, GNorm = 8.4285, lr_0 = 1.0000e-04
Validation rmse = 0.645044
Epoch 29
Loss = 3.2485e-01, PNorm = 44.5033, GNorm = 3.7384, lr_0 = 1.0000e-04
Loss = 3.5925e-01, PNorm = 44.5075, GNorm = 11.3130, lr_0 = 1.0000e-04
Validation rmse = 0.635817
Model 0 best validation rmse = 0.630807 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.555943
Ensemble test rmse = 0.555943
1-fold cross validation
	Seed 0 ==> test rmse = 0.555943
Overall test rmse = 0.555943 +/- 0.000000
Elapsed time = 0:02:08
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.331778
Epoch 1
Loss = 1.4648e+00, PNorm = 43.2639, GNorm = 1.2473, lr_0 = 8.7143e-04
Validation rmse = 1.271776
Epoch 2
Loss = 1.4336e+00, PNorm = 43.2881, GNorm = 0.9693, lr_0 = 9.1030e-04
Validation rmse = 1.267165
Epoch 3
Loss = 1.3386e+00, PNorm = 43.3162, GNorm = 1.2069, lr_0 = 8.0940e-04
Validation rmse = 1.234557
Epoch 4
Validation rmse = 1.290067
Epoch 5
Loss = 1.2899e+00, PNorm = 43.3509, GNorm = 3.2941, lr_0 = 7.1969e-04
Validation rmse = 1.152620
Epoch 6
Loss = 1.1752e+00, PNorm = 43.3908, GNorm = 1.7563, lr_0 = 6.3992e-04
Validation rmse = 1.096133
Epoch 7
Loss = 1.0900e+00, PNorm = 43.4370, GNorm = 2.3075, lr_0 = 5.6899e-04
Validation rmse = 1.170669
Epoch 8
Loss = 1.0321e+00, PNorm = 43.4821, GNorm = 1.1161, lr_0 = 5.0592e-04
Validation rmse = 1.019638
Epoch 9
Validation rmse = 0.989469
Epoch 10
Loss = 8.6931e-01, PNorm = 43.5259, GNorm = 2.4388, lr_0 = 4.4984e-04
Validation rmse = 0.960415
Epoch 11
Loss = 8.5657e-01, PNorm = 43.5652, GNorm = 3.7051, lr_0 = 3.9998e-04
Validation rmse = 0.977992
Epoch 12
Loss = 8.3553e-01, PNorm = 43.5980, GNorm = 7.9817, lr_0 = 3.5565e-04
Validation rmse = 0.922806
Epoch 13
Loss = 8.1856e-01, PNorm = 43.6244, GNorm = 2.4829, lr_0 = 3.1623e-04
Validation rmse = 0.919303
Epoch 14
Validation rmse = 0.952010
Epoch 15
Loss = 7.0177e-01, PNorm = 43.6440, GNorm = 4.7680, lr_0 = 2.8118e-04
Validation rmse = 0.907758
Epoch 16
Loss = 7.4284e-01, PNorm = 43.6629, GNorm = 1.7156, lr_0 = 2.5001e-04
Validation rmse = 0.897147
Epoch 17
Loss = 7.3152e-01, PNorm = 43.6800, GNorm = 3.9523, lr_0 = 2.2230e-04
Validation rmse = 0.896634
Epoch 18
Loss = 7.3626e-01, PNorm = 43.6937, GNorm = 7.7655, lr_0 = 1.9766e-04
Validation rmse = 0.884688
Epoch 19
Validation rmse = 0.923609
Epoch 20
Loss = 7.1739e-01, PNorm = 43.7063, GNorm = 6.8371, lr_0 = 1.7575e-04
Validation rmse = 0.909672
Epoch 21
Loss = 6.3527e-01, PNorm = 43.7176, GNorm = 5.3368, lr_0 = 1.5627e-04
Validation rmse = 0.884127
Epoch 22
Loss = 6.7444e-01, PNorm = 43.7274, GNorm = 6.6094, lr_0 = 1.3895e-04
Validation rmse = 0.880329
Epoch 23
Loss = 6.6957e-01, PNorm = 43.7360, GNorm = 2.2799, lr_0 = 1.2355e-04
Validation rmse = 0.895256
Epoch 24
Validation rmse = 0.877711
Epoch 25
Loss = 7.2259e-01, PNorm = 43.7443, GNorm = 3.9574, lr_0 = 1.0985e-04
Validation rmse = 0.872286
Epoch 26
Loss = 7.1320e-01, PNorm = 43.7508, GNorm = 6.4251, lr_0 = 1.0000e-04
Validation rmse = 0.882718
Epoch 27
Loss = 6.8302e-01, PNorm = 43.7572, GNorm = 6.2931, lr_0 = 1.0000e-04
Validation rmse = 0.880650
Epoch 28
Loss = 6.4775e-01, PNorm = 43.7641, GNorm = 1.6793, lr_0 = 1.0000e-04
Validation rmse = 0.881385
Epoch 29
Validation rmse = 0.882217
Model 0 best validation rmse = 0.872286 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.735347
Ensemble test rmse = 0.735347
1-fold cross validation
	Seed 0 ==> test rmse = 0.735347
Overall test rmse = 0.735347 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.283420
Epoch 1
Loss = 1.4795e+00, PNorm = 43.2616, GNorm = 1.9307, lr_0 = 7.7500e-04
Validation rmse = 1.267951
Epoch 2
Loss = 1.4447e+00, PNorm = 43.2806, GNorm = 1.0268, lr_0 = 9.4019e-04
Validation rmse = 1.276681
Epoch 3
Loss = 1.3997e+00, PNorm = 43.3026, GNorm = 1.5880, lr_0 = 8.4834e-04
Validation rmse = 1.211283
Epoch 4
Loss = 1.2804e+00, PNorm = 43.3264, GNorm = 1.2426, lr_0 = 7.6547e-04
Validation rmse = 1.162992
Epoch 5
Loss = 1.2608e+00, PNorm = 43.3566, GNorm = 1.3233, lr_0 = 6.8363e-04
Validation rmse = 1.098094
Epoch 6
Loss = 1.2143e+00, PNorm = 43.3877, GNorm = 1.7022, lr_0 = 6.1685e-04
Validation rmse = 1.038363
Epoch 7
Loss = 1.1401e+00, PNorm = 43.4232, GNorm = 2.1603, lr_0 = 5.5659e-04
Validation rmse = 0.990570
Epoch 8
Validation rmse = 0.947009
Epoch 9
Loss = 1.0238e+00, PNorm = 43.4648, GNorm = 1.0052, lr_0 = 5.0222e-04
Validation rmse = 0.929702
Epoch 10
Loss = 9.8711e-01, PNorm = 43.5101, GNorm = 5.2020, lr_0 = 4.4852e-04
Validation rmse = 0.896006
Epoch 11
Loss = 9.5931e-01, PNorm = 43.5484, GNorm = 3.1011, lr_0 = 4.0471e-04
Validation rmse = 0.873883
Epoch 12
Loss = 9.0215e-01, PNorm = 43.5820, GNorm = 1.3986, lr_0 = 3.6517e-04
Validation rmse = 0.847803
Epoch 13
Loss = 8.5398e-01, PNorm = 43.6113, GNorm = 2.9459, lr_0 = 3.2950e-04
Validation rmse = 0.895478
Epoch 14
Loss = 8.3807e-01, PNorm = 43.6343, GNorm = 1.7147, lr_0 = 2.9731e-04
Validation rmse = 0.838076
Epoch 15
Loss = 8.1586e-01, PNorm = 43.6564, GNorm = 6.2940, lr_0 = 2.6553e-04
Validation rmse = 0.808359
Epoch 16
Validation rmse = 0.813783
Epoch 17
Loss = 8.1088e-01, PNorm = 43.6752, GNorm = 6.8619, lr_0 = 2.3959e-04
Validation rmse = 0.805243
Epoch 18
Loss = 8.0973e-01, PNorm = 43.6899, GNorm = 10.7424, lr_0 = 2.1618e-04
Validation rmse = 0.784953
Epoch 19
Loss = 8.3493e-01, PNorm = 43.7043, GNorm = 2.5587, lr_0 = 1.9506e-04
Validation rmse = 0.781146
Epoch 20
Loss = 7.0377e-01, PNorm = 43.7195, GNorm = 2.0255, lr_0 = 1.7421e-04
Validation rmse = 0.776626
Epoch 21
Loss = 7.3564e-01, PNorm = 43.7323, GNorm = 5.6429, lr_0 = 1.5719e-04
Validation rmse = 0.779920
Epoch 22
Loss = 7.3636e-01, PNorm = 43.7420, GNorm = 5.5131, lr_0 = 1.4184e-04
Validation rmse = 0.767724
Epoch 23
Loss = 7.0182e-01, PNorm = 43.7513, GNorm = 4.0663, lr_0 = 1.2798e-04
Loss = 6.9432e-01, PNorm = 43.7521, GNorm = 2.6679, lr_0 = 1.2667e-04
Validation rmse = 0.779082
Epoch 24
Validation rmse = 0.766113
Epoch 25
Loss = 6.1770e-01, PNorm = 43.7609, GNorm = 5.6098, lr_0 = 1.1430e-04
Validation rmse = 0.775472
Epoch 26
Loss = 7.3830e-01, PNorm = 43.7682, GNorm = 3.6619, lr_0 = 1.0313e-04
Validation rmse = 0.787909
Epoch 27
Loss = 6.2542e-01, PNorm = 43.7751, GNorm = 3.5322, lr_0 = 1.0000e-04
Validation rmse = 0.772285
Epoch 28
Loss = 7.1079e-01, PNorm = 43.7818, GNorm = 8.9619, lr_0 = 1.0000e-04
Validation rmse = 0.746628
Epoch 29
Loss = 6.6848e-01, PNorm = 43.7894, GNorm = 9.6147, lr_0 = 1.0000e-04
Validation rmse = 0.750454
Model 0 best validation rmse = 0.746628 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.721428
Ensemble test rmse = 0.721428
1-fold cross validation
	Seed 0 ==> test rmse = 0.721428
Overall test rmse = 0.721428 +/- 0.000000
Elapsed time = 0:01:34
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.408031
Epoch 1
Loss = 1.4739e+00, PNorm = 43.2609, GNorm = 2.1667, lr_0 = 7.0000e-04
Validation rmse = 1.316492
Epoch 2
Loss = 1.4627e+00, PNorm = 43.2756, GNorm = 0.7774, lr_0 = 9.6411e-04
Validation rmse = 1.260502
Epoch 3
Loss = 1.3137e+00, PNorm = 43.2977, GNorm = 0.5901, lr_0 = 8.7192e-04
Validation rmse = 1.206560
Epoch 4
Loss = 1.3528e+00, PNorm = 43.3212, GNorm = 0.9511, lr_0 = 7.9578e-04
Validation rmse = 1.137739
Epoch 5
Loss = 1.2161e+00, PNorm = 43.3527, GNorm = 3.0118, lr_0 = 7.1969e-04
Validation rmse = 1.080777
Epoch 6
Loss = 1.1533e+00, PNorm = 43.3848, GNorm = 0.7635, lr_0 = 6.5684e-04
Validation rmse = 1.014500
Epoch 7
Loss = 1.0684e+00, PNorm = 43.4239, GNorm = 3.7611, lr_0 = 5.9948e-04
Validation rmse = 0.995719
Epoch 8
Loss = 1.0884e+00, PNorm = 43.4664, GNorm = 6.8350, lr_0 = 5.4216e-04
Validation rmse = 1.015552
Epoch 9
Loss = 9.8665e-01, PNorm = 43.5000, GNorm = 3.3974, lr_0 = 4.9482e-04
Validation rmse = 0.921984
Epoch 10
Loss = 9.6878e-01, PNorm = 43.5355, GNorm = 2.1973, lr_0 = 4.4750e-04
Validation rmse = 0.874424
Epoch 11
Loss = 8.9111e-01, PNorm = 43.5663, GNorm = 3.2222, lr_0 = 4.0842e-04
Validation rmse = 0.852365
Epoch 12
Loss = 7.9349e-01, PNorm = 43.5929, GNorm = 6.9944, lr_0 = 3.7276e-04
Validation rmse = 0.840483
Epoch 13
Loss = 8.2825e-01, PNorm = 43.6188, GNorm = 2.7750, lr_0 = 3.3711e-04
Validation rmse = 0.824161
Epoch 14
Loss = 7.7344e-01, PNorm = 43.6414, GNorm = 1.5380, lr_0 = 3.0768e-04
Validation rmse = 0.807928
Epoch 15
Loss = 7.7929e-01, PNorm = 43.6623, GNorm = 8.1770, lr_0 = 2.7826e-04
Validation rmse = 0.819410
Epoch 16
Loss = 7.6015e-01, PNorm = 43.6786, GNorm = 6.0799, lr_0 = 2.5396e-04
Validation rmse = 0.784240
Epoch 17
Loss = 7.1739e-01, PNorm = 43.6940, GNorm = 1.6933, lr_0 = 2.3178e-04
Validation rmse = 0.775582
Epoch 18
Loss = 7.2180e-01, PNorm = 43.7116, GNorm = 3.6456, lr_0 = 2.0962e-04
Validation rmse = 0.771962
Epoch 19
Loss = 6.7556e-01, PNorm = 43.7244, GNorm = 3.8348, lr_0 = 1.9131e-04
Validation rmse = 0.781092
Epoch 20
Loss = 6.9814e-01, PNorm = 43.7366, GNorm = 2.5148, lr_0 = 1.7302e-04
Validation rmse = 0.751762
Epoch 21
Loss = 6.7270e-01, PNorm = 43.7470, GNorm = 1.9098, lr_0 = 1.5791e-04
Loss = 7.9535e-01, PNorm = 43.7482, GNorm = 11.7644, lr_0 = 1.5647e-04
Validation rmse = 0.748128
Epoch 22
Loss = 6.6721e-01, PNorm = 43.7586, GNorm = 3.5347, lr_0 = 1.4281e-04
Validation rmse = 0.746949
Epoch 23
Loss = 6.7367e-01, PNorm = 43.7675, GNorm = 5.9399, lr_0 = 1.3034e-04
Validation rmse = 0.767688
Epoch 24
Validation rmse = 0.760533
Epoch 25
Loss = 7.1950e-01, PNorm = 43.7756, GNorm = 9.2183, lr_0 = 1.1788e-04
Validation rmse = 0.733987
Epoch 26
Loss = 6.1081e-01, PNorm = 43.7828, GNorm = 1.5278, lr_0 = 1.0758e-04
Validation rmse = 0.734574
Epoch 27
Loss = 5.9088e-01, PNorm = 43.7898, GNorm = 4.0564, lr_0 = 1.0000e-04
Validation rmse = 0.739372
Epoch 28
Loss = 6.2873e-01, PNorm = 43.7964, GNorm = 8.0238, lr_0 = 1.0000e-04
Validation rmse = 0.737764
Epoch 29
Loss = 5.8648e-01, PNorm = 43.8025, GNorm = 5.9417, lr_0 = 1.0000e-04
Validation rmse = 0.727131
Model 0 best validation rmse = 0.727131 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.726651
Ensemble test rmse = 0.726651
1-fold cross validation
	Seed 0 ==> test rmse = 0.726651
Overall test rmse = 0.726651 +/- 0.000000
Elapsed time = 0:01:47
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8567e+00, PNorm = 43.2621, GNorm = 1.9361, lr_0 = 5.9500e-04
Loss = 1.3655e+00, PNorm = 43.2626, GNorm = 1.8458, lr_0 = 6.4000e-04
Validation rmse = 1.421631
Epoch 1
Loss = 1.4436e+00, PNorm = 43.2791, GNorm = 1.2765, lr_0 = 9.8369e-04
Loss = 1.2710e+00, PNorm = 43.2811, GNorm = 1.0401, lr_0 = 9.7563e-04
Validation rmse = 1.446590
Epoch 2
Loss = 1.3475e+00, PNorm = 43.3048, GNorm = 0.5445, lr_0 = 8.9861e-04
Validation rmse = 1.385339
Epoch 3
Loss = 1.2900e+00, PNorm = 43.3336, GNorm = 1.1030, lr_0 = 8.2767e-04
Validation rmse = 1.283350
Epoch 4
Loss = 1.2111e+00, PNorm = 43.3716, GNorm = 2.9401, lr_0 = 7.5609e-04
Validation rmse = 1.192603
Epoch 5
Loss = 1.1286e+00, PNorm = 43.4147, GNorm = 0.8394, lr_0 = 6.9069e-04
Validation rmse = 1.122632
Epoch 6
Loss = 1.0602e+00, PNorm = 43.4598, GNorm = 4.2403, lr_0 = 6.3617e-04
Validation rmse = 1.016130
Epoch 7
Loss = 9.9083e-01, PNorm = 43.5054, GNorm = 2.4550, lr_0 = 5.8115e-04
Validation rmse = 0.970609
Epoch 8
Loss = 9.4023e-01, PNorm = 43.5469, GNorm = 3.3679, lr_0 = 5.3527e-04
Validation rmse = 0.996891
Epoch 9
Loss = 9.1356e-01, PNorm = 43.5813, GNorm = 2.3732, lr_0 = 4.8897e-04
Validation rmse = 0.950619
Epoch 10
Loss = 8.6085e-01, PNorm = 43.6117, GNorm = 1.9789, lr_0 = 4.4668e-04
Validation rmse = 0.884050
Epoch 11
Loss = 8.0796e-01, PNorm = 43.6416, GNorm = 1.7727, lr_0 = 4.1142e-04
Validation rmse = 0.867375
Epoch 12
Loss = 7.6753e-01, PNorm = 43.6746, GNorm = 7.4149, lr_0 = 3.7584e-04
Validation rmse = 0.875827
Epoch 13
Loss = 7.8310e-01, PNorm = 43.6964, GNorm = 8.0794, lr_0 = 3.4617e-04
Validation rmse = 0.848842
Epoch 14
Loss = 7.0607e-01, PNorm = 43.7194, GNorm = 1.6183, lr_0 = 3.1623e-04
Validation rmse = 0.837763
Epoch 15
Loss = 7.2643e-01, PNorm = 43.7434, GNorm = 1.8874, lr_0 = 2.8888e-04
Validation rmse = 0.837465
Epoch 16
Loss = 6.8789e-01, PNorm = 43.7609, GNorm = 3.8811, lr_0 = 2.6607e-04
Validation rmse = 0.837813
Epoch 17
Loss = 6.6216e-01, PNorm = 43.7774, GNorm = 7.7844, lr_0 = 2.4306e-04
Validation rmse = 0.836609
Epoch 18
Loss = 6.6912e-01, PNorm = 43.7912, GNorm = 10.4135, lr_0 = 2.2387e-04
Validation rmse = 0.837479
Epoch 19
Loss = 6.8118e-01, PNorm = 43.8068, GNorm = 1.9785, lr_0 = 2.0451e-04
Validation rmse = 0.810990
Epoch 20
Loss = 5.9182e-01, PNorm = 43.8206, GNorm = 9.1838, lr_0 = 1.8682e-04
Validation rmse = 0.816886
Epoch 21
Loss = 6.5056e-01, PNorm = 43.8318, GNorm = 1.9520, lr_0 = 1.7207e-04
Validation rmse = 0.804010
Epoch 22
Loss = 6.1679e-01, PNorm = 43.8430, GNorm = 6.1803, lr_0 = 1.5719e-04
Validation rmse = 0.802699
Epoch 23
Loss = 5.4627e-01, PNorm = 43.8531, GNorm = 2.8045, lr_0 = 1.4360e-04
Validation rmse = 0.811626
Epoch 24
Loss = 5.9578e-01, PNorm = 43.8617, GNorm = 5.2595, lr_0 = 1.3226e-04
Validation rmse = 0.800973
Epoch 25
Loss = 5.8207e-01, PNorm = 43.8700, GNorm = 2.0130, lr_0 = 1.2082e-04
Loss = 5.8406e-01, PNorm = 43.8779, GNorm = 4.7054, lr_0 = 1.1128e-04
Validation rmse = 0.802633
Epoch 26
Loss = 5.7625e-01, PNorm = 43.8843, GNorm = 3.8908, lr_0 = 1.0250e-04
Loss = 7.8964e-01, PNorm = 43.8850, GNorm = 12.0196, lr_0 = 1.0166e-04
Validation rmse = 0.799791
Epoch 27
Loss = 5.7649e-01, PNorm = 43.8915, GNorm = 7.6929, lr_0 = 1.0000e-04
Loss = 7.5340e-01, PNorm = 43.8920, GNorm = 3.4089, lr_0 = 1.0000e-04
Validation rmse = 0.809423
Epoch 28
Loss = 6.0231e-01, PNorm = 43.8980, GNorm = 2.6867, lr_0 = 1.0000e-04
Validation rmse = 0.799406
Epoch 29
Loss = 5.8895e-01, PNorm = 43.9037, GNorm = 10.8893, lr_0 = 1.0000e-04
Validation rmse = 0.793008
Model 0 best validation rmse = 0.793008 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.731341
Ensemble test rmse = 0.731341
1-fold cross validation
	Seed 0 ==> test rmse = 0.731341
Overall test rmse = 0.731341 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8794e+00, PNorm = 43.2600, GNorm = 1.1247, lr_0 = 5.5000e-04
Validation rmse = 1.407932
Epoch 1
Loss = 1.4485e+00, PNorm = 43.2711, GNorm = 1.0382, lr_0 = 1.0000e-03
Validation rmse = 1.430129
Epoch 2
Loss = 1.3484e+00, PNorm = 43.2951, GNorm = 0.6546, lr_0 = 9.2106e-04
Validation rmse = 1.357317
Epoch 3
Loss = 1.3039e+00, PNorm = 43.3246, GNorm = 0.7891, lr_0 = 8.4834e-04
Validation rmse = 1.281617
Epoch 4
Loss = 1.2558e+00, PNorm = 43.3549, GNorm = 0.6577, lr_0 = 7.8137e-04
Validation rmse = 1.212995
Epoch 5
Loss = 1.1817e+00, PNorm = 43.3934, GNorm = 2.5755, lr_0 = 7.1969e-04
Validation rmse = 1.133918
Epoch 6
Loss = 1.1068e+00, PNorm = 43.4368, GNorm = 2.6951, lr_0 = 6.6784e-04
Validation rmse = 1.084824
Epoch 7
Loss = 1.0444e+00, PNorm = 43.4857, GNorm = 6.4536, lr_0 = 6.1512e-04
Validation rmse = 1.013550
Epoch 8
Loss = 1.0630e+00, PNorm = 43.5272, GNorm = 4.1319, lr_0 = 5.6656e-04
Loss = 9.5705e-01, PNorm = 43.5664, GNorm = 2.9009, lr_0 = 5.2575e-04
Loss = 9.8222e-01, PNorm = 43.5699, GNorm = 4.2629, lr_0 = 5.2183e-04
Validation rmse = 1.005802
Epoch 9
Loss = 9.1043e-01, PNorm = 43.6037, GNorm = 3.9650, lr_0 = 4.8424e-04
Validation rmse = 0.917703
Epoch 10
Loss = 8.7424e-01, PNorm = 43.6350, GNorm = 7.8956, lr_0 = 4.4602e-04
Validation rmse = 0.955753
Epoch 11
Loss = 8.3346e-01, PNorm = 43.6617, GNorm = 3.2072, lr_0 = 4.1389e-04
Validation rmse = 0.882604
Epoch 12
Loss = 8.0763e-01, PNorm = 43.6909, GNorm = 4.8432, lr_0 = 3.8121e-04
Validation rmse = 0.853259
Epoch 13
Loss = 7.7937e-01, PNorm = 43.7191, GNorm = 2.0890, lr_0 = 3.5112e-04
Validation rmse = 0.853858
Epoch 14
Loss = 7.9711e-01, PNorm = 43.7423, GNorm = 4.7535, lr_0 = 3.2340e-04
Validation rmse = 0.890418
Epoch 15
Loss = 7.7517e-01, PNorm = 43.7573, GNorm = 2.0107, lr_0 = 2.9787e-04
Validation rmse = 0.843131
Epoch 16
Loss = 6.7964e-01, PNorm = 43.7730, GNorm = 1.3157, lr_0 = 2.7641e-04
Loss = 7.1233e-01, PNorm = 43.7891, GNorm = 2.4403, lr_0 = 2.5650e-04
Loss = 6.5526e-01, PNorm = 43.7908, GNorm = 7.8878, lr_0 = 2.5459e-04
Validation rmse = 0.828984
Epoch 17
Loss = 6.8154e-01, PNorm = 43.8068, GNorm = 2.0607, lr_0 = 2.3625e-04
Validation rmse = 0.833376
Epoch 18
Loss = 6.4641e-01, PNorm = 43.8198, GNorm = 1.7109, lr_0 = 2.1760e-04
Validation rmse = 0.820551
Epoch 19
Loss = 6.7426e-01, PNorm = 43.8340, GNorm = 6.7589, lr_0 = 2.0042e-04
Validation rmse = 0.818307
Epoch 20
Loss = 6.2866e-01, PNorm = 43.8465, GNorm = 2.9812, lr_0 = 1.8460e-04
Validation rmse = 0.841927
Epoch 21
Loss = 6.2781e-01, PNorm = 43.8573, GNorm = 3.6594, lr_0 = 1.7003e-04
Validation rmse = 0.834666
Epoch 22
Loss = 6.7563e-01, PNorm = 43.8649, GNorm = 8.2061, lr_0 = 1.5778e-04
Validation rmse = 0.824302
Epoch 23
Loss = 5.8345e-01, PNorm = 43.8740, GNorm = 5.6683, lr_0 = 1.4532e-04
Validation rmse = 0.818415
Epoch 24
Loss = 6.0630e-01, PNorm = 43.8840, GNorm = 3.0034, lr_0 = 1.3385e-04
Validation rmse = 0.822780
Epoch 25
Loss = 7.5252e-01, PNorm = 43.8926, GNorm = 1.8590, lr_0 = 1.2328e-04
Loss = 5.8085e-01, PNorm = 43.9006, GNorm = 3.9582, lr_0 = 1.1440e-04
Loss = 8.4483e-01, PNorm = 43.9013, GNorm = 7.2137, lr_0 = 1.1355e-04
Validation rmse = 0.807397
Epoch 26
Loss = 5.9195e-01, PNorm = 43.9083, GNorm = 2.9955, lr_0 = 1.0537e-04
Validation rmse = 0.811832
Epoch 27
Loss = 5.8861e-01, PNorm = 43.9150, GNorm = 7.2914, lr_0 = 1.0000e-04
Validation rmse = 0.814158
Epoch 28
Loss = 5.5533e-01, PNorm = 43.9216, GNorm = 2.2035, lr_0 = 1.0000e-04
Validation rmse = 0.814177
Epoch 29
Loss = 6.0218e-01, PNorm = 43.9283, GNorm = 4.5055, lr_0 = 1.0000e-04
Validation rmse = 0.825463
Model 0 best validation rmse = 0.807397 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.743928
Ensemble test rmse = 0.743928
1-fold cross validation
	Seed 0 ==> test rmse = 0.743928
Overall test rmse = 0.743928 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8169e+00, PNorm = 43.2606, GNorm = 1.5890, lr_0 = 5.5000e-04
Validation rmse = 1.411875
Epoch 1
Loss = 1.4428e+00, PNorm = 43.2754, GNorm = 0.8621, lr_0 = 1.0000e-03
Validation rmse = 1.438341
Epoch 2
Loss = 1.3483e+00, PNorm = 43.2983, GNorm = 1.4029, lr_0 = 9.2797e-04
Validation rmse = 1.371354
Epoch 3
Loss = 1.2735e+00, PNorm = 43.3245, GNorm = 1.4793, lr_0 = 8.6112e-04
Validation rmse = 1.292476
Epoch 4
Loss = 1.2031e+00, PNorm = 43.3567, GNorm = 1.5034, lr_0 = 7.9909e-04
Validation rmse = 1.202868
Epoch 5
Loss = 1.0581e+00, PNorm = 43.3946, GNorm = 1.0927, lr_0 = 7.4153e-04
Loss = 1.1181e+00, PNorm = 43.4410, GNorm = 6.8077, lr_0 = 6.8812e-04
Validation rmse = 1.167240
Epoch 6
Loss = 1.0772e+00, PNorm = 43.4825, GNorm = 1.1727, lr_0 = 6.3855e-04
Validation rmse = 1.025462
Epoch 7
Loss = 1.0095e+00, PNorm = 43.5269, GNorm = 5.6077, lr_0 = 5.9255e-04
Validation rmse = 1.016321
Epoch 8
Loss = 9.4941e-01, PNorm = 43.5691, GNorm = 1.8666, lr_0 = 5.4987e-04
Validation rmse = 0.960689
Epoch 9
Loss = 8.7414e-01, PNorm = 43.6112, GNorm = 1.1239, lr_0 = 5.1026e-04
Validation rmse = 0.944207
Epoch 10
Loss = 8.4616e-01, PNorm = 43.6522, GNorm = 2.6493, lr_0 = 4.7351e-04
Loss = 8.1318e-01, PNorm = 43.6875, GNorm = 1.6145, lr_0 = 4.3940e-04
Validation rmse = 0.891821
Epoch 11
Loss = 7.8087e-01, PNorm = 43.7184, GNorm = 5.0162, lr_0 = 4.0775e-04
Validation rmse = 0.899988
Epoch 12
Loss = 7.7412e-01, PNorm = 43.7479, GNorm = 9.1570, lr_0 = 3.7837e-04
Validation rmse = 0.866697
Epoch 13
Loss = 7.2308e-01, PNorm = 43.7758, GNorm = 1.7264, lr_0 = 3.5112e-04
Validation rmse = 0.855555
Epoch 14
Loss = 6.9019e-01, PNorm = 43.8017, GNorm = 2.0036, lr_0 = 3.2583e-04
Validation rmse = 0.861002
Epoch 15
Loss = 7.6149e-01, PNorm = 43.8242, GNorm = 3.7149, lr_0 = 3.0236e-04
Loss = 6.6303e-01, PNorm = 43.8450, GNorm = 2.3311, lr_0 = 2.8058e-04
Validation rmse = 0.849789
Epoch 16
Loss = 6.7493e-01, PNorm = 43.8646, GNorm = 1.7589, lr_0 = 2.6037e-04
Validation rmse = 0.855943
Epoch 17
Loss = 6.3631e-01, PNorm = 43.8827, GNorm = 2.3537, lr_0 = 2.4161e-04
Validation rmse = 0.888916
Epoch 18
Loss = 7.3161e-01, PNorm = 43.8987, GNorm = 4.6040, lr_0 = 2.2421e-04
Validation rmse = 0.842140
Epoch 19
Loss = 6.2564e-01, PNorm = 43.9125, GNorm = 3.4092, lr_0 = 2.0806e-04
Validation rmse = 0.839039
Epoch 20
Loss = 6.3213e-01, PNorm = 43.9257, GNorm = 2.3252, lr_0 = 1.9307e-04
Loss = 6.1497e-01, PNorm = 43.9377, GNorm = 3.5749, lr_0 = 1.7916e-04
Validation rmse = 0.845363
Epoch 21
Loss = 6.1720e-01, PNorm = 43.9480, GNorm = 11.2983, lr_0 = 1.6626e-04
Validation rmse = 0.851387
Epoch 22
Loss = 6.1387e-01, PNorm = 43.9575, GNorm = 5.3143, lr_0 = 1.5428e-04
Validation rmse = 0.843263
Epoch 23
Loss = 6.2928e-01, PNorm = 43.9676, GNorm = 3.5221, lr_0 = 1.4317e-04
Validation rmse = 0.841357
Epoch 24
Loss = 5.7568e-01, PNorm = 43.9769, GNorm = 2.0666, lr_0 = 1.3285e-04
Validation rmse = 0.829246
Epoch 25
Loss = 4.9385e-01, PNorm = 43.9850, GNorm = 4.6996, lr_0 = 1.2328e-04
Loss = 5.7737e-01, PNorm = 43.9932, GNorm = 12.0492, lr_0 = 1.1440e-04
Validation rmse = 0.832666
Epoch 26
Loss = 5.6670e-01, PNorm = 44.0004, GNorm = 10.1679, lr_0 = 1.0616e-04
Validation rmse = 0.833702
Epoch 27
Loss = 5.3102e-01, PNorm = 44.0068, GNorm = 9.1792, lr_0 = 1.0000e-04
Validation rmse = 0.829886
Epoch 28
Loss = 5.8398e-01, PNorm = 44.0130, GNorm = 4.0261, lr_0 = 1.0000e-04
Validation rmse = 0.823333
Epoch 29
Loss = 5.7874e-01, PNorm = 44.0193, GNorm = 8.6118, lr_0 = 1.0000e-04
Validation rmse = 0.824296
Model 0 best validation rmse = 0.823333 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.681527
Ensemble test rmse = 0.681527
1-fold cross validation
	Seed 0 ==> test rmse = 0.681527
Overall test rmse = 0.681527 +/- 0.000000
Elapsed time = 0:02:08
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.393006
Epoch 1
Loss = 1.4401e+00, PNorm = 43.2639, GNorm = 1.7045, lr_0 = 8.7143e-04
Validation rmse = 1.334197
Epoch 2
Loss = 1.4380e+00, PNorm = 43.2872, GNorm = 0.9950, lr_0 = 9.1030e-04
Validation rmse = 1.297323
Epoch 3
Loss = 1.3378e+00, PNorm = 43.3146, GNorm = 0.7420, lr_0 = 8.0940e-04
Validation rmse = 1.275756
Epoch 4
Validation rmse = 1.253283
Epoch 5
Loss = 1.2660e+00, PNorm = 43.3427, GNorm = 1.3290, lr_0 = 7.1969e-04
Validation rmse = 1.200310
Epoch 6
Loss = 1.2715e+00, PNorm = 43.3730, GNorm = 1.3891, lr_0 = 6.3992e-04
Validation rmse = 1.130133
Epoch 7
Loss = 1.1744e+00, PNorm = 43.4051, GNorm = 3.0666, lr_0 = 5.6899e-04
Validation rmse = 1.088004
Epoch 8
Loss = 1.1138e+00, PNorm = 43.4410, GNorm = 0.9048, lr_0 = 5.0592e-04
Validation rmse = 1.124856
Epoch 9
Validation rmse = 1.037041
Epoch 10
Loss = 1.0261e+00, PNorm = 43.4724, GNorm = 2.7097, lr_0 = 4.4984e-04
Validation rmse = 0.999559
Epoch 11
Loss = 1.0317e+00, PNorm = 43.5060, GNorm = 6.4856, lr_0 = 3.9998e-04
Validation rmse = 0.969014
Epoch 12
Loss = 9.6801e-01, PNorm = 43.5340, GNorm = 6.9998, lr_0 = 3.5565e-04
Validation rmse = 0.940329
Epoch 13
Loss = 9.4850e-01, PNorm = 43.5563, GNorm = 1.7335, lr_0 = 3.1623e-04
Validation rmse = 0.932209
Epoch 14
Validation rmse = 0.924381
Epoch 15
Loss = 8.2255e-01, PNorm = 43.5787, GNorm = 2.1133, lr_0 = 2.8118e-04
Validation rmse = 0.904586
Epoch 16
Loss = 8.4294e-01, PNorm = 43.5997, GNorm = 4.9531, lr_0 = 2.5001e-04
Validation rmse = 0.892514
Epoch 17
Loss = 8.2729e-01, PNorm = 43.6185, GNorm = 4.1114, lr_0 = 2.2230e-04
Validation rmse = 0.903376
Epoch 18
Loss = 8.1270e-01, PNorm = 43.6357, GNorm = 2.0769, lr_0 = 1.9766e-04
Validation rmse = 0.903371
Epoch 19
Validation rmse = 0.931040
Epoch 20
Loss = 6.3845e-01, PNorm = 43.6497, GNorm = 5.8848, lr_0 = 1.7575e-04
Validation rmse = 0.926236
Epoch 21
Loss = 7.8344e-01, PNorm = 43.6626, GNorm = 7.2398, lr_0 = 1.5627e-04
Validation rmse = 0.875724
Epoch 22
Loss = 7.3328e-01, PNorm = 43.6746, GNorm = 4.9971, lr_0 = 1.3895e-04
Validation rmse = 0.867101
Epoch 23
Loss = 7.2341e-01, PNorm = 43.6844, GNorm = 2.3223, lr_0 = 1.2355e-04
Validation rmse = 0.870861
Epoch 24
Validation rmse = 0.870267
Epoch 25
Loss = 8.0603e-01, PNorm = 43.6939, GNorm = 1.6426, lr_0 = 1.0985e-04
Validation rmse = 0.892564
Epoch 26
Loss = 7.5328e-01, PNorm = 43.7016, GNorm = 3.9692, lr_0 = 1.0000e-04
Validation rmse = 0.863764
Epoch 27
Loss = 7.3005e-01, PNorm = 43.7091, GNorm = 2.2150, lr_0 = 1.0000e-04
Validation rmse = 0.883825
Epoch 28
Loss = 6.8494e-01, PNorm = 43.7168, GNorm = 6.9779, lr_0 = 1.0000e-04
Validation rmse = 0.871487
Epoch 29
Validation rmse = 0.865863
Model 0 best validation rmse = 0.863764 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.731799
Ensemble test rmse = 0.731799
1-fold cross validation
	Seed 0 ==> test rmse = 0.731799
Overall test rmse = 0.731799 +/- 0.000000
Elapsed time = 0:01:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.351226
Epoch 1
Loss = 1.4465e+00, PNorm = 43.2632, GNorm = 2.4348, lr_0 = 7.7500e-04
Validation rmse = 1.278518
Epoch 2
Loss = 1.4693e+00, PNorm = 43.2829, GNorm = 0.8245, lr_0 = 9.4019e-04
Validation rmse = 1.226400
Epoch 3
Loss = 1.3292e+00, PNorm = 43.3059, GNorm = 0.7635, lr_0 = 8.4834e-04
Validation rmse = 1.169916
Epoch 4
Loss = 1.2791e+00, PNorm = 43.3333, GNorm = 0.9200, lr_0 = 7.6547e-04
Validation rmse = 1.102194
Epoch 5
Loss = 1.2201e+00, PNorm = 43.3710, GNorm = 1.7623, lr_0 = 6.8363e-04
Validation rmse = 1.051689
Epoch 6
Loss = 1.1672e+00, PNorm = 43.4093, GNorm = 2.3471, lr_0 = 6.1685e-04
Validation rmse = 1.110224
Epoch 7
Loss = 1.0998e+00, PNorm = 43.4499, GNorm = 1.6336, lr_0 = 5.5659e-04
Validation rmse = 1.003661
Epoch 8
Validation rmse = 0.943347
Epoch 9
Loss = 9.6506e-01, PNorm = 43.4873, GNorm = 1.0282, lr_0 = 5.0222e-04
Validation rmse = 0.939305
Epoch 10
Loss = 9.7068e-01, PNorm = 43.5279, GNorm = 0.9506, lr_0 = 4.4852e-04
Validation rmse = 0.881890
Epoch 11
Loss = 9.1887e-01, PNorm = 43.5578, GNorm = 6.4779, lr_0 = 4.0471e-04
Validation rmse = 0.876656
Epoch 12
Loss = 8.8570e-01, PNorm = 43.5831, GNorm = 4.2716, lr_0 = 3.6517e-04
Validation rmse = 0.875747
Epoch 13
Loss = 8.8066e-01, PNorm = 43.6086, GNorm = 3.7237, lr_0 = 3.2950e-04
Validation rmse = 0.828194
Epoch 14
Loss = 8.0620e-01, PNorm = 43.6336, GNorm = 1.3472, lr_0 = 2.9731e-04
Validation rmse = 0.806822
Epoch 15
Loss = 7.9098e-01, PNorm = 43.6583, GNorm = 1.8008, lr_0 = 2.6553e-04
Validation rmse = 0.803864
Epoch 16
Validation rmse = 0.799535
Epoch 17
Loss = 8.0149e-01, PNorm = 43.6786, GNorm = 3.7874, lr_0 = 2.3959e-04
Validation rmse = 0.782141
Epoch 18
Loss = 7.1801e-01, PNorm = 43.6956, GNorm = 9.1818, lr_0 = 2.1618e-04
Validation rmse = 0.773973
Epoch 19
Loss = 6.9209e-01, PNorm = 43.7114, GNorm = 1.6843, lr_0 = 1.9506e-04
Validation rmse = 0.767365
Epoch 20
Loss = 6.6634e-01, PNorm = 43.7263, GNorm = 1.8695, lr_0 = 1.7421e-04
Validation rmse = 0.767435
Epoch 21
Loss = 6.9758e-01, PNorm = 43.7386, GNorm = 2.1259, lr_0 = 1.5719e-04
Validation rmse = 0.760453
Epoch 22
Loss = 6.9543e-01, PNorm = 43.7496, GNorm = 8.9537, lr_0 = 1.4184e-04
Validation rmse = 0.767081
Epoch 23
Loss = 6.5670e-01, PNorm = 43.7597, GNorm = 7.9160, lr_0 = 1.2798e-04
Loss = 6.8260e-01, PNorm = 43.7607, GNorm = 2.3463, lr_0 = 1.2667e-04
Validation rmse = 0.752214
Epoch 24
Validation rmse = 0.750774
Epoch 25
Loss = 5.4083e-01, PNorm = 43.7697, GNorm = 3.7507, lr_0 = 1.1430e-04
Validation rmse = 0.761303
Epoch 26
Loss = 6.7113e-01, PNorm = 43.7771, GNorm = 2.5326, lr_0 = 1.0313e-04
Validation rmse = 0.752384
Epoch 27
Loss = 6.1413e-01, PNorm = 43.7841, GNorm = 3.8843, lr_0 = 1.0000e-04
Validation rmse = 0.751926
Epoch 28
Loss = 6.3088e-01, PNorm = 43.7911, GNorm = 4.4368, lr_0 = 1.0000e-04
Validation rmse = 0.747611
Epoch 29
Loss = 6.0048e-01, PNorm = 43.7987, GNorm = 1.5668, lr_0 = 1.0000e-04
Validation rmse = 0.744699
Model 0 best validation rmse = 0.744699 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.736962
Ensemble test rmse = 0.736962
1-fold cross validation
	Seed 0 ==> test rmse = 0.736962
Overall test rmse = 0.736962 +/- 0.000000
Elapsed time = 0:01:40
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.302992
Epoch 1
Loss = 1.4942e+00, PNorm = 43.2640, GNorm = 2.7217, lr_0 = 7.0000e-04
Validation rmse = 1.309179
Epoch 2
Loss = 1.4675e+00, PNorm = 43.2852, GNorm = 0.7576, lr_0 = 9.6411e-04
Validation rmse = 1.293562
Epoch 3
Loss = 1.2278e+00, PNorm = 43.3152, GNorm = 0.6447, lr_0 = 8.7192e-04
Validation rmse = 1.227712
Epoch 4
Loss = 1.2588e+00, PNorm = 43.3437, GNorm = 0.5738, lr_0 = 7.9578e-04
Validation rmse = 1.145842
Epoch 5
Loss = 1.1910e+00, PNorm = 43.3804, GNorm = 1.7210, lr_0 = 7.1969e-04
Validation rmse = 1.040991
Epoch 6
Loss = 1.1306e+00, PNorm = 43.4189, GNorm = 2.8792, lr_0 = 6.5684e-04
Validation rmse = 0.964336
Epoch 7
Loss = 1.0397e+00, PNorm = 43.4628, GNorm = 3.0799, lr_0 = 5.9948e-04
Validation rmse = 0.926338
Epoch 8
Loss = 1.0158e+00, PNorm = 43.5101, GNorm = 2.9465, lr_0 = 5.4216e-04
Validation rmse = 0.889007
Epoch 9
Loss = 9.4098e-01, PNorm = 43.5505, GNorm = 2.6110, lr_0 = 4.9482e-04
Validation rmse = 0.866592
Epoch 10
Loss = 8.9612e-01, PNorm = 43.5924, GNorm = 2.2182, lr_0 = 4.4750e-04
Validation rmse = 0.782503
Epoch 11
Loss = 8.3096e-01, PNorm = 43.6258, GNorm = 1.7710, lr_0 = 4.0842e-04
Validation rmse = 0.786172
Epoch 12
Loss = 8.4403e-01, PNorm = 43.6547, GNorm = 1.6768, lr_0 = 3.7276e-04
Validation rmse = 0.756270
Epoch 13
Loss = 7.6078e-01, PNorm = 43.6797, GNorm = 5.9592, lr_0 = 3.3711e-04
Validation rmse = 0.779075
Epoch 14
Loss = 7.1607e-01, PNorm = 43.7023, GNorm = 2.4165, lr_0 = 3.0768e-04
Validation rmse = 0.755685
Epoch 15
Loss = 7.1322e-01, PNorm = 43.7262, GNorm = 2.5512, lr_0 = 2.7826e-04
Validation rmse = 0.747542
Epoch 16
Loss = 7.1306e-01, PNorm = 43.7431, GNorm = 2.8623, lr_0 = 2.5396e-04
Validation rmse = 0.758186
Epoch 17
Loss = 6.7009e-01, PNorm = 43.7591, GNorm = 9.0060, lr_0 = 2.3178e-04
Validation rmse = 0.766509
Epoch 18
Loss = 6.7613e-01, PNorm = 43.7757, GNorm = 11.1627, lr_0 = 2.0962e-04
Validation rmse = 0.705434
Epoch 19
Loss = 6.5273e-01, PNorm = 43.7874, GNorm = 1.5738, lr_0 = 1.9131e-04
Validation rmse = 0.715866
Epoch 20
Loss = 6.3433e-01, PNorm = 43.8007, GNorm = 2.7326, lr_0 = 1.7302e-04
Validation rmse = 0.736694
Epoch 21
Loss = 6.0921e-01, PNorm = 43.8111, GNorm = 2.8513, lr_0 = 1.5791e-04
Loss = 7.0477e-01, PNorm = 43.8123, GNorm = 8.0834, lr_0 = 1.5647e-04
Validation rmse = 0.714074
Epoch 22
Loss = 6.0914e-01, PNorm = 43.8224, GNorm = 2.6587, lr_0 = 1.4281e-04
Validation rmse = 0.745055
Epoch 23
Loss = 6.0305e-01, PNorm = 43.8301, GNorm = 3.9067, lr_0 = 1.3034e-04
Validation rmse = 0.722670
Epoch 24
Validation rmse = 0.719279
Epoch 25
Loss = 5.9022e-01, PNorm = 43.8376, GNorm = 1.5460, lr_0 = 1.1788e-04
Validation rmse = 0.728729
Epoch 26
Loss = 6.1546e-01, PNorm = 43.8450, GNorm = 5.6788, lr_0 = 1.0758e-04
Validation rmse = 0.726547
Epoch 27
Loss = 6.3055e-01, PNorm = 43.8520, GNorm = 5.6199, lr_0 = 1.0000e-04
Validation rmse = 0.725469
Epoch 28
Loss = 6.5508e-01, PNorm = 43.8570, GNorm = 8.4630, lr_0 = 1.0000e-04
Validation rmse = 0.710656
Epoch 29
Loss = 6.3900e-01, PNorm = 43.8626, GNorm = 4.4597, lr_0 = 1.0000e-04
Validation rmse = 0.728620
Model 0 best validation rmse = 0.705434 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.752420
Ensemble test rmse = 0.752420
1-fold cross validation
	Seed 0 ==> test rmse = 0.752420
Overall test rmse = 0.752420 +/- 0.000000
Elapsed time = 0:01:40
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8209e+00, PNorm = 43.2607, GNorm = 1.7734, lr_0 = 5.9500e-04
Loss = 1.5102e+00, PNorm = 43.2610, GNorm = 1.8038, lr_0 = 6.4000e-04
Validation rmse = 1.369649
Epoch 1
Loss = 1.4596e+00, PNorm = 43.2761, GNorm = 0.9613, lr_0 = 9.8369e-04
Loss = 1.3723e+00, PNorm = 43.2786, GNorm = 1.2202, lr_0 = 9.7563e-04
Validation rmse = 1.349703
Epoch 2
Loss = 1.3476e+00, PNorm = 43.3030, GNorm = 0.8898, lr_0 = 8.9861e-04
Validation rmse = 1.294655
Epoch 3
Loss = 1.2893e+00, PNorm = 43.3335, GNorm = 0.5807, lr_0 = 8.2767e-04
Validation rmse = 1.211991
Epoch 4
Loss = 1.2474e+00, PNorm = 43.3698, GNorm = 3.6465, lr_0 = 7.5609e-04
Validation rmse = 1.160864
Epoch 5
Loss = 1.1635e+00, PNorm = 43.4077, GNorm = 2.3633, lr_0 = 6.9069e-04
Validation rmse = 1.120381
Epoch 6
Loss = 1.1055e+00, PNorm = 43.4508, GNorm = 1.5593, lr_0 = 6.3617e-04
Validation rmse = 0.999676
Epoch 7
Loss = 1.0266e+00, PNorm = 43.4962, GNorm = 4.3138, lr_0 = 5.8115e-04
Validation rmse = 1.107331
Epoch 8
Loss = 1.0521e+00, PNorm = 43.5306, GNorm = 3.2739, lr_0 = 5.3527e-04
Validation rmse = 0.904286
Epoch 9
Loss = 9.9929e-01, PNorm = 43.5651, GNorm = 2.2587, lr_0 = 4.8897e-04
Validation rmse = 0.881880
Epoch 10
Loss = 9.0472e-01, PNorm = 43.6015, GNorm = 3.1377, lr_0 = 4.4668e-04
Validation rmse = 0.848567
Epoch 11
Loss = 8.5832e-01, PNorm = 43.6339, GNorm = 2.9660, lr_0 = 4.1142e-04
Validation rmse = 0.810046
Epoch 12
Loss = 8.2856e-01, PNorm = 43.6654, GNorm = 1.6293, lr_0 = 3.7584e-04
Validation rmse = 0.782273
Epoch 13
Loss = 7.7151e-01, PNorm = 43.6921, GNorm = 1.2792, lr_0 = 3.4617e-04
Validation rmse = 0.755887
Epoch 14
Loss = 7.8325e-01, PNorm = 43.7195, GNorm = 3.1334, lr_0 = 3.1623e-04
Validation rmse = 0.739557
Epoch 15
Loss = 7.2299e-01, PNorm = 43.7420, GNorm = 1.8331, lr_0 = 2.8888e-04
Validation rmse = 0.729877
Epoch 16
Loss = 6.7892e-01, PNorm = 43.7628, GNorm = 1.7650, lr_0 = 2.6607e-04
Validation rmse = 0.715041
Epoch 17
Loss = 7.6259e-01, PNorm = 43.7821, GNorm = 3.3054, lr_0 = 2.4306e-04
Validation rmse = 0.722686
Epoch 18
Loss = 6.1158e-01, PNorm = 43.7974, GNorm = 4.2255, lr_0 = 2.2387e-04
Validation rmse = 0.748639
Epoch 19
Loss = 7.1076e-01, PNorm = 43.8143, GNorm = 5.7895, lr_0 = 2.0451e-04
Validation rmse = 0.704224
Epoch 20
Loss = 7.3751e-01, PNorm = 43.8319, GNorm = 12.5042, lr_0 = 1.8682e-04
Validation rmse = 0.700431
Epoch 21
Loss = 6.1302e-01, PNorm = 43.8424, GNorm = 3.4497, lr_0 = 1.7207e-04
Validation rmse = 0.703868
Epoch 22
Loss = 7.2283e-01, PNorm = 43.8532, GNorm = 5.8608, lr_0 = 1.5719e-04
Validation rmse = 0.695486
Epoch 23
Loss = 6.5849e-01, PNorm = 43.8642, GNorm = 4.2535, lr_0 = 1.4360e-04
Validation rmse = 0.691989
Epoch 24
Loss = 4.1751e-01, PNorm = 43.8733, GNorm = 5.9440, lr_0 = 1.3226e-04
Validation rmse = 0.689410
Epoch 25
Loss = 5.0209e-01, PNorm = 43.8811, GNorm = 2.4736, lr_0 = 1.2082e-04
Loss = 6.2752e-01, PNorm = 43.8883, GNorm = 5.5833, lr_0 = 1.1128e-04
Validation rmse = 0.677549
Epoch 26
Loss = 5.9173e-01, PNorm = 43.8953, GNorm = 3.4631, lr_0 = 1.0250e-04
Loss = 6.3865e-01, PNorm = 43.8960, GNorm = 4.0118, lr_0 = 1.0166e-04
Validation rmse = 0.681855
Epoch 27
Loss = 5.9578e-01, PNorm = 43.9023, GNorm = 7.7426, lr_0 = 1.0000e-04
Loss = 5.1184e-01, PNorm = 43.9030, GNorm = 4.7293, lr_0 = 1.0000e-04
Validation rmse = 0.679658
Epoch 28
Loss = 5.8358e-01, PNorm = 43.9101, GNorm = 7.6930, lr_0 = 1.0000e-04
Validation rmse = 0.681003
Epoch 29
Loss = 6.0348e-01, PNorm = 43.9154, GNorm = 3.9260, lr_0 = 1.0000e-04
Validation rmse = 0.680078
Model 0 best validation rmse = 0.677549 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.727269
Ensemble test rmse = 0.727269
1-fold cross validation
	Seed 0 ==> test rmse = 0.727269
Overall test rmse = 0.727269 +/- 0.000000
Elapsed time = 0:01:57
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0079e+00, PNorm = 43.2601, GNorm = 1.4466, lr_0 = 5.5000e-04
Validation rmse = 1.382277
Epoch 1
Loss = 1.4687e+00, PNorm = 43.2689, GNorm = 1.4164, lr_0 = 1.0000e-03
Validation rmse = 1.412030
Epoch 2
Loss = 1.3744e+00, PNorm = 43.2907, GNorm = 2.7093, lr_0 = 9.2106e-04
Validation rmse = 1.302601
Epoch 3
Loss = 1.2930e+00, PNorm = 43.3176, GNorm = 0.7050, lr_0 = 8.4834e-04
Validation rmse = 1.194265
Epoch 4
Loss = 1.2000e+00, PNorm = 43.3555, GNorm = 0.5921, lr_0 = 7.8137e-04
Validation rmse = 1.089576
Epoch 5
Loss = 1.1831e+00, PNorm = 43.3982, GNorm = 2.4868, lr_0 = 7.1969e-04
Validation rmse = 1.024154
Epoch 6
Loss = 1.0951e+00, PNorm = 43.4390, GNorm = 1.6825, lr_0 = 6.6784e-04
Validation rmse = 0.953794
Epoch 7
Loss = 1.0950e+00, PNorm = 43.4906, GNorm = 2.7269, lr_0 = 6.1512e-04
Validation rmse = 0.916887
Epoch 8
Loss = 9.2155e-01, PNorm = 43.5426, GNorm = 2.8719, lr_0 = 5.6656e-04
Loss = 9.3901e-01, PNorm = 43.5792, GNorm = 4.9833, lr_0 = 5.2575e-04
Loss = 6.6924e-01, PNorm = 43.5828, GNorm = 4.2454, lr_0 = 5.2183e-04
Validation rmse = 0.819669
Epoch 9
Loss = 8.7812e-01, PNorm = 43.6172, GNorm = 1.8689, lr_0 = 4.8424e-04
Validation rmse = 0.783596
Epoch 10
Loss = 8.1789e-01, PNorm = 43.6530, GNorm = 2.2879, lr_0 = 4.4602e-04
Validation rmse = 0.785656
Epoch 11
Loss = 8.0354e-01, PNorm = 43.6825, GNorm = 8.3136, lr_0 = 4.1389e-04
Validation rmse = 0.733187
Epoch 12
Loss = 7.6080e-01, PNorm = 43.7057, GNorm = 2.8225, lr_0 = 3.8121e-04
Validation rmse = 0.815009
Epoch 13
Loss = 8.2612e-01, PNorm = 43.7258, GNorm = 12.3691, lr_0 = 3.5112e-04
Validation rmse = 0.797456
Epoch 14
Loss = 7.4069e-01, PNorm = 43.7457, GNorm = 2.9710, lr_0 = 3.2340e-04
Validation rmse = 0.753257
Epoch 15
Loss = 7.0323e-01, PNorm = 43.7668, GNorm = 10.8836, lr_0 = 2.9787e-04
Validation rmse = 0.714406
Epoch 16
Loss = 6.4821e-01, PNorm = 43.7850, GNorm = 2.8128, lr_0 = 2.7641e-04
Loss = 7.2940e-01, PNorm = 43.7971, GNorm = 7.2118, lr_0 = 2.5650e-04
Loss = 4.8129e-01, PNorm = 43.7986, GNorm = 2.7272, lr_0 = 2.5459e-04
Validation rmse = 0.766199
Epoch 17
Loss = 6.8294e-01, PNorm = 43.8126, GNorm = 8.2077, lr_0 = 2.3625e-04
Validation rmse = 0.718567
Epoch 18
Loss = 6.4534e-01, PNorm = 43.8254, GNorm = 6.0851, lr_0 = 2.1760e-04
Validation rmse = 0.707906
Epoch 19
Loss = 6.6091e-01, PNorm = 43.8370, GNorm = 7.3607, lr_0 = 2.0042e-04
Validation rmse = 0.697815
Epoch 20
Loss = 6.5064e-01, PNorm = 43.8497, GNorm = 2.0584, lr_0 = 1.8460e-04
Validation rmse = 0.706738
Epoch 21
Loss = 6.5803e-01, PNorm = 43.8600, GNorm = 8.0505, lr_0 = 1.7003e-04
Validation rmse = 0.693784
Epoch 22
Loss = 6.0965e-01, PNorm = 43.8689, GNorm = 3.9500, lr_0 = 1.5778e-04
Validation rmse = 0.701123
Epoch 23
Loss = 6.2875e-01, PNorm = 43.8772, GNorm = 3.1949, lr_0 = 1.4532e-04
Validation rmse = 0.706223
Epoch 24
Loss = 5.7737e-01, PNorm = 43.8849, GNorm = 3.9394, lr_0 = 1.3385e-04
Validation rmse = 0.690207
Epoch 25
Loss = 5.8526e-01, PNorm = 43.8929, GNorm = 2.9420, lr_0 = 1.2328e-04
Loss = 6.0887e-01, PNorm = 43.8991, GNorm = 6.0877, lr_0 = 1.1440e-04
Loss = 4.5898e-01, PNorm = 43.8996, GNorm = 9.4782, lr_0 = 1.1355e-04
Validation rmse = 0.699832
Epoch 26
Loss = 5.7331e-01, PNorm = 43.9049, GNorm = 6.1275, lr_0 = 1.0537e-04
Validation rmse = 0.690116
Epoch 27
Loss = 5.8194e-01, PNorm = 43.9099, GNorm = 3.6428, lr_0 = 1.0000e-04
Validation rmse = 0.686469
Epoch 28
Loss = 5.7766e-01, PNorm = 43.9152, GNorm = 4.7704, lr_0 = 1.0000e-04
Validation rmse = 0.681209
Epoch 29
Loss = 5.3464e-01, PNorm = 43.9209, GNorm = 3.5495, lr_0 = 1.0000e-04
Validation rmse = 0.687239
Model 0 best validation rmse = 0.681209 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.692628
Ensemble test rmse = 0.692628
1-fold cross validation
	Seed 0 ==> test rmse = 0.692628
Overall test rmse = 0.692628 +/- 0.000000
Elapsed time = 0:02:06
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8576e+00, PNorm = 43.2620, GNorm = 2.5112, lr_0 = 5.5000e-04
Validation rmse = 1.360544
Epoch 1
Loss = 1.4471e+00, PNorm = 43.2735, GNorm = 1.2475, lr_0 = 1.0000e-03
Validation rmse = 1.329308
Epoch 2
Loss = 1.3484e+00, PNorm = 43.2970, GNorm = 0.6477, lr_0 = 9.2797e-04
Validation rmse = 1.248842
Epoch 3
Loss = 1.2705e+00, PNorm = 43.3235, GNorm = 0.9054, lr_0 = 8.6112e-04
Validation rmse = 1.132471
Epoch 4
Loss = 1.2331e+00, PNorm = 43.3563, GNorm = 2.1771, lr_0 = 7.9909e-04
Validation rmse = 1.058465
Epoch 5
Loss = 1.1628e+00, PNorm = 43.3926, GNorm = 0.7977, lr_0 = 7.4153e-04
Loss = 1.1113e+00, PNorm = 43.4346, GNorm = 1.5630, lr_0 = 6.8812e-04
Validation rmse = 0.986688
Epoch 6
Loss = 1.0685e+00, PNorm = 43.4843, GNorm = 1.5475, lr_0 = 6.3855e-04
Validation rmse = 0.914670
Epoch 7
Loss = 9.6569e-01, PNorm = 43.5272, GNorm = 1.6872, lr_0 = 5.9255e-04
Validation rmse = 0.831667
Epoch 8
Loss = 9.6846e-01, PNorm = 43.5754, GNorm = 6.3617, lr_0 = 5.4987e-04
Validation rmse = 0.818710
Epoch 9
Loss = 8.8798e-01, PNorm = 43.6144, GNorm = 8.6317, lr_0 = 5.1026e-04
Validation rmse = 0.784237
Epoch 10
Loss = 8.2562e-01, PNorm = 43.6504, GNorm = 1.8995, lr_0 = 4.7351e-04
Loss = 8.0685e-01, PNorm = 43.6862, GNorm = 3.3101, lr_0 = 4.3940e-04
Validation rmse = 0.744148
Epoch 11
Loss = 7.6612e-01, PNorm = 43.7165, GNorm = 1.5770, lr_0 = 4.0775e-04
Validation rmse = 0.742135
Epoch 12
Loss = 7.2659e-01, PNorm = 43.7445, GNorm = 1.9904, lr_0 = 3.7837e-04
Validation rmse = 0.711202
Epoch 13
Loss = 7.3446e-01, PNorm = 43.7674, GNorm = 1.8141, lr_0 = 3.5112e-04
Validation rmse = 0.703001
Epoch 14
Loss = 6.7943e-01, PNorm = 43.7904, GNorm = 1.9341, lr_0 = 3.2583e-04
Validation rmse = 0.721558
Epoch 15
Loss = 7.1249e-01, PNorm = 43.8098, GNorm = 8.4519, lr_0 = 3.0236e-04
Loss = 6.5349e-01, PNorm = 43.8302, GNorm = 4.7516, lr_0 = 2.8058e-04
Validation rmse = 0.694620
Epoch 16
Loss = 6.5087e-01, PNorm = 43.8465, GNorm = 7.5409, lr_0 = 2.6037e-04
Validation rmse = 0.694286
Epoch 17
Loss = 6.4955e-01, PNorm = 43.8609, GNorm = 6.6710, lr_0 = 2.4161e-04
Validation rmse = 0.686262
Epoch 18
Loss = 5.9224e-01, PNorm = 43.8748, GNorm = 2.8491, lr_0 = 2.2421e-04
Validation rmse = 0.676843
Epoch 19
Loss = 5.6370e-01, PNorm = 43.8878, GNorm = 5.8953, lr_0 = 2.0806e-04
Validation rmse = 0.678805
Epoch 20
Loss = 6.0439e-01, PNorm = 43.8996, GNorm = 2.9445, lr_0 = 1.9307e-04
Loss = 6.0693e-01, PNorm = 43.9103, GNorm = 4.0999, lr_0 = 1.7916e-04
Validation rmse = 0.676813
Epoch 21
Loss = 5.8619e-01, PNorm = 43.9185, GNorm = 4.5813, lr_0 = 1.6626e-04
Validation rmse = 0.680466
Epoch 22
Loss = 5.3123e-01, PNorm = 43.9292, GNorm = 6.3082, lr_0 = 1.5428e-04
Validation rmse = 0.665555
Epoch 23
Loss = 5.0019e-01, PNorm = 43.9388, GNorm = 2.0768, lr_0 = 1.4317e-04
Validation rmse = 0.668606
Epoch 24
Loss = 5.3551e-01, PNorm = 43.9464, GNorm = 13.5909, lr_0 = 1.3285e-04
Validation rmse = 0.682705
Epoch 25
Loss = 6.1656e-01, PNorm = 43.9533, GNorm = 11.9213, lr_0 = 1.2328e-04
Loss = 5.7236e-01, PNorm = 43.9588, GNorm = 4.4381, lr_0 = 1.1440e-04
Validation rmse = 0.696030
Epoch 26
Loss = 5.8275e-01, PNorm = 43.9638, GNorm = 14.0153, lr_0 = 1.0616e-04
Validation rmse = 0.658373
Epoch 27
Loss = 5.3272e-01, PNorm = 43.9699, GNorm = 2.4088, lr_0 = 1.0000e-04
Validation rmse = 0.665090
Epoch 28
Loss = 5.5197e-01, PNorm = 43.9757, GNorm = 6.7861, lr_0 = 1.0000e-04
Validation rmse = 0.661377
Epoch 29
Loss = 5.2396e-01, PNorm = 43.9816, GNorm = 6.8692, lr_0 = 1.0000e-04
Validation rmse = 0.655034
Model 0 best validation rmse = 0.655034 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.668337
Ensemble test rmse = 0.668337
1-fold cross validation
	Seed 0 ==> test rmse = 0.668337
Overall test rmse = 0.668337 +/- 0.000000
Elapsed time = 0:02:14
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.313077
Epoch 1
Loss = 1.4883e+00, PNorm = 43.2628, GNorm = 1.8401, lr_0 = 8.7143e-04
Validation rmse = 1.200099
Epoch 2
Loss = 1.4637e+00, PNorm = 43.2876, GNorm = 0.7894, lr_0 = 9.1030e-04
Validation rmse = 1.157505
Epoch 3
Loss = 1.3870e+00, PNorm = 43.3129, GNorm = 0.4973, lr_0 = 8.0940e-04
Validation rmse = 1.187953
Epoch 4
Validation rmse = 1.115065
Epoch 5
Loss = 1.2556e+00, PNorm = 43.3373, GNorm = 1.4354, lr_0 = 7.1969e-04
Validation rmse = 1.061256
Epoch 6
Loss = 1.2470e+00, PNorm = 43.3645, GNorm = 0.6510, lr_0 = 6.3992e-04
Validation rmse = 1.044159
Epoch 7
Loss = 1.2505e+00, PNorm = 43.3924, GNorm = 0.7133, lr_0 = 5.6899e-04
Validation rmse = 0.987824
Epoch 8
Loss = 1.1692e+00, PNorm = 43.4235, GNorm = 3.4486, lr_0 = 5.0592e-04
Validation rmse = 0.950818
Epoch 9
Validation rmse = 0.938339
Epoch 10
Loss = 1.0929e+00, PNorm = 43.4561, GNorm = 2.5071, lr_0 = 4.4984e-04
Validation rmse = 0.890551
Epoch 11
Loss = 1.0614e+00, PNorm = 43.4883, GNorm = 3.9933, lr_0 = 3.9998e-04
Validation rmse = 0.871526
Epoch 12
Loss = 1.0058e+00, PNorm = 43.5193, GNorm = 2.1433, lr_0 = 3.5565e-04
Validation rmse = 0.860799
Epoch 13
Loss = 9.5814e-01, PNorm = 43.5506, GNorm = 1.7943, lr_0 = 3.1623e-04
Validation rmse = 0.856206
Epoch 14
Validation rmse = 0.828112
Epoch 15
Loss = 8.3319e-01, PNorm = 43.5776, GNorm = 1.0015, lr_0 = 2.8118e-04
Validation rmse = 0.837495
Epoch 16
Loss = 9.0585e-01, PNorm = 43.6004, GNorm = 4.4141, lr_0 = 2.5001e-04
Validation rmse = 0.802725
Epoch 17
Loss = 8.7219e-01, PNorm = 43.6207, GNorm = 2.2786, lr_0 = 2.2230e-04
Validation rmse = 0.815601
Epoch 18
Loss = 8.5277e-01, PNorm = 43.6375, GNorm = 5.1660, lr_0 = 1.9766e-04
Validation rmse = 0.795255
Epoch 19
Validation rmse = 0.782791
Epoch 20
Loss = 7.8150e-01, PNorm = 43.6538, GNorm = 3.8889, lr_0 = 1.7575e-04
Validation rmse = 0.780037
Epoch 21
Loss = 8.1851e-01, PNorm = 43.6683, GNorm = 1.5376, lr_0 = 1.5627e-04
Validation rmse = 0.778564
Epoch 22
Loss = 7.4925e-01, PNorm = 43.6809, GNorm = 1.9109, lr_0 = 1.3895e-04
Validation rmse = 0.769612
Epoch 23
Loss = 7.6818e-01, PNorm = 43.6924, GNorm = 2.0186, lr_0 = 1.2355e-04
Validation rmse = 0.767570
Epoch 24
Validation rmse = 0.762349
Epoch 25
Loss = 6.1759e-01, PNorm = 43.7018, GNorm = 2.7274, lr_0 = 1.0985e-04
Validation rmse = 0.760047
Epoch 26
Loss = 7.5504e-01, PNorm = 43.7107, GNorm = 8.0332, lr_0 = 1.0000e-04
Validation rmse = 0.757383
Epoch 27
Loss = 8.0419e-01, PNorm = 43.7187, GNorm = 7.3802, lr_0 = 1.0000e-04
Validation rmse = 0.817450
Epoch 28
Loss = 7.5905e-01, PNorm = 43.7261, GNorm = 6.1045, lr_0 = 1.0000e-04
Validation rmse = 0.748442
Epoch 29
Validation rmse = 0.742079
Model 0 best validation rmse = 0.742079 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.915460
Ensemble test rmse = 0.915460
1-fold cross validation
	Seed 0 ==> test rmse = 0.915460
Overall test rmse = 0.915460 +/- 0.000000
Elapsed time = 0:01:31
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.356605
Epoch 1
Loss = 1.4978e+00, PNorm = 43.2638, GNorm = 1.4631, lr_0 = 7.7500e-04
Validation rmse = 1.287155
Epoch 2
Loss = 1.3992e+00, PNorm = 43.2876, GNorm = 0.9549, lr_0 = 9.4019e-04
Validation rmse = 1.253453
Epoch 3
Loss = 1.3231e+00, PNorm = 43.3156, GNorm = 0.9069, lr_0 = 8.4834e-04
Validation rmse = 1.211571
Epoch 4
Loss = 1.2932e+00, PNorm = 43.3442, GNorm = 0.6961, lr_0 = 7.6547e-04
Validation rmse = 1.178041
Epoch 5
Loss = 1.2722e+00, PNorm = 43.3763, GNorm = 5.2327, lr_0 = 6.8363e-04
Validation rmse = 1.121213
Epoch 6
Loss = 1.1738e+00, PNorm = 43.4040, GNorm = 0.9174, lr_0 = 6.1685e-04
Validation rmse = 1.152791
Epoch 7
Loss = 1.1377e+00, PNorm = 43.4355, GNorm = 2.9594, lr_0 = 5.5659e-04
Validation rmse = 1.136423
Epoch 8
Validation rmse = 1.115433
Epoch 9
Loss = 9.8233e-01, PNorm = 43.4699, GNorm = 2.4255, lr_0 = 5.0222e-04
Validation rmse = 1.015030
Epoch 10
Loss = 9.9608e-01, PNorm = 43.5098, GNorm = 0.8493, lr_0 = 4.4852e-04
Validation rmse = 1.007933
Epoch 11
Loss = 9.4572e-01, PNorm = 43.5457, GNorm = 1.1413, lr_0 = 4.0471e-04
Validation rmse = 0.952058
Epoch 12
Loss = 9.1198e-01, PNorm = 43.5785, GNorm = 2.2455, lr_0 = 3.6517e-04
Validation rmse = 1.049353
Epoch 13
Loss = 8.8440e-01, PNorm = 43.6092, GNorm = 1.7976, lr_0 = 3.2950e-04
Validation rmse = 0.940836
Epoch 14
Loss = 8.7838e-01, PNorm = 43.6381, GNorm = 1.1325, lr_0 = 2.9731e-04
Validation rmse = 0.926549
Epoch 15
Loss = 8.2529e-01, PNorm = 43.6657, GNorm = 3.3202, lr_0 = 2.6553e-04
Validation rmse = 0.940397
Epoch 16
Validation rmse = 1.026988
Epoch 17
Loss = 7.4321e-01, PNorm = 43.6892, GNorm = 9.5999, lr_0 = 2.3959e-04
Validation rmse = 0.935529
Epoch 18
Loss = 7.9449e-01, PNorm = 43.7106, GNorm = 2.4088, lr_0 = 2.1618e-04
Validation rmse = 0.855478
Epoch 19
Loss = 8.5775e-01, PNorm = 43.7292, GNorm = 1.6772, lr_0 = 1.9506e-04
Validation rmse = 0.864850
Epoch 20
Loss = 6.9956e-01, PNorm = 43.7473, GNorm = 2.9808, lr_0 = 1.7421e-04
Validation rmse = 0.914499
Epoch 21
Loss = 7.4373e-01, PNorm = 43.7617, GNorm = 2.0319, lr_0 = 1.5719e-04
Validation rmse = 0.883344
Epoch 22
Loss = 7.1032e-01, PNorm = 43.7740, GNorm = 6.7912, lr_0 = 1.4184e-04
Validation rmse = 0.850590
Epoch 23
Loss = 6.9015e-01, PNorm = 43.7855, GNorm = 3.2277, lr_0 = 1.2798e-04
Loss = 8.2315e-01, PNorm = 43.7866, GNorm = 7.7997, lr_0 = 1.2667e-04
Validation rmse = 0.834632
Epoch 24
Validation rmse = 0.868884
Epoch 25
Loss = 6.1940e-01, PNorm = 43.7959, GNorm = 1.4506, lr_0 = 1.1430e-04
Validation rmse = 0.846784
Epoch 26
Loss = 6.8475e-01, PNorm = 43.8052, GNorm = 1.8488, lr_0 = 1.0313e-04
Validation rmse = 0.851076
Epoch 27
Loss = 6.5737e-01, PNorm = 43.8133, GNorm = 2.9408, lr_0 = 1.0000e-04
Validation rmse = 0.871128
Epoch 28
Loss = 6.4781e-01, PNorm = 43.8215, GNorm = 1.6418, lr_0 = 1.0000e-04
Validation rmse = 0.854928
Epoch 29
Loss = 6.5828e-01, PNorm = 43.8304, GNorm = 4.0756, lr_0 = 1.0000e-04
Validation rmse = 0.870142
Model 0 best validation rmse = 0.834632 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.653774
Ensemble test rmse = 0.653774
1-fold cross validation
	Seed 0 ==> test rmse = 0.653774
Overall test rmse = 0.653774 +/- 0.000000
Elapsed time = 0:01:39
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.226129
Epoch 1
Loss = 1.4750e+00, PNorm = 43.2604, GNorm = 1.5147, lr_0 = 7.0000e-04
Validation rmse = 1.196539
Epoch 2
Loss = 1.4366e+00, PNorm = 43.2757, GNorm = 0.9229, lr_0 = 9.6411e-04
Validation rmse = 1.131547
Epoch 3
Loss = 1.3247e+00, PNorm = 43.3008, GNorm = 0.5238, lr_0 = 8.7192e-04
Validation rmse = 1.073173
Epoch 4
Loss = 1.2475e+00, PNorm = 43.3243, GNorm = 1.9606, lr_0 = 7.9578e-04
Validation rmse = 1.029607
Epoch 5
Loss = 1.2129e+00, PNorm = 43.3538, GNorm = 1.3159, lr_0 = 7.1969e-04
Validation rmse = 0.999778
Epoch 6
Loss = 1.2032e+00, PNorm = 43.3819, GNorm = 1.1174, lr_0 = 6.5684e-04
Validation rmse = 0.956336
Epoch 7
Loss = 1.0654e+00, PNorm = 43.4167, GNorm = 2.1728, lr_0 = 5.9948e-04
Validation rmse = 0.871520
Epoch 8
Loss = 1.0563e+00, PNorm = 43.4600, GNorm = 2.2197, lr_0 = 5.4216e-04
Validation rmse = 0.815638
Epoch 9
Loss = 9.6394e-01, PNorm = 43.4965, GNorm = 2.6840, lr_0 = 4.9482e-04
Validation rmse = 0.771707
Epoch 10
Loss = 9.3179e-01, PNorm = 43.5385, GNorm = 1.7379, lr_0 = 4.4750e-04
Validation rmse = 0.743645
Epoch 11
Loss = 9.0493e-01, PNorm = 43.5763, GNorm = 2.5583, lr_0 = 4.0842e-04
Validation rmse = 0.727052
Epoch 12
Loss = 8.6497e-01, PNorm = 43.6108, GNorm = 2.7209, lr_0 = 3.7276e-04
Validation rmse = 0.700678
Epoch 13
Loss = 8.0014e-01, PNorm = 43.6465, GNorm = 2.2705, lr_0 = 3.3711e-04
Validation rmse = 0.704942
Epoch 14
Loss = 7.8903e-01, PNorm = 43.6744, GNorm = 1.9882, lr_0 = 3.0768e-04
Validation rmse = 0.670773
Epoch 15
Loss = 7.4831e-01, PNorm = 43.7050, GNorm = 1.7090, lr_0 = 2.7826e-04
Validation rmse = 0.659251
Epoch 16
Loss = 7.6596e-01, PNorm = 43.7270, GNorm = 3.1325, lr_0 = 2.5396e-04
Validation rmse = 0.653189
Epoch 17
Loss = 7.1963e-01, PNorm = 43.7493, GNorm = 9.5691, lr_0 = 2.3178e-04
Validation rmse = 0.663534
Epoch 18
Loss = 7.0140e-01, PNorm = 43.7700, GNorm = 12.8132, lr_0 = 2.0962e-04
Validation rmse = 0.639166
Epoch 19
Loss = 6.6426e-01, PNorm = 43.7876, GNorm = 11.2237, lr_0 = 1.9131e-04
Validation rmse = 0.644717
Epoch 20
Loss = 6.7313e-01, PNorm = 43.8038, GNorm = 7.0155, lr_0 = 1.7302e-04
Validation rmse = 0.625634
Epoch 21
Loss = 6.5326e-01, PNorm = 43.8171, GNorm = 7.7752, lr_0 = 1.5791e-04
Loss = 7.9709e-01, PNorm = 43.8183, GNorm = 13.3332, lr_0 = 1.5647e-04
Validation rmse = 0.652675
Epoch 22
Loss = 6.4549e-01, PNorm = 43.8299, GNorm = 8.1546, lr_0 = 1.4281e-04
Validation rmse = 0.624231
Epoch 23
Loss = 6.3397e-01, PNorm = 43.8407, GNorm = 5.9956, lr_0 = 1.3034e-04
Validation rmse = 0.636249
Epoch 24
Validation rmse = 0.651731
Epoch 25
Loss = 5.9619e-01, PNorm = 43.8505, GNorm = 12.3687, lr_0 = 1.1788e-04
Validation rmse = 0.626475
Epoch 26
Loss = 6.1228e-01, PNorm = 43.8587, GNorm = 8.2190, lr_0 = 1.0758e-04
Validation rmse = 0.617287
Epoch 27
Loss = 5.9402e-01, PNorm = 43.8670, GNorm = 1.8321, lr_0 = 1.0000e-04
Validation rmse = 0.613901
Epoch 28
Loss = 5.3133e-01, PNorm = 43.8743, GNorm = 4.4738, lr_0 = 1.0000e-04
Validation rmse = 0.610362
Epoch 29
Loss = 4.9496e-01, PNorm = 43.8820, GNorm = 1.6344, lr_0 = 1.0000e-04
Validation rmse = 0.613880
Model 0 best validation rmse = 0.610362 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.596607
Ensemble test rmse = 0.596607
1-fold cross validation
	Seed 0 ==> test rmse = 0.596607
Overall test rmse = 0.596607 +/- 0.000000
Elapsed time = 0:01:51
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8792e+00, PNorm = 43.2569, GNorm = 1.3590, lr_0 = 5.9500e-04
Loss = 1.4615e+00, PNorm = 43.2571, GNorm = 1.7366, lr_0 = 6.4000e-04
Validation rmse = 1.370541
Epoch 1
Loss = 1.4890e+00, PNorm = 43.2686, GNorm = 1.1316, lr_0 = 9.8369e-04
Loss = 1.3190e+00, PNorm = 43.2706, GNorm = 1.1408, lr_0 = 9.7563e-04
Validation rmse = 1.237269
Epoch 2
Loss = 1.3514e+00, PNorm = 43.2928, GNorm = 0.6205, lr_0 = 8.9861e-04
Validation rmse = 1.184931
Epoch 3
Loss = 1.3016e+00, PNorm = 43.3206, GNorm = 1.9386, lr_0 = 8.2767e-04
Validation rmse = 1.111276
Epoch 4
Loss = 1.2262e+00, PNorm = 43.3556, GNorm = 2.4776, lr_0 = 7.5609e-04
Validation rmse = 1.040976
Epoch 5
Loss = 1.1763e+00, PNorm = 43.3922, GNorm = 2.8275, lr_0 = 6.9069e-04
Validation rmse = 0.989130
Epoch 6
Loss = 1.0993e+00, PNorm = 43.4305, GNorm = 1.0469, lr_0 = 6.3617e-04
Validation rmse = 0.930640
Epoch 7
Loss = 1.0131e+00, PNorm = 43.4777, GNorm = 1.8554, lr_0 = 5.8115e-04
Validation rmse = 0.935854
Epoch 8
Loss = 9.9887e-01, PNorm = 43.5170, GNorm = 1.2031, lr_0 = 5.3527e-04
Validation rmse = 0.866775
Epoch 9
Loss = 9.2025e-01, PNorm = 43.5578, GNorm = 5.0456, lr_0 = 4.8897e-04
Validation rmse = 0.853708
Epoch 10
Loss = 8.4833e-01, PNorm = 43.5940, GNorm = 7.1982, lr_0 = 4.4668e-04
Validation rmse = 0.832657
Epoch 11
Loss = 8.5165e-01, PNorm = 43.6257, GNorm = 11.2535, lr_0 = 4.1142e-04
Validation rmse = 0.841486
Epoch 12
Loss = 8.7816e-01, PNorm = 43.6580, GNorm = 2.8922, lr_0 = 3.7584e-04
Validation rmse = 0.810354
Epoch 13
Loss = 7.7638e-01, PNorm = 43.6830, GNorm = 5.7093, lr_0 = 3.4617e-04
Validation rmse = 0.806772
Epoch 14
Loss = 7.8972e-01, PNorm = 43.7086, GNorm = 4.8470, lr_0 = 3.1623e-04
Validation rmse = 0.777098
Epoch 15
Loss = 7.2560e-01, PNorm = 43.7313, GNorm = 5.5409, lr_0 = 2.8888e-04
Validation rmse = 0.765431
Epoch 16
Loss = 7.2980e-01, PNorm = 43.7509, GNorm = 10.7031, lr_0 = 2.6607e-04
Validation rmse = 0.774058
Epoch 17
Loss = 7.1999e-01, PNorm = 43.7694, GNorm = 14.2193, lr_0 = 2.4306e-04
Validation rmse = 0.819942
Epoch 18
Loss = 6.9899e-01, PNorm = 43.7834, GNorm = 5.0506, lr_0 = 2.2387e-04
Validation rmse = 0.766088
Epoch 19
Loss = 7.5520e-01, PNorm = 43.7986, GNorm = 6.1722, lr_0 = 2.0451e-04
Validation rmse = 0.744727
Epoch 20
Loss = 7.0038e-01, PNorm = 43.8130, GNorm = 4.1449, lr_0 = 1.8682e-04
Validation rmse = 0.733962
Epoch 21
Loss = 6.3365e-01, PNorm = 43.8241, GNorm = 5.8167, lr_0 = 1.7207e-04
Validation rmse = 0.737766
Epoch 22
Loss = 6.2261e-01, PNorm = 43.8354, GNorm = 2.1267, lr_0 = 1.5719e-04
Validation rmse = 0.728909
Epoch 23
Loss = 6.1310e-01, PNorm = 43.8454, GNorm = 2.1952, lr_0 = 1.4360e-04
Validation rmse = 0.724531
Epoch 24
Loss = 6.9009e-01, PNorm = 43.8546, GNorm = 3.0230, lr_0 = 1.3226e-04
Validation rmse = 0.719564
Epoch 25
Loss = 7.5703e-01, PNorm = 43.8635, GNorm = 6.1272, lr_0 = 1.2082e-04
Loss = 6.1979e-01, PNorm = 43.8703, GNorm = 4.0223, lr_0 = 1.1128e-04
Validation rmse = 0.717357
Epoch 26
Loss = 6.0282e-01, PNorm = 43.8770, GNorm = 3.5692, lr_0 = 1.0250e-04
Loss = 7.4349e-01, PNorm = 43.8776, GNorm = 5.3119, lr_0 = 1.0166e-04
Validation rmse = 0.717281
Epoch 27
Loss = 5.9798e-01, PNorm = 43.8837, GNorm = 2.2564, lr_0 = 1.0000e-04
Loss = 6.6995e-01, PNorm = 43.8842, GNorm = 11.2251, lr_0 = 1.0000e-04
Validation rmse = 0.713699
Epoch 28
Loss = 6.0137e-01, PNorm = 43.8897, GNorm = 8.3486, lr_0 = 1.0000e-04
Validation rmse = 0.710084
Epoch 29
Loss = 6.1778e-01, PNorm = 43.8961, GNorm = 7.2569, lr_0 = 1.0000e-04
Validation rmse = 0.711043
Model 0 best validation rmse = 0.710084 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.602863
Ensemble test rmse = 0.602863
1-fold cross validation
	Seed 0 ==> test rmse = 0.602863
Overall test rmse = 0.602863 +/- 0.000000
Elapsed time = 0:01:54
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9036e+00, PNorm = 43.2584, GNorm = 1.3810, lr_0 = 5.5000e-04
Validation rmse = 1.337706
Epoch 1
Loss = 1.4817e+00, PNorm = 43.2661, GNorm = 0.9932, lr_0 = 1.0000e-03
Validation rmse = 1.232943
Epoch 2
Loss = 1.3305e+00, PNorm = 43.2880, GNorm = 0.9285, lr_0 = 9.2106e-04
Validation rmse = 1.172486
Epoch 3
Loss = 1.2947e+00, PNorm = 43.3158, GNorm = 1.5580, lr_0 = 8.4834e-04
Validation rmse = 1.103866
Epoch 4
Loss = 1.2122e+00, PNorm = 43.3514, GNorm = 1.8022, lr_0 = 7.8137e-04
Validation rmse = 1.056654
Epoch 5
Loss = 1.1243e+00, PNorm = 43.3910, GNorm = 2.1110, lr_0 = 7.1969e-04
Validation rmse = 0.974831
Epoch 6
Loss = 1.0955e+00, PNorm = 43.4320, GNorm = 2.1962, lr_0 = 6.6784e-04
Validation rmse = 0.979775
Epoch 7
Loss = 1.0341e+00, PNorm = 43.4884, GNorm = 1.7081, lr_0 = 6.1512e-04
Validation rmse = 0.888836
Epoch 8
Loss = 8.8160e-01, PNorm = 43.5357, GNorm = 3.6926, lr_0 = 5.6656e-04
Loss = 9.4177e-01, PNorm = 43.5764, GNorm = 3.8856, lr_0 = 5.2575e-04
Loss = 7.4954e-01, PNorm = 43.5802, GNorm = 2.4627, lr_0 = 5.2183e-04
Validation rmse = 0.838152
Epoch 9
Loss = 8.5664e-01, PNorm = 43.6219, GNorm = 2.2512, lr_0 = 4.8424e-04
Validation rmse = 0.842218
Epoch 10
Loss = 8.2362e-01, PNorm = 43.6645, GNorm = 1.9511, lr_0 = 4.4602e-04
Validation rmse = 0.794521
Epoch 11
Loss = 8.0669e-01, PNorm = 43.6888, GNorm = 2.5151, lr_0 = 4.1389e-04
Validation rmse = 0.773835
Epoch 12
Loss = 7.3525e-01, PNorm = 43.7197, GNorm = 6.5829, lr_0 = 3.8121e-04
Validation rmse = 0.778887
Epoch 13
Loss = 7.5721e-01, PNorm = 43.7469, GNorm = 8.9666, lr_0 = 3.5112e-04
Validation rmse = 0.763470
Epoch 14
Loss = 6.8296e-01, PNorm = 43.7737, GNorm = 2.6796, lr_0 = 3.2340e-04
Validation rmse = 0.796172
Epoch 15
Loss = 6.8624e-01, PNorm = 43.7946, GNorm = 9.1218, lr_0 = 2.9787e-04
Validation rmse = 0.739245
Epoch 16
Loss = 6.2407e-01, PNorm = 43.8135, GNorm = 1.5396, lr_0 = 2.7641e-04
Loss = 6.8664e-01, PNorm = 43.8324, GNorm = 14.2850, lr_0 = 2.5650e-04
Loss = 6.4986e-01, PNorm = 43.8338, GNorm = 6.7673, lr_0 = 2.5459e-04
Validation rmse = 0.748992
Epoch 17
Loss = 6.5361e-01, PNorm = 43.8483, GNorm = 2.8906, lr_0 = 2.3625e-04
Validation rmse = 0.727768
Epoch 18
Loss = 6.2489e-01, PNorm = 43.8656, GNorm = 1.9204, lr_0 = 2.1760e-04
Validation rmse = 0.722272
Epoch 19
Loss = 6.1920e-01, PNorm = 43.8785, GNorm = 2.6460, lr_0 = 2.0042e-04
Validation rmse = 0.747157
Epoch 20
Loss = 5.7986e-01, PNorm = 43.8921, GNorm = 10.4863, lr_0 = 1.8460e-04
Validation rmse = 0.744112
Epoch 21
Loss = 5.6963e-01, PNorm = 43.9033, GNorm = 3.5277, lr_0 = 1.7003e-04
Validation rmse = 0.748046
Epoch 22
Loss = 6.8992e-01, PNorm = 43.9131, GNorm = 2.3798, lr_0 = 1.5778e-04
Validation rmse = 0.713661
Epoch 23
Loss = 5.8771e-01, PNorm = 43.9237, GNorm = 2.6376, lr_0 = 1.4532e-04
Validation rmse = 0.721125
Epoch 24
Loss = 5.1454e-01, PNorm = 43.9325, GNorm = 6.0778, lr_0 = 1.3385e-04
Validation rmse = 0.736107
Epoch 25
Loss = 5.6465e-01, PNorm = 43.9402, GNorm = 4.8161, lr_0 = 1.2328e-04
Loss = 5.7091e-01, PNorm = 43.9467, GNorm = 10.0890, lr_0 = 1.1440e-04
Loss = 5.6925e-01, PNorm = 43.9472, GNorm = 9.3368, lr_0 = 1.1355e-04
Validation rmse = 0.715441
Epoch 26
Loss = 5.6121e-01, PNorm = 43.9532, GNorm = 3.9225, lr_0 = 1.0537e-04
Validation rmse = 0.713544
Epoch 27
Loss = 5.5116e-01, PNorm = 43.9586, GNorm = 7.4357, lr_0 = 1.0000e-04
Validation rmse = 0.718527
Epoch 28
Loss = 5.8009e-01, PNorm = 43.9642, GNorm = 9.4865, lr_0 = 1.0000e-04
Validation rmse = 0.713301
Epoch 29
Loss = 5.5777e-01, PNorm = 43.9698, GNorm = 4.0927, lr_0 = 1.0000e-04
Validation rmse = 0.709698
Model 0 best validation rmse = 0.709698 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.592278
Ensemble test rmse = 0.592278
1-fold cross validation
	Seed 0 ==> test rmse = 0.592278
Overall test rmse = 0.592278 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8801e+00, PNorm = 43.2594, GNorm = 1.7616, lr_0 = 5.5000e-04
Validation rmse = 1.397684
Epoch 1
Loss = 1.4852e+00, PNorm = 43.2689, GNorm = 0.9855, lr_0 = 1.0000e-03
Validation rmse = 1.263980
Epoch 2
Loss = 1.3564e+00, PNorm = 43.2917, GNorm = 0.7823, lr_0 = 9.2797e-04
Validation rmse = 1.181675
Epoch 3
Loss = 1.2975e+00, PNorm = 43.3219, GNorm = 1.6658, lr_0 = 8.6112e-04
Validation rmse = 1.077705
Epoch 4
Loss = 1.2387e+00, PNorm = 43.3574, GNorm = 0.9949, lr_0 = 7.9909e-04
Validation rmse = 1.007617
Epoch 5
Loss = 1.1271e+00, PNorm = 43.4014, GNorm = 0.6327, lr_0 = 7.4153e-04
Loss = 1.0819e+00, PNorm = 43.4480, GNorm = 6.1882, lr_0 = 6.8812e-04
Validation rmse = 0.946720
Epoch 6
Loss = 1.0111e+00, PNorm = 43.4933, GNorm = 2.9655, lr_0 = 6.3855e-04
Validation rmse = 0.938984
Epoch 7
Loss = 9.6125e-01, PNorm = 43.5357, GNorm = 4.8951, lr_0 = 5.9255e-04
Validation rmse = 0.849541
Epoch 8
Loss = 9.0815e-01, PNorm = 43.5765, GNorm = 8.9285, lr_0 = 5.4987e-04
Validation rmse = 0.911164
Epoch 9
Loss = 8.7792e-01, PNorm = 43.6165, GNorm = 1.4245, lr_0 = 5.1026e-04
Validation rmse = 0.796183
Epoch 10
Loss = 8.9260e-01, PNorm = 43.6493, GNorm = 2.9581, lr_0 = 4.7351e-04
Loss = 8.1009e-01, PNorm = 43.6810, GNorm = 7.1417, lr_0 = 4.3940e-04
Validation rmse = 0.787167
Epoch 11
Loss = 7.5507e-01, PNorm = 43.7131, GNorm = 3.6037, lr_0 = 4.0775e-04
Validation rmse = 0.754108
Epoch 12
Loss = 7.4865e-01, PNorm = 43.7389, GNorm = 3.2611, lr_0 = 3.7837e-04
Validation rmse = 0.772462
Epoch 13
Loss = 6.7709e-01, PNorm = 43.7645, GNorm = 5.6788, lr_0 = 3.5112e-04
Validation rmse = 0.760626
Epoch 14
Loss = 7.5777e-01, PNorm = 43.7885, GNorm = 1.6769, lr_0 = 3.2583e-04
Validation rmse = 0.716089
Epoch 15
Loss = 7.3713e-01, PNorm = 43.8097, GNorm = 4.1300, lr_0 = 3.0236e-04
Loss = 6.7706e-01, PNorm = 43.8291, GNorm = 13.3312, lr_0 = 2.8058e-04
Validation rmse = 0.731851
Epoch 16
Loss = 6.6672e-01, PNorm = 43.8436, GNorm = 1.5921, lr_0 = 2.6037e-04
Validation rmse = 0.706519
Epoch 17
Loss = 6.4303e-01, PNorm = 43.8608, GNorm = 2.4408, lr_0 = 2.4161e-04
Validation rmse = 0.699163
Epoch 18
Loss = 6.2372e-01, PNorm = 43.8774, GNorm = 13.6931, lr_0 = 2.2421e-04
Validation rmse = 0.721992
Epoch 19
Loss = 5.3804e-01, PNorm = 43.8915, GNorm = 3.0668, lr_0 = 2.0806e-04
Validation rmse = 0.720964
Epoch 20
Loss = 7.3637e-01, PNorm = 43.9029, GNorm = 8.8263, lr_0 = 1.9307e-04
Loss = 6.1625e-01, PNorm = 43.9130, GNorm = 9.2251, lr_0 = 1.7916e-04
Validation rmse = 0.700396
Epoch 21
Loss = 6.3650e-01, PNorm = 43.9226, GNorm = 6.0421, lr_0 = 1.6626e-04
Validation rmse = 0.701004
Epoch 22
Loss = 6.1153e-01, PNorm = 43.9325, GNorm = 4.1031, lr_0 = 1.5428e-04
Validation rmse = 0.689425
Epoch 23
Loss = 5.8026e-01, PNorm = 43.9412, GNorm = 2.8520, lr_0 = 1.4317e-04
Validation rmse = 0.688861
Epoch 24
Loss = 5.2548e-01, PNorm = 43.9491, GNorm = 10.3792, lr_0 = 1.3285e-04
Validation rmse = 0.683557
Epoch 25
Loss = 6.5415e-01, PNorm = 43.9573, GNorm = 1.8740, lr_0 = 1.2328e-04
Loss = 5.4264e-01, PNorm = 43.9647, GNorm = 2.4720, lr_0 = 1.1440e-04
Validation rmse = 0.676815
Epoch 26
Loss = 6.0441e-01, PNorm = 43.9715, GNorm = 9.5677, lr_0 = 1.0616e-04
Validation rmse = 0.678221
Epoch 27
Loss = 5.6731e-01, PNorm = 43.9774, GNorm = 3.8883, lr_0 = 1.0000e-04
Validation rmse = 0.680892
Epoch 28
Loss = 5.6252e-01, PNorm = 43.9833, GNorm = 16.2627, lr_0 = 1.0000e-04
Validation rmse = 0.677283
Epoch 29
Loss = 5.1675e-01, PNorm = 43.9892, GNorm = 3.5036, lr_0 = 1.0000e-04
Validation rmse = 0.681471
Model 0 best validation rmse = 0.676815 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.612181
Ensemble test rmse = 0.612181
1-fold cross validation
	Seed 0 ==> test rmse = 0.612181
Overall test rmse = 0.612181 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.331778
Epoch 1
Loss = 1.4648e+00, PNorm = 43.2639, GNorm = 1.2473, lr_0 = 8.7143e-04
Validation rmse = 1.271776
Epoch 2
Loss = 1.4336e+00, PNorm = 43.2881, GNorm = 0.9693, lr_0 = 9.1030e-04
Validation rmse = 1.267165
Epoch 3
Loss = 1.3386e+00, PNorm = 43.3162, GNorm = 1.2069, lr_0 = 8.0940e-04
Validation rmse = 1.234557
Epoch 4
Validation rmse = 1.290067
Epoch 5
Loss = 1.2899e+00, PNorm = 43.3509, GNorm = 3.2941, lr_0 = 7.1969e-04
Validation rmse = 1.152620
Epoch 6
Loss = 1.1752e+00, PNorm = 43.3908, GNorm = 1.7563, lr_0 = 6.3992e-04
Validation rmse = 1.096133
Epoch 7
Loss = 1.0900e+00, PNorm = 43.4370, GNorm = 2.3075, lr_0 = 5.6899e-04
Validation rmse = 1.170669
Epoch 8
Loss = 1.0321e+00, PNorm = 43.4821, GNorm = 1.1161, lr_0 = 5.0592e-04
Validation rmse = 1.019638
Epoch 9
Validation rmse = 0.989469
Epoch 10
Loss = 8.6931e-01, PNorm = 43.5259, GNorm = 2.4388, lr_0 = 4.4984e-04
Validation rmse = 0.960415
Epoch 11
Loss = 8.5657e-01, PNorm = 43.5652, GNorm = 3.7051, lr_0 = 3.9998e-04
Validation rmse = 0.977992
Epoch 12
Loss = 8.3553e-01, PNorm = 43.5980, GNorm = 7.9817, lr_0 = 3.5565e-04
Validation rmse = 0.922806
Epoch 13
Loss = 8.1856e-01, PNorm = 43.6244, GNorm = 2.4823, lr_0 = 3.1623e-04
Validation rmse = 0.919296
Epoch 14
Validation rmse = 0.952085
Epoch 15
Loss = 7.0186e-01, PNorm = 43.6440, GNorm = 4.7789, lr_0 = 2.8118e-04
Validation rmse = 0.907750
Epoch 16
Loss = 7.4293e-01, PNorm = 43.6629, GNorm = 1.7090, lr_0 = 2.5001e-04
Validation rmse = 0.897153
Epoch 17
Loss = 7.3147e-01, PNorm = 43.6800, GNorm = 3.9483, lr_0 = 2.2230e-04
Validation rmse = 0.896545
Epoch 18
Loss = 7.3617e-01, PNorm = 43.6937, GNorm = 7.7590, lr_0 = 1.9766e-04
Validation rmse = 0.884650
Epoch 19
Validation rmse = 0.922898
Epoch 20
Loss = 7.1647e-01, PNorm = 43.7062, GNorm = 6.7942, lr_0 = 1.7575e-04
Validation rmse = 0.909684
Epoch 21
Loss = 6.3532e-01, PNorm = 43.7175, GNorm = 5.4635, lr_0 = 1.5627e-04
Validation rmse = 0.884235
Epoch 22
Loss = 6.7402e-01, PNorm = 43.7272, GNorm = 6.5138, lr_0 = 1.3895e-04
Validation rmse = 0.880041
Epoch 23
Loss = 6.6961e-01, PNorm = 43.7357, GNorm = 2.3426, lr_0 = 1.2355e-04
Validation rmse = 0.894703
Epoch 24
Validation rmse = 0.877155
Epoch 25
Loss = 7.2286e-01, PNorm = 43.7440, GNorm = 3.9396, lr_0 = 1.0985e-04
Validation rmse = 0.871578
Epoch 26
Loss = 7.1292e-01, PNorm = 43.7506, GNorm = 6.3905, lr_0 = 1.0000e-04
Validation rmse = 0.881529
Epoch 27
Loss = 6.8331e-01, PNorm = 43.7569, GNorm = 6.2509, lr_0 = 1.0000e-04
Validation rmse = 0.880444
Epoch 28
Loss = 6.4803e-01, PNorm = 43.7638, GNorm = 1.7483, lr_0 = 1.0000e-04
Validation rmse = 0.880808
Epoch 29
Validation rmse = 0.881902
Model 0 best validation rmse = 0.871578 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.735172
Ensemble test rmse = 0.735172
1-fold cross validation
	Seed 0 ==> test rmse = 0.735172
Overall test rmse = 0.735172 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.283420
Epoch 1
Loss = 1.4795e+00, PNorm = 43.2616, GNorm = 1.9307, lr_0 = 7.7500e-04
Validation rmse = 1.267951
Epoch 2
Loss = 1.4447e+00, PNorm = 43.2806, GNorm = 1.0268, lr_0 = 9.4019e-04
Validation rmse = 1.276681
Epoch 3
Loss = 1.3997e+00, PNorm = 43.3026, GNorm = 1.5880, lr_0 = 8.4834e-04
Validation rmse = 1.211283
Epoch 4
Loss = 1.2804e+00, PNorm = 43.3264, GNorm = 1.2426, lr_0 = 7.6547e-04
Validation rmse = 1.162992
Epoch 5
Loss = 1.2608e+00, PNorm = 43.3566, GNorm = 1.3233, lr_0 = 6.8363e-04
Validation rmse = 1.098094
Epoch 6
Loss = 1.2143e+00, PNorm = 43.3877, GNorm = 1.7022, lr_0 = 6.1685e-04
Validation rmse = 1.038363
Epoch 7
Loss = 1.1401e+00, PNorm = 43.4232, GNorm = 2.1603, lr_0 = 5.5659e-04
Validation rmse = 0.990570
Epoch 8
Validation rmse = 0.947009
Epoch 9
Loss = 1.0238e+00, PNorm = 43.4648, GNorm = 1.0052, lr_0 = 5.0222e-04
Validation rmse = 0.929702
Epoch 10
Loss = 9.8711e-01, PNorm = 43.5101, GNorm = 5.2020, lr_0 = 4.4852e-04
Validation rmse = 0.896006
Epoch 11
Loss = 9.5931e-01, PNorm = 43.5484, GNorm = 3.1011, lr_0 = 4.0471e-04
Validation rmse = 0.873883
Epoch 12
Loss = 9.0215e-01, PNorm = 43.5820, GNorm = 1.3986, lr_0 = 3.6517e-04
Validation rmse = 0.847803
Epoch 13
Loss = 8.5398e-01, PNorm = 43.6113, GNorm = 2.9459, lr_0 = 3.2950e-04
Validation rmse = 0.895478
Epoch 14
Loss = 8.3807e-01, PNorm = 43.6343, GNorm = 1.7147, lr_0 = 2.9731e-04
Validation rmse = 0.838076
Epoch 15
Loss = 8.1586e-01, PNorm = 43.6564, GNorm = 6.2940, lr_0 = 2.6553e-04
Validation rmse = 0.808359
Epoch 16
Validation rmse = 0.813783
Epoch 17
Loss = 8.1088e-01, PNorm = 43.6752, GNorm = 6.8619, lr_0 = 2.3959e-04
Validation rmse = 0.805243
Epoch 18
Loss = 8.0973e-01, PNorm = 43.6899, GNorm = 10.7424, lr_0 = 2.1618e-04
Validation rmse = 0.784953
Epoch 19
Loss = 8.3493e-01, PNorm = 43.7043, GNorm = 2.5587, lr_0 = 1.9506e-04
Validation rmse = 0.781146
Epoch 20
Loss = 7.0377e-01, PNorm = 43.7195, GNorm = 2.0256, lr_0 = 1.7421e-04
Validation rmse = 0.776627
Epoch 21
Loss = 7.3564e-01, PNorm = 43.7323, GNorm = 5.6397, lr_0 = 1.5719e-04
Validation rmse = 0.779907
Epoch 22
Loss = 7.3635e-01, PNorm = 43.7420, GNorm = 5.5107, lr_0 = 1.4184e-04
Validation rmse = 0.767711
Epoch 23
Loss = 7.0180e-01, PNorm = 43.7513, GNorm = 4.0662, lr_0 = 1.2798e-04
Loss = 6.9430e-01, PNorm = 43.7521, GNorm = 2.6687, lr_0 = 1.2667e-04
Validation rmse = 0.779208
Epoch 24
Validation rmse = 0.766141
Epoch 25
Loss = 6.1759e-01, PNorm = 43.7610, GNorm = 5.5998, lr_0 = 1.1430e-04
Validation rmse = 0.775485
Epoch 26
Loss = 7.3802e-01, PNorm = 43.7682, GNorm = 3.6571, lr_0 = 1.0313e-04
Validation rmse = 0.787807
Epoch 27
Loss = 6.2541e-01, PNorm = 43.7751, GNorm = 3.5132, lr_0 = 1.0000e-04
Validation rmse = 0.772040
Epoch 28
Loss = 7.1065e-01, PNorm = 43.7818, GNorm = 8.9247, lr_0 = 1.0000e-04
Validation rmse = 0.746493
Epoch 29
Loss = 6.6870e-01, PNorm = 43.7894, GNorm = 9.6912, lr_0 = 1.0000e-04
Validation rmse = 0.750310
Model 0 best validation rmse = 0.746493 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.721586
Ensemble test rmse = 0.721586
1-fold cross validation
	Seed 0 ==> test rmse = 0.721586
Overall test rmse = 0.721586 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.408031
Epoch 1
Loss = 1.4739e+00, PNorm = 43.2609, GNorm = 2.1667, lr_0 = 7.0000e-04
Validation rmse = 1.316492
Epoch 2
Loss = 1.4627e+00, PNorm = 43.2756, GNorm = 0.7774, lr_0 = 9.6411e-04
Validation rmse = 1.260502
Epoch 3
Loss = 1.3137e+00, PNorm = 43.2977, GNorm = 0.5901, lr_0 = 8.7192e-04
Validation rmse = 1.206560
Epoch 4
Loss = 1.3528e+00, PNorm = 43.3212, GNorm = 0.9511, lr_0 = 7.9578e-04
Validation rmse = 1.137739
Epoch 5
Loss = 1.2161e+00, PNorm = 43.3527, GNorm = 3.0118, lr_0 = 7.1969e-04
Validation rmse = 1.080777
Epoch 6
Loss = 1.1533e+00, PNorm = 43.3848, GNorm = 0.7635, lr_0 = 6.5684e-04
Validation rmse = 1.014500
Epoch 7
Loss = 1.0684e+00, PNorm = 43.4239, GNorm = 3.7611, lr_0 = 5.9948e-04
Validation rmse = 0.995719
Epoch 8
Loss = 1.0884e+00, PNorm = 43.4664, GNorm = 6.8352, lr_0 = 5.4216e-04
Validation rmse = 1.015605
Epoch 9
Loss = 9.8664e-01, PNorm = 43.5000, GNorm = 3.3990, lr_0 = 4.9482e-04
Validation rmse = 0.922073
Epoch 10
Loss = 9.6880e-01, PNorm = 43.5355, GNorm = 2.1932, lr_0 = 4.4750e-04
Validation rmse = 0.874405
Epoch 11
Loss = 8.9110e-01, PNorm = 43.5663, GNorm = 3.1710, lr_0 = 4.0842e-04
Validation rmse = 0.852999
Epoch 12
Loss = 7.9401e-01, PNorm = 43.5931, GNorm = 6.9926, lr_0 = 3.7276e-04
Validation rmse = 0.840685
Epoch 13
Loss = 8.2809e-01, PNorm = 43.6192, GNorm = 2.5759, lr_0 = 3.3711e-04
Validation rmse = 0.824385
Epoch 14
Loss = 7.7281e-01, PNorm = 43.6418, GNorm = 1.4888, lr_0 = 3.0768e-04
Validation rmse = 0.809169
Epoch 15
Loss = 7.8027e-01, PNorm = 43.6630, GNorm = 8.1337, lr_0 = 2.7826e-04
Validation rmse = 0.819641
Epoch 16
Loss = 7.6053e-01, PNorm = 43.6796, GNorm = 5.6983, lr_0 = 2.5396e-04
Validation rmse = 0.784974
Epoch 17
Loss = 7.1720e-01, PNorm = 43.6954, GNorm = 1.9375, lr_0 = 2.3178e-04
Validation rmse = 0.776854
Epoch 18
Loss = 7.2212e-01, PNorm = 43.7133, GNorm = 3.5016, lr_0 = 2.0962e-04
Validation rmse = 0.772723
Epoch 19
Loss = 6.7571e-01, PNorm = 43.7264, GNorm = 3.6178, lr_0 = 1.9131e-04
Validation rmse = 0.781597
Epoch 20
Loss = 6.9836e-01, PNorm = 43.7385, GNorm = 2.5916, lr_0 = 1.7302e-04
Validation rmse = 0.753170
Epoch 21
Loss = 6.7311e-01, PNorm = 43.7488, GNorm = 1.8911, lr_0 = 1.5791e-04
Loss = 7.9439e-01, PNorm = 43.7500, GNorm = 11.5951, lr_0 = 1.5647e-04
Validation rmse = 0.749422
Epoch 22
Loss = 6.6800e-01, PNorm = 43.7602, GNorm = 3.5000, lr_0 = 1.4281e-04
Validation rmse = 0.748131
Epoch 23
Loss = 6.7530e-01, PNorm = 43.7692, GNorm = 5.8096, lr_0 = 1.3034e-04
Validation rmse = 0.771107
Epoch 24
Validation rmse = 0.763202
Epoch 25
Loss = 7.2281e-01, PNorm = 43.7772, GNorm = 9.3234, lr_0 = 1.1788e-04
Validation rmse = 0.735443
Epoch 26
Loss = 6.1256e-01, PNorm = 43.7844, GNorm = 1.5281, lr_0 = 1.0758e-04
Validation rmse = 0.736551
Epoch 27
Loss = 5.9172e-01, PNorm = 43.7916, GNorm = 4.3783, lr_0 = 1.0000e-04
Validation rmse = 0.740792
Epoch 28
Loss = 6.2899e-01, PNorm = 43.7981, GNorm = 8.1674, lr_0 = 1.0000e-04
Validation rmse = 0.739224
Epoch 29
Loss = 5.8681e-01, PNorm = 43.8042, GNorm = 5.9711, lr_0 = 1.0000e-04
Validation rmse = 0.728763
Model 0 best validation rmse = 0.728763 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.725872
Ensemble test rmse = 0.725872
1-fold cross validation
	Seed 0 ==> test rmse = 0.725872
Overall test rmse = 0.725872 +/- 0.000000
Elapsed time = 0:01:36
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8567e+00, PNorm = 43.2621, GNorm = 1.9361, lr_0 = 5.9500e-04
Loss = 1.3655e+00, PNorm = 43.2626, GNorm = 1.8458, lr_0 = 6.4000e-04
Validation rmse = 1.421631
Epoch 1
Loss = 1.4436e+00, PNorm = 43.2791, GNorm = 1.2765, lr_0 = 9.8369e-04
Loss = 1.2710e+00, PNorm = 43.2811, GNorm = 1.0401, lr_0 = 9.7563e-04
Validation rmse = 1.446590
Epoch 2
Loss = 1.3475e+00, PNorm = 43.3048, GNorm = 0.5445, lr_0 = 8.9861e-04
Validation rmse = 1.385339
Epoch 3
Loss = 1.2900e+00, PNorm = 43.3336, GNorm = 1.1030, lr_0 = 8.2767e-04
Validation rmse = 1.283350
Epoch 4
Loss = 1.2111e+00, PNorm = 43.3716, GNorm = 2.9401, lr_0 = 7.5609e-04
Validation rmse = 1.192603
Epoch 5
Loss = 1.1286e+00, PNorm = 43.4147, GNorm = 0.8394, lr_0 = 6.9069e-04
Validation rmse = 1.122632
Epoch 6
Loss = 1.0602e+00, PNorm = 43.4597, GNorm = 4.2403, lr_0 = 6.3617e-04
Validation rmse = 1.016130
Epoch 7
Loss = 9.9083e-01, PNorm = 43.5054, GNorm = 2.4550, lr_0 = 5.8115e-04
Validation rmse = 0.970609
Epoch 8
Loss = 9.4023e-01, PNorm = 43.5469, GNorm = 3.3679, lr_0 = 5.3527e-04
Validation rmse = 0.996891
Epoch 9
Loss = 9.1356e-01, PNorm = 43.5813, GNorm = 2.3732, lr_0 = 4.8897e-04
Validation rmse = 0.950619
Epoch 10
Loss = 8.6085e-01, PNorm = 43.6117, GNorm = 1.9789, lr_0 = 4.4668e-04
Validation rmse = 0.884050
Epoch 11
Loss = 8.0796e-01, PNorm = 43.6416, GNorm = 1.7728, lr_0 = 4.1142e-04
Validation rmse = 0.867375
Epoch 12
Loss = 7.6753e-01, PNorm = 43.6746, GNorm = 7.4095, lr_0 = 3.7584e-04
Validation rmse = 0.876363
Epoch 13
Loss = 7.8357e-01, PNorm = 43.6963, GNorm = 8.1884, lr_0 = 3.4617e-04
Validation rmse = 0.849315
Epoch 14
Loss = 7.0634e-01, PNorm = 43.7192, GNorm = 1.6521, lr_0 = 3.1623e-04
Validation rmse = 0.837735
Epoch 15
Loss = 7.2603e-01, PNorm = 43.7433, GNorm = 1.8335, lr_0 = 2.8888e-04
Validation rmse = 0.837428
Epoch 16
Loss = 6.8751e-01, PNorm = 43.7610, GNorm = 4.0056, lr_0 = 2.6607e-04
Validation rmse = 0.838494
Epoch 17
Loss = 6.6411e-01, PNorm = 43.7777, GNorm = 8.1846, lr_0 = 2.4306e-04
Validation rmse = 0.837665
Epoch 18
Loss = 6.6923e-01, PNorm = 43.7916, GNorm = 10.1691, lr_0 = 2.2387e-04
Validation rmse = 0.838750
Epoch 19
Loss = 6.8266e-01, PNorm = 43.8069, GNorm = 2.2021, lr_0 = 2.0451e-04
Validation rmse = 0.811404
Epoch 20
Loss = 5.9012e-01, PNorm = 43.8210, GNorm = 8.6643, lr_0 = 1.8682e-04
Validation rmse = 0.816453
Epoch 21
Loss = 6.5037e-01, PNorm = 43.8324, GNorm = 1.6914, lr_0 = 1.7207e-04
Validation rmse = 0.803394
Epoch 22
Loss = 6.1611e-01, PNorm = 43.8436, GNorm = 6.2842, lr_0 = 1.5719e-04
Validation rmse = 0.802968
Epoch 23
Loss = 5.4553e-01, PNorm = 43.8536, GNorm = 2.6531, lr_0 = 1.4360e-04
Validation rmse = 0.810190
Epoch 24
Loss = 5.9316e-01, PNorm = 43.8622, GNorm = 5.0233, lr_0 = 1.3226e-04
Validation rmse = 0.801060
Epoch 25
Loss = 5.7941e-01, PNorm = 43.8706, GNorm = 1.8659, lr_0 = 1.2082e-04
Loss = 5.8366e-01, PNorm = 43.8782, GNorm = 5.4233, lr_0 = 1.1128e-04
Validation rmse = 0.803521
Epoch 26
Loss = 5.7548e-01, PNorm = 43.8845, GNorm = 3.6170, lr_0 = 1.0250e-04
Loss = 7.9635e-01, PNorm = 43.8852, GNorm = 13.0994, lr_0 = 1.0166e-04
Validation rmse = 0.800469
Epoch 27
Loss = 5.7720e-01, PNorm = 43.8916, GNorm = 7.5943, lr_0 = 1.0000e-04
Loss = 7.5615e-01, PNorm = 43.8921, GNorm = 3.3502, lr_0 = 1.0000e-04
Validation rmse = 0.812473
Epoch 28
Loss = 6.0466e-01, PNorm = 43.8981, GNorm = 2.1375, lr_0 = 1.0000e-04
Validation rmse = 0.799929
Epoch 29
Loss = 5.8913e-01, PNorm = 43.9037, GNorm = 10.2337, lr_0 = 1.0000e-04
Validation rmse = 0.793607
Model 0 best validation rmse = 0.793607 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.730131
Ensemble test rmse = 0.730131
1-fold cross validation
	Seed 0 ==> test rmse = 0.730131
Overall test rmse = 0.730131 +/- 0.000000
Elapsed time = 0:01:48
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8794e+00, PNorm = 43.2600, GNorm = 1.1247, lr_0 = 5.5000e-04
Validation rmse = 1.407932
Epoch 1
Loss = 1.4485e+00, PNorm = 43.2711, GNorm = 1.0382, lr_0 = 1.0000e-03
Validation rmse = 1.430129
Epoch 2
Loss = 1.3484e+00, PNorm = 43.2951, GNorm = 0.6546, lr_0 = 9.2106e-04
Validation rmse = 1.357317
Epoch 3
Loss = 1.3039e+00, PNorm = 43.3246, GNorm = 0.7891, lr_0 = 8.4834e-04
Validation rmse = 1.281617
Epoch 4
Loss = 1.2558e+00, PNorm = 43.3549, GNorm = 0.6577, lr_0 = 7.8137e-04
Validation rmse = 1.212993
Epoch 5
Loss = 1.1817e+00, PNorm = 43.3935, GNorm = 2.5772, lr_0 = 7.1969e-04
Validation rmse = 1.133984
Epoch 6
Loss = 1.1069e+00, PNorm = 43.4368, GNorm = 2.6859, lr_0 = 6.6784e-04
Validation rmse = 1.084530
Epoch 7
Loss = 1.0443e+00, PNorm = 43.4858, GNorm = 6.4602, lr_0 = 6.1512e-04
Validation rmse = 1.013269
Epoch 8
Loss = 1.0635e+00, PNorm = 43.5277, GNorm = 4.1905, lr_0 = 5.6656e-04
Loss = 9.5526e-01, PNorm = 43.5676, GNorm = 2.8730, lr_0 = 5.2575e-04
Loss = 9.8038e-01, PNorm = 43.5711, GNorm = 4.3247, lr_0 = 5.2183e-04
Validation rmse = 1.003835
Epoch 9
Loss = 9.0879e-01, PNorm = 43.6053, GNorm = 3.9873, lr_0 = 4.8424e-04
Validation rmse = 0.916847
Epoch 10
Loss = 8.7407e-01, PNorm = 43.6368, GNorm = 8.3212, lr_0 = 4.4602e-04
Validation rmse = 0.954646
Epoch 11
Loss = 8.2908e-01, PNorm = 43.6629, GNorm = 2.5259, lr_0 = 4.1389e-04
Validation rmse = 0.881669
Epoch 12
Loss = 8.0560e-01, PNorm = 43.6920, GNorm = 4.1442, lr_0 = 3.8121e-04
Validation rmse = 0.854449
Epoch 13
Loss = 7.8134e-01, PNorm = 43.7210, GNorm = 2.2672, lr_0 = 3.5112e-04
Validation rmse = 0.851687
Epoch 14
Loss = 7.8715e-01, PNorm = 43.7455, GNorm = 3.5226, lr_0 = 3.2340e-04
Validation rmse = 0.885574
Epoch 15
Loss = 7.6595e-01, PNorm = 43.7613, GNorm = 2.8664, lr_0 = 2.9787e-04
Validation rmse = 0.843055
Epoch 16
Loss = 6.8072e-01, PNorm = 43.7773, GNorm = 1.8426, lr_0 = 2.7641e-04
Loss = 7.0320e-01, PNorm = 43.7938, GNorm = 2.8263, lr_0 = 2.5650e-04
Loss = 6.4427e-01, PNorm = 43.7956, GNorm = 6.6302, lr_0 = 2.5459e-04
Validation rmse = 0.832582
Epoch 17
Loss = 6.7722e-01, PNorm = 43.8120, GNorm = 2.2546, lr_0 = 2.3625e-04
Validation rmse = 0.831731
Epoch 18
Loss = 6.4422e-01, PNorm = 43.8250, GNorm = 1.6748, lr_0 = 2.1760e-04
Validation rmse = 0.821443
Epoch 19
Loss = 6.7290e-01, PNorm = 43.8393, GNorm = 5.6906, lr_0 = 2.0042e-04
Validation rmse = 0.824697
Epoch 20
Loss = 6.2763e-01, PNorm = 43.8521, GNorm = 2.7158, lr_0 = 1.8460e-04
Validation rmse = 0.840481
Epoch 21
Loss = 6.2265e-01, PNorm = 43.8635, GNorm = 3.6526, lr_0 = 1.7003e-04
Validation rmse = 0.833436
Epoch 22
Loss = 6.7272e-01, PNorm = 43.8714, GNorm = 8.2967, lr_0 = 1.5778e-04
Validation rmse = 0.823814
Epoch 23
Loss = 5.8176e-01, PNorm = 43.8803, GNorm = 5.3095, lr_0 = 1.4532e-04
Validation rmse = 0.820142
Epoch 24
Loss = 6.0335e-01, PNorm = 43.8902, GNorm = 3.0632, lr_0 = 1.3385e-04
Validation rmse = 0.823950
Epoch 25
Loss = 7.5601e-01, PNorm = 43.8987, GNorm = 1.9145, lr_0 = 1.2328e-04
Loss = 5.7839e-01, PNorm = 43.9069, GNorm = 4.5167, lr_0 = 1.1440e-04
Loss = 8.4740e-01, PNorm = 43.9076, GNorm = 7.6712, lr_0 = 1.1355e-04
Validation rmse = 0.809238
Epoch 26
Loss = 5.9071e-01, PNorm = 43.9146, GNorm = 3.0439, lr_0 = 1.0537e-04
Validation rmse = 0.812862
Epoch 27
Loss = 5.8615e-01, PNorm = 43.9214, GNorm = 7.1961, lr_0 = 1.0000e-04
Validation rmse = 0.814962
Epoch 28
Loss = 5.5263e-01, PNorm = 43.9279, GNorm = 2.3333, lr_0 = 1.0000e-04
Validation rmse = 0.814910
Epoch 29
Loss = 6.0035e-01, PNorm = 43.9345, GNorm = 4.1394, lr_0 = 1.0000e-04
Validation rmse = 0.826442
Model 0 best validation rmse = 0.809238 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.745401
Ensemble test rmse = 0.745401
1-fold cross validation
	Seed 0 ==> test rmse = 0.745401
Overall test rmse = 0.745401 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8169e+00, PNorm = 43.2606, GNorm = 1.5890, lr_0 = 5.5000e-04
Validation rmse = 1.411875
Epoch 1
Loss = 1.4428e+00, PNorm = 43.2754, GNorm = 0.8621, lr_0 = 1.0000e-03
Validation rmse = 1.438341
Epoch 2
Loss = 1.3483e+00, PNorm = 43.2983, GNorm = 1.4029, lr_0 = 9.2797e-04
Validation rmse = 1.371354
Epoch 3
Loss = 1.2735e+00, PNorm = 43.3245, GNorm = 1.4793, lr_0 = 8.6112e-04
Validation rmse = 1.292476
Epoch 4
Loss = 1.2031e+00, PNorm = 43.3567, GNorm = 1.5034, lr_0 = 7.9909e-04
Validation rmse = 1.202868
Epoch 5
Loss = 1.0581e+00, PNorm = 43.3946, GNorm = 1.0927, lr_0 = 7.4153e-04
Loss = 1.1181e+00, PNorm = 43.4410, GNorm = 6.8077, lr_0 = 6.8812e-04
Validation rmse = 1.167241
Epoch 6
Loss = 1.0772e+00, PNorm = 43.4825, GNorm = 1.1727, lr_0 = 6.3855e-04
Validation rmse = 1.025462
Epoch 7
Loss = 1.0095e+00, PNorm = 43.5269, GNorm = 5.6052, lr_0 = 5.9255e-04
Validation rmse = 1.016325
Epoch 8
Loss = 9.4940e-01, PNorm = 43.5691, GNorm = 1.8677, lr_0 = 5.4987e-04
Validation rmse = 0.960553
Epoch 9
Loss = 8.7413e-01, PNorm = 43.6112, GNorm = 1.1204, lr_0 = 5.1026e-04
Validation rmse = 0.943847
Epoch 10
Loss = 8.4598e-01, PNorm = 43.6523, GNorm = 2.6250, lr_0 = 4.7351e-04
Loss = 8.1258e-01, PNorm = 43.6876, GNorm = 1.5705, lr_0 = 4.3940e-04
Validation rmse = 0.891413
Epoch 11
Loss = 7.8088e-01, PNorm = 43.7181, GNorm = 5.1108, lr_0 = 4.0775e-04
Validation rmse = 0.899315
Epoch 12
Loss = 7.7290e-01, PNorm = 43.7477, GNorm = 8.9160, lr_0 = 3.7837e-04
Validation rmse = 0.864813
Epoch 13
Loss = 7.2189e-01, PNorm = 43.7757, GNorm = 1.8294, lr_0 = 3.5112e-04
Validation rmse = 0.854341
Epoch 14
Loss = 6.8933e-01, PNorm = 43.8017, GNorm = 1.9997, lr_0 = 3.2583e-04
Validation rmse = 0.860994
Epoch 15
Loss = 7.5874e-01, PNorm = 43.8242, GNorm = 3.6978, lr_0 = 3.0236e-04
Loss = 6.6193e-01, PNorm = 43.8451, GNorm = 2.5002, lr_0 = 2.8058e-04
Validation rmse = 0.847402
Epoch 16
Loss = 6.7685e-01, PNorm = 43.8643, GNorm = 1.7754, lr_0 = 2.6037e-04
Validation rmse = 0.855936
Epoch 17
Loss = 6.3685e-01, PNorm = 43.8820, GNorm = 2.2978, lr_0 = 2.4161e-04
Validation rmse = 0.888076
Epoch 18
Loss = 7.3093e-01, PNorm = 43.8978, GNorm = 4.7229, lr_0 = 2.2421e-04
Validation rmse = 0.841425
Epoch 19
Loss = 6.2794e-01, PNorm = 43.9117, GNorm = 3.7672, lr_0 = 2.0806e-04
Validation rmse = 0.837973
Epoch 20
Loss = 6.3005e-01, PNorm = 43.9247, GNorm = 2.0807, lr_0 = 1.9307e-04
Loss = 6.1326e-01, PNorm = 43.9370, GNorm = 3.4267, lr_0 = 1.7916e-04
Validation rmse = 0.842548
Epoch 21
Loss = 6.1690e-01, PNorm = 43.9477, GNorm = 11.3776, lr_0 = 1.6626e-04
Validation rmse = 0.851005
Epoch 22
Loss = 6.1403e-01, PNorm = 43.9574, GNorm = 4.9942, lr_0 = 1.5428e-04
Validation rmse = 0.842656
Epoch 23
Loss = 6.2785e-01, PNorm = 43.9678, GNorm = 3.4939, lr_0 = 1.4317e-04
Validation rmse = 0.839370
Epoch 24
Loss = 5.7350e-01, PNorm = 43.9772, GNorm = 2.1294, lr_0 = 1.3285e-04
Validation rmse = 0.827992
Epoch 25
Loss = 4.9412e-01, PNorm = 43.9852, GNorm = 4.8691, lr_0 = 1.2328e-04
Loss = 5.7586e-01, PNorm = 43.9933, GNorm = 12.3339, lr_0 = 1.1440e-04
Validation rmse = 0.830788
Epoch 26
Loss = 5.6854e-01, PNorm = 44.0007, GNorm = 10.6706, lr_0 = 1.0616e-04
Validation rmse = 0.834250
Epoch 27
Loss = 5.3278e-01, PNorm = 44.0071, GNorm = 9.3736, lr_0 = 1.0000e-04
Validation rmse = 0.829845
Epoch 28
Loss = 5.8242e-01, PNorm = 44.0134, GNorm = 4.2540, lr_0 = 1.0000e-04
Validation rmse = 0.823923
Epoch 29
Loss = 5.7976e-01, PNorm = 44.0198, GNorm = 8.5474, lr_0 = 1.0000e-04
Validation rmse = 0.824495
Model 0 best validation rmse = 0.823923 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.680720
Ensemble test rmse = 0.680720
1-fold cross validation
	Seed 0 ==> test rmse = 0.680720
Overall test rmse = 0.680720 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.393006
Epoch 1
Loss = 1.4401e+00, PNorm = 43.2639, GNorm = 1.7045, lr_0 = 8.7143e-04
Validation rmse = 1.334197
Epoch 2
Loss = 1.4380e+00, PNorm = 43.2872, GNorm = 0.9950, lr_0 = 9.1030e-04
Validation rmse = 1.297323
Epoch 3
Loss = 1.3378e+00, PNorm = 43.3146, GNorm = 0.7420, lr_0 = 8.0940e-04
Validation rmse = 1.275756
Epoch 4
Validation rmse = 1.253283
Epoch 5
Loss = 1.2660e+00, PNorm = 43.3427, GNorm = 1.3290, lr_0 = 7.1969e-04
Validation rmse = 1.200310
Epoch 6
Loss = 1.2715e+00, PNorm = 43.3730, GNorm = 1.3891, lr_0 = 6.3992e-04
Validation rmse = 1.130133
Epoch 7
Loss = 1.1744e+00, PNorm = 43.4051, GNorm = 3.0666, lr_0 = 5.6899e-04
Validation rmse = 1.088004
Epoch 8
Loss = 1.1138e+00, PNorm = 43.4410, GNorm = 0.9048, lr_0 = 5.0592e-04
Validation rmse = 1.124856
Epoch 9
Validation rmse = 1.037041
Epoch 10
Loss = 1.0261e+00, PNorm = 43.4724, GNorm = 2.7097, lr_0 = 4.4984e-04
Validation rmse = 0.999559
Epoch 11
Loss = 1.0317e+00, PNorm = 43.5060, GNorm = 6.4856, lr_0 = 3.9998e-04
Validation rmse = 0.969014
Epoch 12
Loss = 9.6801e-01, PNorm = 43.5340, GNorm = 6.9999, lr_0 = 3.5565e-04
Validation rmse = 0.940329
Epoch 13
Loss = 9.4850e-01, PNorm = 43.5563, GNorm = 1.7335, lr_0 = 3.1623e-04
Validation rmse = 0.932209
Epoch 14
Validation rmse = 0.924381
Epoch 15
Loss = 8.2255e-01, PNorm = 43.5787, GNorm = 2.1133, lr_0 = 2.8118e-04
Validation rmse = 0.904586
Epoch 16
Loss = 8.4294e-01, PNorm = 43.5997, GNorm = 4.9531, lr_0 = 2.5001e-04
Validation rmse = 0.892514
Epoch 17
Loss = 8.2729e-01, PNorm = 43.6185, GNorm = 4.1114, lr_0 = 2.2230e-04
Validation rmse = 0.903376
Epoch 18
Loss = 8.1270e-01, PNorm = 43.6357, GNorm = 2.0769, lr_0 = 1.9766e-04
Validation rmse = 0.903371
Epoch 19
Validation rmse = 0.931040
Epoch 20
Loss = 6.3845e-01, PNorm = 43.6497, GNorm = 5.8847, lr_0 = 1.7575e-04
Validation rmse = 0.926236
Epoch 21
Loss = 7.8344e-01, PNorm = 43.6626, GNorm = 7.2398, lr_0 = 1.5627e-04
Validation rmse = 0.875724
Epoch 22
Loss = 7.3328e-01, PNorm = 43.6746, GNorm = 4.9971, lr_0 = 1.3895e-04
Validation rmse = 0.867101
Epoch 23
Loss = 7.2341e-01, PNorm = 43.6844, GNorm = 2.3223, lr_0 = 1.2355e-04
Validation rmse = 0.870861
Epoch 24
Validation rmse = 0.870267
Epoch 25
Loss = 8.0603e-01, PNorm = 43.6939, GNorm = 1.6426, lr_0 = 1.0985e-04
Validation rmse = 0.892564
Epoch 26
Loss = 7.5328e-01, PNorm = 43.7016, GNorm = 3.9692, lr_0 = 1.0000e-04
Validation rmse = 0.863764
Epoch 27
Loss = 7.3005e-01, PNorm = 43.7091, GNorm = 2.2150, lr_0 = 1.0000e-04
Validation rmse = 0.883825
Epoch 28
Loss = 6.8494e-01, PNorm = 43.7168, GNorm = 6.9780, lr_0 = 1.0000e-04
Validation rmse = 0.871487
Epoch 29
Validation rmse = 0.865863
Model 0 best validation rmse = 0.863764 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.731799
Ensemble test rmse = 0.731799
1-fold cross validation
	Seed 0 ==> test rmse = 0.731799
Overall test rmse = 0.731799 +/- 0.000000
Elapsed time = 0:01:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.351226
Epoch 1
Loss = 1.4465e+00, PNorm = 43.2632, GNorm = 2.4348, lr_0 = 7.7500e-04
Validation rmse = 1.278518
Epoch 2
Loss = 1.4693e+00, PNorm = 43.2829, GNorm = 0.8245, lr_0 = 9.4019e-04
Validation rmse = 1.226400
Epoch 3
Loss = 1.3292e+00, PNorm = 43.3059, GNorm = 0.7635, lr_0 = 8.4834e-04
Validation rmse = 1.169916
Epoch 4
Loss = 1.2791e+00, PNorm = 43.3333, GNorm = 0.9200, lr_0 = 7.6547e-04
Validation rmse = 1.102194
Epoch 5
Loss = 1.2201e+00, PNorm = 43.3710, GNorm = 1.7623, lr_0 = 6.8363e-04
Validation rmse = 1.051689
Epoch 6
Loss = 1.1672e+00, PNorm = 43.4093, GNorm = 2.3471, lr_0 = 6.1685e-04
Validation rmse = 1.110224
Epoch 7
Loss = 1.0998e+00, PNorm = 43.4499, GNorm = 1.6336, lr_0 = 5.5659e-04
Validation rmse = 1.003661
Epoch 8
Validation rmse = 0.943347
Epoch 9
Loss = 9.6506e-01, PNorm = 43.4873, GNorm = 1.0282, lr_0 = 5.0222e-04
Validation rmse = 0.939305
Epoch 10
Loss = 9.7068e-01, PNorm = 43.5279, GNorm = 0.9506, lr_0 = 4.4852e-04
Validation rmse = 0.881890
Epoch 11
Loss = 9.1887e-01, PNorm = 43.5578, GNorm = 6.4779, lr_0 = 4.0471e-04
Validation rmse = 0.876656
Epoch 12
Loss = 8.8570e-01, PNorm = 43.5831, GNorm = 4.2716, lr_0 = 3.6517e-04
Validation rmse = 0.875747
Epoch 13
Loss = 8.8066e-01, PNorm = 43.6086, GNorm = 3.7237, lr_0 = 3.2950e-04
Validation rmse = 0.828194
Epoch 14
Loss = 8.0620e-01, PNorm = 43.6336, GNorm = 1.3472, lr_0 = 2.9731e-04
Validation rmse = 0.806822
Epoch 15
Loss = 7.9098e-01, PNorm = 43.6583, GNorm = 1.8008, lr_0 = 2.6553e-04
Validation rmse = 0.803864
Epoch 16
Validation rmse = 0.799535
Epoch 17
Loss = 8.0149e-01, PNorm = 43.6786, GNorm = 3.7874, lr_0 = 2.3959e-04
Validation rmse = 0.782141
Epoch 18
Loss = 7.1801e-01, PNorm = 43.6956, GNorm = 9.1818, lr_0 = 2.1618e-04
Validation rmse = 0.773973
Epoch 19
Loss = 6.9210e-01, PNorm = 43.7114, GNorm = 1.6843, lr_0 = 1.9506e-04
Validation rmse = 0.767365
Epoch 20
Loss = 6.6634e-01, PNorm = 43.7263, GNorm = 1.8695, lr_0 = 1.7421e-04
Validation rmse = 0.767437
Epoch 21
Loss = 6.9758e-01, PNorm = 43.7386, GNorm = 2.1232, lr_0 = 1.5719e-04
Validation rmse = 0.760461
Epoch 22
Loss = 6.9541e-01, PNorm = 43.7496, GNorm = 8.9501, lr_0 = 1.4184e-04
Validation rmse = 0.767071
Epoch 23
Loss = 6.5669e-01, PNorm = 43.7597, GNorm = 7.9054, lr_0 = 1.2798e-04
Loss = 6.8260e-01, PNorm = 43.7607, GNorm = 2.3501, lr_0 = 1.2667e-04
Validation rmse = 0.752199
Epoch 24
Validation rmse = 0.750754
Epoch 25
Loss = 5.4079e-01, PNorm = 43.7697, GNorm = 3.7550, lr_0 = 1.1430e-04
Validation rmse = 0.761436
Epoch 26
Loss = 6.7108e-01, PNorm = 43.7771, GNorm = 2.5051, lr_0 = 1.0313e-04
Validation rmse = 0.752378
Epoch 27
Loss = 6.1411e-01, PNorm = 43.7841, GNorm = 3.9150, lr_0 = 1.0000e-04
Validation rmse = 0.752030
Epoch 28
Loss = 6.3087e-01, PNorm = 43.7910, GNorm = 4.4111, lr_0 = 1.0000e-04
Validation rmse = 0.747730
Epoch 29
Loss = 6.0039e-01, PNorm = 43.7987, GNorm = 1.5499, lr_0 = 1.0000e-04
Validation rmse = 0.744967
Model 0 best validation rmse = 0.744967 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.736920
Ensemble test rmse = 0.736920
1-fold cross validation
	Seed 0 ==> test rmse = 0.736920
Overall test rmse = 0.736920 +/- 0.000000
Elapsed time = 0:01:29
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.302992
Epoch 1
Loss = 1.4942e+00, PNorm = 43.2640, GNorm = 2.7217, lr_0 = 7.0000e-04
Validation rmse = 1.309179
Epoch 2
Loss = 1.4675e+00, PNorm = 43.2852, GNorm = 0.7576, lr_0 = 9.6411e-04
Validation rmse = 1.293562
Epoch 3
Loss = 1.2278e+00, PNorm = 43.3152, GNorm = 0.6447, lr_0 = 8.7192e-04
Validation rmse = 1.227712
Epoch 4
Loss = 1.2588e+00, PNorm = 43.3437, GNorm = 0.5738, lr_0 = 7.9578e-04
Validation rmse = 1.145842
Epoch 5
Loss = 1.1910e+00, PNorm = 43.3804, GNorm = 1.7210, lr_0 = 7.1969e-04
Validation rmse = 1.040991
Epoch 6
Loss = 1.1306e+00, PNorm = 43.4189, GNorm = 2.8792, lr_0 = 6.5684e-04
Validation rmse = 0.964336
Epoch 7
Loss = 1.0397e+00, PNorm = 43.4628, GNorm = 3.0799, lr_0 = 5.9948e-04
Validation rmse = 0.926338
Epoch 8
Loss = 1.0158e+00, PNorm = 43.5101, GNorm = 2.9465, lr_0 = 5.4216e-04
Validation rmse = 0.889007
Epoch 9
Loss = 9.4098e-01, PNorm = 43.5505, GNorm = 2.6110, lr_0 = 4.9482e-04
Validation rmse = 0.866592
Epoch 10
Loss = 8.9612e-01, PNorm = 43.5924, GNorm = 2.2182, lr_0 = 4.4750e-04
Validation rmse = 0.782503
Epoch 11
Loss = 8.3096e-01, PNorm = 43.6258, GNorm = 1.7710, lr_0 = 4.0842e-04
Validation rmse = 0.786172
Epoch 12
Loss = 8.4403e-01, PNorm = 43.6547, GNorm = 1.6768, lr_0 = 3.7276e-04
Validation rmse = 0.756270
Epoch 13
Loss = 7.6078e-01, PNorm = 43.6797, GNorm = 5.9592, lr_0 = 3.3711e-04
Validation rmse = 0.779076
Epoch 14
Loss = 7.1607e-01, PNorm = 43.7023, GNorm = 2.4165, lr_0 = 3.0768e-04
Validation rmse = 0.755685
Epoch 15
Loss = 7.1322e-01, PNorm = 43.7262, GNorm = 2.5512, lr_0 = 2.7826e-04
Validation rmse = 0.747542
Epoch 16
Loss = 7.1306e-01, PNorm = 43.7431, GNorm = 2.8623, lr_0 = 2.5396e-04
Validation rmse = 0.758186
Epoch 17
Loss = 6.7009e-01, PNorm = 43.7591, GNorm = 9.0060, lr_0 = 2.3178e-04
Validation rmse = 0.766508
Epoch 18
Loss = 6.7613e-01, PNorm = 43.7757, GNorm = 11.1627, lr_0 = 2.0962e-04
Validation rmse = 0.705434
Epoch 19
Loss = 6.5274e-01, PNorm = 43.7874, GNorm = 1.5724, lr_0 = 1.9131e-04
Validation rmse = 0.715904
Epoch 20
Loss = 6.3432e-01, PNorm = 43.8007, GNorm = 2.7289, lr_0 = 1.7302e-04
Validation rmse = 0.736567
Epoch 21
Loss = 6.0924e-01, PNorm = 43.8112, GNorm = 2.8483, lr_0 = 1.5791e-04
Loss = 7.0457e-01, PNorm = 43.8123, GNorm = 8.0809, lr_0 = 1.5647e-04
Validation rmse = 0.714073
Epoch 22
Loss = 6.0923e-01, PNorm = 43.8224, GNorm = 2.6706, lr_0 = 1.4281e-04
Validation rmse = 0.745383
Epoch 23
Loss = 6.0322e-01, PNorm = 43.8301, GNorm = 3.9818, lr_0 = 1.3034e-04
Validation rmse = 0.722647
Epoch 24
Validation rmse = 0.719049
Epoch 25
Loss = 5.9039e-01, PNorm = 43.8377, GNorm = 1.5339, lr_0 = 1.1788e-04
Validation rmse = 0.728446
Epoch 26
Loss = 6.1531e-01, PNorm = 43.8450, GNorm = 5.5961, lr_0 = 1.0758e-04
Validation rmse = 0.725452
Epoch 27
Loss = 6.3044e-01, PNorm = 43.8520, GNorm = 5.8043, lr_0 = 1.0000e-04
Validation rmse = 0.724513
Epoch 28
Loss = 6.5494e-01, PNorm = 43.8570, GNorm = 8.7082, lr_0 = 1.0000e-04
Validation rmse = 0.710425
Epoch 29
Loss = 6.3900e-01, PNorm = 43.8626, GNorm = 4.5974, lr_0 = 1.0000e-04
Validation rmse = 0.728337
Model 0 best validation rmse = 0.705434 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.752420
Ensemble test rmse = 0.752420
1-fold cross validation
	Seed 0 ==> test rmse = 0.752420
Overall test rmse = 0.752420 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8209e+00, PNorm = 43.2607, GNorm = 1.7734, lr_0 = 5.9500e-04
Loss = 1.5102e+00, PNorm = 43.2610, GNorm = 1.8038, lr_0 = 6.4000e-04
Validation rmse = 1.369649
Epoch 1
Loss = 1.4596e+00, PNorm = 43.2761, GNorm = 0.9613, lr_0 = 9.8369e-04
Loss = 1.3723e+00, PNorm = 43.2786, GNorm = 1.2202, lr_0 = 9.7563e-04
Validation rmse = 1.349703
Epoch 2
Loss = 1.3476e+00, PNorm = 43.3030, GNorm = 0.8898, lr_0 = 8.9861e-04
Validation rmse = 1.294655
Epoch 3
Loss = 1.2893e+00, PNorm = 43.3335, GNorm = 0.5807, lr_0 = 8.2767e-04
Validation rmse = 1.211991
Epoch 4
Loss = 1.2474e+00, PNorm = 43.3698, GNorm = 3.6465, lr_0 = 7.5609e-04
Validation rmse = 1.160864
Epoch 5
Loss = 1.1635e+00, PNorm = 43.4077, GNorm = 2.3633, lr_0 = 6.9069e-04
Validation rmse = 1.120381
Epoch 6
Loss = 1.1055e+00, PNorm = 43.4508, GNorm = 1.5593, lr_0 = 6.3617e-04
Validation rmse = 0.999676
Epoch 7
Loss = 1.0266e+00, PNorm = 43.4962, GNorm = 4.3138, lr_0 = 5.8115e-04
Validation rmse = 1.107331
Epoch 8
Loss = 1.0521e+00, PNorm = 43.5306, GNorm = 3.2739, lr_0 = 5.3527e-04
Validation rmse = 0.904286
Epoch 9
Loss = 9.9929e-01, PNorm = 43.5651, GNorm = 2.2587, lr_0 = 4.8897e-04
Validation rmse = 0.881880
Epoch 10
Loss = 9.0472e-01, PNorm = 43.6015, GNorm = 3.1377, lr_0 = 4.4668e-04
Validation rmse = 0.848567
Epoch 11
Loss = 8.5832e-01, PNorm = 43.6339, GNorm = 2.9660, lr_0 = 4.1142e-04
Validation rmse = 0.810046
Epoch 12
Loss = 8.2856e-01, PNorm = 43.6654, GNorm = 1.6293, lr_0 = 3.7584e-04
Validation rmse = 0.782273
Epoch 13
Loss = 7.7151e-01, PNorm = 43.6921, GNorm = 1.2794, lr_0 = 3.4617e-04
Validation rmse = 0.755903
Epoch 14
Loss = 7.8323e-01, PNorm = 43.7195, GNorm = 3.1323, lr_0 = 3.1623e-04
Validation rmse = 0.739650
Epoch 15
Loss = 7.2310e-01, PNorm = 43.7420, GNorm = 1.8314, lr_0 = 2.8888e-04
Validation rmse = 0.729653
Epoch 16
Loss = 6.7860e-01, PNorm = 43.7628, GNorm = 1.7591, lr_0 = 2.6607e-04
Validation rmse = 0.715203
Epoch 17
Loss = 7.6268e-01, PNorm = 43.7821, GNorm = 3.3957, lr_0 = 2.4306e-04
Validation rmse = 0.724208
Epoch 18
Loss = 6.1127e-01, PNorm = 43.7975, GNorm = 4.0540, lr_0 = 2.2387e-04
Validation rmse = 0.748264
Epoch 19
Loss = 7.0988e-01, PNorm = 43.8147, GNorm = 5.8674, lr_0 = 2.0451e-04
Validation rmse = 0.705137
Epoch 20
Loss = 7.3789e-01, PNorm = 43.8322, GNorm = 12.3452, lr_0 = 1.8682e-04
Validation rmse = 0.700645
Epoch 21
Loss = 6.1147e-01, PNorm = 43.8426, GNorm = 3.2252, lr_0 = 1.7207e-04
Validation rmse = 0.703801
Epoch 22
Loss = 7.2145e-01, PNorm = 43.8533, GNorm = 5.8862, lr_0 = 1.5719e-04
Validation rmse = 0.695592
Epoch 23
Loss = 6.5870e-01, PNorm = 43.8641, GNorm = 4.1851, lr_0 = 1.4360e-04
Validation rmse = 0.691253
Epoch 24
Loss = 4.1559e-01, PNorm = 43.8731, GNorm = 5.9554, lr_0 = 1.3226e-04
Validation rmse = 0.689317
Epoch 25
Loss = 5.0156e-01, PNorm = 43.8809, GNorm = 2.4009, lr_0 = 1.2082e-04
Loss = 6.2736e-01, PNorm = 43.8881, GNorm = 5.5287, lr_0 = 1.1128e-04
Validation rmse = 0.677250
Epoch 26
Loss = 5.9172e-01, PNorm = 43.8951, GNorm = 3.2813, lr_0 = 1.0250e-04
Loss = 6.3596e-01, PNorm = 43.8957, GNorm = 4.0649, lr_0 = 1.0166e-04
Validation rmse = 0.681262
Epoch 27
Loss = 5.9556e-01, PNorm = 43.9019, GNorm = 7.8646, lr_0 = 1.0000e-04
Loss = 5.1087e-01, PNorm = 43.9026, GNorm = 4.8559, lr_0 = 1.0000e-04
Validation rmse = 0.678911
Epoch 28
Loss = 5.8361e-01, PNorm = 43.9095, GNorm = 7.9862, lr_0 = 1.0000e-04
Validation rmse = 0.680001
Epoch 29
Loss = 6.0271e-01, PNorm = 43.9145, GNorm = 3.3829, lr_0 = 1.0000e-04
Validation rmse = 0.679245
Model 0 best validation rmse = 0.677250 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.727999
Ensemble test rmse = 0.727999
1-fold cross validation
	Seed 0 ==> test rmse = 0.727999
Overall test rmse = 0.727999 +/- 0.000000
Elapsed time = 0:01:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 2.0079e+00, PNorm = 43.2601, GNorm = 1.4466, lr_0 = 5.5000e-04
Validation rmse = 1.382277
Epoch 1
Loss = 1.4687e+00, PNorm = 43.2689, GNorm = 1.4164, lr_0 = 1.0000e-03
Validation rmse = 1.412030
Epoch 2
Loss = 1.3744e+00, PNorm = 43.2907, GNorm = 2.7093, lr_0 = 9.2106e-04
Validation rmse = 1.302601
Epoch 3
Loss = 1.2930e+00, PNorm = 43.3176, GNorm = 0.7050, lr_0 = 8.4834e-04
Validation rmse = 1.194265
Epoch 4
Loss = 1.2000e+00, PNorm = 43.3555, GNorm = 0.5921, lr_0 = 7.8137e-04
Validation rmse = 1.089576
Epoch 5
Loss = 1.1831e+00, PNorm = 43.3982, GNorm = 2.4868, lr_0 = 7.1969e-04
Validation rmse = 1.024154
Epoch 6
Loss = 1.0951e+00, PNorm = 43.4390, GNorm = 1.6825, lr_0 = 6.6784e-04
Validation rmse = 0.953794
Epoch 7
Loss = 1.0950e+00, PNorm = 43.4906, GNorm = 2.7269, lr_0 = 6.1512e-04
Validation rmse = 0.916887
Epoch 8
Loss = 9.2155e-01, PNorm = 43.5426, GNorm = 2.8719, lr_0 = 5.6656e-04
Loss = 9.3901e-01, PNorm = 43.5792, GNorm = 4.9833, lr_0 = 5.2575e-04
Loss = 6.6924e-01, PNorm = 43.5828, GNorm = 4.2454, lr_0 = 5.2183e-04
Validation rmse = 0.819669
Epoch 9
Loss = 8.7812e-01, PNorm = 43.6172, GNorm = 1.8689, lr_0 = 4.8424e-04
Validation rmse = 0.783596
Epoch 10
Loss = 8.1789e-01, PNorm = 43.6530, GNorm = 2.2879, lr_0 = 4.4602e-04
Validation rmse = 0.785656
Epoch 11
Loss = 8.0354e-01, PNorm = 43.6825, GNorm = 8.3136, lr_0 = 4.1389e-04
Validation rmse = 0.733187
Epoch 12
Loss = 7.6080e-01, PNorm = 43.7057, GNorm = 2.8225, lr_0 = 3.8121e-04
Validation rmse = 0.814996
Epoch 13
Loss = 8.2610e-01, PNorm = 43.7258, GNorm = 12.3685, lr_0 = 3.5112e-04
Validation rmse = 0.797427
Epoch 14
Loss = 7.4064e-01, PNorm = 43.7457, GNorm = 2.9558, lr_0 = 3.2340e-04
Validation rmse = 0.753498
Epoch 15
Loss = 7.0322e-01, PNorm = 43.7668, GNorm = 10.8418, lr_0 = 2.9787e-04
Validation rmse = 0.714385
Epoch 16
Loss = 6.4835e-01, PNorm = 43.7850, GNorm = 2.8439, lr_0 = 2.7641e-04
Loss = 7.2948e-01, PNorm = 43.7971, GNorm = 7.2109, lr_0 = 2.5650e-04
Loss = 4.8135e-01, PNorm = 43.7987, GNorm = 2.7190, lr_0 = 2.5459e-04
Validation rmse = 0.766507
Epoch 17
Loss = 6.8308e-01, PNorm = 43.8126, GNorm = 8.1872, lr_0 = 2.3625e-04
Validation rmse = 0.718502
Epoch 18
Loss = 6.4535e-01, PNorm = 43.8253, GNorm = 6.0365, lr_0 = 2.1760e-04
Validation rmse = 0.708158
Epoch 19
Loss = 6.6089e-01, PNorm = 43.8370, GNorm = 7.3573, lr_0 = 2.0042e-04
Validation rmse = 0.697509
Epoch 20
Loss = 6.5061e-01, PNorm = 43.8497, GNorm = 2.0558, lr_0 = 1.8460e-04
Validation rmse = 0.707608
Epoch 21
Loss = 6.5777e-01, PNorm = 43.8600, GNorm = 7.9487, lr_0 = 1.7003e-04
Validation rmse = 0.694671
Epoch 22
Loss = 6.0973e-01, PNorm = 43.8689, GNorm = 4.0244, lr_0 = 1.5778e-04
Validation rmse = 0.701014
Epoch 23
Loss = 6.2856e-01, PNorm = 43.8773, GNorm = 3.1274, lr_0 = 1.4532e-04
Validation rmse = 0.705681
Epoch 24
Loss = 5.7691e-01, PNorm = 43.8850, GNorm = 4.1076, lr_0 = 1.3385e-04
Validation rmse = 0.690475
Epoch 25
Loss = 5.8506e-01, PNorm = 43.8929, GNorm = 2.8257, lr_0 = 1.2328e-04
Loss = 6.0934e-01, PNorm = 43.8990, GNorm = 6.1243, lr_0 = 1.1440e-04
Loss = 4.6138e-01, PNorm = 43.8996, GNorm = 9.6213, lr_0 = 1.1355e-04
Validation rmse = 0.700904
Epoch 26
Loss = 5.7363e-01, PNorm = 43.9049, GNorm = 6.1217, lr_0 = 1.0537e-04
Validation rmse = 0.690260
Epoch 27
Loss = 5.8228e-01, PNorm = 43.9100, GNorm = 3.6265, lr_0 = 1.0000e-04
Validation rmse = 0.687795
Epoch 28
Loss = 5.7729e-01, PNorm = 43.9152, GNorm = 4.9052, lr_0 = 1.0000e-04
Validation rmse = 0.681510
Epoch 29
Loss = 5.3452e-01, PNorm = 43.9210, GNorm = 3.5160, lr_0 = 1.0000e-04
Validation rmse = 0.687245
Model 0 best validation rmse = 0.681510 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.692127
Ensemble test rmse = 0.692127
1-fold cross validation
	Seed 0 ==> test rmse = 0.692127
Overall test rmse = 0.692127 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-bf03a4a3-2c6a-42b5-a688-408252238029.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8576e+00, PNorm = 43.2620, GNorm = 2.5112, lr_0 = 5.5000e-04
Validation rmse = 1.360544
Epoch 1
Loss = 1.4471e+00, PNorm = 43.2735, GNorm = 1.2475, lr_0 = 1.0000e-03
Validation rmse = 1.329308
Epoch 2
Loss = 1.3484e+00, PNorm = 43.2970, GNorm = 0.6477, lr_0 = 9.2797e-04
Validation rmse = 1.248842
Epoch 3
Loss = 1.2705e+00, PNorm = 43.3235, GNorm = 0.9054, lr_0 = 8.6112e-04
Validation rmse = 1.132471
Epoch 4
Loss = 1.2331e+00, PNorm = 43.3563, GNorm = 2.1771, lr_0 = 7.9909e-04
Validation rmse = 1.058465
Epoch 5
Loss = 1.1628e+00, PNorm = 43.3926, GNorm = 0.7977, lr_0 = 7.4153e-04
Loss = 1.1113e+00, PNorm = 43.4346, GNorm = 1.5630, lr_0 = 6.8812e-04
Validation rmse = 0.986688
Epoch 6
Loss = 1.0685e+00, PNorm = 43.4843, GNorm = 1.5475, lr_0 = 6.3855e-04
Validation rmse = 0.914670
Epoch 7
Loss = 9.6569e-01, PNorm = 43.5272, GNorm = 1.6873, lr_0 = 5.9255e-04
Validation rmse = 0.831667
Epoch 8
Loss = 9.6846e-01, PNorm = 43.5754, GNorm = 6.3617, lr_0 = 5.4987e-04
Validation rmse = 0.818710
Epoch 9
Loss = 8.8798e-01, PNorm = 43.6144, GNorm = 8.6316, lr_0 = 5.1026e-04
Validation rmse = 0.784237
Epoch 10
Loss = 8.2562e-01, PNorm = 43.6504, GNorm = 1.8995, lr_0 = 4.7351e-04
Loss = 8.0685e-01, PNorm = 43.6862, GNorm = 3.3101, lr_0 = 4.3940e-04
Validation rmse = 0.744148
Epoch 11
Loss = 7.6612e-01, PNorm = 43.7165, GNorm = 1.5769, lr_0 = 4.0775e-04
Validation rmse = 0.742134
Epoch 12
Loss = 7.2659e-01, PNorm = 43.7445, GNorm = 1.9904, lr_0 = 3.7837e-04
Validation rmse = 0.711203
Epoch 13
Loss = 7.3446e-01, PNorm = 43.7674, GNorm = 1.8147, lr_0 = 3.5112e-04
Validation rmse = 0.702995
Epoch 14
Loss = 6.7941e-01, PNorm = 43.7904, GNorm = 1.9326, lr_0 = 3.2583e-04
Validation rmse = 0.721445
Epoch 15
Loss = 7.1229e-01, PNorm = 43.8098, GNorm = 8.4495, lr_0 = 3.0236e-04
Loss = 6.5388e-01, PNorm = 43.8302, GNorm = 4.8958, lr_0 = 2.8058e-04
Validation rmse = 0.694981
Epoch 16
Loss = 6.5126e-01, PNorm = 43.8464, GNorm = 7.5031, lr_0 = 2.6037e-04
Validation rmse = 0.694639
Epoch 17
Loss = 6.4967e-01, PNorm = 43.8605, GNorm = 6.7997, lr_0 = 2.4161e-04
Validation rmse = 0.686448
Epoch 18
Loss = 5.9262e-01, PNorm = 43.8742, GNorm = 2.8118, lr_0 = 2.2421e-04
Validation rmse = 0.677034
Epoch 19
Loss = 5.6374e-01, PNorm = 43.8872, GNorm = 5.9809, lr_0 = 2.0806e-04
Validation rmse = 0.677864
Epoch 20
Loss = 6.0455e-01, PNorm = 43.8989, GNorm = 3.0337, lr_0 = 1.9307e-04
Loss = 6.0589e-01, PNorm = 43.9097, GNorm = 3.8419, lr_0 = 1.7916e-04
Validation rmse = 0.677008
Epoch 21
Loss = 5.8646e-01, PNorm = 43.9181, GNorm = 4.5999, lr_0 = 1.6626e-04
Validation rmse = 0.678950
Epoch 22
Loss = 5.3102e-01, PNorm = 43.9288, GNorm = 6.4963, lr_0 = 1.5428e-04
Validation rmse = 0.664854
Epoch 23
Loss = 4.9995e-01, PNorm = 43.9385, GNorm = 2.0100, lr_0 = 1.4317e-04
Validation rmse = 0.668533
Epoch 24
Loss = 5.3633e-01, PNorm = 43.9460, GNorm = 13.7738, lr_0 = 1.3285e-04
Validation rmse = 0.682446
Epoch 25
Loss = 6.1464e-01, PNorm = 43.9529, GNorm = 11.7561, lr_0 = 1.2328e-04
Loss = 5.7202e-01, PNorm = 43.9586, GNorm = 4.4206, lr_0 = 1.1440e-04
Validation rmse = 0.696322
Epoch 26
Loss = 5.8170e-01, PNorm = 43.9636, GNorm = 13.9424, lr_0 = 1.0616e-04
Validation rmse = 0.658772
Epoch 27
Loss = 5.3215e-01, PNorm = 43.9697, GNorm = 2.4345, lr_0 = 1.0000e-04
Validation rmse = 0.665204
Epoch 28
Loss = 5.5184e-01, PNorm = 43.9755, GNorm = 6.9743, lr_0 = 1.0000e-04
Validation rmse = 0.660839
Epoch 29
Loss = 5.2358e-01, PNorm = 43.9814, GNorm = 6.9795, lr_0 = 1.0000e-04
Validation rmse = 0.655084
Model 0 best validation rmse = 0.655084 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.667669
Ensemble test rmse = 0.667669
1-fold cross validation
	Seed 0 ==> test rmse = 0.667669
Overall test rmse = 0.667669 +/- 0.000000
Elapsed time = 0:02:03
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 10,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pre_train_data.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 2,502 | train size = 2,001 | val size = 250 | test size = 251
Fitting scaler
Building model 0
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6347e+00, PNorm = 34.0559, GNorm = 2.8431, lr_0 = 1.2475e-04
Loss = 1.1698e+00, PNorm = 34.0561, GNorm = 5.2993, lr_0 = 1.4725e-04
Loss = 1.2769e+00, PNorm = 34.0559, GNorm = 2.7461, lr_0 = 1.6975e-04
Loss = 1.6393e+00, PNorm = 34.0562, GNorm = 1.8636, lr_0 = 1.9225e-04
Loss = 1.6271e+00, PNorm = 34.0578, GNorm = 2.1114, lr_0 = 2.1475e-04
Loss = 1.4332e+00, PNorm = 34.0597, GNorm = 2.6145, lr_0 = 2.3725e-04
Loss = 1.5550e+00, PNorm = 34.0623, GNorm = 2.0605, lr_0 = 2.5975e-04
Loss = 1.4275e+00, PNorm = 34.0655, GNorm = 5.8239, lr_0 = 2.8225e-04
Loss = 1.4532e+00, PNorm = 34.0705, GNorm = 3.9871, lr_0 = 3.0475e-04
Loss = 1.4488e+00, PNorm = 34.0770, GNorm = 2.0192, lr_0 = 3.2725e-04
Loss = 1.1913e+00, PNorm = 34.0841, GNorm = 1.2117, lr_0 = 3.4975e-04
Loss = 1.4935e+00, PNorm = 34.0956, GNorm = 6.5480, lr_0 = 3.7225e-04
Loss = 1.3781e+00, PNorm = 34.1090, GNorm = 0.8827, lr_0 = 3.9475e-04
Loss = 1.2924e+00, PNorm = 34.1167, GNorm = 4.5561, lr_0 = 4.1725e-04
Loss = 1.2141e+00, PNorm = 34.1218, GNorm = 2.5106, lr_0 = 4.3975e-04
Loss = 1.3994e+00, PNorm = 34.1336, GNorm = 1.0422, lr_0 = 4.6225e-04
Loss = 1.4202e+00, PNorm = 34.1526, GNorm = 3.1622, lr_0 = 4.8475e-04
Loss = 1.2899e+00, PNorm = 34.1747, GNorm = 6.9018, lr_0 = 5.0725e-04
Loss = 1.3127e+00, PNorm = 34.1897, GNorm = 1.2020, lr_0 = 5.2975e-04
Loss = 1.0932e+00, PNorm = 34.2106, GNorm = 2.9899, lr_0 = 5.5225e-04
Loss = 6.5315e-01, PNorm = 34.2123, GNorm = 2.8897, lr_0 = 5.5450e-04
Validation rmse = 1.205700
Epoch 1
Loss = 1.1233e+00, PNorm = 34.2220, GNorm = 0.7545, lr_0 = 5.7700e-04
Loss = 1.3940e+00, PNorm = 34.2377, GNorm = 3.1759, lr_0 = 5.9950e-04
Loss = 1.1714e+00, PNorm = 34.2567, GNorm = 4.8757, lr_0 = 6.2200e-04
Loss = 1.1744e+00, PNorm = 34.2718, GNorm = 1.1083, lr_0 = 6.4450e-04
Loss = 1.2738e+00, PNorm = 34.2821, GNorm = 3.2697, lr_0 = 6.6700e-04
Loss = 1.2088e+00, PNorm = 34.2981, GNorm = 2.7514, lr_0 = 6.8950e-04
Loss = 1.1800e+00, PNorm = 34.3186, GNorm = 2.1185, lr_0 = 7.1200e-04
Loss = 1.2587e+00, PNorm = 34.3382, GNorm = 3.6923, lr_0 = 7.3450e-04
Loss = 1.1864e+00, PNorm = 34.3622, GNorm = 1.3557, lr_0 = 7.5700e-04
Loss = 1.2714e+00, PNorm = 34.3998, GNorm = 1.1796, lr_0 = 7.7950e-04
Loss = 1.1613e+00, PNorm = 34.4306, GNorm = 1.5791, lr_0 = 8.0200e-04
Loss = 1.2060e+00, PNorm = 34.4564, GNorm = 2.1972, lr_0 = 8.2450e-04
Loss = 1.3323e+00, PNorm = 34.4989, GNorm = 1.9296, lr_0 = 8.4700e-04
Loss = 1.4333e+00, PNorm = 34.5343, GNorm = 2.6907, lr_0 = 8.6950e-04
Loss = 1.2095e+00, PNorm = 34.5896, GNorm = 1.0119, lr_0 = 8.9200e-04
Loss = 1.2704e+00, PNorm = 34.6308, GNorm = 1.3006, lr_0 = 9.1450e-04
Loss = 1.2621e+00, PNorm = 34.6635, GNorm = 1.0618, lr_0 = 9.3700e-04
Loss = 1.1790e+00, PNorm = 34.6919, GNorm = 1.1444, lr_0 = 9.5950e-04
Loss = 1.1642e+00, PNorm = 34.7203, GNorm = 1.4376, lr_0 = 9.8200e-04
Loss = 1.2049e+00, PNorm = 34.7567, GNorm = 0.9322, lr_0 = 9.9918e-04
Loss = 4.2625e+00, PNorm = 34.7602, GNorm = 24.0049, lr_0 = 9.9877e-04
Validation rmse = 1.200871
Epoch 2
Loss = 1.5549e+00, PNorm = 34.8259, GNorm = 0.4801, lr_0 = 9.9467e-04
Loss = 1.2806e+00, PNorm = 34.9088, GNorm = 0.9897, lr_0 = 9.9059e-04
Loss = 1.1108e+00, PNorm = 34.9750, GNorm = 2.4462, lr_0 = 9.8652e-04
Loss = 1.3490e+00, PNorm = 35.0107, GNorm = 0.6351, lr_0 = 9.8247e-04
Loss = 1.2251e+00, PNorm = 35.0492, GNorm = 0.5067, lr_0 = 9.7844e-04
Loss = 1.1998e+00, PNorm = 35.0859, GNorm = 0.7817, lr_0 = 9.7443e-04
Loss = 1.0442e+00, PNorm = 35.1153, GNorm = 1.2556, lr_0 = 9.7043e-04
Loss = 1.3096e+00, PNorm = 35.1251, GNorm = 0.7008, lr_0 = 9.6645e-04
Loss = 1.1536e+00, PNorm = 35.1329, GNorm = 0.7752, lr_0 = 9.6248e-04
Loss = 1.1595e+00, PNorm = 35.1551, GNorm = 1.0584, lr_0 = 9.5853e-04
Loss = 1.2378e+00, PNorm = 35.1820, GNorm = 1.8399, lr_0 = 9.5460e-04
Loss = 1.1569e+00, PNorm = 35.1963, GNorm = 0.6997, lr_0 = 9.5068e-04
Loss = 1.2293e+00, PNorm = 35.2150, GNorm = 0.4861, lr_0 = 9.4678e-04
Loss = 1.1575e+00, PNorm = 35.2453, GNorm = 0.5297, lr_0 = 9.4290e-04
Loss = 1.1896e+00, PNorm = 35.2721, GNorm = 1.0450, lr_0 = 9.3903e-04
Loss = 1.3150e+00, PNorm = 35.2988, GNorm = 0.8081, lr_0 = 9.3517e-04
Loss = 1.0947e+00, PNorm = 35.3220, GNorm = 0.5812, lr_0 = 9.3134e-04
Loss = 1.2053e+00, PNorm = 35.3505, GNorm = 0.5412, lr_0 = 9.2752e-04
Loss = 1.0875e+00, PNorm = 35.3774, GNorm = 1.2517, lr_0 = 9.2371e-04
Loss = 1.1006e+00, PNorm = 35.4145, GNorm = 1.7576, lr_0 = 9.1992e-04
Loss = 5.4923e-01, PNorm = 35.4178, GNorm = 1.3994, lr_0 = 9.1954e-04
Validation rmse = 1.093777
Epoch 3
Loss = 1.1799e+00, PNorm = 35.4394, GNorm = 0.6348, lr_0 = 9.1577e-04
Loss = 1.1050e+00, PNorm = 35.4787, GNorm = 1.7918, lr_0 = 9.1201e-04
Loss = 1.2256e+00, PNorm = 35.5093, GNorm = 0.8986, lr_0 = 9.0827e-04
Loss = 1.0695e+00, PNorm = 35.5328, GNorm = 1.7486, lr_0 = 9.0454e-04
Loss = 1.0685e+00, PNorm = 35.5527, GNorm = 0.4551, lr_0 = 9.0083e-04
Loss = 1.0901e+00, PNorm = 35.5924, GNorm = 1.2925, lr_0 = 8.9713e-04
Loss = 1.1491e+00, PNorm = 35.6259, GNorm = 0.6195, lr_0 = 8.9345e-04
Loss = 1.1308e+00, PNorm = 35.6657, GNorm = 4.3091, lr_0 = 8.8979e-04
Loss = 1.2314e+00, PNorm = 35.6910, GNorm = 1.0034, lr_0 = 8.8614e-04
Loss = 1.0835e+00, PNorm = 35.7363, GNorm = 2.5506, lr_0 = 8.8250e-04
Loss = 1.1183e+00, PNorm = 35.7738, GNorm = 1.2967, lr_0 = 8.7888e-04
Loss = 1.1619e+00, PNorm = 35.8148, GNorm = 1.4880, lr_0 = 8.7527e-04
Loss = 1.2172e+00, PNorm = 35.8450, GNorm = 1.1560, lr_0 = 8.7168e-04
Loss = 1.1858e+00, PNorm = 35.8648, GNorm = 0.8127, lr_0 = 8.6810e-04
Loss = 1.2246e+00, PNorm = 35.8860, GNorm = 1.2957, lr_0 = 8.6454e-04
Loss = 1.2182e+00, PNorm = 35.9131, GNorm = 1.3092, lr_0 = 8.6099e-04
Loss = 1.0488e+00, PNorm = 35.9352, GNorm = 1.2857, lr_0 = 8.5746e-04
Loss = 9.3691e-01, PNorm = 35.9691, GNorm = 1.5438, lr_0 = 8.5394e-04
Loss = 1.0524e+00, PNorm = 35.9972, GNorm = 1.0274, lr_0 = 8.5044e-04
Loss = 1.0700e+00, PNorm = 36.0220, GNorm = 2.1446, lr_0 = 8.4695e-04
Loss = 5.6199e-01, PNorm = 36.0252, GNorm = 1.8250, lr_0 = 8.4660e-04
Validation rmse = 1.059264
Epoch 4
Loss = 1.0125e+00, PNorm = 36.0518, GNorm = 1.2170, lr_0 = 8.4313e-04
Loss = 1.1592e+00, PNorm = 36.0847, GNorm = 0.9195, lr_0 = 8.3967e-04
Loss = 1.1456e+00, PNorm = 36.1356, GNorm = 0.6700, lr_0 = 8.3622e-04
Loss = 1.1750e+00, PNorm = 36.1771, GNorm = 1.2631, lr_0 = 8.3279e-04
Loss = 1.1650e+00, PNorm = 36.2168, GNorm = 0.7041, lr_0 = 8.2937e-04
Loss = 1.0782e+00, PNorm = 36.2520, GNorm = 3.0256, lr_0 = 8.2597e-04
Loss = 1.0778e+00, PNorm = 36.2911, GNorm = 1.7542, lr_0 = 8.2258e-04
Loss = 1.0823e+00, PNorm = 36.3215, GNorm = 1.0046, lr_0 = 8.1921e-04
Loss = 1.0962e+00, PNorm = 36.3697, GNorm = 2.1797, lr_0 = 8.1584e-04
Loss = 1.0696e+00, PNorm = 36.3913, GNorm = 1.7428, lr_0 = 8.1250e-04
Loss = 1.0859e+00, PNorm = 36.4179, GNorm = 0.8338, lr_0 = 8.0916e-04
Loss = 9.9972e-01, PNorm = 36.4474, GNorm = 1.1769, lr_0 = 8.0584e-04
Loss = 1.2951e+00, PNorm = 36.4815, GNorm = 2.6288, lr_0 = 8.0254e-04
Loss = 1.0722e+00, PNorm = 36.5116, GNorm = 1.2539, lr_0 = 7.9924e-04
Loss = 9.9832e-01, PNorm = 36.5578, GNorm = 1.5943, lr_0 = 7.9596e-04
Loss = 1.1667e+00, PNorm = 36.5808, GNorm = 3.7486, lr_0 = 7.9270e-04
Loss = 1.0580e+00, PNorm = 36.6105, GNorm = 1.1272, lr_0 = 7.8944e-04
Loss = 1.0172e+00, PNorm = 36.6357, GNorm = 1.4028, lr_0 = 7.8620e-04
Loss = 1.0190e+00, PNorm = 36.6568, GNorm = 1.5111, lr_0 = 7.8298e-04
Loss = 1.0471e+00, PNorm = 36.6821, GNorm = 2.1347, lr_0 = 7.7977e-04
Loss = 4.7257e-01, PNorm = 36.6854, GNorm = 2.1992, lr_0 = 7.7945e-04
Validation rmse = 1.002948
Epoch 5
Loss = 1.0262e+00, PNorm = 36.7343, GNorm = 0.9809, lr_0 = 7.7625e-04
Loss = 9.8939e-01, PNorm = 36.7533, GNorm = 1.1325, lr_0 = 7.7306e-04
Loss = 1.0325e+00, PNorm = 36.7852, GNorm = 1.8311, lr_0 = 7.6989e-04
Loss = 1.0725e+00, PNorm = 36.8264, GNorm = 0.8185, lr_0 = 7.6673e-04
Loss = 1.0867e+00, PNorm = 36.8660, GNorm = 3.7932, lr_0 = 7.6358e-04
Loss = 9.8154e-01, PNorm = 36.8973, GNorm = 1.7384, lr_0 = 7.6045e-04
Loss = 1.1454e+00, PNorm = 36.9293, GNorm = 1.7403, lr_0 = 7.5733e-04
Loss = 1.0231e+00, PNorm = 36.9617, GNorm = 1.2606, lr_0 = 7.5422e-04
Loss = 1.0855e+00, PNorm = 36.9935, GNorm = 2.5629, lr_0 = 7.5113e-04
Loss = 9.3376e-01, PNorm = 37.0241, GNorm = 1.0299, lr_0 = 7.4805e-04
Loss = 1.2125e+00, PNorm = 37.0533, GNorm = 2.8194, lr_0 = 7.4498e-04
Loss = 9.6466e-01, PNorm = 37.0898, GNorm = 1.4666, lr_0 = 7.4192e-04
Loss = 1.0646e+00, PNorm = 37.1183, GNorm = 0.8136, lr_0 = 7.3888e-04
Loss = 1.1746e+00, PNorm = 37.1512, GNorm = 3.4335, lr_0 = 7.3584e-04
Loss = 1.0423e+00, PNorm = 37.1759, GNorm = 1.3243, lr_0 = 7.3282e-04
Loss = 9.8894e-01, PNorm = 37.2037, GNorm = 1.8247, lr_0 = 7.2982e-04
Loss = 9.5256e-01, PNorm = 37.2118, GNorm = 1.2163, lr_0 = 7.2682e-04
Loss = 1.0485e+00, PNorm = 37.2301, GNorm = 2.3670, lr_0 = 7.2384e-04
Loss = 9.9941e-01, PNorm = 37.2700, GNorm = 2.5442, lr_0 = 7.2087e-04
Loss = 1.1703e+00, PNorm = 37.3121, GNorm = 0.7165, lr_0 = 7.1791e-04
Loss = 8.1571e-01, PNorm = 37.3149, GNorm = 4.8682, lr_0 = 7.1762e-04
Validation rmse = 0.994472
Epoch 6
Loss = 9.7743e-01, PNorm = 37.3446, GNorm = 1.9172, lr_0 = 7.1467e-04
Loss = 3.8619e+00, PNorm = 37.4330, GNorm = 2.6339, lr_0 = 7.1174e-04
Loss = 1.1617e+00, PNorm = 37.5834, GNorm = 0.6261, lr_0 = 7.0882e-04
Loss = 1.2600e+00, PNorm = 37.6703, GNorm = 2.2277, lr_0 = 7.0591e-04
Loss = 1.1874e+00, PNorm = 37.7230, GNorm = 3.1930, lr_0 = 7.0301e-04
Loss = 1.1593e+00, PNorm = 37.7541, GNorm = 1.4406, lr_0 = 7.0013e-04
Loss = 1.1286e+00, PNorm = 37.7801, GNorm = 2.4563, lr_0 = 6.9726e-04
Loss = 1.1765e+00, PNorm = 37.8066, GNorm = 2.0710, lr_0 = 6.9440e-04
Loss = 1.0930e+00, PNorm = 37.8276, GNorm = 3.0289, lr_0 = 6.9155e-04
Loss = 1.1369e+00, PNorm = 37.8458, GNorm = 1.0734, lr_0 = 6.8871e-04
Loss = 1.1440e+00, PNorm = 37.8617, GNorm = 2.0313, lr_0 = 6.8588e-04
Loss = 1.0940e+00, PNorm = 37.8780, GNorm = 1.5319, lr_0 = 6.8307e-04
Loss = 1.1323e+00, PNorm = 37.8950, GNorm = 1.4130, lr_0 = 6.8027e-04
Loss = 1.1153e+00, PNorm = 37.9137, GNorm = 1.0953, lr_0 = 6.7747e-04
Loss = 1.0029e+00, PNorm = 37.9340, GNorm = 1.6814, lr_0 = 6.7469e-04
Loss = 9.7260e-01, PNorm = 37.9574, GNorm = 2.4295, lr_0 = 6.7193e-04
Loss = 1.1520e+00, PNorm = 37.9746, GNorm = 2.8348, lr_0 = 6.6917e-04
Loss = 1.1373e+00, PNorm = 37.9856, GNorm = 1.0134, lr_0 = 6.6642e-04
Loss = 9.9007e-01, PNorm = 38.0077, GNorm = 1.1870, lr_0 = 6.6369e-04
Loss = 1.0550e+00, PNorm = 38.0296, GNorm = 2.0405, lr_0 = 6.6097e-04
Loss = 6.1194e-01, PNorm = 38.0323, GNorm = 4.5056, lr_0 = 6.6069e-04
Validation rmse = 1.027169
Epoch 7
Loss = 1.1152e+00, PNorm = 38.0561, GNorm = 2.7350, lr_0 = 6.5798e-04
Loss = 1.1314e+00, PNorm = 38.0819, GNorm = 0.9570, lr_0 = 6.5528e-04
Loss = 9.9462e-01, PNorm = 38.1086, GNorm = 1.4470, lr_0 = 6.5259e-04
Loss = 1.0907e+00, PNorm = 38.1261, GNorm = 3.2832, lr_0 = 6.4992e-04
Loss = 1.0569e+00, PNorm = 38.1445, GNorm = 1.7976, lr_0 = 6.4725e-04
Loss = 1.0473e+00, PNorm = 38.1659, GNorm = 1.5994, lr_0 = 6.4459e-04
Loss = 1.1025e+00, PNorm = 38.2022, GNorm = 3.0627, lr_0 = 6.4195e-04
Loss = 9.4982e-01, PNorm = 38.2380, GNorm = 1.6995, lr_0 = 6.3931e-04
Loss = 9.3099e-01, PNorm = 38.2666, GNorm = 4.3221, lr_0 = 6.3669e-04
Loss = 9.6181e-01, PNorm = 38.2858, GNorm = 1.2438, lr_0 = 6.3408e-04
Loss = 1.0129e+00, PNorm = 38.3218, GNorm = 3.0403, lr_0 = 6.3148e-04
Loss = 1.0158e+00, PNorm = 38.3491, GNorm = 1.6380, lr_0 = 6.2889e-04
Loss = 1.0938e+00, PNorm = 38.3719, GNorm = 3.2595, lr_0 = 6.2630e-04
Loss = 1.0944e+00, PNorm = 38.3944, GNorm = 2.0082, lr_0 = 6.2373e-04
Loss = 1.0318e+00, PNorm = 38.4218, GNorm = 2.8933, lr_0 = 6.2118e-04
Loss = 1.0457e+00, PNorm = 38.4455, GNorm = 1.2236, lr_0 = 6.1863e-04
Loss = 9.9095e-01, PNorm = 38.4695, GNorm = 2.4650, lr_0 = 6.1609e-04
Loss = 1.0047e+00, PNorm = 38.4933, GNorm = 2.4709, lr_0 = 6.1356e-04
Loss = 1.1285e+00, PNorm = 38.5205, GNorm = 1.9618, lr_0 = 6.1104e-04
Loss = 1.0654e+00, PNorm = 38.5426, GNorm = 1.9157, lr_0 = 6.0854e-04
Loss = 8.8037e-01, PNorm = 38.5440, GNorm = 4.7993, lr_0 = 6.0829e-04
Validation rmse = 0.942961
Epoch 8
Loss = 1.0928e+00, PNorm = 38.5649, GNorm = 1.5415, lr_0 = 6.0579e-04
Loss = 1.0325e+00, PNorm = 38.5951, GNorm = 1.5919, lr_0 = 6.0330e-04
Loss = 1.0375e+00, PNorm = 38.6179, GNorm = 2.1076, lr_0 = 6.0083e-04
Loss = 9.6237e-01, PNorm = 38.6441, GNorm = 1.3737, lr_0 = 5.9836e-04
Loss = 9.0669e-01, PNorm = 38.6677, GNorm = 2.0162, lr_0 = 5.9591e-04
Loss = 1.0152e+00, PNorm = 38.6852, GNorm = 5.4692, lr_0 = 5.9346e-04
Loss = 8.0337e-01, PNorm = 38.7062, GNorm = 2.2866, lr_0 = 5.9103e-04
Loss = 1.0031e+00, PNorm = 38.7392, GNorm = 10.9005, lr_0 = 5.8860e-04
Loss = 1.1637e+00, PNorm = 38.7681, GNorm = 1.4257, lr_0 = 5.8619e-04
Loss = 9.5066e-01, PNorm = 38.7956, GNorm = 1.4813, lr_0 = 5.8378e-04
Loss = 1.1400e+00, PNorm = 38.8092, GNorm = 2.4792, lr_0 = 5.8139e-04
Loss = 1.0319e+00, PNorm = 38.8157, GNorm = 1.7520, lr_0 = 5.7900e-04
Loss = 1.0796e+00, PNorm = 38.8251, GNorm = 0.9193, lr_0 = 5.7662e-04
Loss = 1.0615e+00, PNorm = 38.8475, GNorm = 3.7317, lr_0 = 5.7426e-04
Loss = 9.1284e-01, PNorm = 38.8612, GNorm = 2.4587, lr_0 = 5.7190e-04
Loss = 9.3357e-01, PNorm = 38.8835, GNorm = 6.2011, lr_0 = 5.6956e-04
Loss = 8.3059e-01, PNorm = 38.9038, GNorm = 3.0835, lr_0 = 5.6722e-04
Loss = 8.6080e-01, PNorm = 38.9277, GNorm = 2.8972, lr_0 = 5.6489e-04
Loss = 1.0154e+00, PNorm = 38.9481, GNorm = 2.8690, lr_0 = 5.6257e-04
Loss = 1.0611e+00, PNorm = 38.9642, GNorm = 2.4517, lr_0 = 5.6026e-04
Loss = 1.9768e+00, PNorm = 38.9674, GNorm = 4.2308, lr_0 = 5.6003e-04
Validation rmse = 0.898427
Epoch 9
Loss = 9.5494e-01, PNorm = 38.9951, GNorm = 2.9947, lr_0 = 5.5774e-04
Loss = 8.6404e-01, PNorm = 39.0220, GNorm = 2.5591, lr_0 = 5.5545e-04
Loss = 9.5902e-01, PNorm = 39.0499, GNorm = 6.3997, lr_0 = 5.5317e-04
Loss = 8.8787e-01, PNorm = 39.0634, GNorm = 2.8846, lr_0 = 5.5090e-04
Loss = 1.0479e+00, PNorm = 39.0752, GNorm = 1.7939, lr_0 = 5.4864e-04
Loss = 9.4194e-01, PNorm = 39.0905, GNorm = 1.9302, lr_0 = 5.4639e-04
Loss = 8.9904e-01, PNorm = 39.1157, GNorm = 1.7976, lr_0 = 5.4414e-04
Loss = 9.0467e-01, PNorm = 39.1387, GNorm = 3.9320, lr_0 = 5.4191e-04
Loss = 1.0078e+00, PNorm = 39.1519, GNorm = 2.3474, lr_0 = 5.3969e-04
Loss = 8.7324e-01, PNorm = 39.1696, GNorm = 3.2420, lr_0 = 5.3747e-04
Loss = 8.5440e-01, PNorm = 39.1909, GNorm = 2.6789, lr_0 = 5.3527e-04
Loss = 9.5118e-01, PNorm = 39.2043, GNorm = 3.2887, lr_0 = 5.3307e-04
Loss = 9.5655e-01, PNorm = 39.2278, GNorm = 0.9662, lr_0 = 5.3088e-04
Loss = 8.7846e-01, PNorm = 39.2455, GNorm = 3.5629, lr_0 = 5.2871e-04
Loss = 9.0851e-01, PNorm = 39.2685, GNorm = 1.3317, lr_0 = 5.2654e-04
Loss = 1.1142e+00, PNorm = 39.2866, GNorm = 2.8072, lr_0 = 5.2438e-04
Loss = 1.1235e+00, PNorm = 39.3031, GNorm = 1.8530, lr_0 = 5.2222e-04
Loss = 9.0362e-01, PNorm = 39.3199, GNorm = 2.8862, lr_0 = 5.2008e-04
Loss = 8.3152e-01, PNorm = 39.3339, GNorm = 1.0857, lr_0 = 5.1795e-04
Loss = 1.0283e+00, PNorm = 39.3477, GNorm = 2.5295, lr_0 = 5.1582e-04
Validation rmse = 0.902569
Epoch 10
Loss = 9.3198e-01, PNorm = 39.3753, GNorm = 3.1261, lr_0 = 5.1371e-04
Loss = 8.8514e-01, PNorm = 39.4005, GNorm = 3.4268, lr_0 = 5.1160e-04
Loss = 9.1015e-01, PNorm = 39.4227, GNorm = 2.5086, lr_0 = 5.0950e-04
Loss = 1.0001e+00, PNorm = 39.4339, GNorm = 2.1325, lr_0 = 5.0741e-04
Loss = 8.7245e-01, PNorm = 39.4508, GNorm = 1.4976, lr_0 = 5.0533e-04
Loss = 9.3322e-01, PNorm = 39.4673, GNorm = 1.6230, lr_0 = 5.0325e-04
Loss = 1.0377e+00, PNorm = 39.4854, GNorm = 5.0531, lr_0 = 5.0119e-04
Loss = 8.4667e-01, PNorm = 39.5032, GNorm = 2.0124, lr_0 = 4.9913e-04
Loss = 1.0327e+00, PNorm = 39.5273, GNorm = 1.6166, lr_0 = 4.9708e-04
Loss = 9.0529e-01, PNorm = 39.5476, GNorm = 2.2039, lr_0 = 4.9504e-04
Loss = 9.1453e-01, PNorm = 39.5672, GNorm = 1.3957, lr_0 = 4.9301e-04
Loss = 8.8961e-01, PNorm = 39.5968, GNorm = 3.8710, lr_0 = 4.9099e-04
Loss = 8.7387e-01, PNorm = 39.6147, GNorm = 4.2085, lr_0 = 4.8897e-04
Loss = 8.6937e-01, PNorm = 39.6180, GNorm = 5.4733, lr_0 = 4.8697e-04
Loss = 9.0593e-01, PNorm = 39.6279, GNorm = 1.2115, lr_0 = 4.8497e-04
Loss = 1.0265e+00, PNorm = 39.6410, GNorm = 2.4487, lr_0 = 4.8298e-04
Loss = 9.3969e-01, PNorm = 39.6583, GNorm = 1.4400, lr_0 = 4.8100e-04
Loss = 8.5936e-01, PNorm = 39.6777, GNorm = 2.6334, lr_0 = 4.7902e-04
Loss = 9.0169e-01, PNorm = 39.6946, GNorm = 2.5527, lr_0 = 4.7706e-04
Loss = 8.0876e-01, PNorm = 39.7156, GNorm = 3.5997, lr_0 = 4.7510e-04
Validation rmse = 0.863689
Epoch 11
Loss = 8.3073e-01, PNorm = 39.7301, GNorm = 2.1411, lr_0 = 4.7296e-04
Loss = 9.9031e-01, PNorm = 39.7448, GNorm = 2.9466, lr_0 = 4.7102e-04
Loss = 8.1481e-01, PNorm = 39.7759, GNorm = 1.7300, lr_0 = 4.6908e-04
Loss = 8.5457e-01, PNorm = 39.8017, GNorm = 6.2659, lr_0 = 4.6716e-04
Loss = 9.0277e-01, PNorm = 39.8195, GNorm = 2.4161, lr_0 = 4.6524e-04
Loss = 1.0215e+00, PNorm = 39.8361, GNorm = 2.5937, lr_0 = 4.6333e-04
Loss = 7.7112e-01, PNorm = 39.8494, GNorm = 1.2773, lr_0 = 4.6143e-04
Loss = 9.2967e-01, PNorm = 39.8655, GNorm = 1.8281, lr_0 = 4.5954e-04
Loss = 7.5383e-01, PNorm = 39.8815, GNorm = 2.7057, lr_0 = 4.5765e-04
Loss = 7.7203e-01, PNorm = 39.8986, GNorm = 1.4373, lr_0 = 4.5577e-04
Loss = 8.0573e-01, PNorm = 39.9211, GNorm = 3.0246, lr_0 = 4.5390e-04
Loss = 8.0196e-01, PNorm = 39.9409, GNorm = 3.8295, lr_0 = 4.5204e-04
Loss = 9.1817e-01, PNorm = 39.9468, GNorm = 2.6075, lr_0 = 4.5019e-04
Loss = 9.8386e-01, PNorm = 39.9581, GNorm = 2.2829, lr_0 = 4.4834e-04
Loss = 9.1820e-01, PNorm = 39.9775, GNorm = 1.8715, lr_0 = 4.4650e-04
Loss = 9.2815e-01, PNorm = 39.9924, GNorm = 4.0791, lr_0 = 4.4467e-04
Loss = 7.8743e-01, PNorm = 40.0094, GNorm = 3.8034, lr_0 = 4.4284e-04
Loss = 1.1053e+00, PNorm = 40.0303, GNorm = 1.8362, lr_0 = 4.4103e-04
Loss = 9.5010e-01, PNorm = 40.0504, GNorm = 2.6496, lr_0 = 4.3922e-04
Loss = 9.6974e-01, PNorm = 40.0668, GNorm = 2.8804, lr_0 = 4.3741e-04
Validation rmse = 0.852813
Epoch 12
Loss = 9.1063e-01, PNorm = 40.0908, GNorm = 3.0563, lr_0 = 4.3544e-04
Loss = 8.4791e-01, PNorm = 40.1125, GNorm = 1.5474, lr_0 = 4.3365e-04
Loss = 7.9927e-01, PNorm = 40.1310, GNorm = 12.3439, lr_0 = 4.3187e-04
Loss = 1.0204e+00, PNorm = 40.1430, GNorm = 1.1884, lr_0 = 4.3010e-04
Loss = 9.6411e-01, PNorm = 40.1580, GNorm = 2.0739, lr_0 = 4.2834e-04
Loss = 8.6926e-01, PNorm = 40.1701, GNorm = 5.2305, lr_0 = 4.2658e-04
Loss = 9.4329e-01, PNorm = 40.1853, GNorm = 4.5669, lr_0 = 4.2483e-04
Loss = 9.4887e-01, PNorm = 40.2030, GNorm = 4.9493, lr_0 = 4.2309e-04
Loss = 9.6051e-01, PNorm = 40.2179, GNorm = 2.9716, lr_0 = 4.2135e-04
Loss = 7.6791e-01, PNorm = 40.2316, GNorm = 2.0887, lr_0 = 4.1962e-04
Loss = 7.2253e-01, PNorm = 40.2412, GNorm = 2.4084, lr_0 = 4.1790e-04
Loss = 8.3546e-01, PNorm = 40.2617, GNorm = 2.7668, lr_0 = 4.1618e-04
Loss = 8.2550e-01, PNorm = 40.2731, GNorm = 2.3233, lr_0 = 4.1448e-04
Loss = 8.3832e-01, PNorm = 40.2881, GNorm = 2.2450, lr_0 = 4.1278e-04
Loss = 7.9650e-01, PNorm = 40.3022, GNorm = 2.2312, lr_0 = 4.1108e-04
Loss = 8.6651e-01, PNorm = 40.3095, GNorm = 2.4464, lr_0 = 4.0940e-04
Loss = 8.6157e-01, PNorm = 40.3214, GNorm = 1.4877, lr_0 = 4.0772e-04
Loss = 1.0044e+00, PNorm = 40.3331, GNorm = 2.1189, lr_0 = 4.0604e-04
Loss = 8.4865e-01, PNorm = 40.3410, GNorm = 2.7701, lr_0 = 4.0438e-04
Loss = 9.6934e-01, PNorm = 40.3510, GNorm = 5.3093, lr_0 = 4.0272e-04
Validation rmse = 0.805109
Epoch 13
Loss = 7.3981e-01, PNorm = 40.3707, GNorm = 3.8664, lr_0 = 4.0090e-04
Loss = 8.8995e-01, PNorm = 40.3887, GNorm = 1.9675, lr_0 = 3.9925e-04
Loss = 9.9387e-01, PNorm = 40.4043, GNorm = 1.7301, lr_0 = 3.9762e-04
Loss = 1.0054e+00, PNorm = 40.4133, GNorm = 2.8205, lr_0 = 3.9598e-04
Loss = 7.0908e-01, PNorm = 40.4220, GNorm = 2.5100, lr_0 = 3.9436e-04
Loss = 8.4525e-01, PNorm = 40.4375, GNorm = 3.5759, lr_0 = 3.9274e-04
Loss = 8.5999e-01, PNorm = 40.4534, GNorm = 4.0574, lr_0 = 3.9113e-04
Loss = 8.2027e-01, PNorm = 40.4635, GNorm = 4.1935, lr_0 = 3.8953e-04
Loss = 7.4723e-01, PNorm = 40.4737, GNorm = 3.7363, lr_0 = 3.8793e-04
Loss = 8.3002e-01, PNorm = 40.4899, GNorm = 4.5427, lr_0 = 3.8634e-04
Loss = 8.5990e-01, PNorm = 40.5157, GNorm = 3.8141, lr_0 = 3.8475e-04
Loss = 8.8193e-01, PNorm = 40.5306, GNorm = 1.8631, lr_0 = 3.8317e-04
Loss = 8.6162e-01, PNorm = 40.5421, GNorm = 4.4459, lr_0 = 3.8160e-04
Loss = 8.1995e-01, PNorm = 40.5539, GNorm = 1.7439, lr_0 = 3.8003e-04
Loss = 7.8417e-01, PNorm = 40.5655, GNorm = 1.7729, lr_0 = 3.7847e-04
Loss = 8.0126e-01, PNorm = 40.5773, GNorm = 2.7919, lr_0 = 3.7692e-04
Loss = 8.7073e-01, PNorm = 40.5909, GNorm = 4.3054, lr_0 = 3.7537e-04
Loss = 8.6326e-01, PNorm = 40.6019, GNorm = 5.3822, lr_0 = 3.7383e-04
Loss = 8.6010e-01, PNorm = 40.6142, GNorm = 1.9524, lr_0 = 3.7230e-04
Loss = 8.5627e-01, PNorm = 40.6276, GNorm = 1.4524, lr_0 = 3.7077e-04
Validation rmse = 0.775766
Epoch 14
Loss = 7.9601e-01, PNorm = 40.6405, GNorm = 3.6436, lr_0 = 3.6910e-04
Loss = 8.1469e-01, PNorm = 40.6557, GNorm = 3.3152, lr_0 = 3.6758e-04
Loss = 7.5772e-01, PNorm = 40.6704, GNorm = 2.6364, lr_0 = 3.6608e-04
Loss = 7.9756e-01, PNorm = 40.6829, GNorm = 3.1396, lr_0 = 3.6457e-04
Loss = 8.0051e-01, PNorm = 40.6883, GNorm = 2.1136, lr_0 = 3.6308e-04
Loss = 8.4441e-01, PNorm = 40.6978, GNorm = 2.0709, lr_0 = 3.6159e-04
Loss = 7.1378e-01, PNorm = 40.7095, GNorm = 4.2881, lr_0 = 3.6010e-04
Loss = 7.6537e-01, PNorm = 40.7232, GNorm = 2.9864, lr_0 = 3.5863e-04
Loss = 7.7239e-01, PNorm = 40.7352, GNorm = 7.2752, lr_0 = 3.5716e-04
Loss = 8.6684e-01, PNorm = 40.7430, GNorm = 2.2268, lr_0 = 3.5569e-04
Loss = 8.3373e-01, PNorm = 40.7564, GNorm = 1.9092, lr_0 = 3.5423e-04
Loss = 8.0329e-01, PNorm = 40.7679, GNorm = 3.5041, lr_0 = 3.5278e-04
Loss = 7.9890e-01, PNorm = 40.7825, GNorm = 4.6556, lr_0 = 3.5133e-04
Loss = 8.2359e-01, PNorm = 40.7943, GNorm = 2.5814, lr_0 = 3.4989e-04
Loss = 8.5398e-01, PNorm = 40.8050, GNorm = 1.8944, lr_0 = 3.4845e-04
Loss = 8.0512e-01, PNorm = 40.8148, GNorm = 1.8527, lr_0 = 3.4702e-04
Loss = 8.5004e-01, PNorm = 40.8261, GNorm = 9.2067, lr_0 = 3.4560e-04
Loss = 8.4798e-01, PNorm = 40.8420, GNorm = 13.3508, lr_0 = 3.4418e-04
Loss = 7.9868e-01, PNorm = 40.8534, GNorm = 2.2748, lr_0 = 3.4277e-04
Loss = 8.6434e-01, PNorm = 40.8603, GNorm = 2.2639, lr_0 = 3.4136e-04
Validation rmse = 0.858986
Epoch 15
Loss = 9.0302e-01, PNorm = 40.8789, GNorm = 1.9809, lr_0 = 3.3982e-04
Loss = 9.7794e-01, PNorm = 40.8945, GNorm = 1.9644, lr_0 = 3.3843e-04
Loss = 8.7624e-01, PNorm = 40.9062, GNorm = 2.9145, lr_0 = 3.3704e-04
Loss = 7.5284e-01, PNorm = 40.9225, GNorm = 3.6144, lr_0 = 3.3565e-04
Loss = 7.3380e-01, PNorm = 40.9376, GNorm = 2.2622, lr_0 = 3.3428e-04
Loss = 8.7064e-01, PNorm = 40.9468, GNorm = 2.8741, lr_0 = 3.3291e-04
Loss = 7.0552e-01, PNorm = 40.9555, GNorm = 3.5680, lr_0 = 3.3154e-04
Loss = 7.1577e-01, PNorm = 40.9668, GNorm = 2.7464, lr_0 = 3.3018e-04
Loss = 7.6677e-01, PNorm = 40.9813, GNorm = 2.5171, lr_0 = 3.2882e-04
Loss = 7.3345e-01, PNorm = 40.9903, GNorm = 3.4142, lr_0 = 3.2748e-04
Loss = 6.6900e-01, PNorm = 41.0027, GNorm = 3.4866, lr_0 = 3.2613e-04
Loss = 7.5947e-01, PNorm = 41.0156, GNorm = 2.1622, lr_0 = 3.2479e-04
Loss = 8.2251e-01, PNorm = 41.0256, GNorm = 2.2220, lr_0 = 3.2346e-04
Loss = 6.4913e-01, PNorm = 41.0386, GNorm = 3.0593, lr_0 = 3.2213e-04
Loss = 6.8070e-01, PNorm = 41.0529, GNorm = 6.2900, lr_0 = 3.2081e-04
Loss = 8.6290e-01, PNorm = 41.0625, GNorm = 3.3776, lr_0 = 3.1950e-04
Loss = 8.4078e-01, PNorm = 41.0711, GNorm = 2.5066, lr_0 = 3.1818e-04
Loss = 7.7226e-01, PNorm = 41.0832, GNorm = 2.4767, lr_0 = 3.1688e-04
Loss = 8.2424e-01, PNorm = 41.0945, GNorm = 4.1700, lr_0 = 3.1558e-04
Loss = 7.3220e-01, PNorm = 41.1044, GNorm = 2.7436, lr_0 = 3.1428e-04
Validation rmse = 0.753858
Epoch 16
Loss = 9.0274e-01, PNorm = 41.1226, GNorm = 4.6367, lr_0 = 3.1287e-04
Loss = 8.3833e-01, PNorm = 41.1322, GNorm = 2.6687, lr_0 = 3.1158e-04
Loss = 8.5357e-01, PNorm = 41.1436, GNorm = 2.4332, lr_0 = 3.1030e-04
Loss = 7.8181e-01, PNorm = 41.1589, GNorm = 2.6454, lr_0 = 3.0903e-04
Loss = 7.2541e-01, PNorm = 41.1742, GNorm = 2.3871, lr_0 = 3.0776e-04
Loss = 7.8670e-01, PNorm = 41.1900, GNorm = 1.8301, lr_0 = 3.0650e-04
Loss = 7.6915e-01, PNorm = 41.2044, GNorm = 1.9116, lr_0 = 3.0524e-04
Loss = 6.2726e-01, PNorm = 41.2162, GNorm = 3.5761, lr_0 = 3.0399e-04
Loss = 5.7203e-01, PNorm = 41.2289, GNorm = 5.6642, lr_0 = 3.0274e-04
Loss = 6.6550e-01, PNorm = 41.2382, GNorm = 6.1269, lr_0 = 3.0150e-04
Loss = 8.0716e-01, PNorm = 41.2441, GNorm = 2.6448, lr_0 = 3.0026e-04
Loss = 8.1334e-01, PNorm = 41.2504, GNorm = 1.8463, lr_0 = 2.9903e-04
Loss = 7.1571e-01, PNorm = 41.2564, GNorm = 2.3411, lr_0 = 2.9780e-04
Loss = 7.4002e-01, PNorm = 41.2647, GNorm = 5.3191, lr_0 = 2.9658e-04
Loss = 7.1265e-01, PNorm = 41.2747, GNorm = 3.9415, lr_0 = 2.9536e-04
Loss = 8.6063e-01, PNorm = 41.2772, GNorm = 3.5005, lr_0 = 2.9415e-04
Loss = 7.5390e-01, PNorm = 41.2862, GNorm = 3.0478, lr_0 = 2.9294e-04
Loss = 8.5360e-01, PNorm = 41.2999, GNorm = 2.2901, lr_0 = 2.9174e-04
Loss = 6.6393e-01, PNorm = 41.3128, GNorm = 2.6108, lr_0 = 2.9055e-04
Loss = 7.8182e-01, PNorm = 41.3268, GNorm = 2.9768, lr_0 = 2.8935e-04
Validation rmse = 0.767027
Epoch 17
Loss = 7.0822e-01, PNorm = 41.3403, GNorm = 6.1383, lr_0 = 2.8805e-04
Loss = 7.2842e-01, PNorm = 41.3445, GNorm = 5.1874, lr_0 = 2.8687e-04
Loss = 7.1163e-01, PNorm = 41.3550, GNorm = 3.0964, lr_0 = 2.8569e-04
Loss = 8.2409e-01, PNorm = 41.3638, GNorm = 5.2720, lr_0 = 2.8452e-04
Loss = 6.9109e-01, PNorm = 41.3700, GNorm = 3.0386, lr_0 = 2.8335e-04
Loss = 6.3285e-01, PNorm = 41.3790, GNorm = 8.0586, lr_0 = 2.8219e-04
Loss = 7.9159e-01, PNorm = 41.3857, GNorm = 4.2467, lr_0 = 2.8103e-04
Loss = 7.8951e-01, PNorm = 41.3891, GNorm = 3.6602, lr_0 = 2.7988e-04
Loss = 7.5092e-01, PNorm = 41.3960, GNorm = 5.1018, lr_0 = 2.7873e-04
Loss = 6.6342e-01, PNorm = 41.4041, GNorm = 2.4526, lr_0 = 2.7758e-04
Loss = 7.2001e-01, PNorm = 41.4162, GNorm = 4.8111, lr_0 = 2.7644e-04
Loss = 6.7871e-01, PNorm = 41.4264, GNorm = 5.0724, lr_0 = 2.7531e-04
Loss = 8.1990e-01, PNorm = 41.4383, GNorm = 3.9845, lr_0 = 2.7418e-04
Loss = 6.6128e-01, PNorm = 41.4477, GNorm = 3.2190, lr_0 = 2.7305e-04
Loss = 6.7829e-01, PNorm = 41.4629, GNorm = 6.5899, lr_0 = 2.7193e-04
Loss = 6.6855e-01, PNorm = 41.4765, GNorm = 4.2294, lr_0 = 2.7082e-04
Loss = 6.1149e-01, PNorm = 41.4838, GNorm = 8.3734, lr_0 = 2.6971e-04
Loss = 7.5519e-01, PNorm = 41.4874, GNorm = 2.3302, lr_0 = 2.6860e-04
Loss = 7.9794e-01, PNorm = 41.5013, GNorm = 4.7777, lr_0 = 2.6750e-04
Loss = 6.7077e-01, PNorm = 41.5159, GNorm = 4.5974, lr_0 = 2.6640e-04
Validation rmse = 0.752302
Epoch 18
Loss = 7.1424e-01, PNorm = 41.5272, GNorm = 3.7134, lr_0 = 2.6520e-04
Loss = 6.5350e-01, PNorm = 41.5332, GNorm = 4.3428, lr_0 = 2.6411e-04
Loss = 6.6580e-01, PNorm = 41.5357, GNorm = 7.0263, lr_0 = 2.6303e-04
Loss = 6.8516e-01, PNorm = 41.5468, GNorm = 7.6367, lr_0 = 2.6195e-04
Loss = 6.0219e-01, PNorm = 41.5593, GNorm = 4.6380, lr_0 = 2.6087e-04
Loss = 6.1986e-01, PNorm = 41.5690, GNorm = 11.3803, lr_0 = 2.5980e-04
Loss = 6.4346e-01, PNorm = 41.5823, GNorm = 10.0068, lr_0 = 2.5874e-04
Loss = 7.9846e-01, PNorm = 41.5934, GNorm = 3.6214, lr_0 = 2.5767e-04
Loss = 6.7668e-01, PNorm = 41.6019, GNorm = 5.1895, lr_0 = 2.5662e-04
Loss = 6.4298e-01, PNorm = 41.6094, GNorm = 2.4975, lr_0 = 2.5556e-04
Loss = 6.4964e-01, PNorm = 41.6180, GNorm = 2.7113, lr_0 = 2.5452e-04
Loss = 6.8177e-01, PNorm = 41.6276, GNorm = 2.9667, lr_0 = 2.5347e-04
Loss = 7.9078e-01, PNorm = 41.6337, GNorm = 5.4455, lr_0 = 2.5243e-04
Loss = 6.5224e-01, PNorm = 41.6429, GNorm = 4.4841, lr_0 = 2.5140e-04
Loss = 5.5523e-01, PNorm = 41.6540, GNorm = 4.3688, lr_0 = 2.5036e-04
Loss = 6.3400e-01, PNorm = 41.6631, GNorm = 3.2401, lr_0 = 2.4934e-04
Loss = 6.6704e-01, PNorm = 41.6706, GNorm = 4.1890, lr_0 = 2.4831e-04
Loss = 7.4922e-01, PNorm = 41.6769, GNorm = 5.4601, lr_0 = 2.4729e-04
Loss = 6.6064e-01, PNorm = 41.6835, GNorm = 3.5380, lr_0 = 2.4628e-04
Loss = 8.5560e-01, PNorm = 41.6916, GNorm = 1.8644, lr_0 = 2.4527e-04
Validation rmse = 0.738245
Epoch 19
Loss = 5.8320e-01, PNorm = 41.7025, GNorm = 2.3245, lr_0 = 2.4416e-04
Loss = 7.4014e-01, PNorm = 41.7130, GNorm = 3.7199, lr_0 = 2.4316e-04
Loss = 7.1911e-01, PNorm = 41.7236, GNorm = 4.0519, lr_0 = 2.4216e-04
Loss = 7.5541e-01, PNorm = 41.7325, GNorm = 4.3284, lr_0 = 2.4117e-04
Loss = 6.1478e-01, PNorm = 41.7423, GNorm = 5.4080, lr_0 = 2.4018e-04
Loss = 5.9194e-01, PNorm = 41.7449, GNorm = 4.4372, lr_0 = 2.3919e-04
Loss = 7.0364e-01, PNorm = 41.7502, GNorm = 6.2407, lr_0 = 2.3821e-04
Loss = 6.4383e-01, PNorm = 41.7598, GNorm = 4.0087, lr_0 = 2.3723e-04
Loss = 6.9279e-01, PNorm = 41.7704, GNorm = 7.3427, lr_0 = 2.3626e-04
Loss = 6.6506e-01, PNorm = 41.7787, GNorm = 3.2005, lr_0 = 2.3529e-04
Loss = 5.9537e-01, PNorm = 41.7844, GNorm = 2.8306, lr_0 = 2.3433e-04
Loss = 6.8973e-01, PNorm = 41.7898, GNorm = 4.2061, lr_0 = 2.3336e-04
Loss = 7.5401e-01, PNorm = 41.7970, GNorm = 2.8956, lr_0 = 2.3241e-04
Loss = 6.4542e-01, PNorm = 41.8044, GNorm = 2.4105, lr_0 = 2.3145e-04
Loss = 7.2689e-01, PNorm = 41.8101, GNorm = 2.3376, lr_0 = 2.3050e-04
Loss = 5.3187e-01, PNorm = 41.8150, GNorm = 3.7086, lr_0 = 2.2956e-04
Loss = 5.8554e-01, PNorm = 41.8201, GNorm = 10.2096, lr_0 = 2.2862e-04
Loss = 6.1491e-01, PNorm = 41.8273, GNorm = 8.3713, lr_0 = 2.2768e-04
Loss = 7.4920e-01, PNorm = 41.8361, GNorm = 5.5236, lr_0 = 2.2674e-04
Loss = 6.5270e-01, PNorm = 41.8511, GNorm = 2.6875, lr_0 = 2.2581e-04
Validation rmse = 0.727893
Epoch 20
Loss = 5.8390e-01, PNorm = 41.8621, GNorm = 7.2552, lr_0 = 2.2489e-04
Loss = 5.8299e-01, PNorm = 41.8729, GNorm = 11.5003, lr_0 = 2.2396e-04
Loss = 5.3880e-01, PNorm = 41.8822, GNorm = 3.6106, lr_0 = 2.2305e-04
Loss = 5.9256e-01, PNorm = 41.8900, GNorm = 5.5301, lr_0 = 2.2213e-04
Loss = 6.2081e-01, PNorm = 41.8970, GNorm = 3.8929, lr_0 = 2.2122e-04
Loss = 6.7469e-01, PNorm = 41.9032, GNorm = 4.7586, lr_0 = 2.2031e-04
Loss = 6.4081e-01, PNorm = 41.9069, GNorm = 3.5647, lr_0 = 2.1941e-04
Loss = 5.7393e-01, PNorm = 41.9119, GNorm = 3.5834, lr_0 = 2.1851e-04
Loss = 6.7171e-01, PNorm = 41.9197, GNorm = 3.2917, lr_0 = 2.1761e-04
Loss = 6.9630e-01, PNorm = 41.9245, GNorm = 4.9921, lr_0 = 2.1672e-04
Loss = 6.6818e-01, PNorm = 41.9304, GNorm = 4.9328, lr_0 = 2.1583e-04
Loss = 6.2081e-01, PNorm = 41.9357, GNorm = 3.7157, lr_0 = 2.1494e-04
Loss = 7.3934e-01, PNorm = 41.9419, GNorm = 6.0506, lr_0 = 2.1406e-04
Loss = 6.0866e-01, PNorm = 41.9492, GNorm = 2.3905, lr_0 = 2.1318e-04
Loss = 6.9832e-01, PNorm = 41.9541, GNorm = 3.7923, lr_0 = 2.1231e-04
Loss = 6.5605e-01, PNorm = 41.9585, GNorm = 8.4159, lr_0 = 2.1144e-04
Loss = 7.5516e-01, PNorm = 41.9651, GNorm = 3.7970, lr_0 = 2.1057e-04
Loss = 6.2024e-01, PNorm = 41.9723, GNorm = 3.4434, lr_0 = 2.0970e-04
Loss = 6.1449e-01, PNorm = 41.9798, GNorm = 5.5722, lr_0 = 2.0884e-04
Loss = 6.0526e-01, PNorm = 41.9861, GNorm = 6.4084, lr_0 = 2.0799e-04
Validation rmse = 0.734751
Epoch 21
Loss = 8.1165e-01, PNorm = 41.9929, GNorm = 5.4963, lr_0 = 2.0705e-04
Loss = 5.3810e-01, PNorm = 41.9996, GNorm = 3.5643, lr_0 = 2.0620e-04
Loss = 5.7486e-01, PNorm = 42.0054, GNorm = 3.6522, lr_0 = 2.0535e-04
Loss = 6.3907e-01, PNorm = 42.0106, GNorm = 5.9584, lr_0 = 2.0451e-04
Loss = 6.9535e-01, PNorm = 42.0146, GNorm = 4.5104, lr_0 = 2.0367e-04
Loss = 5.7280e-01, PNorm = 42.0212, GNorm = 7.0541, lr_0 = 2.0283e-04
Loss = 5.7237e-01, PNorm = 42.0290, GNorm = 3.0486, lr_0 = 2.0200e-04
Loss = 5.7432e-01, PNorm = 42.0429, GNorm = 5.5859, lr_0 = 2.0117e-04
Loss = 6.5230e-01, PNorm = 42.0533, GNorm = 6.9145, lr_0 = 2.0035e-04
Loss = 4.2863e-01, PNorm = 42.0617, GNorm = 3.1845, lr_0 = 1.9953e-04
Loss = 7.6683e-01, PNorm = 42.0696, GNorm = 5.2533, lr_0 = 1.9871e-04
Loss = 6.7211e-01, PNorm = 42.0740, GNorm = 6.6608, lr_0 = 1.9789e-04
Loss = 7.1104e-01, PNorm = 42.0756, GNorm = 5.2438, lr_0 = 1.9708e-04
Loss = 5.4737e-01, PNorm = 42.0816, GNorm = 4.0474, lr_0 = 1.9627e-04
Loss = 5.5833e-01, PNorm = 42.0889, GNorm = 6.7997, lr_0 = 1.9547e-04
Loss = 7.1857e-01, PNorm = 42.0950, GNorm = 4.7162, lr_0 = 1.9466e-04
Loss = 4.8911e-01, PNorm = 42.1020, GNorm = 4.3604, lr_0 = 1.9387e-04
Loss = 5.0873e-01, PNorm = 42.1116, GNorm = 3.8265, lr_0 = 1.9307e-04
Loss = 6.3304e-01, PNorm = 42.1175, GNorm = 8.1841, lr_0 = 1.9228e-04
Loss = 6.1445e-01, PNorm = 42.1245, GNorm = 2.4089, lr_0 = 1.9149e-04
Validation rmse = 0.740904
Epoch 22
Loss = 5.6302e-01, PNorm = 42.1273, GNorm = 2.9241, lr_0 = 1.9062e-04
Loss = 5.4460e-01, PNorm = 42.1324, GNorm = 4.3779, lr_0 = 1.8984e-04
Loss = 5.9648e-01, PNorm = 42.1396, GNorm = 2.6721, lr_0 = 1.8906e-04
Loss = 6.9846e-01, PNorm = 42.1471, GNorm = 11.3660, lr_0 = 1.8829e-04
Loss = 6.0939e-01, PNorm = 42.1547, GNorm = 6.3770, lr_0 = 1.8751e-04
Loss = 5.8487e-01, PNorm = 42.1612, GNorm = 6.3298, lr_0 = 1.8675e-04
Loss = 5.9228e-01, PNorm = 42.1682, GNorm = 6.4767, lr_0 = 1.8598e-04
Loss = 7.4141e-01, PNorm = 42.1760, GNorm = 4.5659, lr_0 = 1.8522e-04
Loss = 4.3687e-01, PNorm = 42.1816, GNorm = 5.2716, lr_0 = 1.8446e-04
Loss = 5.0570e-01, PNorm = 42.1868, GNorm = 3.5885, lr_0 = 1.8370e-04
Loss = 5.0254e-01, PNorm = 42.1921, GNorm = 7.7525, lr_0 = 1.8295e-04
Loss = 5.8592e-01, PNorm = 42.1959, GNorm = 5.8113, lr_0 = 1.8219e-04
Loss = 4.5880e-01, PNorm = 42.2028, GNorm = 4.4324, lr_0 = 1.8145e-04
Loss = 4.8766e-01, PNorm = 42.2090, GNorm = 5.9265, lr_0 = 1.8070e-04
Loss = 6.0351e-01, PNorm = 42.2168, GNorm = 8.2668, lr_0 = 1.7996e-04
Loss = 6.3973e-01, PNorm = 42.2240, GNorm = 5.8946, lr_0 = 1.7922e-04
Loss = 6.7423e-01, PNorm = 42.2278, GNorm = 3.7633, lr_0 = 1.7849e-04
Loss = 6.4692e-01, PNorm = 42.2310, GNorm = 2.7258, lr_0 = 1.7775e-04
Loss = 6.6473e-01, PNorm = 42.2329, GNorm = 4.1607, lr_0 = 1.7703e-04
Loss = 6.5477e-01, PNorm = 42.2379, GNorm = 2.6597, lr_0 = 1.7630e-04
Validation rmse = 0.716477
Epoch 23
Loss = 4.1543e-01, PNorm = 42.2446, GNorm = 3.3073, lr_0 = 1.7550e-04
Loss = 6.0176e-01, PNorm = 42.2511, GNorm = 8.3845, lr_0 = 1.7478e-04
Loss = 7.2886e-01, PNorm = 42.2553, GNorm = 4.7771, lr_0 = 1.7407e-04
Loss = 5.8754e-01, PNorm = 42.2622, GNorm = 7.2650, lr_0 = 1.7335e-04
Loss = 6.3259e-01, PNorm = 42.2674, GNorm = 5.2443, lr_0 = 1.7264e-04
Loss = 5.9176e-01, PNorm = 42.2744, GNorm = 6.4394, lr_0 = 1.7193e-04
Loss = 5.0804e-01, PNorm = 42.2815, GNorm = 3.2634, lr_0 = 1.7123e-04
Loss = 6.1118e-01, PNorm = 42.2844, GNorm = 9.6610, lr_0 = 1.7052e-04
Loss = 4.8797e-01, PNorm = 42.2884, GNorm = 4.5638, lr_0 = 1.6982e-04
Loss = 4.4760e-01, PNorm = 42.2954, GNorm = 9.9240, lr_0 = 1.6913e-04
Loss = 4.9494e-01, PNorm = 42.3019, GNorm = 3.5222, lr_0 = 1.6843e-04
Loss = 3.6417e-01, PNorm = 42.3068, GNorm = 4.6719, lr_0 = 1.6774e-04
Loss = 7.1679e-01, PNorm = 42.3123, GNorm = 5.6339, lr_0 = 1.6705e-04
Loss = 5.4646e-01, PNorm = 42.3174, GNorm = 8.2176, lr_0 = 1.6637e-04
Loss = 5.0222e-01, PNorm = 42.3209, GNorm = 6.5371, lr_0 = 1.6569e-04
Loss = 6.4005e-01, PNorm = 42.3268, GNorm = 2.8875, lr_0 = 1.6501e-04
Loss = 5.4145e-01, PNorm = 42.3316, GNorm = 4.0694, lr_0 = 1.6433e-04
Loss = 5.5486e-01, PNorm = 42.3372, GNorm = 3.1180, lr_0 = 1.6365e-04
Loss = 6.7484e-01, PNorm = 42.3404, GNorm = 6.9946, lr_0 = 1.6298e-04
Loss = 4.8871e-01, PNorm = 42.3413, GNorm = 6.2418, lr_0 = 1.6231e-04
Validation rmse = 0.719794
Epoch 24
Loss = 6.1300e-01, PNorm = 42.3489, GNorm = 8.1949, lr_0 = 1.6158e-04
Loss = 4.5317e-01, PNorm = 42.3524, GNorm = 7.2544, lr_0 = 1.6092e-04
Loss = 6.5993e-01, PNorm = 42.3550, GNorm = 4.4997, lr_0 = 1.6026e-04
Loss = 5.6398e-01, PNorm = 42.3616, GNorm = 3.9792, lr_0 = 1.5960e-04
Loss = 6.3249e-01, PNorm = 42.3681, GNorm = 11.6068, lr_0 = 1.5895e-04
Loss = 6.8008e-01, PNorm = 42.3725, GNorm = 3.1883, lr_0 = 1.5829e-04
Loss = 6.0096e-01, PNorm = 42.3754, GNorm = 2.3225, lr_0 = 1.5764e-04
Loss = 5.6185e-01, PNorm = 42.3791, GNorm = 2.8355, lr_0 = 1.5700e-04
Loss = 4.8649e-01, PNorm = 42.3843, GNorm = 5.3051, lr_0 = 1.5635e-04
Loss = 5.2765e-01, PNorm = 42.3894, GNorm = 4.2487, lr_0 = 1.5571e-04
Loss = 5.7172e-01, PNorm = 42.3933, GNorm = 8.3189, lr_0 = 1.5507e-04
Loss = 4.5721e-01, PNorm = 42.3976, GNorm = 5.8547, lr_0 = 1.5444e-04
Loss = 5.8037e-01, PNorm = 42.4029, GNorm = 3.5368, lr_0 = 1.5380e-04
Loss = 6.2725e-01, PNorm = 42.4114, GNorm = 4.5631, lr_0 = 1.5317e-04
Loss = 4.6223e-01, PNorm = 42.4188, GNorm = 9.2492, lr_0 = 1.5254e-04
Loss = 4.3432e-01, PNorm = 42.4257, GNorm = 9.0016, lr_0 = 1.5192e-04
Loss = 2.8438e-01, PNorm = 42.4321, GNorm = 4.8496, lr_0 = 1.5129e-04
Loss = 5.4389e-01, PNorm = 42.4402, GNorm = 6.4716, lr_0 = 1.5067e-04
Loss = 4.0623e-01, PNorm = 42.4466, GNorm = 7.2212, lr_0 = 1.5005e-04
Loss = 6.4935e-01, PNorm = 42.4504, GNorm = 5.1888, lr_0 = 1.4944e-04
Validation rmse = 0.711401
Epoch 25
Loss = 4.8684e-01, PNorm = 42.4559, GNorm = 9.1558, lr_0 = 1.4876e-04
Loss = 4.3017e-01, PNorm = 42.4622, GNorm = 6.6878, lr_0 = 1.4815e-04
Loss = 5.2391e-01, PNorm = 42.4678, GNorm = 4.3206, lr_0 = 1.4755e-04
Loss = 4.4003e-01, PNorm = 42.4734, GNorm = 5.3619, lr_0 = 1.4694e-04
Loss = 2.7117e-01, PNorm = 42.4799, GNorm = 6.3937, lr_0 = 1.4634e-04
Loss = 5.6431e-01, PNorm = 42.4808, GNorm = 5.5287, lr_0 = 1.4574e-04
Loss = 3.6966e-01, PNorm = 42.4820, GNorm = 4.1767, lr_0 = 1.4514e-04
Loss = 4.9986e-01, PNorm = 42.4840, GNorm = 4.2382, lr_0 = 1.4454e-04
Loss = 6.4133e-01, PNorm = 42.4884, GNorm = 22.1886, lr_0 = 1.4395e-04
Loss = 4.3942e-01, PNorm = 42.4933, GNorm = 5.0779, lr_0 = 1.4336e-04
Loss = 5.0933e-01, PNorm = 42.4987, GNorm = 7.3517, lr_0 = 1.4277e-04
Loss = 6.0546e-01, PNorm = 42.5041, GNorm = 10.6370, lr_0 = 1.4219e-04
Loss = 5.9356e-01, PNorm = 42.5102, GNorm = 5.7616, lr_0 = 1.4160e-04
Loss = 5.2280e-01, PNorm = 42.5163, GNorm = 3.4746, lr_0 = 1.4102e-04
Loss = 6.2119e-01, PNorm = 42.5201, GNorm = 6.2953, lr_0 = 1.4044e-04
Loss = 5.0111e-01, PNorm = 42.5233, GNorm = 8.4175, lr_0 = 1.3987e-04
Loss = 6.0303e-01, PNorm = 42.5270, GNorm = 6.8297, lr_0 = 1.3929e-04
Loss = 5.7822e-01, PNorm = 42.5302, GNorm = 5.0866, lr_0 = 1.3872e-04
Loss = 5.7813e-01, PNorm = 42.5339, GNorm = 4.4788, lr_0 = 1.3815e-04
Loss = 5.2825e-01, PNorm = 42.5376, GNorm = 3.8848, lr_0 = 1.3759e-04
Validation rmse = 0.703861
Epoch 26
Loss = 5.9875e-01, PNorm = 42.5421, GNorm = 5.6607, lr_0 = 1.3696e-04
Loss = 4.3305e-01, PNorm = 42.5482, GNorm = 2.4183, lr_0 = 1.3640e-04
Loss = 5.3619e-01, PNorm = 42.5517, GNorm = 5.0548, lr_0 = 1.3584e-04
Loss = 4.7107e-01, PNorm = 42.5550, GNorm = 4.6911, lr_0 = 1.3529e-04
Loss = 4.5581e-01, PNorm = 42.5586, GNorm = 5.3955, lr_0 = 1.3473e-04
Loss = 5.2611e-01, PNorm = 42.5623, GNorm = 4.8563, lr_0 = 1.3418e-04
Loss = 6.5267e-01, PNorm = 42.5649, GNorm = 15.2724, lr_0 = 1.3363e-04
Loss = 5.5665e-01, PNorm = 42.5672, GNorm = 3.5333, lr_0 = 1.3308e-04
Loss = 5.0710e-01, PNorm = 42.5718, GNorm = 4.7089, lr_0 = 1.3253e-04
Loss = 5.0170e-01, PNorm = 42.5762, GNorm = 8.2500, lr_0 = 1.3199e-04
Loss = 4.7266e-01, PNorm = 42.5813, GNorm = 3.5530, lr_0 = 1.3145e-04
Loss = 4.4510e-01, PNorm = 42.5869, GNorm = 12.1739, lr_0 = 1.3091e-04
Loss = 6.1396e-01, PNorm = 42.5902, GNorm = 4.1841, lr_0 = 1.3037e-04
Loss = 4.3590e-01, PNorm = 42.5942, GNorm = 5.8336, lr_0 = 1.2984e-04
Loss = 6.0901e-01, PNorm = 42.5976, GNorm = 7.7148, lr_0 = 1.2930e-04
Loss = 4.7250e-01, PNorm = 42.6020, GNorm = 5.6423, lr_0 = 1.2877e-04
Loss = 4.0485e-01, PNorm = 42.6057, GNorm = 5.2840, lr_0 = 1.2824e-04
Loss = 4.6110e-01, PNorm = 42.6098, GNorm = 9.5730, lr_0 = 1.2772e-04
Loss = 4.0651e-01, PNorm = 42.6137, GNorm = 5.6672, lr_0 = 1.2719e-04
Loss = 6.2092e-01, PNorm = 42.6163, GNorm = 3.8588, lr_0 = 1.2667e-04
Validation rmse = 0.701285
Epoch 27
Loss = 6.6531e-01, PNorm = 42.6197, GNorm = 4.4949, lr_0 = 1.2610e-04
Loss = 5.3263e-01, PNorm = 42.6233, GNorm = 8.8788, lr_0 = 1.2558e-04
Loss = 4.3885e-01, PNorm = 42.6285, GNorm = 7.1156, lr_0 = 1.2507e-04
Loss = 4.4375e-01, PNorm = 42.6334, GNorm = 3.9905, lr_0 = 1.2455e-04
Loss = 5.4246e-01, PNorm = 42.6387, GNorm = 3.7718, lr_0 = 1.2404e-04
Loss = 5.7332e-01, PNorm = 42.6428, GNorm = 25.6977, lr_0 = 1.2353e-04
Loss = 3.8352e-01, PNorm = 42.6436, GNorm = 4.7738, lr_0 = 1.2303e-04
Loss = 4.6824e-01, PNorm = 42.6468, GNorm = 3.9481, lr_0 = 1.2252e-04
Loss = 5.0041e-01, PNorm = 42.6493, GNorm = 8.3333, lr_0 = 1.2202e-04
Loss = 4.8214e-01, PNorm = 42.6513, GNorm = 4.9248, lr_0 = 1.2152e-04
Loss = 4.7301e-01, PNorm = 42.6544, GNorm = 9.1707, lr_0 = 1.2102e-04
Loss = 3.1304e-01, PNorm = 42.6589, GNorm = 5.9804, lr_0 = 1.2052e-04
Loss = 4.7401e-01, PNorm = 42.6618, GNorm = 10.5484, lr_0 = 1.2003e-04
Loss = 5.4839e-01, PNorm = 42.6649, GNorm = 6.0835, lr_0 = 1.1954e-04
Loss = 5.9240e-01, PNorm = 42.6696, GNorm = 8.6311, lr_0 = 1.1905e-04
Loss = 4.7743e-01, PNorm = 42.6732, GNorm = 7.0776, lr_0 = 1.1856e-04
Loss = 5.3382e-01, PNorm = 42.6746, GNorm = 11.8717, lr_0 = 1.1807e-04
Loss = 4.2424e-01, PNorm = 42.6755, GNorm = 3.9753, lr_0 = 1.1759e-04
Loss = 3.3997e-01, PNorm = 42.6778, GNorm = 9.3336, lr_0 = 1.1710e-04
Loss = 4.5406e-01, PNorm = 42.6792, GNorm = 4.6416, lr_0 = 1.1662e-04
Validation rmse = 0.698838
Epoch 28
Loss = 4.0037e-01, PNorm = 42.6835, GNorm = 12.6359, lr_0 = 1.1610e-04
Loss = 4.0809e-01, PNorm = 42.6866, GNorm = 4.3898, lr_0 = 1.1562e-04
Loss = 5.1575e-01, PNorm = 42.6930, GNorm = 5.4792, lr_0 = 1.1515e-04
Loss = 4.0581e-01, PNorm = 42.6997, GNorm = 4.4985, lr_0 = 1.1467e-04
Loss = 3.5626e-01, PNorm = 42.7051, GNorm = 4.5908, lr_0 = 1.1420e-04
Loss = 5.5215e-01, PNorm = 42.7097, GNorm = 5.6532, lr_0 = 1.1373e-04
Loss = 4.5714e-01, PNorm = 42.7131, GNorm = 9.7845, lr_0 = 1.1327e-04
Loss = 4.5417e-01, PNorm = 42.7144, GNorm = 6.4497, lr_0 = 1.1280e-04
Loss = 4.4055e-01, PNorm = 42.7162, GNorm = 14.6007, lr_0 = 1.1234e-04
Loss = 6.2789e-01, PNorm = 42.7192, GNorm = 7.9856, lr_0 = 1.1188e-04
Loss = 4.9759e-01, PNorm = 42.7234, GNorm = 3.9935, lr_0 = 1.1142e-04
Loss = 4.7146e-01, PNorm = 42.7265, GNorm = 5.9715, lr_0 = 1.1096e-04
Loss = 4.9992e-01, PNorm = 42.7292, GNorm = 7.4040, lr_0 = 1.1051e-04
Loss = 4.8703e-01, PNorm = 42.7323, GNorm = 8.0180, lr_0 = 1.1005e-04
Loss = 4.3939e-01, PNorm = 42.7337, GNorm = 5.7718, lr_0 = 1.0960e-04
Loss = 5.3010e-01, PNorm = 42.7351, GNorm = 11.2476, lr_0 = 1.0915e-04
Loss = 5.4186e-01, PNorm = 42.7374, GNorm = 9.2877, lr_0 = 1.0871e-04
Loss = 3.6547e-01, PNorm = 42.7411, GNorm = 3.4329, lr_0 = 1.0826e-04
Loss = 4.8588e-01, PNorm = 42.7445, GNorm = 6.0258, lr_0 = 1.0781e-04
Loss = 3.6217e-01, PNorm = 42.7468, GNorm = 6.0832, lr_0 = 1.0737e-04
Validation rmse = 0.695258
Epoch 29
Loss = 4.4875e-01, PNorm = 42.7501, GNorm = 5.4772, lr_0 = 1.0689e-04
Loss = 4.6489e-01, PNorm = 42.7536, GNorm = 15.8124, lr_0 = 1.0645e-04
Loss = 3.0827e-01, PNorm = 42.7565, GNorm = 7.3777, lr_0 = 1.0601e-04
Loss = 3.7815e-01, PNorm = 42.7593, GNorm = 5.0960, lr_0 = 1.0558e-04
Loss = 5.7483e-01, PNorm = 42.7620, GNorm = 6.2555, lr_0 = 1.0514e-04
Loss = 3.3044e-01, PNorm = 42.7650, GNorm = 4.9293, lr_0 = 1.0471e-04
Loss = 4.1116e-01, PNorm = 42.7693, GNorm = 9.9561, lr_0 = 1.0428e-04
Loss = 5.4217e-01, PNorm = 42.7737, GNorm = 7.7886, lr_0 = 1.0386e-04
Loss = 5.6842e-01, PNorm = 42.7757, GNorm = 6.1960, lr_0 = 1.0343e-04
Loss = 4.7539e-01, PNorm = 42.7780, GNorm = 4.4885, lr_0 = 1.0300e-04
Loss = 3.7447e-01, PNorm = 42.7799, GNorm = 9.6712, lr_0 = 1.0258e-04
Loss = 4.5354e-01, PNorm = 42.7834, GNorm = 11.0252, lr_0 = 1.0216e-04
Loss = 3.9150e-01, PNorm = 42.7878, GNorm = 4.5990, lr_0 = 1.0174e-04
Loss = 5.0676e-01, PNorm = 42.7907, GNorm = 6.6717, lr_0 = 1.0132e-04
Loss = 5.0126e-01, PNorm = 42.7920, GNorm = 13.0302, lr_0 = 1.0091e-04
Loss = 4.1555e-01, PNorm = 42.7943, GNorm = 5.2263, lr_0 = 1.0049e-04
Loss = 5.2867e-01, PNorm = 42.7976, GNorm = 5.0192, lr_0 = 1.0008e-04
Loss = 4.1599e-01, PNorm = 42.8017, GNorm = 3.9703, lr_0 = 1.0000e-04
Loss = 4.4816e-01, PNorm = 42.8071, GNorm = 7.2472, lr_0 = 1.0000e-04
Loss = 4.0284e-01, PNorm = 42.8100, GNorm = 2.9603, lr_0 = 1.0000e-04
Validation rmse = 0.706168
Model 0 best validation rmse = 0.695258 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.821046
Ensemble test rmse = 0.821046
1-fold cross validation
	Seed 0 ==> test rmse = 0.821046
Overall test rmse = 0.821046 +/- 0.000000
Elapsed time = 0:04:24
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.401543
Epoch 1
Loss = 1.4310e+00, PNorm = 42.7473, GNorm = 0.8380, lr_0 = 8.7143e-04
Validation rmse = 1.333386
Epoch 2
Loss = 1.3754e+00, PNorm = 42.7768, GNorm = 0.7473, lr_0 = 9.1030e-04
Validation rmse = 1.351509
Epoch 3
Loss = 1.3268e+00, PNorm = 42.8087, GNorm = 1.4955, lr_0 = 8.0940e-04
Validation rmse = 1.314112
Epoch 4
Validation rmse = 1.279339
Epoch 5
Loss = 1.2554e+00, PNorm = 42.8396, GNorm = 1.3998, lr_0 = 7.1969e-04
Validation rmse = 1.236518
Epoch 6
Loss = 1.2386e+00, PNorm = 42.8727, GNorm = 0.6159, lr_0 = 6.3992e-04
Validation rmse = 1.212043
Epoch 7
Loss = 1.1690e+00, PNorm = 42.9146, GNorm = 1.3154, lr_0 = 5.6899e-04
Validation rmse = 1.254354
Epoch 8
Loss = 1.1530e+00, PNorm = 42.9596, GNorm = 3.3057, lr_0 = 5.0592e-04
Validation rmse = 1.135660
Epoch 9
Validation rmse = 1.119142
Epoch 10
Loss = 9.7113e-01, PNorm = 43.0056, GNorm = 3.7296, lr_0 = 4.4984e-04
Validation rmse = 1.087815
Epoch 11
Loss = 9.8739e-01, PNorm = 43.0520, GNorm = 1.7354, lr_0 = 3.9998e-04
Validation rmse = 1.087518
Epoch 12
Loss = 9.6077e-01, PNorm = 43.0968, GNorm = 3.0407, lr_0 = 3.5565e-04
Validation rmse = 1.035177
Epoch 13
Loss = 9.4441e-01, PNorm = 43.1347, GNorm = 9.3918, lr_0 = 3.1623e-04
Validation rmse = 1.017951
Epoch 14
Validation rmse = 1.072022
Epoch 15
Loss = 8.8413e-01, PNorm = 43.1598, GNorm = 7.8771, lr_0 = 2.8118e-04
Validation rmse = 1.006200
Epoch 16
Loss = 8.7131e-01, PNorm = 43.1821, GNorm = 2.8195, lr_0 = 2.5001e-04
Validation rmse = 1.011849
Epoch 17
Loss = 8.4891e-01, PNorm = 43.2006, GNorm = 5.4771, lr_0 = 2.2230e-04
Validation rmse = 0.987157
Epoch 18
Loss = 8.5571e-01, PNorm = 43.2171, GNorm = 9.8969, lr_0 = 1.9766e-04
Validation rmse = 0.978726
Epoch 19
Validation rmse = 1.013242
Epoch 20
Loss = 8.2398e-01, PNorm = 43.2320, GNorm = 8.0724, lr_0 = 1.7575e-04
Validation rmse = 0.971370
Epoch 21
Loss = 7.1408e-01, PNorm = 43.2458, GNorm = 3.6362, lr_0 = 1.5627e-04
Validation rmse = 0.957460
Epoch 22
Loss = 7.5330e-01, PNorm = 43.2582, GNorm = 8.7597, lr_0 = 1.3895e-04
Validation rmse = 0.950811
Epoch 23
Loss = 7.6087e-01, PNorm = 43.2679, GNorm = 2.1172, lr_0 = 1.2355e-04
Validation rmse = 0.963974
Epoch 24
Validation rmse = 0.944089
Epoch 25
Loss = 7.5987e-01, PNorm = 43.2781, GNorm = 3.6558, lr_0 = 1.0985e-04
Validation rmse = 0.930819
Epoch 26
Loss = 8.0694e-01, PNorm = 43.2863, GNorm = 6.2332, lr_0 = 1.0000e-04
Validation rmse = 0.945333
Epoch 27
Loss = 7.6072e-01, PNorm = 43.2938, GNorm = 8.7099, lr_0 = 1.0000e-04
Validation rmse = 0.942204
Epoch 28
Loss = 7.2423e-01, PNorm = 43.3013, GNorm = 2.0858, lr_0 = 1.0000e-04
Validation rmse = 0.938625
Epoch 29
Validation rmse = 0.931954
Model 0 best validation rmse = 0.930819 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.797503
Ensemble test rmse = 0.797503
1-fold cross validation
	Seed 0 ==> test rmse = 0.797503
Overall test rmse = 0.797503 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.269464
Epoch 1
Loss = 1.4395e+00, PNorm = 42.7432, GNorm = 1.2110, lr_0 = 7.7500e-04
Validation rmse = 1.290154
Epoch 2
Loss = 1.3987e+00, PNorm = 42.7654, GNorm = 0.6639, lr_0 = 9.4019e-04
Validation rmse = 1.298891
Epoch 3
Loss = 1.3838e+00, PNorm = 42.7922, GNorm = 1.1868, lr_0 = 8.4834e-04
Validation rmse = 1.213811
Epoch 4
Loss = 1.2803e+00, PNorm = 42.8180, GNorm = 1.6981, lr_0 = 7.6547e-04
Validation rmse = 1.193431
Epoch 5
Loss = 1.2850e+00, PNorm = 42.8528, GNorm = 1.5291, lr_0 = 6.8363e-04
Validation rmse = 1.142415
Epoch 6
Loss = 1.2466e+00, PNorm = 42.8904, GNorm = 1.1977, lr_0 = 6.1685e-04
Validation rmse = 1.092146
Epoch 7
Loss = 1.1876e+00, PNorm = 42.9367, GNorm = 0.9787, lr_0 = 5.5659e-04
Validation rmse = 1.046746
Epoch 8
Validation rmse = 1.001432
Epoch 9
Loss = 1.1161e+00, PNorm = 42.9890, GNorm = 1.4412, lr_0 = 5.0222e-04
Validation rmse = 0.980370
Epoch 10
Loss = 1.0528e+00, PNorm = 43.0473, GNorm = 4.2958, lr_0 = 4.4852e-04
Validation rmse = 0.930709
Epoch 11
Loss = 1.0428e+00, PNorm = 43.0971, GNorm = 6.2867, lr_0 = 4.0471e-04
Validation rmse = 0.935483
Epoch 12
Loss = 9.5528e-01, PNorm = 43.1415, GNorm = 3.3768, lr_0 = 3.6517e-04
Validation rmse = 0.876021
Epoch 13
Loss = 9.1015e-01, PNorm = 43.1794, GNorm = 4.4726, lr_0 = 3.2950e-04
Validation rmse = 0.915120
Epoch 14
Loss = 9.0060e-01, PNorm = 43.2098, GNorm = 3.5305, lr_0 = 2.9731e-04
Validation rmse = 0.847339
Epoch 15
Loss = 8.5829e-01, PNorm = 43.2366, GNorm = 2.4176, lr_0 = 2.6553e-04
Validation rmse = 0.833665
Epoch 16
Validation rmse = 0.830591
Epoch 17
Loss = 8.2820e-01, PNorm = 43.2573, GNorm = 6.4697, lr_0 = 2.3959e-04
Validation rmse = 0.822474
Epoch 18
Loss = 7.6718e-01, PNorm = 43.2729, GNorm = 3.5204, lr_0 = 2.1618e-04
Validation rmse = 0.812340
Epoch 19
Loss = 8.4826e-01, PNorm = 43.2866, GNorm = 5.4474, lr_0 = 1.9506e-04
Validation rmse = 0.802864
Epoch 20
Loss = 7.3584e-01, PNorm = 43.3030, GNorm = 4.2878, lr_0 = 1.7421e-04
Validation rmse = 0.799498
Epoch 21
Loss = 7.9250e-01, PNorm = 43.3165, GNorm = 8.3539, lr_0 = 1.5719e-04
Validation rmse = 0.797860
Epoch 22
Loss = 7.9305e-01, PNorm = 43.3268, GNorm = 8.4021, lr_0 = 1.4184e-04
Validation rmse = 0.793276
Epoch 23
Loss = 7.3319e-01, PNorm = 43.3368, GNorm = 2.6116, lr_0 = 1.2798e-04
Loss = 7.7648e-01, PNorm = 43.3378, GNorm = 2.2017, lr_0 = 1.2667e-04
Validation rmse = 0.809465
Epoch 24
Validation rmse = 0.799727
Epoch 25
Loss = 6.3548e-01, PNorm = 43.3476, GNorm = 2.8338, lr_0 = 1.1430e-04
Validation rmse = 0.815223
Epoch 26
Loss = 7.7604e-01, PNorm = 43.3555, GNorm = 8.8881, lr_0 = 1.0313e-04
Validation rmse = 0.822967
Epoch 27
Loss = 6.8113e-01, PNorm = 43.3628, GNorm = 4.6299, lr_0 = 1.0000e-04
Validation rmse = 0.794700
Epoch 28
Loss = 7.4291e-01, PNorm = 43.3701, GNorm = 12.9705, lr_0 = 1.0000e-04
Validation rmse = 0.767282
Epoch 29
Loss = 7.0785e-01, PNorm = 43.3777, GNorm = 10.7357, lr_0 = 1.0000e-04
Validation rmse = 0.769081
Model 0 best validation rmse = 0.767282 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.776738
Ensemble test rmse = 0.776738
1-fold cross validation
	Seed 0 ==> test rmse = 0.776738
Overall test rmse = 0.776738 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.343823
Epoch 1
Loss = 1.4336e+00, PNorm = 42.7424, GNorm = 1.5436, lr_0 = 7.0000e-04
Validation rmse = 1.356436
Epoch 2
Loss = 1.4394e+00, PNorm = 42.7615, GNorm = 1.5808, lr_0 = 9.6411e-04
Validation rmse = 1.298007
Epoch 3
Loss = 1.2997e+00, PNorm = 42.7915, GNorm = 1.0501, lr_0 = 8.7192e-04
Validation rmse = 1.198181
Epoch 4
Loss = 1.3389e+00, PNorm = 42.8222, GNorm = 0.6025, lr_0 = 7.9578e-04
Validation rmse = 1.137755
Epoch 5
Loss = 1.2135e+00, PNorm = 42.8647, GNorm = 3.1301, lr_0 = 7.1969e-04
Validation rmse = 1.118343
Epoch 6
Loss = 1.1832e+00, PNorm = 42.9143, GNorm = 0.6673, lr_0 = 6.5684e-04
Validation rmse = 1.026955
Epoch 7
Loss = 1.1033e+00, PNorm = 42.9663, GNorm = 5.0344, lr_0 = 5.9948e-04
Validation rmse = 1.002450
Epoch 8
Loss = 1.1124e+00, PNorm = 43.0203, GNorm = 6.9622, lr_0 = 5.4216e-04
Validation rmse = 1.040590
Epoch 9
Loss = 1.0279e+00, PNorm = 43.0672, GNorm = 2.2734, lr_0 = 4.9482e-04
Validation rmse = 0.928904
Epoch 10
Loss = 9.9887e-01, PNorm = 43.1187, GNorm = 3.7575, lr_0 = 4.4750e-04
Validation rmse = 0.885467
Epoch 11
Loss = 9.3558e-01, PNorm = 43.1570, GNorm = 4.2755, lr_0 = 4.0842e-04
Validation rmse = 0.900024
Epoch 12
Loss = 8.0688e-01, PNorm = 43.1900, GNorm = 4.5791, lr_0 = 3.7276e-04
Validation rmse = 0.853643
Epoch 13
Loss = 8.6407e-01, PNorm = 43.2218, GNorm = 2.6485, lr_0 = 3.3711e-04
Validation rmse = 0.844909
Epoch 14
Loss = 8.2045e-01, PNorm = 43.2471, GNorm = 2.6437, lr_0 = 3.0768e-04
Validation rmse = 0.829605
Epoch 15
Loss = 8.2819e-01, PNorm = 43.2713, GNorm = 1.8500, lr_0 = 2.7826e-04
Validation rmse = 0.823575
Epoch 16
Loss = 8.0006e-01, PNorm = 43.2911, GNorm = 5.7351, lr_0 = 2.5396e-04
Validation rmse = 0.830539
Epoch 17
Loss = 7.4841e-01, PNorm = 43.3076, GNorm = 6.0683, lr_0 = 2.3178e-04
Validation rmse = 0.816495
Epoch 18
Loss = 7.7821e-01, PNorm = 43.3252, GNorm = 5.1445, lr_0 = 2.0962e-04
Validation rmse = 0.800639
Epoch 19
Loss = 7.1545e-01, PNorm = 43.3397, GNorm = 3.3902, lr_0 = 1.9131e-04
Validation rmse = 0.819083
Epoch 20
Loss = 7.4239e-01, PNorm = 43.3532, GNorm = 4.9344, lr_0 = 1.7302e-04
Validation rmse = 0.787707
Epoch 21
Loss = 7.2140e-01, PNorm = 43.3642, GNorm = 3.2221, lr_0 = 1.5791e-04
Loss = 8.5737e-01, PNorm = 43.3655, GNorm = 13.0830, lr_0 = 1.5647e-04
Validation rmse = 0.785466
Epoch 22
Loss = 7.1505e-01, PNorm = 43.3764, GNorm = 3.0508, lr_0 = 1.4281e-04
Validation rmse = 0.794421
Epoch 23
Loss = 7.2810e-01, PNorm = 43.3866, GNorm = 8.9048, lr_0 = 1.3034e-04
Validation rmse = 0.781109
Epoch 24
Validation rmse = 0.783388
Epoch 25
Loss = 7.2618e-01, PNorm = 43.3956, GNorm = 5.8767, lr_0 = 1.1788e-04
Validation rmse = 0.773491
Epoch 26
Loss = 6.6160e-01, PNorm = 43.4033, GNorm = 1.5562, lr_0 = 1.0758e-04
Validation rmse = 0.782764
Epoch 27
Loss = 6.4039e-01, PNorm = 43.4105, GNorm = 2.5191, lr_0 = 1.0000e-04
Validation rmse = 0.777096
Epoch 28
Loss = 6.5054e-01, PNorm = 43.4171, GNorm = 8.1555, lr_0 = 1.0000e-04
Validation rmse = 0.775005
Epoch 29
Loss = 6.3748e-01, PNorm = 43.4237, GNorm = 6.3913, lr_0 = 1.0000e-04
Validation rmse = 0.770010
Model 0 best validation rmse = 0.770010 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.812822
Ensemble test rmse = 0.812822
1-fold cross validation
	Seed 0 ==> test rmse = 0.812822
Overall test rmse = 0.812822 +/- 0.000000
Elapsed time = 0:01:36
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6834e+00, PNorm = 42.7442, GNorm = 1.0133, lr_0 = 5.9500e-04
Loss = 1.3476e+00, PNorm = 42.7447, GNorm = 1.1844, lr_0 = 6.4000e-04
Validation rmse = 1.449771
Epoch 1
Loss = 1.4115e+00, PNorm = 42.7626, GNorm = 1.4629, lr_0 = 9.8369e-04
Loss = 1.1917e+00, PNorm = 42.7651, GNorm = 1.0508, lr_0 = 9.7563e-04
Validation rmse = 1.413982
Epoch 2
Loss = 1.3306e+00, PNorm = 42.7964, GNorm = 0.6540, lr_0 = 8.9861e-04
Validation rmse = 1.346470
Epoch 3
Loss = 1.2897e+00, PNorm = 42.8320, GNorm = 2.0983, lr_0 = 8.2767e-04
Validation rmse = 1.296197
Epoch 4
Loss = 1.2282e+00, PNorm = 42.8793, GNorm = 3.1047, lr_0 = 7.5609e-04
Validation rmse = 1.222223
Epoch 5
Loss = 1.1843e+00, PNorm = 42.9324, GNorm = 1.0706, lr_0 = 6.9069e-04
Validation rmse = 1.174863
Epoch 6
Loss = 1.1251e+00, PNorm = 42.9829, GNorm = 0.8304, lr_0 = 6.3617e-04
Validation rmse = 1.129028
Epoch 7
Loss = 1.0631e+00, PNorm = 43.0423, GNorm = 3.6623, lr_0 = 5.8115e-04
Validation rmse = 1.046598
Epoch 8
Loss = 9.6883e-01, PNorm = 43.0970, GNorm = 1.3641, lr_0 = 5.3527e-04
Validation rmse = 1.035524
Epoch 9
Loss = 9.4519e-01, PNorm = 43.1456, GNorm = 4.0120, lr_0 = 4.8897e-04
Validation rmse = 0.965761
Epoch 10
Loss = 8.8429e-01, PNorm = 43.1904, GNorm = 8.6950, lr_0 = 4.4668e-04
Validation rmse = 1.012292
Epoch 11
Loss = 9.7137e-01, PNorm = 43.2193, GNorm = 7.7573, lr_0 = 4.1142e-04
Validation rmse = 0.939590
Epoch 12
Loss = 8.1431e-01, PNorm = 43.2508, GNorm = 5.2751, lr_0 = 3.7584e-04
Validation rmse = 0.956550
Epoch 13
Loss = 8.4834e-01, PNorm = 43.2791, GNorm = 6.7482, lr_0 = 3.4617e-04
Validation rmse = 0.905690
Epoch 14
Loss = 7.6443e-01, PNorm = 43.3045, GNorm = 3.8364, lr_0 = 3.1623e-04
Validation rmse = 0.900454
Epoch 15
Loss = 7.8468e-01, PNorm = 43.3295, GNorm = 3.3728, lr_0 = 2.8888e-04
Validation rmse = 0.886171
Epoch 16
Loss = 7.4329e-01, PNorm = 43.3489, GNorm = 2.7170, lr_0 = 2.6607e-04
Validation rmse = 0.883160
Epoch 17
Loss = 6.9743e-01, PNorm = 43.3664, GNorm = 2.7532, lr_0 = 2.4306e-04
Validation rmse = 0.885230
Epoch 18
Loss = 7.2929e-01, PNorm = 43.3817, GNorm = 11.0742, lr_0 = 2.2387e-04
Validation rmse = 0.887148
Epoch 19
Loss = 7.1372e-01, PNorm = 43.3981, GNorm = 1.7851, lr_0 = 2.0451e-04
Validation rmse = 0.873453
Epoch 20
Loss = 6.5374e-01, PNorm = 43.4133, GNorm = 9.2542, lr_0 = 1.8682e-04
Validation rmse = 0.872072
Epoch 21
Loss = 7.1879e-01, PNorm = 43.4257, GNorm = 5.5295, lr_0 = 1.7207e-04
Validation rmse = 0.868201
Epoch 22
Loss = 6.8526e-01, PNorm = 43.4371, GNorm = 5.7347, lr_0 = 1.5719e-04
Validation rmse = 0.873374
Epoch 23
Loss = 5.9624e-01, PNorm = 43.4471, GNorm = 3.6333, lr_0 = 1.4360e-04
Validation rmse = 0.874242
Epoch 24
Loss = 6.5276e-01, PNorm = 43.4557, GNorm = 5.1423, lr_0 = 1.3226e-04
Validation rmse = 0.867293
Epoch 25
Loss = 6.4438e-01, PNorm = 43.4647, GNorm = 2.4360, lr_0 = 1.2082e-04
Loss = 6.4563e-01, PNorm = 43.4728, GNorm = 5.9302, lr_0 = 1.1128e-04
Validation rmse = 0.862534
Epoch 26
Loss = 6.4066e-01, PNorm = 43.4796, GNorm = 5.0361, lr_0 = 1.0250e-04
Loss = 7.8229e-01, PNorm = 43.4803, GNorm = 8.1109, lr_0 = 1.0166e-04
Validation rmse = 0.863936
Epoch 27
Loss = 6.3330e-01, PNorm = 43.4873, GNorm = 4.8493, lr_0 = 1.0000e-04
Loss = 8.4701e-01, PNorm = 43.4880, GNorm = 3.8635, lr_0 = 1.0000e-04
Validation rmse = 0.875863
Epoch 28
Loss = 6.6473e-01, PNorm = 43.4947, GNorm = 3.4176, lr_0 = 1.0000e-04
Validation rmse = 0.864442
Epoch 29
Loss = 6.4451e-01, PNorm = 43.5006, GNorm = 7.5106, lr_0 = 1.0000e-04
Validation rmse = 0.858383
Model 0 best validation rmse = 0.858383 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.803456
Ensemble test rmse = 0.803456
1-fold cross validation
	Seed 0 ==> test rmse = 0.803456
Overall test rmse = 0.803456 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6678e+00, PNorm = 42.7438, GNorm = 0.9470, lr_0 = 5.5000e-04
Validation rmse = 1.423305
Epoch 1
Loss = 1.3989e+00, PNorm = 42.7578, GNorm = 0.4398, lr_0 = 1.0000e-03
Validation rmse = 1.403958
Epoch 2
Loss = 1.3330e+00, PNorm = 42.7888, GNorm = 1.8175, lr_0 = 9.2106e-04
Validation rmse = 1.332098
Epoch 3
Loss = 1.2964e+00, PNorm = 42.8217, GNorm = 1.1317, lr_0 = 8.4834e-04
Validation rmse = 1.294649
Epoch 4
Loss = 1.2753e+00, PNorm = 42.8621, GNorm = 1.1060, lr_0 = 7.8137e-04
Validation rmse = 1.250937
Epoch 5
Loss = 1.2043e+00, PNorm = 42.9152, GNorm = 1.5192, lr_0 = 7.1969e-04
Validation rmse = 1.221048
Epoch 6
Loss = 1.1741e+00, PNorm = 42.9730, GNorm = 2.9059, lr_0 = 6.6784e-04
Validation rmse = 1.135817
Epoch 7
Loss = 1.0810e+00, PNorm = 43.0351, GNorm = 5.6976, lr_0 = 6.1512e-04
Validation rmse = 1.074082
Epoch 8
Loss = 1.0830e+00, PNorm = 43.0924, GNorm = 3.6084, lr_0 = 5.6656e-04
Loss = 9.8601e-01, PNorm = 43.1456, GNorm = 2.0923, lr_0 = 5.2575e-04
Loss = 1.1745e+00, PNorm = 43.1494, GNorm = 11.1982, lr_0 = 5.2183e-04
Validation rmse = 1.060061
Epoch 9
Loss = 9.4597e-01, PNorm = 43.1909, GNorm = 5.9679, lr_0 = 4.8424e-04
Validation rmse = 0.998103
Epoch 10
Loss = 8.7747e-01, PNorm = 43.2320, GNorm = 7.9871, lr_0 = 4.4602e-04
Validation rmse = 0.943508
Epoch 11
Loss = 8.3453e-01, PNorm = 43.2649, GNorm = 1.6027, lr_0 = 4.1389e-04
Validation rmse = 0.986495
Epoch 12
Loss = 8.5260e-01, PNorm = 43.2997, GNorm = 5.7085, lr_0 = 3.8121e-04
Validation rmse = 0.920258
Epoch 13
Loss = 8.0746e-01, PNorm = 43.3303, GNorm = 4.5456, lr_0 = 3.5112e-04
Validation rmse = 0.942014
Epoch 14
Loss = 8.6992e-01, PNorm = 43.3572, GNorm = 14.1342, lr_0 = 3.2340e-04
Validation rmse = 0.957737
Epoch 15
Loss = 7.7909e-01, PNorm = 43.3729, GNorm = 5.1150, lr_0 = 2.9787e-04
Validation rmse = 0.907648
Epoch 16
Loss = 7.4286e-01, PNorm = 43.3894, GNorm = 2.8949, lr_0 = 2.7641e-04
Loss = 7.5789e-01, PNorm = 43.4048, GNorm = 3.8366, lr_0 = 2.5650e-04
Loss = 5.6090e-01, PNorm = 43.4065, GNorm = 4.9433, lr_0 = 2.5459e-04
Validation rmse = 0.914922
Epoch 17
Loss = 7.2891e-01, PNorm = 43.4228, GNorm = 3.2245, lr_0 = 2.3625e-04
Validation rmse = 0.885273
Epoch 18
Loss = 6.8661e-01, PNorm = 43.4380, GNorm = 2.7133, lr_0 = 2.1760e-04
Validation rmse = 0.872767
Epoch 19
Loss = 7.1910e-01, PNorm = 43.4526, GNorm = 3.1805, lr_0 = 2.0042e-04
Validation rmse = 0.891649
Epoch 20
Loss = 6.8522e-01, PNorm = 43.4658, GNorm = 4.0990, lr_0 = 1.8460e-04
Validation rmse = 0.880490
Epoch 21
Loss = 6.5554e-01, PNorm = 43.4762, GNorm = 1.7460, lr_0 = 1.7003e-04
Validation rmse = 0.888426
Epoch 22
Loss = 7.0325e-01, PNorm = 43.4836, GNorm = 8.6211, lr_0 = 1.5778e-04
Validation rmse = 0.872707
Epoch 23
Loss = 6.4246e-01, PNorm = 43.4933, GNorm = 9.0182, lr_0 = 1.4532e-04
Validation rmse = 0.872424
Epoch 24
Loss = 6.5738e-01, PNorm = 43.5037, GNorm = 3.4061, lr_0 = 1.3385e-04
Validation rmse = 0.882194
Epoch 25
Loss = 8.0492e-01, PNorm = 43.5122, GNorm = 2.4084, lr_0 = 1.2328e-04
Loss = 6.3055e-01, PNorm = 43.5207, GNorm = 7.4082, lr_0 = 1.1440e-04
Loss = 9.3409e-01, PNorm = 43.5214, GNorm = 9.0038, lr_0 = 1.1355e-04
Validation rmse = 0.865672
Epoch 26
Loss = 6.3315e-01, PNorm = 43.5288, GNorm = 2.7625, lr_0 = 1.0537e-04
Validation rmse = 0.871049
Epoch 27
Loss = 6.4275e-01, PNorm = 43.5352, GNorm = 11.5305, lr_0 = 1.0000e-04
Validation rmse = 0.873480
Epoch 28
Loss = 5.9429e-01, PNorm = 43.5420, GNorm = 3.4818, lr_0 = 1.0000e-04
Validation rmse = 0.888782
Epoch 29
Loss = 6.7448e-01, PNorm = 43.5487, GNorm = 6.1538, lr_0 = 1.0000e-04
Validation rmse = 0.892854
Model 0 best validation rmse = 0.865672 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.792068
Ensemble test rmse = 0.792068
1-fold cross validation
	Seed 0 ==> test rmse = 0.792068
Overall test rmse = 0.792068 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6588e+00, PNorm = 42.7440, GNorm = 0.9241, lr_0 = 5.5000e-04
Validation rmse = 1.464158
Epoch 1
Loss = 1.4012e+00, PNorm = 42.7594, GNorm = 1.0198, lr_0 = 1.0000e-03
Validation rmse = 1.429819
Epoch 2
Loss = 1.3430e+00, PNorm = 42.7871, GNorm = 0.7789, lr_0 = 9.2797e-04
Validation rmse = 1.354808
Epoch 3
Loss = 1.2801e+00, PNorm = 42.8217, GNorm = 2.1450, lr_0 = 8.6112e-04
Validation rmse = 1.303625
Epoch 4
Loss = 1.2165e+00, PNorm = 42.8631, GNorm = 1.8710, lr_0 = 7.9909e-04
Validation rmse = 1.246505
Epoch 5
Loss = 1.0651e+00, PNorm = 42.9117, GNorm = 0.7125, lr_0 = 7.4153e-04
Loss = 1.1823e+00, PNorm = 42.9698, GNorm = 5.1635, lr_0 = 6.8812e-04
Validation rmse = 1.185820
Epoch 6
Loss = 1.1645e+00, PNorm = 43.0199, GNorm = 4.3397, lr_0 = 6.3855e-04
Validation rmse = 1.249227
Epoch 7
Loss = 1.0635e+00, PNorm = 43.0740, GNorm = 1.5195, lr_0 = 5.9255e-04
Validation rmse = 1.103650
Epoch 8
Loss = 1.0080e+00, PNorm = 43.1282, GNorm = 1.3059, lr_0 = 5.4987e-04
Validation rmse = 1.029632
Epoch 9
Loss = 9.5444e-01, PNorm = 43.1859, GNorm = 2.6324, lr_0 = 5.1026e-04
Validation rmse = 1.002133
Epoch 10
Loss = 8.6132e-01, PNorm = 43.2361, GNorm = 2.4782, lr_0 = 4.7351e-04
Loss = 8.7114e-01, PNorm = 43.2790, GNorm = 5.6103, lr_0 = 4.3940e-04
Validation rmse = 0.946611
Epoch 11
Loss = 8.5377e-01, PNorm = 43.3130, GNorm = 8.1256, lr_0 = 4.0775e-04
Validation rmse = 0.975212
Epoch 12
Loss = 8.3021e-01, PNorm = 43.3430, GNorm = 6.2381, lr_0 = 3.7837e-04
Validation rmse = 0.926935
Epoch 13
Loss = 7.7546e-01, PNorm = 43.3702, GNorm = 1.3334, lr_0 = 3.5112e-04
Validation rmse = 0.908008
Epoch 14
Loss = 7.4963e-01, PNorm = 43.3956, GNorm = 5.1549, lr_0 = 3.2583e-04
Validation rmse = 0.911231
Epoch 15
Loss = 8.0446e-01, PNorm = 43.4185, GNorm = 5.3222, lr_0 = 3.0236e-04
Loss = 7.2597e-01, PNorm = 43.4388, GNorm = 2.2115, lr_0 = 2.8058e-04
Validation rmse = 0.902363
Epoch 16
Loss = 7.3519e-01, PNorm = 43.4569, GNorm = 2.4216, lr_0 = 2.6037e-04
Validation rmse = 0.935088
Epoch 17
Loss = 7.3111e-01, PNorm = 43.4725, GNorm = 2.2163, lr_0 = 2.4161e-04
Validation rmse = 0.947224
Epoch 18
Loss = 7.9019e-01, PNorm = 43.4868, GNorm = 6.1689, lr_0 = 2.2421e-04
Validation rmse = 0.908286
Epoch 19
Loss = 7.2042e-01, PNorm = 43.5017, GNorm = 9.8870, lr_0 = 2.0806e-04
Validation rmse = 0.896333
Epoch 20
Loss = 7.2715e-01, PNorm = 43.5141, GNorm = 2.8336, lr_0 = 1.9307e-04
Loss = 6.6874e-01, PNorm = 43.5252, GNorm = 2.2745, lr_0 = 1.7916e-04
Validation rmse = 0.890589
Epoch 21
Loss = 6.5881e-01, PNorm = 43.5361, GNorm = 6.1509, lr_0 = 1.6626e-04
Validation rmse = 0.896119
Epoch 22
Loss = 6.6882e-01, PNorm = 43.5469, GNorm = 8.9522, lr_0 = 1.5428e-04
Validation rmse = 0.894102
Epoch 23
Loss = 7.1107e-01, PNorm = 43.5568, GNorm = 4.1316, lr_0 = 1.4317e-04
Validation rmse = 0.903239
Epoch 24
Loss = 6.5937e-01, PNorm = 43.5658, GNorm = 2.3293, lr_0 = 1.3285e-04
Validation rmse = 0.884432
Epoch 25
Loss = 5.6254e-01, PNorm = 43.5739, GNorm = 3.4264, lr_0 = 1.2328e-04
Loss = 6.4078e-01, PNorm = 43.5820, GNorm = 9.6335, lr_0 = 1.1440e-04
Validation rmse = 0.887676
Epoch 26
Loss = 6.2943e-01, PNorm = 43.5897, GNorm = 6.9856, lr_0 = 1.0616e-04
Validation rmse = 0.887592
Epoch 27
Loss = 5.8613e-01, PNorm = 43.5965, GNorm = 7.5469, lr_0 = 1.0000e-04
Validation rmse = 0.885119
Epoch 28
Loss = 6.5138e-01, PNorm = 43.6030, GNorm = 2.5240, lr_0 = 1.0000e-04
Validation rmse = 0.882333
Epoch 29
Loss = 6.1867e-01, PNorm = 43.6095, GNorm = 6.1313, lr_0 = 1.0000e-04
Validation rmse = 0.884705
Model 0 best validation rmse = 0.882333 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.742660
Ensemble test rmse = 0.742660
1-fold cross validation
	Seed 0 ==> test rmse = 0.742660
Overall test rmse = 0.742660 +/- 0.000000
Elapsed time = 0:01:59
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.402838
Epoch 1
Loss = 1.3991e+00, PNorm = 42.7412, GNorm = 1.0669, lr_0 = 8.7143e-04
Validation rmse = 1.364989
Epoch 2
Loss = 1.3957e+00, PNorm = 42.7635, GNorm = 0.8439, lr_0 = 9.1030e-04
Validation rmse = 1.335010
Epoch 3
Loss = 1.3348e+00, PNorm = 42.7920, GNorm = 0.5653, lr_0 = 8.0940e-04
Validation rmse = 1.299787
Epoch 4
Validation rmse = 1.264987
Epoch 5
Loss = 1.2912e+00, PNorm = 42.8222, GNorm = 0.9741, lr_0 = 7.1969e-04
Validation rmse = 1.243705
Epoch 6
Loss = 1.2871e+00, PNorm = 42.8576, GNorm = 1.6602, lr_0 = 6.3992e-04
Validation rmse = 1.192251
Epoch 7
Loss = 1.1908e+00, PNorm = 42.8986, GNorm = 0.5086, lr_0 = 5.6899e-04
Validation rmse = 1.164155
Epoch 8
Loss = 1.1484e+00, PNorm = 42.9441, GNorm = 0.8602, lr_0 = 5.0592e-04
Validation rmse = 1.178679
Epoch 9
Validation rmse = 1.084143
Epoch 10
Loss = 1.0694e+00, PNorm = 42.9855, GNorm = 2.4817, lr_0 = 4.4984e-04
Validation rmse = 1.029420
Epoch 11
Loss = 1.0633e+00, PNorm = 43.0305, GNorm = 5.2690, lr_0 = 3.9998e-04
Validation rmse = 1.024254
Epoch 12
Loss = 1.0231e+00, PNorm = 43.0700, GNorm = 6.2370, lr_0 = 3.5565e-04
Validation rmse = 0.973742
Epoch 13
Loss = 1.0041e+00, PNorm = 43.1025, GNorm = 2.1274, lr_0 = 3.1623e-04
Validation rmse = 0.958116
Epoch 14
Validation rmse = 0.935008
Epoch 15
Loss = 8.3970e-01, PNorm = 43.1314, GNorm = 1.1490, lr_0 = 2.8118e-04
Validation rmse = 0.917510
Epoch 16
Loss = 8.8184e-01, PNorm = 43.1580, GNorm = 5.3816, lr_0 = 2.5001e-04
Validation rmse = 0.911711
Epoch 17
Loss = 8.7232e-01, PNorm = 43.1814, GNorm = 2.0674, lr_0 = 2.2230e-04
Validation rmse = 0.893962
Epoch 18
Loss = 8.4238e-01, PNorm = 43.2027, GNorm = 2.5644, lr_0 = 1.9766e-04
Validation rmse = 0.883919
Epoch 19
Validation rmse = 0.889001
Epoch 20
Loss = 6.5385e-01, PNorm = 43.2211, GNorm = 4.4391, lr_0 = 1.7575e-04
Validation rmse = 0.894778
Epoch 21
Loss = 7.9559e-01, PNorm = 43.2381, GNorm = 2.6893, lr_0 = 1.5627e-04
Validation rmse = 0.866586
Epoch 22
Loss = 7.5375e-01, PNorm = 43.2530, GNorm = 1.3923, lr_0 = 1.3895e-04
Validation rmse = 0.868709
Epoch 23
Loss = 7.3596e-01, PNorm = 43.2651, GNorm = 4.2509, lr_0 = 1.2355e-04
Validation rmse = 0.853891
Epoch 24
Validation rmse = 0.843569
Epoch 25
Loss = 8.2530e-01, PNorm = 43.2765, GNorm = 2.1860, lr_0 = 1.0985e-04
Validation rmse = 0.846945
Epoch 26
Loss = 7.4252e-01, PNorm = 43.2861, GNorm = 2.3649, lr_0 = 1.0000e-04
Validation rmse = 0.849822
Epoch 27
Loss = 7.4252e-01, PNorm = 43.2950, GNorm = 4.3861, lr_0 = 1.0000e-04
Validation rmse = 0.859035
Epoch 28
Loss = 6.9551e-01, PNorm = 43.3043, GNorm = 5.5185, lr_0 = 1.0000e-04
Validation rmse = 0.853747
Epoch 29
Validation rmse = 0.846054
Model 0 best validation rmse = 0.843569 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.743714
Ensemble test rmse = 0.743714
1-fold cross validation
	Seed 0 ==> test rmse = 0.743714
Overall test rmse = 0.743714 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.374577
Epoch 1
Loss = 1.4319e+00, PNorm = 42.7433, GNorm = 2.1020, lr_0 = 7.7500e-04
Validation rmse = 1.327167
Epoch 2
Loss = 1.4447e+00, PNorm = 42.7628, GNorm = 0.9674, lr_0 = 9.4019e-04
Validation rmse = 1.265201
Epoch 3
Loss = 1.3320e+00, PNorm = 42.7894, GNorm = 0.5150, lr_0 = 8.4834e-04
Validation rmse = 1.215262
Epoch 4
Loss = 1.2956e+00, PNorm = 42.8172, GNorm = 0.7186, lr_0 = 7.6547e-04
Validation rmse = 1.170530
Epoch 5
Loss = 1.2583e+00, PNorm = 42.8582, GNorm = 2.2200, lr_0 = 6.8363e-04
Validation rmse = 1.133971
Epoch 6
Loss = 1.2141e+00, PNorm = 42.9039, GNorm = 0.9987, lr_0 = 6.1685e-04
Validation rmse = 1.192028
Epoch 7
Loss = 1.1612e+00, PNorm = 42.9512, GNorm = 1.1172, lr_0 = 5.5659e-04
Validation rmse = 1.080688
Epoch 8
Validation rmse = 1.031776
Epoch 9
Loss = 1.0109e+00, PNorm = 42.9998, GNorm = 0.8440, lr_0 = 5.0222e-04
Validation rmse = 1.029802
Epoch 10
Loss = 1.0272e+00, PNorm = 43.0548, GNorm = 1.6395, lr_0 = 4.4852e-04
Validation rmse = 0.983580
Epoch 11
Loss = 9.7934e-01, PNorm = 43.0967, GNorm = 2.8679, lr_0 = 4.0471e-04
Validation rmse = 0.969916
Epoch 12
Loss = 9.6144e-01, PNorm = 43.1329, GNorm = 8.4813, lr_0 = 3.6517e-04
Validation rmse = 0.946497
Epoch 13
Loss = 9.3872e-01, PNorm = 43.1671, GNorm = 1.2500, lr_0 = 3.2950e-04
Validation rmse = 0.888942
Epoch 14
Loss = 8.5946e-01, PNorm = 43.1985, GNorm = 1.6580, lr_0 = 2.9731e-04
Validation rmse = 0.872600
Epoch 15
Loss = 8.3703e-01, PNorm = 43.2300, GNorm = 2.4515, lr_0 = 2.6553e-04
Validation rmse = 0.866289
Epoch 16
Validation rmse = 0.843560
Epoch 17
Loss = 7.9522e-01, PNorm = 43.2564, GNorm = 4.1306, lr_0 = 2.3959e-04
Validation rmse = 0.843443
Epoch 18
Loss = 7.9566e-01, PNorm = 43.2771, GNorm = 13.0437, lr_0 = 2.1618e-04
Validation rmse = 0.820215
Epoch 19
Loss = 7.6339e-01, PNorm = 43.2957, GNorm = 4.6444, lr_0 = 1.9506e-04
Validation rmse = 0.811406
Epoch 20
Loss = 7.2040e-01, PNorm = 43.3142, GNorm = 5.4561, lr_0 = 1.7421e-04
Validation rmse = 0.808217
Epoch 21
Loss = 7.2418e-01, PNorm = 43.3305, GNorm = 4.8545, lr_0 = 1.5719e-04
Validation rmse = 0.795769
Epoch 22
Loss = 7.3140e-01, PNorm = 43.3445, GNorm = 14.7737, lr_0 = 1.4184e-04
Validation rmse = 0.814157
Epoch 23
Loss = 7.1586e-01, PNorm = 43.3564, GNorm = 10.3685, lr_0 = 1.2798e-04
Loss = 6.7196e-01, PNorm = 43.3575, GNorm = 3.1275, lr_0 = 1.2667e-04
Validation rmse = 0.784743
Epoch 24
Validation rmse = 0.783346
Epoch 25
Loss = 5.5024e-01, PNorm = 43.3683, GNorm = 4.3027, lr_0 = 1.1430e-04
Validation rmse = 0.786541
Epoch 26
Loss = 7.4199e-01, PNorm = 43.3774, GNorm = 3.2345, lr_0 = 1.0313e-04
Validation rmse = 0.778344
Epoch 27
Loss = 6.2945e-01, PNorm = 43.3864, GNorm = 2.0502, lr_0 = 1.0000e-04
Validation rmse = 0.775825
Epoch 28
Loss = 6.8354e-01, PNorm = 43.3951, GNorm = 2.3181, lr_0 = 1.0000e-04
Validation rmse = 0.771442
Epoch 29
Loss = 6.3633e-01, PNorm = 43.4043, GNorm = 6.1076, lr_0 = 1.0000e-04
Validation rmse = 0.768219
Model 0 best validation rmse = 0.768219 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.757977
Ensemble test rmse = 0.757977
1-fold cross validation
	Seed 0 ==> test rmse = 0.757977
Overall test rmse = 0.757977 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.372215
Epoch 1
Loss = 1.5250e+00, PNorm = 42.7438, GNorm = 3.2972, lr_0 = 7.0000e-04
Validation rmse = 1.318958
Epoch 2
Loss = 1.4488e+00, PNorm = 42.7637, GNorm = 0.4517, lr_0 = 9.6411e-04
Validation rmse = 1.308893
Epoch 3
Loss = 1.2518e+00, PNorm = 42.7919, GNorm = 0.7861, lr_0 = 8.7192e-04
Validation rmse = 1.250322
Epoch 4
Loss = 1.2929e+00, PNorm = 42.8187, GNorm = 0.7885, lr_0 = 7.9578e-04
Validation rmse = 1.207064
Epoch 5
Loss = 1.2369e+00, PNorm = 42.8554, GNorm = 1.8478, lr_0 = 7.1969e-04
Validation rmse = 1.137330
Epoch 6
Loss = 1.2300e+00, PNorm = 42.8915, GNorm = 3.7569, lr_0 = 6.5684e-04
Validation rmse = 1.107441
Epoch 7
Loss = 1.1563e+00, PNorm = 42.9332, GNorm = 0.8365, lr_0 = 5.9948e-04
Validation rmse = 1.043471
Epoch 8
Loss = 1.1219e+00, PNorm = 42.9837, GNorm = 1.6740, lr_0 = 5.4216e-04
Validation rmse = 1.031018
Epoch 9
Loss = 1.0687e+00, PNorm = 43.0324, GNorm = 3.0597, lr_0 = 4.9482e-04
Validation rmse = 0.962243
Epoch 10
Loss = 1.0378e+00, PNorm = 43.0883, GNorm = 1.0524, lr_0 = 4.4750e-04
Validation rmse = 0.875733
Epoch 11
Loss = 9.6597e-01, PNorm = 43.1358, GNorm = 5.4752, lr_0 = 4.0842e-04
Validation rmse = 0.854567
Epoch 12
Loss = 9.2490e-01, PNorm = 43.1745, GNorm = 10.3907, lr_0 = 3.7276e-04
Validation rmse = 0.926847
Epoch 13
Loss = 8.4634e-01, PNorm = 43.2090, GNorm = 7.6003, lr_0 = 3.3711e-04
Validation rmse = 0.810834
Epoch 14
Loss = 8.0433e-01, PNorm = 43.2378, GNorm = 1.9262, lr_0 = 3.0768e-04
Validation rmse = 0.833960
Epoch 15
Loss = 8.2869e-01, PNorm = 43.2676, GNorm = 6.1204, lr_0 = 2.7826e-04
Validation rmse = 0.818572
Epoch 16
Loss = 7.9605e-01, PNorm = 43.2895, GNorm = 3.7332, lr_0 = 2.5396e-04
Validation rmse = 0.784959
Epoch 17
Loss = 7.2956e-01, PNorm = 43.3100, GNorm = 3.3961, lr_0 = 2.3178e-04
Validation rmse = 0.765752
Epoch 18
Loss = 7.2888e-01, PNorm = 43.3307, GNorm = 5.2582, lr_0 = 2.0962e-04
Validation rmse = 0.777713
Epoch 19
Loss = 7.3180e-01, PNorm = 43.3456, GNorm = 1.4833, lr_0 = 1.9131e-04
Validation rmse = 0.809539
Epoch 20
Loss = 7.1047e-01, PNorm = 43.3605, GNorm = 5.7936, lr_0 = 1.7302e-04
Validation rmse = 0.745173
Epoch 21
Loss = 6.9902e-01, PNorm = 43.3727, GNorm = 14.1468, lr_0 = 1.5791e-04
Loss = 8.2512e-01, PNorm = 43.3739, GNorm = 16.0000, lr_0 = 1.5647e-04
Validation rmse = 0.761776
Epoch 22
Loss = 6.9055e-01, PNorm = 43.3849, GNorm = 4.4564, lr_0 = 1.4281e-04
Validation rmse = 0.826002
Epoch 23
Loss = 6.8497e-01, PNorm = 43.3940, GNorm = 8.0393, lr_0 = 1.3034e-04
Validation rmse = 0.779461
Epoch 24
Validation rmse = 0.752567
Epoch 25
Loss = 6.2986e-01, PNorm = 43.4031, GNorm = 2.1159, lr_0 = 1.1788e-04
Validation rmse = 0.770573
Epoch 26
Loss = 6.6550e-01, PNorm = 43.4115, GNorm = 6.0110, lr_0 = 1.0758e-04
Validation rmse = 0.749340
Epoch 27
Loss = 7.0076e-01, PNorm = 43.4195, GNorm = 14.1318, lr_0 = 1.0000e-04
Validation rmse = 0.738307
Epoch 28
Loss = 7.1785e-01, PNorm = 43.4256, GNorm = 17.5934, lr_0 = 1.0000e-04
Validation rmse = 0.738554
Epoch 29
Loss = 6.9955e-01, PNorm = 43.4319, GNorm = 9.7735, lr_0 = 1.0000e-04
Validation rmse = 0.771703
Model 0 best validation rmse = 0.738307 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.745046
Ensemble test rmse = 0.745046
1-fold cross validation
	Seed 0 ==> test rmse = 0.745046
Overall test rmse = 0.745046 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6845e+00, PNorm = 42.7418, GNorm = 1.2238, lr_0 = 5.9500e-04
Loss = 1.4322e+00, PNorm = 42.7419, GNorm = 1.3536, lr_0 = 6.4000e-04
Validation rmse = 1.407741
Epoch 1
Loss = 1.4180e+00, PNorm = 42.7556, GNorm = 0.5469, lr_0 = 9.8369e-04
Loss = 1.3140e+00, PNorm = 42.7579, GNorm = 0.7443, lr_0 = 9.7563e-04
Validation rmse = 1.390685
Epoch 2
Loss = 1.3505e+00, PNorm = 42.7821, GNorm = 1.5549, lr_0 = 8.9861e-04
Validation rmse = 1.341245
Epoch 3
Loss = 1.3059e+00, PNorm = 42.8103, GNorm = 0.8135, lr_0 = 8.2767e-04
Validation rmse = 1.272038
Epoch 4
Loss = 1.2756e+00, PNorm = 42.8490, GNorm = 3.6237, lr_0 = 7.5609e-04
Validation rmse = 1.241406
Epoch 5
Loss = 1.2067e+00, PNorm = 42.8944, GNorm = 2.9070, lr_0 = 6.9069e-04
Validation rmse = 1.204724
Epoch 6
Loss = 1.1747e+00, PNorm = 42.9427, GNorm = 0.8866, lr_0 = 6.3617e-04
Validation rmse = 1.100598
Epoch 7
Loss = 1.1016e+00, PNorm = 42.9964, GNorm = 2.0507, lr_0 = 5.8115e-04
Validation rmse = 1.187140
Epoch 8
Loss = 1.1387e+00, PNorm = 43.0453, GNorm = 6.2251, lr_0 = 5.3527e-04
Validation rmse = 1.067715
Epoch 9
Loss = 1.0796e+00, PNorm = 43.0940, GNorm = 1.8573, lr_0 = 4.8897e-04
Validation rmse = 0.985401
Epoch 10
Loss = 9.6639e-01, PNorm = 43.1438, GNorm = 2.6772, lr_0 = 4.4668e-04
Validation rmse = 0.922141
Epoch 11
Loss = 9.5789e-01, PNorm = 43.1901, GNorm = 1.1722, lr_0 = 4.1142e-04
Validation rmse = 0.890739
Epoch 12
Loss = 9.0216e-01, PNorm = 43.2355, GNorm = 1.3633, lr_0 = 3.7584e-04
Validation rmse = 0.855247
Epoch 13
Loss = 8.2917e-01, PNorm = 43.2725, GNorm = 1.3443, lr_0 = 3.4617e-04
Validation rmse = 0.825874
Epoch 14
Loss = 8.6037e-01, PNorm = 43.3053, GNorm = 3.7454, lr_0 = 3.1623e-04
Validation rmse = 0.808041
Epoch 15
Loss = 7.9191e-01, PNorm = 43.3396, GNorm = 4.1197, lr_0 = 2.8888e-04
Validation rmse = 0.787307
Epoch 16
Loss = 7.3935e-01, PNorm = 43.3671, GNorm = 1.9360, lr_0 = 2.6607e-04
Validation rmse = 0.775307
Epoch 17
Loss = 8.0579e-01, PNorm = 43.3921, GNorm = 3.2781, lr_0 = 2.4306e-04
Validation rmse = 0.770293
Epoch 18
Loss = 6.6752e-01, PNorm = 43.4117, GNorm = 3.6596, lr_0 = 2.2387e-04
Validation rmse = 0.798949
Epoch 19
Loss = 7.3712e-01, PNorm = 43.4307, GNorm = 3.0407, lr_0 = 2.0451e-04
Validation rmse = 0.757068
Epoch 20
Loss = 7.5234e-01, PNorm = 43.4513, GNorm = 10.0334, lr_0 = 1.8682e-04
Validation rmse = 0.751000
Epoch 21
Loss = 6.5851e-01, PNorm = 43.4646, GNorm = 2.4136, lr_0 = 1.7207e-04
Validation rmse = 0.749018
Epoch 22
Loss = 7.5154e-01, PNorm = 43.4777, GNorm = 6.6948, lr_0 = 1.5719e-04
Validation rmse = 0.738447
Epoch 23
Loss = 6.9252e-01, PNorm = 43.4900, GNorm = 2.0814, lr_0 = 1.4360e-04
Validation rmse = 0.734285
Epoch 24
Loss = 4.5237e-01, PNorm = 43.5012, GNorm = 7.3403, lr_0 = 1.3226e-04
Validation rmse = 0.732885
Epoch 25
Loss = 5.6436e-01, PNorm = 43.5112, GNorm = 4.9118, lr_0 = 1.2082e-04
Loss = 6.6139e-01, PNorm = 43.5206, GNorm = 4.8943, lr_0 = 1.1128e-04
Validation rmse = 0.723946
Epoch 26
Loss = 6.3169e-01, PNorm = 43.5287, GNorm = 3.0128, lr_0 = 1.0250e-04
Loss = 6.6019e-01, PNorm = 43.5295, GNorm = 8.8828, lr_0 = 1.0166e-04
Validation rmse = 0.723347
Epoch 27
Loss = 6.2941e-01, PNorm = 43.5371, GNorm = 5.3912, lr_0 = 1.0000e-04
Loss = 5.4849e-01, PNorm = 43.5379, GNorm = 6.1756, lr_0 = 1.0000e-04
Validation rmse = 0.720051
Epoch 28
Loss = 6.2236e-01, PNorm = 43.5458, GNorm = 11.7749, lr_0 = 1.0000e-04
Validation rmse = 0.719743
Epoch 29
Loss = 6.3348e-01, PNorm = 43.5521, GNorm = 2.4750, lr_0 = 1.0000e-04
Validation rmse = 0.711417
Model 0 best validation rmse = 0.711417 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.721865
Ensemble test rmse = 0.721865
1-fold cross validation
	Seed 0 ==> test rmse = 0.721865
Overall test rmse = 0.721865 +/- 0.000000
Elapsed time = 0:01:44
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7500e+00, PNorm = 42.7428, GNorm = 1.0896, lr_0 = 5.5000e-04
Validation rmse = 1.425275
Epoch 1
Loss = 1.4307e+00, PNorm = 42.7523, GNorm = 0.7593, lr_0 = 1.0000e-03
Validation rmse = 1.404211
Epoch 2
Loss = 1.3580e+00, PNorm = 42.7769, GNorm = 2.4743, lr_0 = 9.2106e-04
Validation rmse = 1.329487
Epoch 3
Loss = 1.2930e+00, PNorm = 42.8079, GNorm = 0.6145, lr_0 = 8.4834e-04
Validation rmse = 1.233197
Epoch 4
Loss = 1.2227e+00, PNorm = 42.8490, GNorm = 0.7172, lr_0 = 7.8137e-04
Validation rmse = 1.171944
Epoch 5
Loss = 1.2315e+00, PNorm = 42.8951, GNorm = 3.1635, lr_0 = 7.1969e-04
Validation rmse = 1.130364
Epoch 6
Loss = 1.1610e+00, PNorm = 42.9400, GNorm = 0.7414, lr_0 = 6.6784e-04
Validation rmse = 1.050745
Epoch 7
Loss = 1.1885e+00, PNorm = 42.9941, GNorm = 2.0209, lr_0 = 6.1512e-04
Validation rmse = 0.993581
Epoch 8
Loss = 9.8284e-01, PNorm = 43.0544, GNorm = 0.9088, lr_0 = 5.6656e-04
Loss = 1.0156e+00, PNorm = 43.1083, GNorm = 5.7429, lr_0 = 5.2575e-04
Loss = 9.6052e-01, PNorm = 43.1135, GNorm = 3.7246, lr_0 = 5.2183e-04
Validation rmse = 0.897373
Epoch 9
Loss = 9.5695e-01, PNorm = 43.1641, GNorm = 2.9839, lr_0 = 4.8424e-04
Validation rmse = 0.878575
Epoch 10
Loss = 9.2002e-01, PNorm = 43.2121, GNorm = 2.0502, lr_0 = 4.4602e-04
Validation rmse = 0.844839
Epoch 11
Loss = 8.5271e-01, PNorm = 43.2517, GNorm = 2.9734, lr_0 = 4.1389e-04
Validation rmse = 0.784513
Epoch 12
Loss = 8.0418e-01, PNorm = 43.2898, GNorm = 1.9654, lr_0 = 3.8121e-04
Validation rmse = 0.879292
Epoch 13
Loss = 9.3330e-01, PNorm = 43.3134, GNorm = 13.6918, lr_0 = 3.5112e-04
Validation rmse = 0.855444
Epoch 14
Loss = 8.1110e-01, PNorm = 43.3380, GNorm = 3.7367, lr_0 = 3.2340e-04
Validation rmse = 0.793340
Epoch 15
Loss = 7.4162e-01, PNorm = 43.3641, GNorm = 8.7302, lr_0 = 2.9787e-04
Validation rmse = 0.748932
Epoch 16
Loss = 6.8702e-01, PNorm = 43.3860, GNorm = 4.6550, lr_0 = 2.7641e-04
Loss = 7.9009e-01, PNorm = 43.4018, GNorm = 11.1058, lr_0 = 2.5650e-04
Loss = 5.7903e-01, PNorm = 43.4034, GNorm = 3.4362, lr_0 = 2.5459e-04
Validation rmse = 0.782529
Epoch 17
Loss = 7.2150e-01, PNorm = 43.4184, GNorm = 6.5276, lr_0 = 2.3625e-04
Validation rmse = 0.743004
Epoch 18
Loss = 6.9335e-01, PNorm = 43.4339, GNorm = 2.7385, lr_0 = 2.1760e-04
Validation rmse = 0.741406
Epoch 19
Loss = 6.9055e-01, PNorm = 43.4485, GNorm = 1.7019, lr_0 = 2.0042e-04
Validation rmse = 0.745512
Epoch 20
Loss = 7.2269e-01, PNorm = 43.4619, GNorm = 2.3287, lr_0 = 1.8460e-04
Validation rmse = 0.730931
Epoch 21
Loss = 6.9126e-01, PNorm = 43.4745, GNorm = 6.4182, lr_0 = 1.7003e-04
Validation rmse = 0.725261
Epoch 22
Loss = 6.6119e-01, PNorm = 43.4851, GNorm = 2.8432, lr_0 = 1.5778e-04
Validation rmse = 0.732189
Epoch 23
Loss = 6.5484e-01, PNorm = 43.4945, GNorm = 7.6717, lr_0 = 1.4532e-04
Validation rmse = 0.749887
Epoch 24
Loss = 6.1887e-01, PNorm = 43.5023, GNorm = 7.4007, lr_0 = 1.3385e-04
Validation rmse = 0.715656
Epoch 25
Loss = 5.9222e-01, PNorm = 43.5102, GNorm = 3.1287, lr_0 = 1.2328e-04
Loss = 6.4982e-01, PNorm = 43.5173, GNorm = 8.1974, lr_0 = 1.1440e-04
Loss = 5.6714e-01, PNorm = 43.5179, GNorm = 8.9355, lr_0 = 1.1355e-04
Validation rmse = 0.725646
Epoch 26
Loss = 6.1920e-01, PNorm = 43.5243, GNorm = 4.3906, lr_0 = 1.0537e-04
Validation rmse = 0.715537
Epoch 27
Loss = 6.1979e-01, PNorm = 43.5300, GNorm = 4.0747, lr_0 = 1.0000e-04
Validation rmse = 0.712593
Epoch 28
Loss = 6.1755e-01, PNorm = 43.5357, GNorm = 5.2077, lr_0 = 1.0000e-04
Validation rmse = 0.709407
Epoch 29
Loss = 5.8147e-01, PNorm = 43.5425, GNorm = 1.9846, lr_0 = 1.0000e-04
Validation rmse = 0.716953
Model 0 best validation rmse = 0.709407 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.702308
Ensemble test rmse = 0.702308
1-fold cross validation
	Seed 0 ==> test rmse = 0.702308
Overall test rmse = 0.702308 +/- 0.000000
Elapsed time = 0:01:51
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6833e+00, PNorm = 42.7432, GNorm = 2.3409, lr_0 = 5.5000e-04
Validation rmse = 1.380866
Epoch 1
Loss = 1.4041e+00, PNorm = 42.7538, GNorm = 0.5739, lr_0 = 1.0000e-03
Validation rmse = 1.330090
Epoch 2
Loss = 1.3380e+00, PNorm = 42.7787, GNorm = 1.5462, lr_0 = 9.2797e-04
Validation rmse = 1.265369
Epoch 3
Loss = 1.2906e+00, PNorm = 42.8042, GNorm = 0.8524, lr_0 = 8.6112e-04
Validation rmse = 1.196325
Epoch 4
Loss = 1.2863e+00, PNorm = 42.8385, GNorm = 2.5539, lr_0 = 7.9909e-04
Validation rmse = 1.137781
Epoch 5
Loss = 1.1966e+00, PNorm = 42.8790, GNorm = 1.3345, lr_0 = 7.4153e-04
Loss = 1.1865e+00, PNorm = 42.9253, GNorm = 0.7772, lr_0 = 6.8812e-04
Validation rmse = 1.160723
Epoch 6
Loss = 1.1620e+00, PNorm = 42.9771, GNorm = 1.7737, lr_0 = 6.3855e-04
Validation rmse = 1.016888
Epoch 7
Loss = 1.0720e+00, PNorm = 43.0295, GNorm = 1.1780, lr_0 = 5.9255e-04
Validation rmse = 0.931036
Epoch 8
Loss = 1.0665e+00, PNorm = 43.0889, GNorm = 1.8899, lr_0 = 5.4987e-04
Validation rmse = 0.909855
Epoch 9
Loss = 9.4514e-01, PNorm = 43.1401, GNorm = 5.4417, lr_0 = 5.1026e-04
Validation rmse = 0.831768
Epoch 10
Loss = 9.7097e-01, PNorm = 43.1856, GNorm = 4.8208, lr_0 = 4.7351e-04
Loss = 9.0006e-01, PNorm = 43.2293, GNorm = 6.7791, lr_0 = 4.3940e-04
Validation rmse = 0.813299
Epoch 11
Loss = 8.2596e-01, PNorm = 43.2710, GNorm = 8.2163, lr_0 = 4.0775e-04
Validation rmse = 0.781014
Epoch 12
Loss = 8.3387e-01, PNorm = 43.3055, GNorm = 11.3533, lr_0 = 3.7837e-04
Validation rmse = 0.761155
Epoch 13
Loss = 8.0695e-01, PNorm = 43.3361, GNorm = 5.2818, lr_0 = 3.5112e-04
Validation rmse = 0.740667
Epoch 14
Loss = 7.7236e-01, PNorm = 43.3647, GNorm = 5.2851, lr_0 = 3.2583e-04
Validation rmse = 0.746703
Epoch 15
Loss = 7.8500e-01, PNorm = 43.3905, GNorm = 9.3197, lr_0 = 3.0236e-04
Loss = 7.0350e-01, PNorm = 43.4159, GNorm = 2.2110, lr_0 = 2.8058e-04
Validation rmse = 0.705835
Epoch 16
Loss = 7.0232e-01, PNorm = 43.4352, GNorm = 6.0593, lr_0 = 2.6037e-04
Validation rmse = 0.720297
Epoch 17
Loss = 7.1980e-01, PNorm = 43.4537, GNorm = 8.6127, lr_0 = 2.4161e-04
Validation rmse = 0.695085
Epoch 18
Loss = 6.5443e-01, PNorm = 43.4703, GNorm = 4.8873, lr_0 = 2.2421e-04
Validation rmse = 0.695781
Epoch 19
Loss = 6.0656e-01, PNorm = 43.4856, GNorm = 8.9679, lr_0 = 2.0806e-04
Validation rmse = 0.689451
Epoch 20
Loss = 6.6400e-01, PNorm = 43.5003, GNorm = 3.9395, lr_0 = 1.9307e-04
Loss = 6.6801e-01, PNorm = 43.5121, GNorm = 2.3875, lr_0 = 1.7916e-04
Validation rmse = 0.706090
Epoch 21
Loss = 6.5404e-01, PNorm = 43.5214, GNorm = 8.7469, lr_0 = 1.6626e-04
Validation rmse = 0.691493
Epoch 22
Loss = 5.8657e-01, PNorm = 43.5325, GNorm = 7.1482, lr_0 = 1.5428e-04
Validation rmse = 0.685344
Epoch 23
Loss = 5.5837e-01, PNorm = 43.5427, GNorm = 1.6380, lr_0 = 1.4317e-04
Validation rmse = 0.683154
Epoch 24
Loss = 6.1017e-01, PNorm = 43.5516, GNorm = 19.7177, lr_0 = 1.3285e-04
Validation rmse = 0.699406
Epoch 25
Loss = 6.7727e-01, PNorm = 43.5597, GNorm = 12.6808, lr_0 = 1.2328e-04
Loss = 6.2204e-01, PNorm = 43.5663, GNorm = 10.5009, lr_0 = 1.1440e-04
Validation rmse = 0.697492
Epoch 26
Loss = 6.2469e-01, PNorm = 43.5721, GNorm = 12.7141, lr_0 = 1.0616e-04
Validation rmse = 0.673951
Epoch 27
Loss = 5.8142e-01, PNorm = 43.5785, GNorm = 2.6678, lr_0 = 1.0000e-04
Validation rmse = 0.680353
Epoch 28
Loss = 6.0520e-01, PNorm = 43.5842, GNorm = 7.9787, lr_0 = 1.0000e-04
Validation rmse = 0.673089
Epoch 29
Loss = 5.6721e-01, PNorm = 43.5904, GNorm = 6.7746, lr_0 = 1.0000e-04
Validation rmse = 0.672802
Model 0 best validation rmse = 0.672802 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.674213
Ensemble test rmse = 0.674213
1-fold cross validation
	Seed 0 ==> test rmse = 0.674213
Overall test rmse = 0.674213 +/- 0.000000
Elapsed time = 0:01:59
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 999 | train size = 799 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.286321
Epoch 1
Loss = 1.4352e+00, PNorm = 42.7425, GNorm = 1.1993, lr_0 = 8.7143e-04
Validation rmse = 1.221146
Epoch 2
Loss = 1.3993e+00, PNorm = 42.7641, GNorm = 0.5016, lr_0 = 9.1030e-04
Validation rmse = 1.209425
Epoch 3
Loss = 1.3799e+00, PNorm = 42.7891, GNorm = 0.7017, lr_0 = 8.0940e-04
Validation rmse = 1.242381
Epoch 4
Validation rmse = 1.146312
Epoch 5
Loss = 1.2769e+00, PNorm = 42.8125, GNorm = 0.6518, lr_0 = 7.1969e-04
Validation rmse = 1.105493
Epoch 6
Loss = 1.2584e+00, PNorm = 42.8420, GNorm = 0.5976, lr_0 = 6.3992e-04
Validation rmse = 1.059609
Epoch 7
Loss = 1.2455e+00, PNorm = 42.8790, GNorm = 0.7056, lr_0 = 5.6899e-04
Validation rmse = 1.026569
Epoch 8
Loss = 1.1590e+00, PNorm = 42.9224, GNorm = 1.7627, lr_0 = 5.0592e-04
Validation rmse = 1.003768
Epoch 9
Validation rmse = 1.005954
Epoch 10
Loss = 1.1272e+00, PNorm = 42.9601, GNorm = 4.0324, lr_0 = 4.4984e-04
Validation rmse = 0.972706
Epoch 11
Loss = 1.0985e+00, PNorm = 42.9942, GNorm = 3.0980, lr_0 = 3.9998e-04
Validation rmse = 0.925789
Epoch 12
Loss = 1.0427e+00, PNorm = 43.0288, GNorm = 5.2596, lr_0 = 3.5565e-04
Validation rmse = 0.913125
Epoch 13
Loss = 9.9384e-01, PNorm = 43.0647, GNorm = 1.3397, lr_0 = 3.1623e-04
Validation rmse = 0.890062
Epoch 14
Validation rmse = 0.876897
Epoch 15
Loss = 8.8707e-01, PNorm = 43.0999, GNorm = 1.8892, lr_0 = 2.8118e-04
Validation rmse = 0.862347
Epoch 16
Loss = 9.5982e-01, PNorm = 43.1286, GNorm = 7.6342, lr_0 = 2.5001e-04
Validation rmse = 0.850550
Epoch 17
Loss = 9.0490e-01, PNorm = 43.1534, GNorm = 2.1703, lr_0 = 2.2230e-04
Validation rmse = 0.849036
Epoch 18
Loss = 8.7535e-01, PNorm = 43.1732, GNorm = 7.8799, lr_0 = 1.9766e-04
Validation rmse = 0.834755
Epoch 19
Validation rmse = 0.834910
Epoch 20
Loss = 7.8751e-01, PNorm = 43.1911, GNorm = 3.3065, lr_0 = 1.7575e-04
Validation rmse = 0.825143
Epoch 21
Loss = 8.6322e-01, PNorm = 43.2063, GNorm = 3.0611, lr_0 = 1.5627e-04
Validation rmse = 0.815888
Epoch 22
Loss = 7.7803e-01, PNorm = 43.2206, GNorm = 9.2253, lr_0 = 1.3895e-04
Validation rmse = 0.819361
Epoch 23
Loss = 8.0461e-01, PNorm = 43.2333, GNorm = 2.0565, lr_0 = 1.2355e-04
Validation rmse = 0.817822
Epoch 24
Validation rmse = 0.809227
Epoch 25
Loss = 6.6192e-01, PNorm = 43.2439, GNorm = 1.8967, lr_0 = 1.0985e-04
Validation rmse = 0.805151
Epoch 26
Loss = 7.7340e-01, PNorm = 43.2538, GNorm = 8.3107, lr_0 = 1.0000e-04
Validation rmse = 0.801602
Epoch 27
Loss = 8.0478e-01, PNorm = 43.2627, GNorm = 7.3160, lr_0 = 1.0000e-04
Validation rmse = 0.837298
Epoch 28
Loss = 7.7378e-01, PNorm = 43.2709, GNorm = 5.5116, lr_0 = 1.0000e-04
Validation rmse = 0.804709
Epoch 29
Validation rmse = 0.791713
Model 0 best validation rmse = 0.791713 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.928184
Ensemble test rmse = 0.928184
1-fold cross validation
	Seed 0 ==> test rmse = 0.928184
Overall test rmse = 0.928184 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,099 | train size = 879 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.355089
Epoch 1
Loss = 1.4592e+00, PNorm = 42.7418, GNorm = 0.9225, lr_0 = 7.7500e-04
Validation rmse = 1.337002
Epoch 2
Loss = 1.3252e+00, PNorm = 42.7605, GNorm = 0.6464, lr_0 = 9.4019e-04
Validation rmse = 1.256757
Epoch 3
Loss = 1.3138e+00, PNorm = 42.7871, GNorm = 0.4388, lr_0 = 8.4834e-04
Validation rmse = 1.200990
Epoch 4
Loss = 1.2974e+00, PNorm = 42.8188, GNorm = 0.5852, lr_0 = 7.6547e-04
Validation rmse = 1.148708
Epoch 5
Loss = 1.2834e+00, PNorm = 42.8598, GNorm = 4.3221, lr_0 = 6.8363e-04
Validation rmse = 1.123000
Epoch 6
Loss = 1.2079e+00, PNorm = 42.8949, GNorm = 1.6025, lr_0 = 6.1685e-04
Validation rmse = 1.108806
Epoch 7
Loss = 1.1570e+00, PNorm = 42.9365, GNorm = 2.4033, lr_0 = 5.5659e-04
Validation rmse = 1.131293
Epoch 8
Validation rmse = 1.105164
Epoch 9
Loss = 9.4489e-01, PNorm = 42.9833, GNorm = 2.1018, lr_0 = 5.0222e-04
Validation rmse = 1.035201
Epoch 10
Loss = 1.0011e+00, PNorm = 43.0348, GNorm = 1.4890, lr_0 = 4.4852e-04
Validation rmse = 1.095744
Epoch 11
Loss = 9.6794e-01, PNorm = 43.0769, GNorm = 3.4681, lr_0 = 4.0471e-04
Validation rmse = 0.971711
Epoch 12
Loss = 9.3022e-01, PNorm = 43.1131, GNorm = 1.5814, lr_0 = 3.6517e-04
Validation rmse = 1.098068
Epoch 13
Loss = 9.1298e-01, PNorm = 43.1447, GNorm = 6.0010, lr_0 = 3.2950e-04
Validation rmse = 0.959790
Epoch 14
Loss = 8.6364e-01, PNorm = 43.1734, GNorm = 3.6061, lr_0 = 2.9731e-04
Validation rmse = 1.023791
Epoch 15
Loss = 8.3570e-01, PNorm = 43.1999, GNorm = 5.1951, lr_0 = 2.6553e-04
Validation rmse = 0.946608
Epoch 16
Validation rmse = 1.067519
Epoch 17
Loss = 7.5611e-01, PNorm = 43.2221, GNorm = 14.0409, lr_0 = 2.3959e-04
Validation rmse = 0.936203
Epoch 18
Loss = 7.9219e-01, PNorm = 43.2422, GNorm = 8.7387, lr_0 = 2.1618e-04
Validation rmse = 0.893599
Epoch 19
Loss = 8.9450e-01, PNorm = 43.2590, GNorm = 1.6099, lr_0 = 1.9506e-04
Validation rmse = 0.897844
Epoch 20
Loss = 7.3178e-01, PNorm = 43.2749, GNorm = 1.8945, lr_0 = 1.7421e-04
Validation rmse = 0.940570
Epoch 21
Loss = 7.5174e-01, PNorm = 43.2881, GNorm = 4.3529, lr_0 = 1.5719e-04
Validation rmse = 0.940399
Epoch 22
Loss = 7.2861e-01, PNorm = 43.2999, GNorm = 9.1945, lr_0 = 1.4184e-04
Validation rmse = 0.891891
Epoch 23
Loss = 7.1310e-01, PNorm = 43.3106, GNorm = 5.1917, lr_0 = 1.2798e-04
Loss = 8.3782e-01, PNorm = 43.3116, GNorm = 10.3499, lr_0 = 1.2667e-04
Validation rmse = 0.875855
Epoch 24
Validation rmse = 0.907696
Epoch 25
Loss = 6.2237e-01, PNorm = 43.3208, GNorm = 2.2246, lr_0 = 1.1430e-04
Validation rmse = 0.890803
Epoch 26
Loss = 7.2625e-01, PNorm = 43.3296, GNorm = 2.9298, lr_0 = 1.0313e-04
Validation rmse = 0.897805
Epoch 27
Loss = 6.8407e-01, PNorm = 43.3376, GNorm = 2.6489, lr_0 = 1.0000e-04
Validation rmse = 0.927987
Epoch 28
Loss = 6.8495e-01, PNorm = 43.3457, GNorm = 2.4522, lr_0 = 1.0000e-04
Validation rmse = 0.900012
Epoch 29
Loss = 6.8266e-01, PNorm = 43.3543, GNorm = 8.5985, lr_0 = 1.0000e-04
Validation rmse = 0.904060
Model 0 best validation rmse = 0.875855 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.685303
Ensemble test rmse = 0.685303
1-fold cross validation
	Seed 0 ==> test rmse = 0.685303
Overall test rmse = 0.685303 +/- 0.000000
Elapsed time = 0:01:28
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,199 | train size = 959 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.233554
Epoch 1
Loss = 1.4258e+00, PNorm = 42.7403, GNorm = 1.1896, lr_0 = 7.0000e-04
Validation rmse = 1.219394
Epoch 2
Loss = 1.3810e+00, PNorm = 42.7518, GNorm = 0.5614, lr_0 = 9.6411e-04
Validation rmse = 1.164628
Epoch 3
Loss = 1.3533e+00, PNorm = 42.7775, GNorm = 0.4849, lr_0 = 8.7192e-04
Validation rmse = 1.119396
Epoch 4
Loss = 1.2576e+00, PNorm = 42.8030, GNorm = 1.4195, lr_0 = 7.9578e-04
Validation rmse = 1.141413
Epoch 5
Loss = 1.2525e+00, PNorm = 42.8372, GNorm = 1.1719, lr_0 = 7.1969e-04
Validation rmse = 1.079550
Epoch 6
Loss = 1.2625e+00, PNorm = 42.8715, GNorm = 0.7150, lr_0 = 6.5684e-04
Validation rmse = 1.104318
Epoch 7
Loss = 1.1458e+00, PNorm = 42.9128, GNorm = 0.7571, lr_0 = 5.9948e-04
Validation rmse = 0.962502
Epoch 8
Loss = 1.1276e+00, PNorm = 42.9633, GNorm = 1.7089, lr_0 = 5.4216e-04
Validation rmse = 0.874057
Epoch 9
Loss = 1.0373e+00, PNorm = 43.0101, GNorm = 3.3445, lr_0 = 4.9482e-04
Validation rmse = 0.832375
Epoch 10
Loss = 1.0310e+00, PNorm = 43.0588, GNorm = 3.9834, lr_0 = 4.4750e-04
Validation rmse = 0.794936
Epoch 11
Loss = 9.8328e-01, PNorm = 43.1012, GNorm = 4.1016, lr_0 = 4.0842e-04
Validation rmse = 0.771821
Epoch 12
Loss = 9.3649e-01, PNorm = 43.1395, GNorm = 6.2490, lr_0 = 3.7276e-04
Validation rmse = 0.744120
Epoch 13
Loss = 8.4374e-01, PNorm = 43.1768, GNorm = 5.2999, lr_0 = 3.3711e-04
Validation rmse = 0.720445
Epoch 14
Loss = 8.6204e-01, PNorm = 43.2043, GNorm = 4.5313, lr_0 = 3.0768e-04
Validation rmse = 0.724890
Epoch 15
Loss = 8.2195e-01, PNorm = 43.2339, GNorm = 2.4476, lr_0 = 2.7826e-04
Validation rmse = 0.691252
Epoch 16
Loss = 8.0880e-01, PNorm = 43.2559, GNorm = 1.9226, lr_0 = 2.5396e-04
Validation rmse = 0.681194
Epoch 17
Loss = 7.8503e-01, PNorm = 43.2790, GNorm = 4.8602, lr_0 = 2.3178e-04
Validation rmse = 0.685356
Epoch 18
Loss = 7.5962e-01, PNorm = 43.3008, GNorm = 9.0433, lr_0 = 2.0962e-04
Validation rmse = 0.662702
Epoch 19
Loss = 7.2838e-01, PNorm = 43.3189, GNorm = 8.9931, lr_0 = 1.9131e-04
Validation rmse = 0.653868
Epoch 20
Loss = 7.2999e-01, PNorm = 43.3367, GNorm = 6.8142, lr_0 = 1.7302e-04
Validation rmse = 0.646560
Epoch 21
Loss = 7.1718e-01, PNorm = 43.3517, GNorm = 6.2446, lr_0 = 1.5791e-04
Loss = 7.9144e-01, PNorm = 43.3528, GNorm = 10.0890, lr_0 = 1.5647e-04
Validation rmse = 0.676188
Epoch 22
Loss = 6.9606e-01, PNorm = 43.3649, GNorm = 7.3726, lr_0 = 1.4281e-04
Validation rmse = 0.640906
Epoch 23
Loss = 6.8859e-01, PNorm = 43.3771, GNorm = 7.4454, lr_0 = 1.3034e-04
Validation rmse = 0.650469
Epoch 24
Validation rmse = 0.668286
Epoch 25
Loss = 6.3357e-01, PNorm = 43.3882, GNorm = 12.7787, lr_0 = 1.1788e-04
Validation rmse = 0.639296
Epoch 26
Loss = 6.8266e-01, PNorm = 43.3977, GNorm = 4.1709, lr_0 = 1.0758e-04
Validation rmse = 0.631319
Epoch 27
Loss = 6.4356e-01, PNorm = 43.4062, GNorm = 5.5599, lr_0 = 1.0000e-04
Validation rmse = 0.632191
Epoch 28
Loss = 5.5426e-01, PNorm = 43.4145, GNorm = 3.1735, lr_0 = 1.0000e-04
Validation rmse = 0.634205
Epoch 29
Loss = 5.6334e-01, PNorm = 43.4229, GNorm = 5.8361, lr_0 = 1.0000e-04
Validation rmse = 0.637500
Model 0 best validation rmse = 0.631319 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.663866
Ensemble test rmse = 0.663866
1-fold cross validation
	Seed 0 ==> test rmse = 0.663866
Overall test rmse = 0.663866 +/- 0.000000
Elapsed time = 0:01:36
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,299 | train size = 1,039 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6744e+00, PNorm = 42.7377, GNorm = 0.9156, lr_0 = 5.9500e-04
Loss = 1.3877e+00, PNorm = 42.7375, GNorm = 1.2947, lr_0 = 6.4000e-04
Validation rmse = 1.347617
Epoch 1
Loss = 1.4258e+00, PNorm = 42.7480, GNorm = 1.0449, lr_0 = 9.8369e-04
Loss = 1.2619e+00, PNorm = 42.7501, GNorm = 0.8275, lr_0 = 9.7563e-04
Validation rmse = 1.268576
Epoch 2
Loss = 1.3448e+00, PNorm = 42.7733, GNorm = 0.5949, lr_0 = 8.9861e-04
Validation rmse = 1.191895
Epoch 3
Loss = 1.3133e+00, PNorm = 42.8018, GNorm = 3.3272, lr_0 = 8.2767e-04
Validation rmse = 1.133662
Epoch 4
Loss = 1.2551e+00, PNorm = 42.8409, GNorm = 1.9204, lr_0 = 7.5609e-04
Validation rmse = 1.077656
Epoch 5
Loss = 1.2067e+00, PNorm = 42.8884, GNorm = 3.0492, lr_0 = 6.9069e-04
Validation rmse = 1.038325
Epoch 6
Loss = 1.1414e+00, PNorm = 42.9422, GNorm = 0.7269, lr_0 = 6.3617e-04
Validation rmse = 0.967046
Epoch 7
Loss = 1.0455e+00, PNorm = 43.0053, GNorm = 1.3790, lr_0 = 5.8115e-04
Validation rmse = 1.019510
Epoch 8
Loss = 1.0551e+00, PNorm = 43.0477, GNorm = 2.7493, lr_0 = 5.3527e-04
Validation rmse = 0.915066
Epoch 9
Loss = 9.6381e-01, PNorm = 43.0895, GNorm = 7.1073, lr_0 = 4.8897e-04
Validation rmse = 0.887076
Epoch 10
Loss = 8.8007e-01, PNorm = 43.1281, GNorm = 7.0867, lr_0 = 4.4668e-04
Validation rmse = 0.852718
Epoch 11
Loss = 9.0524e-01, PNorm = 43.1598, GNorm = 11.5107, lr_0 = 4.1142e-04
Validation rmse = 0.900032
Epoch 12
Loss = 9.3169e-01, PNorm = 43.1887, GNorm = 1.4779, lr_0 = 3.7584e-04
Validation rmse = 0.856218
Epoch 13
Loss = 8.3878e-01, PNorm = 43.2132, GNorm = 4.5022, lr_0 = 3.4617e-04
Validation rmse = 0.850288
Epoch 14
Loss = 8.3275e-01, PNorm = 43.2407, GNorm = 6.2219, lr_0 = 3.1623e-04
Validation rmse = 0.814731
Epoch 15
Loss = 7.7143e-01, PNorm = 43.2646, GNorm = 3.9565, lr_0 = 2.8888e-04
Validation rmse = 0.838814
Epoch 16
Loss = 7.7646e-01, PNorm = 43.2860, GNorm = 6.7665, lr_0 = 2.6607e-04
Validation rmse = 0.800379
Epoch 17
Loss = 7.7140e-01, PNorm = 43.3059, GNorm = 16.4703, lr_0 = 2.4306e-04
Validation rmse = 0.848666
Epoch 18
Loss = 7.7241e-01, PNorm = 43.3206, GNorm = 9.4240, lr_0 = 2.2387e-04
Validation rmse = 0.815177
Epoch 19
Loss = 8.0511e-01, PNorm = 43.3359, GNorm = 8.8897, lr_0 = 2.0451e-04
Validation rmse = 0.791329
Epoch 20
Loss = 7.7838e-01, PNorm = 43.3506, GNorm = 2.4331, lr_0 = 1.8682e-04
Validation rmse = 0.777304
Epoch 21
Loss = 7.0737e-01, PNorm = 43.3628, GNorm = 8.0788, lr_0 = 1.7207e-04
Validation rmse = 0.786886
Epoch 22
Loss = 6.5931e-01, PNorm = 43.3748, GNorm = 4.3090, lr_0 = 1.5719e-04
Validation rmse = 0.772455
Epoch 23
Loss = 6.8208e-01, PNorm = 43.3862, GNorm = 2.3450, lr_0 = 1.4360e-04
Validation rmse = 0.764717
Epoch 24
Loss = 7.2252e-01, PNorm = 43.3962, GNorm = 3.6300, lr_0 = 1.3226e-04
Validation rmse = 0.760606
Epoch 25
Loss = 8.6053e-01, PNorm = 43.4062, GNorm = 9.6068, lr_0 = 1.2082e-04
Loss = 6.7084e-01, PNorm = 43.4142, GNorm = 5.2000, lr_0 = 1.1128e-04
Validation rmse = 0.757993
Epoch 26
Loss = 6.6119e-01, PNorm = 43.4217, GNorm = 3.5405, lr_0 = 1.0250e-04
Loss = 8.4820e-01, PNorm = 43.4224, GNorm = 7.5332, lr_0 = 1.0166e-04
Validation rmse = 0.758598
Epoch 27
Loss = 6.6589e-01, PNorm = 43.4293, GNorm = 3.1510, lr_0 = 1.0000e-04
Loss = 7.1992e-01, PNorm = 43.4299, GNorm = 14.1151, lr_0 = 1.0000e-04
Validation rmse = 0.757991
Epoch 28
Loss = 6.7799e-01, PNorm = 43.4364, GNorm = 16.5990, lr_0 = 1.0000e-04
Validation rmse = 0.750068
Epoch 29
Loss = 6.8083e-01, PNorm = 43.4426, GNorm = 10.9131, lr_0 = 1.0000e-04
Validation rmse = 0.747858
Model 0 best validation rmse = 0.747858 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.654263
Ensemble test rmse = 0.654263
1-fold cross validation
	Seed 0 ==> test rmse = 0.654263
Overall test rmse = 0.654263 +/- 0.000000
Elapsed time = 0:01:45
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,399 | train size = 1,119 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6846e+00, PNorm = 42.7399, GNorm = 0.9246, lr_0 = 5.5000e-04
Validation rmse = 1.334969
Epoch 1
Loss = 1.4231e+00, PNorm = 42.7489, GNorm = 0.7687, lr_0 = 1.0000e-03
Validation rmse = 1.270236
Epoch 2
Loss = 1.3230e+00, PNorm = 42.7746, GNorm = 0.5619, lr_0 = 9.2106e-04
Validation rmse = 1.179236
Epoch 3
Loss = 1.3093e+00, PNorm = 42.8075, GNorm = 0.9231, lr_0 = 8.4834e-04
Validation rmse = 1.104485
Epoch 4
Loss = 1.2111e+00, PNorm = 42.8500, GNorm = 0.5817, lr_0 = 7.8137e-04
Validation rmse = 1.039956
Epoch 5
Loss = 1.1346e+00, PNorm = 42.9041, GNorm = 0.7244, lr_0 = 7.1969e-04
Validation rmse = 1.114123
Epoch 6
Loss = 1.1944e+00, PNorm = 42.9567, GNorm = 5.8821, lr_0 = 6.6784e-04
Validation rmse = 0.962200
Epoch 7
Loss = 1.0788e+00, PNorm = 43.0131, GNorm = 3.2991, lr_0 = 6.1512e-04
Validation rmse = 0.944968
Epoch 8
Loss = 8.8707e-01, PNorm = 43.0646, GNorm = 3.9410, lr_0 = 5.6656e-04
Loss = 9.9426e-01, PNorm = 43.1066, GNorm = 2.7793, lr_0 = 5.2575e-04
Loss = 7.8751e-01, PNorm = 43.1108, GNorm = 2.3505, lr_0 = 5.2183e-04
Validation rmse = 0.885396
Epoch 9
Loss = 9.1629e-01, PNorm = 43.1515, GNorm = 3.6402, lr_0 = 4.8424e-04
Validation rmse = 0.914194
Epoch 10
Loss = 9.2788e-01, PNorm = 43.1906, GNorm = 9.2664, lr_0 = 4.4602e-04
Validation rmse = 0.858720
Epoch 11
Loss = 8.9388e-01, PNorm = 43.2172, GNorm = 9.2935, lr_0 = 4.1389e-04
Validation rmse = 0.842138
Epoch 12
Loss = 8.2488e-01, PNorm = 43.2456, GNorm = 8.0502, lr_0 = 3.8121e-04
Validation rmse = 0.838439
Epoch 13
Loss = 8.1508e-01, PNorm = 43.2754, GNorm = 1.9178, lr_0 = 3.5112e-04
Validation rmse = 0.811943
Epoch 14
Loss = 7.5612e-01, PNorm = 43.3063, GNorm = 5.3095, lr_0 = 3.2340e-04
Validation rmse = 0.815887
Epoch 15
Loss = 7.6241e-01, PNorm = 43.3332, GNorm = 7.6255, lr_0 = 2.9787e-04
Validation rmse = 0.786586
Epoch 16
Loss = 6.5782e-01, PNorm = 43.3562, GNorm = 4.2398, lr_0 = 2.7641e-04
Loss = 7.2781e-01, PNorm = 43.3778, GNorm = 9.5498, lr_0 = 2.5650e-04
Loss = 6.1431e-01, PNorm = 43.3798, GNorm = 5.2793, lr_0 = 2.5459e-04
Validation rmse = 0.780260
Epoch 17
Loss = 7.1188e-01, PNorm = 43.3975, GNorm = 4.1800, lr_0 = 2.3625e-04
Validation rmse = 0.790581
Epoch 18
Loss = 7.0634e-01, PNorm = 43.4165, GNorm = 2.3061, lr_0 = 2.1760e-04
Validation rmse = 0.764847
Epoch 19
Loss = 6.8501e-01, PNorm = 43.4324, GNorm = 3.5620, lr_0 = 2.0042e-04
Validation rmse = 0.791554
Epoch 20
Loss = 6.5341e-01, PNorm = 43.4463, GNorm = 9.1710, lr_0 = 1.8460e-04
Validation rmse = 0.772054
Epoch 21
Loss = 6.3698e-01, PNorm = 43.4586, GNorm = 4.8968, lr_0 = 1.7003e-04
Validation rmse = 0.784940
Epoch 22
Loss = 7.5760e-01, PNorm = 43.4694, GNorm = 6.8420, lr_0 = 1.5778e-04
Validation rmse = 0.751826
Epoch 23
Loss = 6.3866e-01, PNorm = 43.4813, GNorm = 5.6127, lr_0 = 1.4532e-04
Validation rmse = 0.749754
Epoch 24
Loss = 5.8687e-01, PNorm = 43.4921, GNorm = 2.1050, lr_0 = 1.3385e-04
Validation rmse = 0.743380
Epoch 25
Loss = 6.3481e-01, PNorm = 43.5020, GNorm = 1.5483, lr_0 = 1.2328e-04
Loss = 6.0753e-01, PNorm = 43.5107, GNorm = 6.1422, lr_0 = 1.1440e-04
Loss = 6.1277e-01, PNorm = 43.5114, GNorm = 11.8133, lr_0 = 1.1355e-04
Validation rmse = 0.739338
Epoch 26
Loss = 6.1290e-01, PNorm = 43.5183, GNorm = 3.2437, lr_0 = 1.0537e-04
Validation rmse = 0.736807
Epoch 27
Loss = 5.9231e-01, PNorm = 43.5240, GNorm = 4.2740, lr_0 = 1.0000e-04
Validation rmse = 0.733412
Epoch 28
Loss = 6.2959e-01, PNorm = 43.5306, GNorm = 11.8661, lr_0 = 1.0000e-04
Validation rmse = 0.735319
Epoch 29
Loss = 6.2773e-01, PNorm = 43.5374, GNorm = 3.0222, lr_0 = 1.0000e-04
Validation rmse = 0.733131
Model 0 best validation rmse = 0.733131 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.652778
Ensemble test rmse = 0.652778
1-fold cross validation
	Seed 0 ==> test rmse = 0.652778
Overall test rmse = 0.652778 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/rand_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model_random_sampling',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,499 | train size = 1,199 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6649e+00, PNorm = 42.7397, GNorm = 1.3930, lr_0 = 5.5000e-04
Validation rmse = 1.402822
Epoch 1
Loss = 1.4241e+00, PNorm = 42.7491, GNorm = 0.6843, lr_0 = 1.0000e-03
Validation rmse = 1.274188
Epoch 2
Loss = 1.3659e+00, PNorm = 42.7737, GNorm = 1.1101, lr_0 = 9.2797e-04
Validation rmse = 1.173526
Epoch 3
Loss = 1.3170e+00, PNorm = 42.8060, GNorm = 1.6860, lr_0 = 8.6112e-04
Validation rmse = 1.116888
Epoch 4
Loss = 1.2946e+00, PNorm = 42.8459, GNorm = 1.1121, lr_0 = 7.9909e-04
Validation rmse = 1.035690
Epoch 5
Loss = 1.1909e+00, PNorm = 42.8980, GNorm = 1.4467, lr_0 = 7.4153e-04
Loss = 1.1342e+00, PNorm = 42.9528, GNorm = 7.0326, lr_0 = 6.8812e-04
Validation rmse = 0.987404
Epoch 6
Loss = 1.0560e+00, PNorm = 43.0043, GNorm = 3.7157, lr_0 = 6.3855e-04
Validation rmse = 0.955165
Epoch 7
Loss = 9.9534e-01, PNorm = 43.0555, GNorm = 6.5606, lr_0 = 5.9255e-04
Validation rmse = 0.901788
Epoch 8
Loss = 9.4677e-01, PNorm = 43.0987, GNorm = 4.7217, lr_0 = 5.4987e-04
Validation rmse = 1.066250
Epoch 9
Loss = 9.7155e-01, PNorm = 43.1375, GNorm = 2.6834, lr_0 = 5.1026e-04
Validation rmse = 0.895798
Epoch 10
Loss = 1.0750e+00, PNorm = 43.1679, GNorm = 7.2965, lr_0 = 4.7351e-04
Loss = 8.6987e-01, PNorm = 43.2015, GNorm = 2.5184, lr_0 = 4.3940e-04
Validation rmse = 0.860438
Epoch 11
Loss = 8.1146e-01, PNorm = 43.2331, GNorm = 1.8208, lr_0 = 4.0775e-04
Validation rmse = 0.819234
Epoch 12
Loss = 8.2838e-01, PNorm = 43.2625, GNorm = 3.6938, lr_0 = 3.7837e-04
Validation rmse = 0.813231
Epoch 13
Loss = 7.6219e-01, PNorm = 43.2938, GNorm = 2.9929, lr_0 = 3.5112e-04
Validation rmse = 0.838786
Epoch 14
Loss = 8.4208e-01, PNorm = 43.3174, GNorm = 1.8687, lr_0 = 3.2583e-04
Validation rmse = 0.769863
Epoch 15
Loss = 9.0540e-01, PNorm = 43.3408, GNorm = 6.5351, lr_0 = 3.0236e-04
Loss = 7.3205e-01, PNorm = 43.3604, GNorm = 15.7983, lr_0 = 2.8058e-04
Validation rmse = 0.790675
Epoch 16
Loss = 7.4033e-01, PNorm = 43.3773, GNorm = 3.7198, lr_0 = 2.6037e-04
Validation rmse = 0.762290
Epoch 17
Loss = 7.2729e-01, PNorm = 43.3960, GNorm = 4.5924, lr_0 = 2.4161e-04
Validation rmse = 0.751514
Epoch 18
Loss = 7.0031e-01, PNorm = 43.4124, GNorm = 16.2050, lr_0 = 2.2421e-04
Validation rmse = 0.773053
Epoch 19
Loss = 6.1271e-01, PNorm = 43.4274, GNorm = 2.9459, lr_0 = 2.0806e-04
Validation rmse = 0.760802
Epoch 20
Loss = 7.7033e-01, PNorm = 43.4389, GNorm = 9.0730, lr_0 = 1.9307e-04
Loss = 6.8168e-01, PNorm = 43.4496, GNorm = 8.8063, lr_0 = 1.7916e-04
Validation rmse = 0.736552
Epoch 21
Loss = 6.9348e-01, PNorm = 43.4613, GNorm = 5.0740, lr_0 = 1.6626e-04
Validation rmse = 0.740476
Epoch 22
Loss = 6.6924e-01, PNorm = 43.4724, GNorm = 4.6667, lr_0 = 1.5428e-04
Validation rmse = 0.726242
Epoch 23
Loss = 6.4934e-01, PNorm = 43.4822, GNorm = 6.1591, lr_0 = 1.4317e-04
Validation rmse = 0.724626
Epoch 24
Loss = 5.8459e-01, PNorm = 43.4911, GNorm = 12.2562, lr_0 = 1.3285e-04
Validation rmse = 0.723727
Epoch 25
Loss = 7.6263e-01, PNorm = 43.5004, GNorm = 2.4248, lr_0 = 1.2328e-04
Loss = 6.0468e-01, PNorm = 43.5084, GNorm = 4.2087, lr_0 = 1.1440e-04
Validation rmse = 0.717499
Epoch 26
Loss = 6.6929e-01, PNorm = 43.5161, GNorm = 10.2539, lr_0 = 1.0616e-04
Validation rmse = 0.712151
Epoch 27
Loss = 6.3120e-01, PNorm = 43.5225, GNorm = 5.0646, lr_0 = 1.0000e-04
Validation rmse = 0.716782
Epoch 28
Loss = 6.3499e-01, PNorm = 43.5290, GNorm = 17.9508, lr_0 = 1.0000e-04
Validation rmse = 0.711156
Epoch 29
Loss = 5.7016e-01, PNorm = 43.5355, GNorm = 5.8709, lr_0 = 1.0000e-04
Validation rmse = 0.718670
Model 0 best validation rmse = 0.711156 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.664223
Ensemble test rmse = 0.664223
1-fold cross validation
	Seed 0 ==> test rmse = 0.664223
Overall test rmse = 0.664223 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7287e+00, PNorm = 42.7423, GNorm = 1.4330, lr_0 = 4.0937e-04
Validation rmse = 1.375020
Epoch 1
Loss = 1.4048e+00, PNorm = 42.7452, GNorm = 0.9355, lr_0 = 6.9063e-04
Loss = 1.3932e+00, PNorm = 42.7575, GNorm = 1.0605, lr_0 = 9.7187e-04
Validation rmse = 1.272537
Epoch 2
Loss = 1.2756e+00, PNorm = 42.7864, GNorm = 1.8424, lr_0 = 9.5480e-04
Validation rmse = 1.256230
Epoch 3
Loss = 1.3291e+00, PNorm = 42.8249, GNorm = 1.7225, lr_0 = 9.0696e-04
Loss = 1.1820e+00, PNorm = 42.8729, GNorm = 2.5573, lr_0 = 8.6152e-04
Validation rmse = 1.116064
Epoch 4
Loss = 1.0494e+00, PNorm = 42.9356, GNorm = 5.4469, lr_0 = 8.1836e-04
Loss = 1.1931e+00, PNorm = 42.9994, GNorm = 12.4342, lr_0 = 7.7737e-04
Validation rmse = 1.398969
Epoch 5
Loss = 1.1787e+00, PNorm = 43.0374, GNorm = 3.7497, lr_0 = 7.3842e-04
Validation rmse = 1.065627
Epoch 6
Loss = 9.6464e-01, PNorm = 43.0826, GNorm = 1.0520, lr_0 = 7.0143e-04
Loss = 9.8176e-01, PNorm = 43.1356, GNorm = 2.2481, lr_0 = 6.6629e-04
Validation rmse = 0.978860
Epoch 7
Loss = 8.8711e-01, PNorm = 43.1888, GNorm = 7.1552, lr_0 = 6.3291e-04
Validation rmse = 1.002927
Epoch 8
Loss = 9.6347e-01, PNorm = 43.2317, GNorm = 1.5452, lr_0 = 6.0120e-04
Loss = 8.2179e-01, PNorm = 43.2675, GNorm = 12.4276, lr_0 = 5.7108e-04
Validation rmse = 0.908927
Epoch 9
Loss = 8.3202e-01, PNorm = 43.2914, GNorm = 2.2442, lr_0 = 5.4247e-04
Loss = 8.6528e-01, PNorm = 43.3216, GNorm = 6.7094, lr_0 = 5.1529e-04
Validation rmse = 0.897079
Epoch 10
Loss = 7.6026e-01, PNorm = 43.3525, GNorm = 3.0678, lr_0 = 4.8948e-04
Validation rmse = 0.931608
Epoch 11
Loss = 6.9537e-01, PNorm = 43.3811, GNorm = 3.8698, lr_0 = 4.6495e-04
Loss = 7.3578e-01, PNorm = 43.4080, GNorm = 4.2669, lr_0 = 4.4166e-04
Validation rmse = 0.867237
Epoch 12
Loss = 6.8451e-01, PNorm = 43.4311, GNorm = 2.5242, lr_0 = 4.1953e-04
Validation rmse = 0.856373
Epoch 13
Loss = 6.8714e-01, PNorm = 43.4571, GNorm = 6.0156, lr_0 = 3.9852e-04
Loss = 6.2968e-01, PNorm = 43.4824, GNorm = 3.3042, lr_0 = 3.7855e-04
Validation rmse = 0.882093
Epoch 14
Loss = 6.8545e-01, PNorm = 43.5020, GNorm = 4.1944, lr_0 = 3.5959e-04
Loss = 6.4576e-01, PNorm = 43.5239, GNorm = 5.5333, lr_0 = 3.4157e-04
Validation rmse = 0.857497
Epoch 15
Loss = 5.9478e-01, PNorm = 43.5460, GNorm = 3.1035, lr_0 = 3.2446e-04
Validation rmse = 0.844711
Epoch 16
Loss = 5.7856e-01, PNorm = 43.5674, GNorm = 3.6403, lr_0 = 3.0820e-04
Loss = 6.2346e-01, PNorm = 43.5847, GNorm = 4.2137, lr_0 = 2.9276e-04
Validation rmse = 0.834209
Epoch 17
Loss = 5.9087e-01, PNorm = 43.6015, GNorm = 10.6394, lr_0 = 2.7810e-04
Validation rmse = 0.832013
Epoch 18
Loss = 5.7603e-01, PNorm = 43.6173, GNorm = 3.3029, lr_0 = 2.6416e-04
Loss = 5.6023e-01, PNorm = 43.6342, GNorm = 11.7914, lr_0 = 2.5093e-04
Validation rmse = 0.886197
Epoch 19
Loss = 5.2751e-01, PNorm = 43.6476, GNorm = 3.1347, lr_0 = 2.3836e-04
Loss = 5.7455e-01, PNorm = 43.6615, GNorm = 4.3232, lr_0 = 2.2642e-04
Validation rmse = 0.819376
Epoch 20
Loss = 5.2626e-01, PNorm = 43.6763, GNorm = 4.2919, lr_0 = 2.1507e-04
Validation rmse = 0.814554
Epoch 21
Loss = 6.1210e-01, PNorm = 43.6890, GNorm = 3.4155, lr_0 = 2.0430e-04
Loss = 4.9051e-01, PNorm = 43.7021, GNorm = 13.6261, lr_0 = 1.9406e-04
Validation rmse = 0.833282
Epoch 22
Loss = 5.7886e-01, PNorm = 43.7125, GNorm = 6.7799, lr_0 = 1.8434e-04
Validation rmse = 0.844097
Epoch 23
Loss = 5.2765e-01, PNorm = 43.7244, GNorm = 3.1980, lr_0 = 1.7511e-04
Loss = 4.8686e-01, PNorm = 43.7352, GNorm = 8.3969, lr_0 = 1.6633e-04
Validation rmse = 0.831893
Epoch 24
Loss = 4.7042e-01, PNorm = 43.7456, GNorm = 2.6907, lr_0 = 1.5800e-04
Loss = 5.0960e-01, PNorm = 43.7555, GNorm = 5.3065, lr_0 = 1.5009e-04
Validation rmse = 0.808306
Epoch 25
Loss = 4.9737e-01, PNorm = 43.7632, GNorm = 3.4226, lr_0 = 1.4257e-04
Validation rmse = 0.820430
Epoch 26
Loss = 4.9467e-01, PNorm = 43.7723, GNorm = 2.9110, lr_0 = 1.3542e-04
Loss = 4.5089e-01, PNorm = 43.7808, GNorm = 19.0140, lr_0 = 1.2864e-04
Validation rmse = 0.810658
Epoch 27
Loss = 5.1570e-01, PNorm = 43.7891, GNorm = 2.4936, lr_0 = 1.2220e-04
Validation rmse = 0.808717
Epoch 28
Loss = 5.3879e-01, PNorm = 43.7963, GNorm = 9.5002, lr_0 = 1.1607e-04
Loss = 5.2756e-01, PNorm = 43.8015, GNorm = 16.9006, lr_0 = 1.1026e-04
Validation rmse = 0.829543
Epoch 29
Loss = 5.0551e-01, PNorm = 43.8076, GNorm = 6.3045, lr_0 = 1.0473e-04
Loss = 4.4543e-01, PNorm = 43.8143, GNorm = 10.1179, lr_0 = 1.0000e-04
Validation rmse = 0.811184
Model 0 best validation rmse = 0.808306 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.653802
Ensemble test rmse = 0.653802
1-fold cross validation
	Seed 0 ==> test rmse = 0.653802
Overall test rmse = 0.653802 +/- 0.000000
Elapsed time = 0:01:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7362e+00, PNorm = 42.7414, GNorm = 1.7710, lr_0 = 4.0937e-04
Validation rmse = 1.460066
Epoch 1
Loss = 1.4384e+00, PNorm = 42.7433, GNorm = 0.7680, lr_0 = 7.1875e-04
Loss = 1.3772e+00, PNorm = 42.7594, GNorm = 0.7158, lr_0 = 1.0000e-03
Validation rmse = 1.376906
Epoch 2
Loss = 1.3037e+00, PNorm = 42.7837, GNorm = 1.2007, lr_0 = 9.4990e-04
Loss = 1.2388e+00, PNorm = 42.8221, GNorm = 1.3257, lr_0 = 9.0231e-04
Validation rmse = 1.283744
Epoch 3
Loss = 1.1620e+00, PNorm = 42.8692, GNorm = 0.8901, lr_0 = 8.5711e-04
Validation rmse = 1.125212
Epoch 4
Loss = 9.7730e-01, PNorm = 42.9298, GNorm = 4.7680, lr_0 = 8.1417e-04
Loss = 1.0657e+00, PNorm = 42.9890, GNorm = 6.8693, lr_0 = 7.7338e-04
Validation rmse = 1.100417
Epoch 5
Loss = 1.0713e+00, PNorm = 43.0353, GNorm = 3.4377, lr_0 = 7.3463e-04
Loss = 9.1498e-01, PNorm = 43.0873, GNorm = 3.4303, lr_0 = 6.9783e-04
Loss = 8.6523e-01, PNorm = 43.0935, GNorm = 2.0560, lr_0 = 6.9425e-04
Validation rmse = 0.997584
Epoch 6
Loss = 8.4556e-01, PNorm = 43.1465, GNorm = 8.6086, lr_0 = 6.5947e-04
Validation rmse = 0.908934
Epoch 7
Loss = 7.6726e-01, PNorm = 43.1932, GNorm = 2.0584, lr_0 = 6.2643e-04
Loss = 7.8703e-01, PNorm = 43.2351, GNorm = 6.5305, lr_0 = 5.9505e-04
Validation rmse = 0.873379
Epoch 8
Loss = 7.7455e-01, PNorm = 43.2674, GNorm = 2.3294, lr_0 = 5.6524e-04
Loss = 7.0012e-01, PNorm = 43.3036, GNorm = 5.0474, lr_0 = 5.3692e-04
Validation rmse = 0.870435
Epoch 9
Loss = 7.0739e-01, PNorm = 43.3380, GNorm = 7.3636, lr_0 = 5.1002e-04
Validation rmse = 0.956415
Epoch 10
Loss = 6.2540e-01, PNorm = 43.3646, GNorm = 4.0717, lr_0 = 4.8447e-04
Loss = 8.0240e-01, PNorm = 43.3824, GNorm = 9.6422, lr_0 = 4.6020e-04
Validation rmse = 0.905500
Epoch 11
Loss = 6.7667e-01, PNorm = 43.4095, GNorm = 3.2456, lr_0 = 4.3490e-04
Loss = 6.1667e-01, PNorm = 43.4366, GNorm = 2.5635, lr_0 = 4.1312e-04
Validation rmse = 0.855237
Epoch 12
Loss = 5.8318e-01, PNorm = 43.4571, GNorm = 3.2794, lr_0 = 3.9242e-04
Validation rmse = 0.800317
Epoch 13
Loss = 5.6947e-01, PNorm = 43.4780, GNorm = 4.7630, lr_0 = 3.7276e-04
Loss = 6.0175e-01, PNorm = 43.4975, GNorm = 8.0161, lr_0 = 3.5408e-04
Validation rmse = 0.870074
Epoch 14
Loss = 5.8505e-01, PNorm = 43.5193, GNorm = 6.7574, lr_0 = 3.3635e-04
Loss = 5.7999e-01, PNorm = 43.5368, GNorm = 5.8002, lr_0 = 3.1950e-04
Validation rmse = 0.893006
Epoch 15
Loss = 5.6646e-01, PNorm = 43.5522, GNorm = 6.6000, lr_0 = 3.0349e-04
Validation rmse = 0.809958
Epoch 16
Loss = 5.7481e-01, PNorm = 43.5717, GNorm = 4.8999, lr_0 = 2.8681e-04
Loss = 5.1157e-01, PNorm = 43.5880, GNorm = 19.3880, lr_0 = 2.7244e-04
Validation rmse = 0.802716
Epoch 17
Loss = 5.5758e-01, PNorm = 43.5994, GNorm = 9.6266, lr_0 = 2.5879e-04
Loss = 5.1604e-01, PNorm = 43.6129, GNorm = 4.2309, lr_0 = 2.4582e-04
Validation rmse = 0.814866
Epoch 18
Loss = 5.4109e-01, PNorm = 43.6272, GNorm = 7.9833, lr_0 = 2.3351e-04
Validation rmse = 0.871269
Epoch 19
Loss = 5.4504e-01, PNorm = 43.6391, GNorm = 18.3118, lr_0 = 2.2181e-04
Loss = 5.4111e-01, PNorm = 43.6507, GNorm = 6.0729, lr_0 = 2.1070e-04
Validation rmse = 0.841933
Epoch 20
Loss = 4.3614e-01, PNorm = 43.6626, GNorm = 2.6415, lr_0 = 2.0014e-04
Loss = 4.9981e-01, PNorm = 43.6738, GNorm = 10.5313, lr_0 = 1.9012e-04
Validation rmse = 0.781036
Epoch 21
Loss = 4.6489e-01, PNorm = 43.6816, GNorm = 6.4423, lr_0 = 1.7967e-04
Validation rmse = 0.786895
Epoch 22
Loss = 4.9321e-01, PNorm = 43.6909, GNorm = 3.1053, lr_0 = 1.7066e-04
Loss = 4.7488e-01, PNorm = 43.6998, GNorm = 12.4603, lr_0 = 1.6211e-04
Validation rmse = 0.791172
Epoch 23
Loss = 4.4061e-01, PNorm = 43.7075, GNorm = 5.8368, lr_0 = 1.5399e-04
Loss = 4.3812e-01, PNorm = 43.7151, GNorm = 4.9377, lr_0 = 1.4628e-04
Validation rmse = 0.761147
Epoch 24
Loss = 4.5099e-01, PNorm = 43.7236, GNorm = 3.8960, lr_0 = 1.3895e-04
Loss = 4.2835e-01, PNorm = 43.7308, GNorm = 6.9057, lr_0 = 1.3199e-04
Validation rmse = 0.762994
Epoch 25
Loss = 3.9978e-01, PNorm = 43.7375, GNorm = 9.9965, lr_0 = 1.2538e-04
Validation rmse = 0.777220
Epoch 26
Loss = 3.8656e-01, PNorm = 43.7438, GNorm = 4.7549, lr_0 = 1.1848e-04
Loss = 4.7631e-01, PNorm = 43.7491, GNorm = 14.5650, lr_0 = 1.1255e-04
Validation rmse = 0.758387
Epoch 27
Loss = 4.2575e-01, PNorm = 43.7550, GNorm = 4.6062, lr_0 = 1.0691e-04
Loss = 4.0822e-01, PNorm = 43.7608, GNorm = 8.1679, lr_0 = 1.0155e-04
Validation rmse = 0.781495
Epoch 28
Loss = 4.1204e-01, PNorm = 43.7667, GNorm = 4.9290, lr_0 = 1.0000e-04
Validation rmse = 0.768243
Epoch 29
Loss = 3.5923e-01, PNorm = 43.7719, GNorm = 6.3110, lr_0 = 1.0000e-04
Loss = 4.0975e-01, PNorm = 43.7774, GNorm = 4.5442, lr_0 = 1.0000e-04
Validation rmse = 0.766154
Model 0 best validation rmse = 0.758387 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.633403
Ensemble test rmse = 0.633403
1-fold cross validation
	Seed 0 ==> test rmse = 0.633403
Overall test rmse = 0.633403 +/- 0.000000
Elapsed time = 0:01:22
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8141e+00, PNorm = 42.7408, GNorm = 2.0518, lr_0 = 3.9118e-04
Validation rmse = 1.439413
Epoch 1
Loss = 1.3893e+00, PNorm = 42.7424, GNorm = 1.1906, lr_0 = 6.8235e-04
Loss = 1.3683e+00, PNorm = 42.7578, GNorm = 0.8752, lr_0 = 9.4706e-04
Validation rmse = 1.369500
Epoch 2
Loss = 1.3320e+00, PNorm = 42.7840, GNorm = 2.1245, lr_0 = 9.6204e-04
Loss = 1.2226e+00, PNorm = 42.8182, GNorm = 1.4591, lr_0 = 9.1661e-04
Validation rmse = 1.235157
Epoch 3
Loss = 1.1943e+00, PNorm = 42.8703, GNorm = 5.6333, lr_0 = 8.6911e-04
Loss = 1.1303e+00, PNorm = 42.9248, GNorm = 4.6949, lr_0 = 8.2807e-04
Validation rmse = 1.095096
Epoch 4
Loss = 1.0782e+00, PNorm = 42.9813, GNorm = 3.4095, lr_0 = 7.8897e-04
Validation rmse = 0.991182
Epoch 5
Loss = 9.2971e-01, PNorm = 43.0421, GNorm = 4.2925, lr_0 = 7.5171e-04
Loss = 9.3627e-01, PNorm = 43.0971, GNorm = 8.3991, lr_0 = 7.1621e-04
Validation rmse = 1.038948
Epoch 6
Loss = 8.9417e-01, PNorm = 43.1478, GNorm = 6.4973, lr_0 = 6.7910e-04
Loss = 8.1371e-01, PNorm = 43.2006, GNorm = 2.8259, lr_0 = 6.4703e-04
Validation rmse = 0.874663
Epoch 7
Loss = 7.8866e-01, PNorm = 43.2395, GNorm = 6.8217, lr_0 = 6.1648e-04
Loss = 7.8408e-01, PNorm = 43.2752, GNorm = 2.5490, lr_0 = 5.8736e-04
Loss = 9.0197e-01, PNorm = 43.2783, GNorm = 9.0524, lr_0 = 5.8453e-04
Validation rmse = 0.853504
Epoch 8
Loss = 7.5507e-01, PNorm = 43.3118, GNorm = 6.9962, lr_0 = 5.5693e-04
Validation rmse = 0.803008
Epoch 9
Loss = 5.8133e-01, PNorm = 43.3438, GNorm = 2.8689, lr_0 = 5.3063e-04
Loss = 6.9111e-01, PNorm = 43.3743, GNorm = 2.1061, lr_0 = 5.0557e-04
Validation rmse = 0.817810
Epoch 10
Loss = 6.5549e-01, PNorm = 43.3972, GNorm = 5.8032, lr_0 = 4.8170e-04
Loss = 6.0116e-01, PNorm = 43.4238, GNorm = 5.9695, lr_0 = 4.5895e-04
Validation rmse = 0.860494
Epoch 11
Loss = 5.9498e-01, PNorm = 43.4527, GNorm = 2.9457, lr_0 = 4.3517e-04
Loss = 5.9222e-01, PNorm = 43.4718, GNorm = 8.2621, lr_0 = 4.1462e-04
Validation rmse = 0.766325
Epoch 12
Loss = 5.8055e-01, PNorm = 43.4956, GNorm = 10.4555, lr_0 = 3.9504e-04
Validation rmse = 0.757577
Epoch 13
Loss = 6.4378e-01, PNorm = 43.5149, GNorm = 2.1469, lr_0 = 3.7457e-04
Loss = 5.1924e-01, PNorm = 43.5356, GNorm = 3.1042, lr_0 = 3.5688e-04
Validation rmse = 0.770058
Epoch 14
Loss = 4.8088e-01, PNorm = 43.5567, GNorm = 10.4636, lr_0 = 3.4003e-04
Loss = 5.3357e-01, PNorm = 43.5751, GNorm = 3.4330, lr_0 = 3.2397e-04
Validation rmse = 0.770524
Epoch 15
Loss = 4.3655e-01, PNorm = 43.5939, GNorm = 3.5903, lr_0 = 3.0867e-04
Loss = 5.1971e-01, PNorm = 43.6129, GNorm = 6.9792, lr_0 = 2.9409e-04
Validation rmse = 0.726405
Epoch 16
Loss = 4.5534e-01, PNorm = 43.6286, GNorm = 8.5425, lr_0 = 2.7885e-04
Validation rmse = 0.727142
Epoch 17
Loss = 5.6326e-01, PNorm = 43.6441, GNorm = 10.8361, lr_0 = 2.6569e-04
Loss = 4.5155e-01, PNorm = 43.6578, GNorm = 6.3574, lr_0 = 2.5314e-04
Validation rmse = 0.728346
Epoch 18
Loss = 4.0053e-01, PNorm = 43.6727, GNorm = 4.5399, lr_0 = 2.4002e-04
Loss = 4.4199e-01, PNorm = 43.6850, GNorm = 7.6012, lr_0 = 2.2869e-04
Validation rmse = 0.726555
Epoch 19
Loss = 4.4630e-01, PNorm = 43.6967, GNorm = 4.6072, lr_0 = 2.1789e-04
Loss = 4.1735e-01, PNorm = 43.7097, GNorm = 9.5630, lr_0 = 2.0760e-04
Validation rmse = 0.726947
Epoch 20
Loss = 3.9573e-01, PNorm = 43.7187, GNorm = 9.6925, lr_0 = 1.9780e-04
Validation rmse = 0.826422
Epoch 21
Loss = 3.3053e-01, PNorm = 43.7300, GNorm = 8.1848, lr_0 = 1.8755e-04
Loss = 3.9816e-01, PNorm = 43.7404, GNorm = 3.9816, lr_0 = 1.7869e-04
Validation rmse = 0.721722
Epoch 22
Loss = 4.5746e-01, PNorm = 43.7516, GNorm = 2.3423, lr_0 = 1.7025e-04
Loss = 3.4807e-01, PNorm = 43.7597, GNorm = 3.0859, lr_0 = 1.6221e-04
Validation rmse = 0.769832
Epoch 23
Loss = 4.2051e-01, PNorm = 43.7693, GNorm = 6.5872, lr_0 = 1.5381e-04
Loss = 3.6670e-01, PNorm = 43.7775, GNorm = 3.1036, lr_0 = 1.4654e-04
Validation rmse = 0.762491
Epoch 24
Loss = 3.9933e-01, PNorm = 43.7834, GNorm = 14.1449, lr_0 = 1.3962e-04
Loss = 4.1160e-01, PNorm = 43.7902, GNorm = 6.6169, lr_0 = 1.3303e-04
Validation rmse = 0.745501
Epoch 25
Loss = 4.0280e-01, PNorm = 43.7963, GNorm = 10.1738, lr_0 = 1.2675e-04
Validation rmse = 0.703527
Epoch 26
Loss = 4.3641e-01, PNorm = 43.8038, GNorm = 11.0478, lr_0 = 1.2018e-04
Loss = 3.2446e-01, PNorm = 43.8111, GNorm = 3.8353, lr_0 = 1.1450e-04
Validation rmse = 0.727855
Epoch 27
Loss = 3.2194e-01, PNorm = 43.8163, GNorm = 4.8943, lr_0 = 1.0910e-04
Loss = 3.3358e-01, PNorm = 43.8216, GNorm = 9.2620, lr_0 = 1.0395e-04
Validation rmse = 0.710046
Epoch 28
Loss = 3.4598e-01, PNorm = 43.8277, GNorm = 8.7772, lr_0 = 1.0000e-04
Loss = 3.4131e-01, PNorm = 43.8330, GNorm = 9.1440, lr_0 = 1.0000e-04
Validation rmse = 0.739789
Epoch 29
Loss = 2.8384e-01, PNorm = 43.8375, GNorm = 11.7859, lr_0 = 1.0000e-04
Validation rmse = 0.719355
Model 0 best validation rmse = 0.703527 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.682349
Ensemble test rmse = 0.682349
1-fold cross validation
	Seed 0 ==> test rmse = 0.682349
Overall test rmse = 0.682349 +/- 0.000000
Elapsed time = 0:01:26
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7099e+00, PNorm = 42.7405, GNorm = 2.1013, lr_0 = 3.7500e-04
Validation rmse = 1.355288
Epoch 1
Loss = 1.4254e+00, PNorm = 42.7418, GNorm = 1.0204, lr_0 = 6.5000e-04
Loss = 1.3421e+00, PNorm = 42.7545, GNorm = 0.6770, lr_0 = 9.0000e-04
Validation rmse = 1.262794
Epoch 2
Loss = 1.2141e+00, PNorm = 42.7913, GNorm = 1.7597, lr_0 = 9.6853e-04
Loss = 1.2248e+00, PNorm = 42.8389, GNorm = 1.8354, lr_0 = 9.2527e-04
Validation rmse = 1.021368
Epoch 3
Loss = 1.0831e+00, PNorm = 42.9020, GNorm = 4.6680, lr_0 = 8.8395e-04
Loss = 9.8612e-01, PNorm = 42.9756, GNorm = 4.1270, lr_0 = 8.4448e-04
Validation rmse = 0.908489
Epoch 4
Loss = 9.0198e-01, PNorm = 43.0491, GNorm = 24.0827, lr_0 = 8.0309e-04
Loss = 9.9135e-01, PNorm = 43.0863, GNorm = 3.4364, lr_0 = 7.6722e-04
Validation rmse = 0.881855
Epoch 5
Loss = 8.5299e-01, PNorm = 43.1346, GNorm = 2.8879, lr_0 = 7.3296e-04
Loss = 7.5726e-01, PNorm = 43.1885, GNorm = 2.6198, lr_0 = 7.0023e-04
Loss = 6.6642e-01, PNorm = 43.1920, GNorm = 3.4183, lr_0 = 6.9703e-04
Validation rmse = 0.799445
Epoch 6
Loss = 7.5750e-01, PNorm = 43.2332, GNorm = 2.7024, lr_0 = 6.6591e-04
Validation rmse = 0.761244
Epoch 7
Loss = 6.7521e-01, PNorm = 43.2652, GNorm = 2.0156, lr_0 = 6.3327e-04
Loss = 6.4658e-01, PNorm = 43.2920, GNorm = 7.6631, lr_0 = 6.0499e-04
Validation rmse = 0.811907
Epoch 8
Loss = 6.5737e-01, PNorm = 43.3207, GNorm = 11.9265, lr_0 = 5.7797e-04
Loss = 6.1277e-01, PNorm = 43.3513, GNorm = 4.3884, lr_0 = 5.5216e-04
Validation rmse = 0.777791
Epoch 9
Loss = 5.2918e-01, PNorm = 43.3790, GNorm = 3.8502, lr_0 = 5.2510e-04
Loss = 6.0342e-01, PNorm = 43.4055, GNorm = 3.5453, lr_0 = 5.0165e-04
Validation rmse = 0.727694
Epoch 10
Loss = 5.3503e-01, PNorm = 43.4284, GNorm = 3.9304, lr_0 = 4.7924e-04
Loss = 5.5008e-01, PNorm = 43.4532, GNorm = 2.7726, lr_0 = 4.5784e-04
Validation rmse = 0.728902
Epoch 11
Loss = 6.0051e-01, PNorm = 43.4711, GNorm = 6.1010, lr_0 = 4.3540e-04
Loss = 5.0002e-01, PNorm = 43.4912, GNorm = 2.5635, lr_0 = 4.1596e-04
Loss = 3.7618e-01, PNorm = 43.4937, GNorm = 6.5249, lr_0 = 4.1406e-04
Validation rmse = 0.731039
Epoch 12
Loss = 5.1553e-01, PNorm = 43.5110, GNorm = 10.6394, lr_0 = 3.9557e-04
Validation rmse = 0.771469
Epoch 13
Loss = 5.7578e-01, PNorm = 43.5257, GNorm = 3.9584, lr_0 = 3.7790e-04
Loss = 6.6023e-01, PNorm = 43.5407, GNorm = 8.2922, lr_0 = 3.6103e-04
Validation rmse = 0.698954
Epoch 14
Loss = 4.9030e-01, PNorm = 43.5609, GNorm = 9.4646, lr_0 = 3.4333e-04
Loss = 5.2372e-01, PNorm = 43.5800, GNorm = 16.4765, lr_0 = 3.2800e-04
Validation rmse = 0.719229
Epoch 15
Loss = 3.9861e-01, PNorm = 43.5997, GNorm = 2.9087, lr_0 = 3.1335e-04
Loss = 4.4352e-01, PNorm = 43.6145, GNorm = 11.2385, lr_0 = 2.9936e-04
Validation rmse = 0.725846
Epoch 16
Loss = 4.8018e-01, PNorm = 43.6248, GNorm = 2.6901, lr_0 = 2.8469e-04
Loss = 4.2977e-01, PNorm = 43.6386, GNorm = 2.6805, lr_0 = 2.7197e-04
Validation rmse = 0.682067
Epoch 17
Loss = 4.2239e-01, PNorm = 43.6544, GNorm = 10.7658, lr_0 = 2.5864e-04
Loss = 4.1735e-01, PNorm = 43.6642, GNorm = 4.2042, lr_0 = 2.4709e-04
Validation rmse = 0.707629
Epoch 18
Loss = 3.9754e-01, PNorm = 43.6729, GNorm = 4.2495, lr_0 = 2.3606e-04
Validation rmse = 0.685691
Epoch 19
Loss = 3.8581e-01, PNorm = 43.6869, GNorm = 3.0515, lr_0 = 2.2449e-04
Loss = 4.1046e-01, PNorm = 43.6979, GNorm = 4.2635, lr_0 = 2.1446e-04
Validation rmse = 0.691190
Epoch 20
Loss = 2.7238e-01, PNorm = 43.7080, GNorm = 5.2092, lr_0 = 2.0488e-04
Loss = 3.5775e-01, PNorm = 43.7177, GNorm = 6.5321, lr_0 = 1.9573e-04
Validation rmse = 0.692664
Epoch 21
Loss = 3.3362e-01, PNorm = 43.7263, GNorm = 5.9835, lr_0 = 1.8614e-04
Loss = 4.0130e-01, PNorm = 43.7363, GNorm = 6.8889, lr_0 = 1.7783e-04
Validation rmse = 0.678926
Epoch 22
Loss = 4.1811e-01, PNorm = 43.7452, GNorm = 4.3283, lr_0 = 1.6911e-04
Loss = 3.5576e-01, PNorm = 43.7527, GNorm = 6.7268, lr_0 = 1.6156e-04
Validation rmse = 0.682448
Epoch 23
Loss = 3.2666e-01, PNorm = 43.7609, GNorm = 5.5123, lr_0 = 1.5434e-04
Loss = 4.0768e-01, PNorm = 43.7690, GNorm = 3.9756, lr_0 = 1.4745e-04
Validation rmse = 0.687499
Epoch 24
Loss = 3.0734e-01, PNorm = 43.7759, GNorm = 5.0968, lr_0 = 1.4022e-04
Loss = 4.0143e-01, PNorm = 43.7829, GNorm = 7.8588, lr_0 = 1.3396e-04
Validation rmse = 0.674732
Epoch 25
Loss = 3.1475e-01, PNorm = 43.7906, GNorm = 3.9252, lr_0 = 1.2798e-04
Validation rmse = 0.684095
Epoch 26
Loss = 3.4162e-01, PNorm = 43.7965, GNorm = 2.6508, lr_0 = 1.2171e-04
Loss = 2.8914e-01, PNorm = 43.8015, GNorm = 4.0123, lr_0 = 1.1627e-04
Validation rmse = 0.675811
Epoch 27
Loss = 3.0231e-01, PNorm = 43.8086, GNorm = 9.7081, lr_0 = 1.1057e-04
Loss = 3.2130e-01, PNorm = 43.8142, GNorm = 4.3659, lr_0 = 1.0564e-04
Validation rmse = 0.675237
Epoch 28
Loss = 3.1584e-01, PNorm = 43.8192, GNorm = 14.4283, lr_0 = 1.0092e-04
Loss = 3.0051e-01, PNorm = 43.8241, GNorm = 3.8900, lr_0 = 1.0000e-04
Validation rmse = 0.680650
Epoch 29
Loss = 2.9025e-01, PNorm = 43.8302, GNorm = 3.2683, lr_0 = 1.0000e-04
Loss = 3.4766e-01, PNorm = 43.8353, GNorm = 3.5016, lr_0 = 1.0000e-04
Validation rmse = 0.674900
Model 0 best validation rmse = 0.674732 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.608695
Ensemble test rmse = 0.608695
1-fold cross validation
	Seed 0 ==> test rmse = 0.608695
Overall test rmse = 0.608695 +/- 0.000000
Elapsed time = 0:01:30
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7789e+00, PNorm = 42.7405, GNorm = 1.4376, lr_0 = 3.6053e-04
Validation rmse = 1.348141
Epoch 1
Loss = 1.3993e+00, PNorm = 42.7432, GNorm = 1.1130, lr_0 = 6.2105e-04
Loss = 1.3384e+00, PNorm = 42.7577, GNorm = 0.9414, lr_0 = 8.5789e-04
Validation rmse = 1.251262
Epoch 2
Loss = 1.3038e+00, PNorm = 42.7913, GNorm = 0.9303, lr_0 = 9.7859e-04
Loss = 1.2017e+00, PNorm = 42.8375, GNorm = 0.7769, lr_0 = 9.3714e-04
Validation rmse = 1.034558
Epoch 3
Loss = 1.0448e+00, PNorm = 42.9046, GNorm = 7.1651, lr_0 = 8.9357e-04
Loss = 1.0178e+00, PNorm = 42.9653, GNorm = 2.6416, lr_0 = 8.5572e-04
Validation rmse = 0.990670
Epoch 4
Loss = 1.0813e+00, PNorm = 43.0365, GNorm = 17.0535, lr_0 = 8.1593e-04
Loss = 9.3837e-01, PNorm = 43.0780, GNorm = 1.9948, lr_0 = 7.8137e-04
Validation rmse = 0.870215
Epoch 5
Loss = 7.7580e-01, PNorm = 43.1295, GNorm = 2.1711, lr_0 = 7.4827e-04
Loss = 8.2853e-01, PNorm = 43.1791, GNorm = 4.6330, lr_0 = 7.1658e-04
Validation rmse = 0.831051
Epoch 6
Loss = 7.3121e-01, PNorm = 43.2198, GNorm = 3.3854, lr_0 = 6.8326e-04
Loss = 6.9824e-01, PNorm = 43.2565, GNorm = 2.3082, lr_0 = 6.5432e-04
Validation rmse = 0.816307
Epoch 7
Loss = 6.7618e-01, PNorm = 43.2850, GNorm = 2.6429, lr_0 = 6.2390e-04
Loss = 6.7314e-01, PNorm = 43.3172, GNorm = 5.1359, lr_0 = 5.9747e-04
Validation rmse = 0.817766
Epoch 8
Loss = 5.9461e-01, PNorm = 43.3530, GNorm = 3.0314, lr_0 = 5.6969e-04
Loss = 6.2354e-01, PNorm = 43.3872, GNorm = 4.3002, lr_0 = 5.4556e-04
Validation rmse = 0.891883
Epoch 9
Loss = 5.8472e-01, PNorm = 43.4106, GNorm = 6.9342, lr_0 = 5.2019e-04
Loss = 6.3013e-01, PNorm = 43.4383, GNorm = 7.3457, lr_0 = 4.9816e-04
Validation rmse = 0.776429
Epoch 10
Loss = 5.6892e-01, PNorm = 43.4565, GNorm = 2.9756, lr_0 = 4.7706e-04
Loss = 5.6538e-01, PNorm = 43.4811, GNorm = 1.9520, lr_0 = 4.5685e-04
Validation rmse = 0.744139
Epoch 11
Loss = 4.8654e-01, PNorm = 43.5127, GNorm = 3.6622, lr_0 = 4.3561e-04
Loss = 5.5765e-01, PNorm = 43.5286, GNorm = 4.1816, lr_0 = 4.1716e-04
Loss = 7.9425e-01, PNorm = 43.5294, GNorm = 7.8093, lr_0 = 4.1536e-04
Validation rmse = 0.767002
Epoch 12
Loss = 5.2048e-01, PNorm = 43.5471, GNorm = 3.4186, lr_0 = 3.9776e-04
Validation rmse = 0.736103
Epoch 13
Loss = 4.0077e-01, PNorm = 43.5699, GNorm = 5.0165, lr_0 = 3.7927e-04
Loss = 5.0524e-01, PNorm = 43.5858, GNorm = 8.6165, lr_0 = 3.6320e-04
Validation rmse = 0.740216
Epoch 14
Loss = 4.0773e-01, PNorm = 43.6090, GNorm = 12.4024, lr_0 = 3.4632e-04
Loss = 4.6615e-01, PNorm = 43.6297, GNorm = 6.9026, lr_0 = 3.3165e-04
Validation rmse = 0.735862
Epoch 15
Loss = 4.1181e-01, PNorm = 43.6466, GNorm = 4.3331, lr_0 = 3.1760e-04
Loss = 5.1803e-01, PNorm = 43.6594, GNorm = 8.2406, lr_0 = 3.0415e-04
Validation rmse = 0.718272
Epoch 16
Loss = 4.2876e-01, PNorm = 43.6727, GNorm = 9.9145, lr_0 = 2.9001e-04
Loss = 4.7979e-01, PNorm = 43.6870, GNorm = 3.4739, lr_0 = 2.7772e-04
Validation rmse = 0.709443
Epoch 17
Loss = 3.8372e-01, PNorm = 43.7030, GNorm = 3.6826, lr_0 = 2.6481e-04
Loss = 4.1756e-01, PNorm = 43.7166, GNorm = 13.7209, lr_0 = 2.5359e-04
Validation rmse = 0.737591
Epoch 18
Loss = 4.4171e-01, PNorm = 43.7258, GNorm = 7.4139, lr_0 = 2.4180e-04
Loss = 4.5586e-01, PNorm = 43.7360, GNorm = 6.3047, lr_0 = 2.3156e-04
Validation rmse = 0.703786
Epoch 19
Loss = 4.4823e-01, PNorm = 43.7476, GNorm = 6.7953, lr_0 = 2.2079e-04
Loss = 4.0244e-01, PNorm = 43.7602, GNorm = 8.2118, lr_0 = 2.1144e-04
Validation rmse = 0.723135
Epoch 20
Loss = 3.9038e-01, PNorm = 43.7667, GNorm = 11.1714, lr_0 = 2.0248e-04
Loss = 3.7080e-01, PNorm = 43.7754, GNorm = 10.2585, lr_0 = 1.9391e-04
Validation rmse = 0.706867
Epoch 21
Loss = 3.2751e-01, PNorm = 43.7880, GNorm = 7.6073, lr_0 = 1.8489e-04
Loss = 3.8605e-01, PNorm = 43.7951, GNorm = 11.3172, lr_0 = 1.7706e-04
Validation rmse = 0.692806
Epoch 22
Loss = 4.2255e-01, PNorm = 43.8049, GNorm = 7.4165, lr_0 = 1.6883e-04
Loss = 3.4715e-01, PNorm = 43.8138, GNorm = 4.4499, lr_0 = 1.6168e-04
Validation rmse = 0.729695
Epoch 23
Loss = 3.3370e-01, PNorm = 43.8215, GNorm = 2.7004, lr_0 = 1.5416e-04
Loss = 3.6936e-01, PNorm = 43.8274, GNorm = 6.6970, lr_0 = 1.4763e-04
Loss = 2.7178e-01, PNorm = 43.8278, GNorm = 17.8646, lr_0 = 1.4699e-04
Validation rmse = 0.699297
Epoch 24
Loss = 3.4991e-01, PNorm = 43.8338, GNorm = 5.2392, lr_0 = 1.4077e-04
Loss = 3.6649e-01, PNorm = 43.8396, GNorm = 12.4409, lr_0 = 1.3480e-04
Validation rmse = 0.720197
Epoch 25
Loss = 3.1753e-01, PNorm = 43.8464, GNorm = 3.2189, lr_0 = 1.2909e-04
Validation rmse = 0.701000
Epoch 26
Loss = 4.6199e-01, PNorm = 43.8530, GNorm = 3.3346, lr_0 = 1.2309e-04
Loss = 3.3111e-01, PNorm = 43.8588, GNorm = 6.5811, lr_0 = 1.1788e-04
Validation rmse = 0.698621
Epoch 27
Loss = 3.6406e-01, PNorm = 43.8650, GNorm = 6.4822, lr_0 = 1.1240e-04
Loss = 3.0614e-01, PNorm = 43.8705, GNorm = 4.1142, lr_0 = 1.0764e-04
Validation rmse = 0.700276
Epoch 28
Loss = 3.8742e-01, PNorm = 43.8756, GNorm = 3.3964, lr_0 = 1.0263e-04
Loss = 2.9158e-01, PNorm = 43.8804, GNorm = 3.4182, lr_0 = 1.0000e-04
Validation rmse = 0.713409
Epoch 29
Loss = 2.8259e-01, PNorm = 43.8855, GNorm = 4.7185, lr_0 = 1.0000e-04
Loss = 3.0624e-01, PNorm = 43.8903, GNorm = 5.6183, lr_0 = 1.0000e-04
Validation rmse = 0.691320
Model 0 best validation rmse = 0.691320 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.618200
Ensemble test rmse = 0.618200
1-fold cross validation
	Seed 0 ==> test rmse = 0.618200
Overall test rmse = 0.618200 +/- 0.000000
Elapsed time = 0:01:36
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8654e+00, PNorm = 42.7411, GNorm = 1.9877, lr_0 = 3.4750e-04
Loss = 1.3935e+00, PNorm = 42.7392, GNorm = 0.9576, lr_0 = 5.7250e-04
Validation rmse = 1.503319
Epoch 1
Loss = 1.3239e+00, PNorm = 42.7489, GNorm = 0.8923, lr_0 = 7.9750e-04
Loss = 1.3203e+00, PNorm = 42.7740, GNorm = 1.1779, lr_0 = 9.9590e-04
Validation rmse = 1.386346
Epoch 2
Loss = 1.2098e+00, PNorm = 42.8135, GNorm = 1.2654, lr_0 = 9.5578e-04
Loss = 1.1257e+00, PNorm = 42.8661, GNorm = 5.2626, lr_0 = 9.1728e-04
Validation rmse = 1.409774
Epoch 3
Loss = 1.1636e+00, PNorm = 42.9152, GNorm = 3.3626, lr_0 = 8.8032e-04
Loss = 1.0047e+00, PNorm = 42.9765, GNorm = 2.5811, lr_0 = 8.4486e-04
Validation rmse = 1.171951
Epoch 4
Loss = 9.7296e-01, PNorm = 43.0390, GNorm = 3.2806, lr_0 = 8.1083e-04
Loss = 8.1866e-01, PNorm = 43.1087, GNorm = 1.8316, lr_0 = 7.7816e-04
Validation rmse = 0.969779
Epoch 5
Loss = 8.1392e-01, PNorm = 43.1589, GNorm = 3.5189, lr_0 = 7.4682e-04
Loss = 7.2588e-01, PNorm = 43.2005, GNorm = 6.8660, lr_0 = 7.1673e-04
Validation rmse = 0.881898
Epoch 6
Loss = 6.8507e-01, PNorm = 43.2476, GNorm = 6.6978, lr_0 = 6.8786e-04
Loss = 7.7607e-01, PNorm = 43.2769, GNorm = 2.2156, lr_0 = 6.6015e-04
Validation rmse = 0.975072
Epoch 7
Loss = 7.0758e-01, PNorm = 43.3166, GNorm = 10.0786, lr_0 = 6.3356e-04
Loss = 6.4408e-01, PNorm = 43.3428, GNorm = 9.4588, lr_0 = 6.0803e-04
Validation rmse = 0.870800
Epoch 8
Loss = 6.5204e-01, PNorm = 43.3713, GNorm = 8.8163, lr_0 = 5.8354e-04
Loss = 5.6220e-01, PNorm = 43.3981, GNorm = 1.7563, lr_0 = 5.6003e-04
Validation rmse = 0.817536
Epoch 9
Loss = 5.6612e-01, PNorm = 43.4260, GNorm = 4.7001, lr_0 = 5.3747e-04
Loss = 5.5311e-01, PNorm = 43.4491, GNorm = 3.0929, lr_0 = 5.1582e-04
Validation rmse = 0.808958
Epoch 10
Loss = 5.3634e-01, PNorm = 43.4759, GNorm = 8.6893, lr_0 = 4.9504e-04
Loss = 5.7935e-01, PNorm = 43.4970, GNorm = 2.9003, lr_0 = 4.7510e-04
Validation rmse = 0.832535
Epoch 11
Loss = 5.2510e-01, PNorm = 43.5161, GNorm = 19.9449, lr_0 = 4.5596e-04
Loss = 5.7411e-01, PNorm = 43.5348, GNorm = 3.9773, lr_0 = 4.3759e-04
Validation rmse = 0.818603
Epoch 12
Loss = 5.0349e-01, PNorm = 43.5563, GNorm = 3.1996, lr_0 = 4.1997e-04
Loss = 4.7511e-01, PNorm = 43.5756, GNorm = 3.8083, lr_0 = 4.0305e-04
Validation rmse = 0.818272
Epoch 13
Loss = 4.0913e-01, PNorm = 43.5918, GNorm = 2.1206, lr_0 = 3.8681e-04
Loss = 5.1663e-01, PNorm = 43.6060, GNorm = 6.7141, lr_0 = 3.7123e-04
Validation rmse = 0.795451
Epoch 14
Loss = 4.6328e-01, PNorm = 43.6244, GNorm = 3.9393, lr_0 = 3.5628e-04
Loss = 4.2413e-01, PNorm = 43.6395, GNorm = 5.7900, lr_0 = 3.4192e-04
Validation rmse = 0.845237
Epoch 15
Loss = 4.1892e-01, PNorm = 43.6531, GNorm = 6.7634, lr_0 = 3.2815e-04
Loss = 4.9001e-01, PNorm = 43.6680, GNorm = 7.6233, lr_0 = 3.1493e-04
Validation rmse = 0.799268
Epoch 16
Loss = 4.6384e-01, PNorm = 43.6801, GNorm = 3.4397, lr_0 = 3.0224e-04
Loss = 4.0099e-01, PNorm = 43.6949, GNorm = 3.1472, lr_0 = 2.9007e-04
Validation rmse = 0.779612
Epoch 17
Loss = 4.4467e-01, PNorm = 43.7089, GNorm = 4.8278, lr_0 = 2.7838e-04
Loss = 3.5901e-01, PNorm = 43.7205, GNorm = 10.4204, lr_0 = 2.6717e-04
Validation rmse = 0.764374
Epoch 18
Loss = 4.2281e-01, PNorm = 43.7307, GNorm = 3.8278, lr_0 = 2.5641e-04
Loss = 4.0922e-01, PNorm = 43.7437, GNorm = 2.5172, lr_0 = 2.4608e-04
Validation rmse = 0.789345
Epoch 19
Loss = 3.7080e-01, PNorm = 43.7534, GNorm = 3.4475, lr_0 = 2.3616e-04
Loss = 3.8070e-01, PNorm = 43.7656, GNorm = 5.9794, lr_0 = 2.2665e-04
Validation rmse = 0.789946
Epoch 20
Loss = 4.1302e-01, PNorm = 43.7751, GNorm = 12.1246, lr_0 = 2.1752e-04
Loss = 4.0970e-01, PNorm = 43.7830, GNorm = 7.4457, lr_0 = 2.0876e-04
Validation rmse = 0.793058
Epoch 21
Loss = 4.3074e-01, PNorm = 43.7895, GNorm = 4.1878, lr_0 = 2.0035e-04
Loss = 3.9860e-01, PNorm = 43.7991, GNorm = 5.9706, lr_0 = 1.9228e-04
Validation rmse = 0.780448
Epoch 22
Loss = 3.2835e-01, PNorm = 43.8091, GNorm = 5.5875, lr_0 = 1.8453e-04
Loss = 3.7106e-01, PNorm = 43.8161, GNorm = 4.7988, lr_0 = 1.7710e-04
Validation rmse = 0.782151
Epoch 23
Loss = 3.3795e-01, PNorm = 43.8235, GNorm = 3.8820, lr_0 = 1.6996e-04
Loss = 3.4401e-01, PNorm = 43.8317, GNorm = 7.5376, lr_0 = 1.6312e-04
Validation rmse = 0.794764
Epoch 24
Loss = 3.3368e-01, PNorm = 43.8384, GNorm = 8.9562, lr_0 = 1.5655e-04
Loss = 3.4045e-01, PNorm = 43.8451, GNorm = 6.4406, lr_0 = 1.5024e-04
Validation rmse = 0.770831
Epoch 25
Loss = 3.3772e-01, PNorm = 43.8526, GNorm = 3.0770, lr_0 = 1.4419e-04
Loss = 3.2981e-01, PNorm = 43.8584, GNorm = 3.4739, lr_0 = 1.3838e-04
Validation rmse = 0.759006
Epoch 26
Loss = 3.1513e-01, PNorm = 43.8651, GNorm = 5.3861, lr_0 = 1.3280e-04
Loss = 3.3167e-01, PNorm = 43.8715, GNorm = 10.9781, lr_0 = 1.2746e-04
Validation rmse = 0.767421
Epoch 27
Loss = 3.4199e-01, PNorm = 43.8771, GNorm = 18.0006, lr_0 = 1.2232e-04
Loss = 3.2322e-01, PNorm = 43.8824, GNorm = 6.3134, lr_0 = 1.1739e-04
Validation rmse = 0.799997
Epoch 28
Loss = 3.1655e-01, PNorm = 43.8882, GNorm = 3.0199, lr_0 = 1.1266e-04
Loss = 3.3052e-01, PNorm = 43.8938, GNorm = 3.3620, lr_0 = 1.0813e-04
Validation rmse = 0.765928
Epoch 29
Loss = 3.0608e-01, PNorm = 43.8986, GNorm = 3.5971, lr_0 = 1.0377e-04
Loss = 2.9951e-01, PNorm = 43.9033, GNorm = 4.2354, lr_0 = 1.0000e-04
Validation rmse = 0.768633
Model 0 best validation rmse = 0.759006 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.632744
Ensemble test rmse = 0.632744
1-fold cross validation
	Seed 0 ==> test rmse = 0.632744
Overall test rmse = 0.632744 +/- 0.000000
Elapsed time = 0:01:38
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.9206e+00, PNorm = 42.7401, GNorm = 2.4737, lr_0 = 3.4750e-04
Loss = 1.4213e+00, PNorm = 42.7390, GNorm = 0.8931, lr_0 = 5.7250e-04
Loss = 1.2964e+00, PNorm = 42.7394, GNorm = 1.6543, lr_0 = 5.9500e-04
Validation rmse = 1.490323
Epoch 1
Loss = 1.3450e+00, PNorm = 42.7488, GNorm = 1.3348, lr_0 = 8.2000e-04
Loss = 1.2819e+00, PNorm = 42.7718, GNorm = 1.3676, lr_0 = 9.9181e-04
Validation rmse = 1.347967
Epoch 2
Loss = 1.1876e+00, PNorm = 42.8146, GNorm = 2.9381, lr_0 = 9.5186e-04
Loss = 1.1130e+00, PNorm = 42.8668, GNorm = 2.1627, lr_0 = 9.1351e-04
Validation rmse = 1.196990
Epoch 3
Loss = 1.0587e+00, PNorm = 42.9297, GNorm = 3.8657, lr_0 = 8.7671e-04
Loss = 9.4995e-01, PNorm = 42.9914, GNorm = 13.8143, lr_0 = 8.4140e-04
Validation rmse = 1.166041
Epoch 4
Loss = 8.8177e-01, PNorm = 43.0496, GNorm = 3.3540, lr_0 = 8.0750e-04
Loss = 8.7867e-01, PNorm = 43.0977, GNorm = 7.8635, lr_0 = 7.7497e-04
Validation rmse = 1.072722
Epoch 5
Loss = 8.1038e-01, PNorm = 43.1434, GNorm = 3.3545, lr_0 = 7.4375e-04
Loss = 7.4046e-01, PNorm = 43.1858, GNorm = 3.8744, lr_0 = 7.1379e-04
Validation rmse = 0.972355
Epoch 6
Loss = 6.1761e-01, PNorm = 43.2254, GNorm = 6.7831, lr_0 = 6.8223e-04
Loss = 6.8209e-01, PNorm = 43.2639, GNorm = 3.7988, lr_0 = 6.5474e-04
Validation rmse = 0.949781
Epoch 7
Loss = 7.2262e-01, PNorm = 43.3001, GNorm = 6.3316, lr_0 = 6.2837e-04
Loss = 6.2988e-01, PNorm = 43.3291, GNorm = 6.3577, lr_0 = 6.0306e-04
Validation rmse = 0.917344
Epoch 8
Loss = 5.4643e-01, PNorm = 43.3664, GNorm = 10.7806, lr_0 = 5.7876e-04
Loss = 5.7907e-01, PNorm = 43.3961, GNorm = 2.6021, lr_0 = 5.5545e-04
Validation rmse = 0.910677
Epoch 9
Loss = 4.9606e-01, PNorm = 43.4149, GNorm = 4.2492, lr_0 = 5.3307e-04
Loss = 5.4847e-01, PNorm = 43.4414, GNorm = 11.7645, lr_0 = 5.1160e-04
Validation rmse = 0.928420
Epoch 10
Loss = 5.8500e-01, PNorm = 43.4619, GNorm = 2.3886, lr_0 = 4.9099e-04
Loss = 5.0236e-01, PNorm = 43.4800, GNorm = 6.3850, lr_0 = 4.7121e-04
Validation rmse = 0.935434
Epoch 11
Loss = 5.6441e-01, PNorm = 43.5042, GNorm = 2.1670, lr_0 = 4.5037e-04
Loss = 4.9426e-01, PNorm = 43.5262, GNorm = 7.6931, lr_0 = 4.3223e-04
Validation rmse = 0.883793
Epoch 12
Loss = 5.8105e-01, PNorm = 43.5411, GNorm = 10.5333, lr_0 = 4.1482e-04
Loss = 4.8886e-01, PNorm = 43.5577, GNorm = 5.0627, lr_0 = 3.9811e-04
Loss = 4.8471e-01, PNorm = 43.5756, GNorm = 15.9818, lr_0 = 3.8207e-04
Validation rmse = 0.906615
Epoch 13
Loss = 5.3336e-01, PNorm = 43.5939, GNorm = 12.3023, lr_0 = 3.6668e-04
Loss = 4.5659e-01, PNorm = 43.6091, GNorm = 2.6307, lr_0 = 3.5191e-04
Validation rmse = 0.885504
Epoch 14
Loss = 4.1930e-01, PNorm = 43.6259, GNorm = 11.7246, lr_0 = 3.3773e-04
Loss = 5.0364e-01, PNorm = 43.6388, GNorm = 16.9024, lr_0 = 3.2413e-04
Validation rmse = 0.901037
Epoch 15
Loss = 4.3519e-01, PNorm = 43.6534, GNorm = 3.3889, lr_0 = 3.1107e-04
Loss = 4.3659e-01, PNorm = 43.6677, GNorm = 4.1186, lr_0 = 2.9854e-04
Validation rmse = 0.871275
Epoch 16
Loss = 4.1909e-01, PNorm = 43.6829, GNorm = 4.0104, lr_0 = 2.8534e-04
Loss = 4.0266e-01, PNorm = 43.6963, GNorm = 6.4885, lr_0 = 2.7384e-04
Validation rmse = 0.896164
Epoch 17
Loss = 3.8028e-01, PNorm = 43.7038, GNorm = 9.1196, lr_0 = 2.6281e-04
Loss = 4.1285e-01, PNorm = 43.7141, GNorm = 2.2944, lr_0 = 2.5222e-04
Validation rmse = 0.870691
Epoch 18
Loss = 3.6304e-01, PNorm = 43.7268, GNorm = 4.9688, lr_0 = 2.4206e-04
Loss = 4.0304e-01, PNorm = 43.7359, GNorm = 2.7230, lr_0 = 2.3231e-04
Validation rmse = 0.868651
Epoch 19
Loss = 4.0134e-01, PNorm = 43.7450, GNorm = 3.5273, lr_0 = 2.2295e-04
Loss = 4.0801e-01, PNorm = 43.7545, GNorm = 5.7748, lr_0 = 2.1397e-04
Validation rmse = 0.857347
Epoch 20
Loss = 3.3611e-01, PNorm = 43.7657, GNorm = 10.3076, lr_0 = 2.0535e-04
Loss = 3.6617e-01, PNorm = 43.7737, GNorm = 3.4056, lr_0 = 1.9708e-04
Validation rmse = 0.874481
Epoch 21
Loss = 3.5228e-01, PNorm = 43.7829, GNorm = 4.4141, lr_0 = 1.8836e-04
Loss = 3.4379e-01, PNorm = 43.7900, GNorm = 3.2835, lr_0 = 1.8078e-04
Validation rmse = 0.858609
Epoch 22
Loss = 2.8280e-01, PNorm = 43.7989, GNorm = 8.1033, lr_0 = 1.7349e-04
Loss = 3.3730e-01, PNorm = 43.8085, GNorm = 4.8153, lr_0 = 1.6651e-04
Validation rmse = 0.888501
Epoch 23
Loss = 1.8167e-01, PNorm = 43.8152, GNorm = 3.5551, lr_0 = 1.5980e-04
Loss = 3.9699e-01, PNorm = 43.8210, GNorm = 4.0421, lr_0 = 1.5336e-04
Validation rmse = 0.857398
Epoch 24
Loss = 6.5484e-01, PNorm = 43.8274, GNorm = 4.1917, lr_0 = 1.4718e-04
Loss = 3.1190e-01, PNorm = 43.8349, GNorm = 3.3389, lr_0 = 1.4125e-04
Loss = 2.7503e-01, PNorm = 43.8435, GNorm = 7.7933, lr_0 = 1.3556e-04
Validation rmse = 0.865797
Epoch 25
Loss = 2.9325e-01, PNorm = 43.8498, GNorm = 3.8600, lr_0 = 1.3010e-04
Loss = 3.3938e-01, PNorm = 43.8548, GNorm = 4.4286, lr_0 = 1.2486e-04
Loss = 2.4422e-01, PNorm = 43.8553, GNorm = 2.6572, lr_0 = 1.2435e-04
Validation rmse = 0.869779
Epoch 26
Loss = 3.4140e-01, PNorm = 43.8608, GNorm = 4.5599, lr_0 = 1.1934e-04
Loss = 2.9648e-01, PNorm = 43.8657, GNorm = 3.5967, lr_0 = 1.1453e-04
Validation rmse = 0.853085
Epoch 27
Loss = 2.8859e-01, PNorm = 43.8707, GNorm = 5.8098, lr_0 = 1.0992e-04
Loss = 2.9433e-01, PNorm = 43.8758, GNorm = 4.5898, lr_0 = 1.0549e-04
Validation rmse = 0.860873
Epoch 28
Loss = 2.5877e-01, PNorm = 43.8806, GNorm = 5.2207, lr_0 = 1.0124e-04
Loss = 2.9782e-01, PNorm = 43.8851, GNorm = 6.7919, lr_0 = 1.0000e-04
Validation rmse = 0.866561
Epoch 29
Loss = 3.1936e-01, PNorm = 43.8887, GNorm = 4.6351, lr_0 = 1.0000e-04
Loss = 2.6839e-01, PNorm = 43.8927, GNorm = 10.1731, lr_0 = 1.0000e-04
Validation rmse = 0.851530
Model 0 best validation rmse = 0.851530 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.656402
Ensemble test rmse = 0.656402
1-fold cross validation
	Seed 0 ==> test rmse = 0.656402
Overall test rmse = 0.656402 +/- 0.000000
Elapsed time = 0:01:42
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7349e+00, PNorm = 42.7369, GNorm = 2.5835, lr_0 = 3.3571e-04
Loss = 1.4329e+00, PNorm = 42.7344, GNorm = 0.8903, lr_0 = 5.5000e-04
Validation rmse = 1.478926
Epoch 1
Loss = 1.3007e+00, PNorm = 42.7472, GNorm = 0.9031, lr_0 = 7.8571e-04
Loss = 1.2657e+00, PNorm = 42.7748, GNorm = 1.3015, lr_0 = 1.0000e-03
Validation rmse = 1.303939
Epoch 2
Loss = 1.1687e+00, PNorm = 42.8216, GNorm = 2.7652, lr_0 = 9.6160e-04
Loss = 1.0951e+00, PNorm = 42.8831, GNorm = 5.4571, lr_0 = 9.2467e-04
Validation rmse = 1.074876
Epoch 3
Loss = 9.4727e-01, PNorm = 42.9450, GNorm = 1.9009, lr_0 = 8.8568e-04
Loss = 9.4343e-01, PNorm = 43.0107, GNorm = 11.7445, lr_0 = 8.5167e-04
Validation rmse = 0.964251
Epoch 4
Loss = 9.5851e-01, PNorm = 43.0678, GNorm = 3.1672, lr_0 = 8.1896e-04
Loss = 8.2207e-01, PNorm = 43.1169, GNorm = 3.2756, lr_0 = 7.8751e-04
Validation rmse = 0.946860
Epoch 5
Loss = 6.0499e-01, PNorm = 43.1526, GNorm = 5.0658, lr_0 = 7.5727e-04
Loss = 6.8317e-01, PNorm = 43.2010, GNorm = 9.0884, lr_0 = 7.2819e-04
Validation rmse = 0.925762
Epoch 6
Loss = 7.2339e-01, PNorm = 43.2341, GNorm = 1.7720, lr_0 = 6.9749e-04
Loss = 6.8420e-01, PNorm = 43.2658, GNorm = 13.1538, lr_0 = 6.7070e-04
Loss = 6.9063e-01, PNorm = 43.3053, GNorm = 2.9026, lr_0 = 6.4495e-04
Validation rmse = 0.911245
Epoch 7
Loss = 5.6305e-01, PNorm = 43.3460, GNorm = 3.7195, lr_0 = 6.2018e-04
Loss = 6.7506e-01, PNorm = 43.3721, GNorm = 4.7010, lr_0 = 5.9636e-04
Validation rmse = 0.908390
Epoch 8
Loss = 6.0190e-01, PNorm = 43.3990, GNorm = 4.2221, lr_0 = 5.7122e-04
Loss = 5.5404e-01, PNorm = 43.4287, GNorm = 3.2042, lr_0 = 5.4928e-04
Validation rmse = 0.858257
Epoch 9
Loss = 5.3211e-01, PNorm = 43.4496, GNorm = 3.0340, lr_0 = 5.2819e-04
Loss = 5.4508e-01, PNorm = 43.4687, GNorm = 11.0328, lr_0 = 5.0790e-04
Validation rmse = 0.848755
Epoch 10
Loss = 5.1719e-01, PNorm = 43.4885, GNorm = 7.3609, lr_0 = 4.8840e-04
Loss = 5.6804e-01, PNorm = 43.5097, GNorm = 6.8798, lr_0 = 4.6964e-04
Validation rmse = 0.836713
Epoch 11
Loss = 5.4001e-01, PNorm = 43.5359, GNorm = 8.1796, lr_0 = 4.4984e-04
Loss = 4.8613e-01, PNorm = 43.5512, GNorm = 3.7639, lr_0 = 4.3257e-04
Validation rmse = 0.838176
Epoch 12
Loss = 5.3725e-01, PNorm = 43.5727, GNorm = 4.7771, lr_0 = 4.1596e-04
Loss = 4.5454e-01, PNorm = 43.5887, GNorm = 4.6597, lr_0 = 3.9998e-04
Loss = 5.1355e-01, PNorm = 43.6021, GNorm = 7.2257, lr_0 = 3.8462e-04
Loss = 7.0261e-01, PNorm = 43.6035, GNorm = 3.8768, lr_0 = 3.8312e-04
Validation rmse = 0.840921
Epoch 13
Loss = 4.6344e-01, PNorm = 43.6192, GNorm = 4.5823, lr_0 = 3.6841e-04
Loss = 4.2913e-01, PNorm = 43.6372, GNorm = 6.1299, lr_0 = 3.5426e-04
Validation rmse = 0.840775
Epoch 14
Loss = 4.0021e-01, PNorm = 43.6517, GNorm = 7.9050, lr_0 = 3.4065e-04
Loss = 4.3298e-01, PNorm = 43.6652, GNorm = 2.9002, lr_0 = 3.2757e-04
Validation rmse = 0.810782
Epoch 15
Loss = 5.4533e-01, PNorm = 43.6780, GNorm = 8.2021, lr_0 = 3.1499e-04
Loss = 4.5134e-01, PNorm = 43.6933, GNorm = 8.1075, lr_0 = 3.0290e-04
Validation rmse = 0.806684
Epoch 16
Loss = 3.6522e-01, PNorm = 43.7086, GNorm = 4.5388, lr_0 = 2.9012e-04
Loss = 4.5851e-01, PNorm = 43.7204, GNorm = 3.0819, lr_0 = 2.7898e-04
Validation rmse = 0.832330
Epoch 17
Loss = 4.6242e-01, PNorm = 43.7331, GNorm = 3.3449, lr_0 = 2.6827e-04
Loss = 3.9937e-01, PNorm = 43.7423, GNorm = 11.9907, lr_0 = 2.5797e-04
Validation rmse = 0.803908
Epoch 18
Loss = 3.4643e-01, PNorm = 43.7542, GNorm = 2.2176, lr_0 = 2.4709e-04
Loss = 3.8204e-01, PNorm = 43.7643, GNorm = 8.3424, lr_0 = 2.3760e-04
Loss = 4.3685e-01, PNorm = 43.7741, GNorm = 12.5445, lr_0 = 2.2848e-04
Validation rmse = 0.802215
Epoch 19
Loss = 4.1616e-01, PNorm = 43.7852, GNorm = 9.5344, lr_0 = 2.1970e-04
Loss = 3.9901e-01, PNorm = 43.7960, GNorm = 21.6903, lr_0 = 2.1127e-04
Validation rmse = 0.807744
Epoch 20
Loss = 3.2322e-01, PNorm = 43.8062, GNorm = 7.5572, lr_0 = 2.0315e-04
Loss = 4.1000e-01, PNorm = 43.8145, GNorm = 3.8769, lr_0 = 1.9535e-04
Validation rmse = 0.797436
Epoch 21
Loss = 3.1889e-01, PNorm = 43.8232, GNorm = 3.9532, lr_0 = 1.8712e-04
Loss = 3.4360e-01, PNorm = 43.8323, GNorm = 4.0839, lr_0 = 1.7993e-04
Validation rmse = 0.788303
Epoch 22
Loss = 3.9040e-01, PNorm = 43.8387, GNorm = 5.2707, lr_0 = 1.7302e-04
Loss = 3.2936e-01, PNorm = 43.8447, GNorm = 6.0142, lr_0 = 1.6638e-04
Validation rmse = 0.795714
Epoch 23
Loss = 3.3961e-01, PNorm = 43.8543, GNorm = 11.8282, lr_0 = 1.5936e-04
Loss = 3.5379e-01, PNorm = 43.8615, GNorm = 5.1488, lr_0 = 1.5324e-04
Validation rmse = 0.787383
Epoch 24
Loss = 2.8858e-01, PNorm = 43.8680, GNorm = 6.8881, lr_0 = 1.4736e-04
Loss = 3.5983e-01, PNorm = 43.8753, GNorm = 4.1085, lr_0 = 1.4170e-04
Loss = 2.8649e-01, PNorm = 43.8824, GNorm = 3.7797, lr_0 = 1.3626e-04
Validation rmse = 0.794073
Epoch 25
Loss = 3.1619e-01, PNorm = 43.8884, GNorm = 4.8250, lr_0 = 1.3102e-04
Loss = 2.8926e-01, PNorm = 43.8940, GNorm = 4.5234, lr_0 = 1.2599e-04
Validation rmse = 0.783841
Epoch 26
Loss = 2.9297e-01, PNorm = 43.9000, GNorm = 3.9922, lr_0 = 1.2068e-04
Loss = 2.8694e-01, PNorm = 43.9068, GNorm = 6.3943, lr_0 = 1.1604e-04
Validation rmse = 0.787749
Epoch 27
Loss = 2.7745e-01, PNorm = 43.9110, GNorm = 3.2239, lr_0 = 1.1159e-04
Loss = 3.2467e-01, PNorm = 43.9159, GNorm = 7.3940, lr_0 = 1.0730e-04
Validation rmse = 0.776055
Epoch 28
Loss = 2.7267e-01, PNorm = 43.9211, GNorm = 3.2253, lr_0 = 1.0278e-04
Loss = 2.9208e-01, PNorm = 43.9255, GNorm = 8.0728, lr_0 = 1.0000e-04
Validation rmse = 0.785664
Epoch 29
Loss = 2.9728e-01, PNorm = 43.9295, GNorm = 3.3351, lr_0 = 1.0000e-04
Loss = 2.4614e-01, PNorm = 43.9343, GNorm = 9.8678, lr_0 = 1.0000e-04
Validation rmse = 0.781432
Model 0 best validation rmse = 0.776055 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.629297
Ensemble test rmse = 0.629297
1-fold cross validation
	Seed 0 ==> test rmse = 0.629297
Overall test rmse = 0.629297 +/- 0.000000
Elapsed time = 0:01:47
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8253e+00, PNorm = 42.7394, GNorm = 2.3323, lr_0 = 3.2500e-04
Loss = 1.4072e+00, PNorm = 42.7384, GNorm = 1.0607, lr_0 = 5.2955e-04
Validation rmse = 1.484934
Epoch 1
Loss = 1.3315e+00, PNorm = 42.7499, GNorm = 1.7430, lr_0 = 7.5455e-04
Loss = 1.2976e+00, PNorm = 42.7727, GNorm = 1.0666, lr_0 = 9.5909e-04
Validation rmse = 1.311336
Epoch 2
Loss = 1.1507e+00, PNorm = 42.8218, GNorm = 2.1769, lr_0 = 9.6692e-04
Loss = 1.1045e+00, PNorm = 42.8833, GNorm = 1.3249, lr_0 = 9.3144e-04
Validation rmse = 1.153499
Epoch 3
Loss = 9.6619e-01, PNorm = 42.9452, GNorm = 3.1258, lr_0 = 8.9727e-04
Loss = 8.9196e-01, PNorm = 43.0058, GNorm = 2.0435, lr_0 = 8.6435e-04
Validation rmse = 1.045369
Epoch 4
Loss = 1.3987e+00, PNorm = 43.0672, GNorm = 27.3428, lr_0 = 8.2953e-04
Loss = 8.9360e-01, PNorm = 43.1060, GNorm = 5.2101, lr_0 = 7.9909e-04
Loss = 7.7620e-01, PNorm = 43.1555, GNorm = 4.7501, lr_0 = 7.6977e-04
Validation rmse = 0.931817
Epoch 5
Loss = 6.5755e-01, PNorm = 43.1960, GNorm = 5.9302, lr_0 = 7.4153e-04
Loss = 6.9913e-01, PNorm = 43.2279, GNorm = 6.5610, lr_0 = 7.1433e-04
Validation rmse = 0.920022
Epoch 6
Loss = 7.2352e-01, PNorm = 43.2684, GNorm = 10.1566, lr_0 = 6.8555e-04
Loss = 6.3177e-01, PNorm = 43.2986, GNorm = 2.2097, lr_0 = 6.6040e-04
Validation rmse = 0.869531
Epoch 7
Loss = 6.8753e-01, PNorm = 43.3305, GNorm = 6.6618, lr_0 = 6.3379e-04
Loss = 5.6977e-01, PNorm = 43.3612, GNorm = 6.5188, lr_0 = 6.1054e-04
Validation rmse = 0.875680
Epoch 8
Loss = 3.2131e-01, PNorm = 43.3908, GNorm = 4.8486, lr_0 = 5.8814e-04
Loss = 5.8086e-01, PNorm = 43.4134, GNorm = 9.0955, lr_0 = 5.6656e-04
Loss = 5.5720e-01, PNorm = 43.4323, GNorm = 3.4078, lr_0 = 5.4577e-04
Validation rmse = 0.889352
Epoch 9
Loss = 5.0777e-01, PNorm = 43.4627, GNorm = 2.7384, lr_0 = 5.2379e-04
Loss = 5.8677e-01, PNorm = 43.4791, GNorm = 5.0828, lr_0 = 5.0457e-04
Validation rmse = 0.842652
Epoch 10
Loss = 4.6363e-01, PNorm = 43.5026, GNorm = 2.5815, lr_0 = 4.8606e-04
Loss = 5.3692e-01, PNorm = 43.5273, GNorm = 6.2745, lr_0 = 4.6822e-04
Validation rmse = 0.971226
Epoch 11
Loss = 5.8072e-01, PNorm = 43.5440, GNorm = 3.6280, lr_0 = 4.4936e-04
Loss = 5.1527e-01, PNorm = 43.5602, GNorm = 14.4788, lr_0 = 4.3288e-04
Validation rmse = 0.853063
Epoch 12
Loss = 5.1769e-01, PNorm = 43.5814, GNorm = 3.3358, lr_0 = 4.1544e-04
Loss = 4.5725e-01, PNorm = 43.6025, GNorm = 19.9719, lr_0 = 4.0020e-04
Loss = 4.0787e-01, PNorm = 43.6162, GNorm = 3.9107, lr_0 = 3.8551e-04
Validation rmse = 0.835928
Epoch 13
Loss = 4.9395e-01, PNorm = 43.6256, GNorm = 3.2979, lr_0 = 3.7137e-04
Loss = 4.1897e-01, PNorm = 43.6439, GNorm = 4.1103, lr_0 = 3.5774e-04
Validation rmse = 0.822350
Epoch 14
Loss = 4.6358e-01, PNorm = 43.6608, GNorm = 6.4046, lr_0 = 3.4333e-04
Loss = 4.2622e-01, PNorm = 43.6769, GNorm = 6.3936, lr_0 = 3.3074e-04
Validation rmse = 0.846804
Epoch 15
Loss = 4.1856e-01, PNorm = 43.6880, GNorm = 6.5995, lr_0 = 3.1860e-04
Loss = 4.1231e-01, PNorm = 43.7008, GNorm = 8.8687, lr_0 = 3.0691e-04
Validation rmse = 0.838683
Epoch 16
Loss = 3.0677e-01, PNorm = 43.7155, GNorm = 2.4111, lr_0 = 2.9455e-04
Loss = 4.6108e-01, PNorm = 43.7266, GNorm = 3.9819, lr_0 = 2.8374e-04
Loss = 4.0109e-01, PNorm = 43.7371, GNorm = 14.8774, lr_0 = 2.7333e-04
Loss = 3.1738e-01, PNorm = 43.7384, GNorm = 11.1903, lr_0 = 2.7231e-04
Validation rmse = 0.813117
Epoch 17
Loss = 3.6896e-01, PNorm = 43.7498, GNorm = 6.1065, lr_0 = 2.6232e-04
Loss = 4.0648e-01, PNorm = 43.7639, GNorm = 9.2955, lr_0 = 2.5270e-04
Validation rmse = 0.822033
Epoch 18
Loss = 4.1280e-01, PNorm = 43.7754, GNorm = 3.7716, lr_0 = 2.4342e-04
Loss = 3.6135e-01, PNorm = 43.7846, GNorm = 5.8948, lr_0 = 2.3449e-04
Validation rmse = 0.811779
Epoch 19
Loss = 4.0355e-01, PNorm = 43.7934, GNorm = 9.6259, lr_0 = 2.2505e-04
Loss = 3.6311e-01, PNorm = 43.8006, GNorm = 3.7120, lr_0 = 2.1679e-04
Validation rmse = 0.808076
Epoch 20
Loss = 3.7423e-01, PNorm = 43.8104, GNorm = 5.4693, lr_0 = 2.0884e-04
Loss = 3.6926e-01, PNorm = 43.8200, GNorm = 8.8346, lr_0 = 2.0117e-04
Loss = 2.9419e-01, PNorm = 43.8277, GNorm = 3.6952, lr_0 = 1.9379e-04
Loss = -2.9528e-02, PNorm = 43.8285, GNorm = 4.8040, lr_0 = 1.9307e-04
Validation rmse = 0.807251
Epoch 21
Loss = 2.9392e-01, PNorm = 43.8356, GNorm = 8.2984, lr_0 = 1.8599e-04
Loss = 3.7674e-01, PNorm = 43.8430, GNorm = 11.8831, lr_0 = 1.7916e-04
Validation rmse = 0.848319
Epoch 22
Loss = 3.3614e-01, PNorm = 43.8508, GNorm = 3.6615, lr_0 = 1.7195e-04
Loss = 3.2577e-01, PNorm = 43.8585, GNorm = 6.9370, lr_0 = 1.6564e-04
Validation rmse = 0.812053
Epoch 23
Loss = 2.6282e-01, PNorm = 43.8640, GNorm = 5.2013, lr_0 = 1.5956e-04
Loss = 3.5409e-01, PNorm = 43.8694, GNorm = 2.3713, lr_0 = 1.5371e-04
Validation rmse = 0.800286
Epoch 24
Loss = 3.3039e-01, PNorm = 43.8780, GNorm = 4.1799, lr_0 = 1.4751e-04
Loss = 2.9480e-01, PNorm = 43.8849, GNorm = 8.9360, lr_0 = 1.4210e-04
Loss = 3.2751e-01, PNorm = 43.8880, GNorm = 7.8815, lr_0 = 1.3689e-04
Validation rmse = 0.803966
Epoch 25
Loss = 3.5133e-01, PNorm = 43.8935, GNorm = 2.5783, lr_0 = 1.3187e-04
Loss = 3.0380e-01, PNorm = 43.9002, GNorm = 3.3006, lr_0 = 1.2703e-04
Validation rmse = 0.806739
Epoch 26
Loss = 2.7558e-01, PNorm = 43.9070, GNorm = 4.7386, lr_0 = 1.2191e-04
Loss = 3.2035e-01, PNorm = 43.9115, GNorm = 14.8536, lr_0 = 1.1744e-04
Validation rmse = 0.801489
Epoch 27
Loss = 3.0444e-01, PNorm = 43.9163, GNorm = 5.0288, lr_0 = 1.1271e-04
Loss = 3.0773e-01, PNorm = 43.9208, GNorm = 7.4368, lr_0 = 1.0857e-04
Validation rmse = 0.800741
Epoch 28
Loss = 3.9032e-01, PNorm = 43.9260, GNorm = 7.7031, lr_0 = 1.0459e-04
Loss = 2.3196e-01, PNorm = 43.9307, GNorm = 4.7280, lr_0 = 1.0075e-04
Validation rmse = 0.802422
Epoch 29
Loss = 2.1881e-01, PNorm = 43.9355, GNorm = 3.8297, lr_0 = 1.0000e-04
Loss = 2.3687e-01, PNorm = 43.9391, GNorm = 9.8470, lr_0 = 1.0000e-04
Loss = 3.4869e-01, PNorm = 43.9424, GNorm = 4.6179, lr_0 = 1.0000e-04
Validation rmse = 0.800037
Model 0 best validation rmse = 0.800037 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.662931
Ensemble test rmse = 0.662931
1-fold cross validation
	Seed 0 ==> test rmse = 0.662931
Overall test rmse = 0.662931 +/- 0.000000
Elapsed time = 0:01:50
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8089e+00, PNorm = 42.7400, GNorm = 3.9481, lr_0 = 3.1522e-04
Loss = 1.4021e+00, PNorm = 42.7389, GNorm = 1.8528, lr_0 = 5.1087e-04
Validation rmse = 1.449254
Epoch 1
Loss = 1.3246e+00, PNorm = 42.7479, GNorm = 1.4921, lr_0 = 7.2609e-04
Loss = 1.2640e+00, PNorm = 42.7729, GNorm = 1.9673, lr_0 = 9.2174e-04
Validation rmse = 1.264476
Epoch 2
Loss = 1.0498e+00, PNorm = 42.8226, GNorm = 3.5501, lr_0 = 9.7528e-04
Loss = 1.1580e+00, PNorm = 42.8794, GNorm = 1.4020, lr_0 = 9.4103e-04
Validation rmse = 1.278856
Epoch 3
Loss = 1.0786e+00, PNorm = 42.9483, GNorm = 9.2985, lr_0 = 9.0474e-04
Loss = 9.3402e-01, PNorm = 42.9988, GNorm = 1.9940, lr_0 = 8.7296e-04
Loss = 8.7767e-01, PNorm = 43.0565, GNorm = 3.5396, lr_0 = 8.4230e-04
Validation rmse = 0.943680
Epoch 4
Loss = 7.2681e-01, PNorm = 43.1123, GNorm = 7.2923, lr_0 = 8.0981e-04
Loss = 8.2549e-01, PNorm = 43.1480, GNorm = 4.2531, lr_0 = 7.8137e-04
Validation rmse = 0.931996
Epoch 5
Loss = 6.6068e-01, PNorm = 43.1914, GNorm = 5.1156, lr_0 = 7.5393e-04
Loss = 7.2078e-01, PNorm = 43.2279, GNorm = 8.0660, lr_0 = 7.2745e-04
Validation rmse = 0.846294
Epoch 6
Loss = 7.0981e-01, PNorm = 43.2660, GNorm = 1.8468, lr_0 = 6.9939e-04
Loss = 6.9978e-01, PNorm = 43.3021, GNorm = 5.3128, lr_0 = 6.7483e-04
Loss = 7.0845e-01, PNorm = 43.3356, GNorm = 11.9581, lr_0 = 6.5113e-04
Validation rmse = 1.046974
Epoch 7
Loss = 8.2318e-01, PNorm = 43.3587, GNorm = 4.0548, lr_0 = 6.2601e-04
Loss = 6.3312e-01, PNorm = 43.3879, GNorm = 8.8872, lr_0 = 6.0403e-04
Validation rmse = 0.861669
Epoch 8
Loss = 5.2101e-01, PNorm = 43.4214, GNorm = 4.2786, lr_0 = 5.8073e-04
Loss = 5.3889e-01, PNorm = 43.4493, GNorm = 9.3296, lr_0 = 5.6033e-04
Validation rmse = 0.814644
Epoch 9
Loss = 5.3171e-01, PNorm = 43.4751, GNorm = 4.4984, lr_0 = 5.3872e-04
Loss = 5.4817e-01, PNorm = 43.5011, GNorm = 7.5001, lr_0 = 5.1980e-04
Loss = 5.5364e-01, PNorm = 43.5236, GNorm = 7.5781, lr_0 = 5.0155e-04
Validation rmse = 0.834992
Epoch 10
Loss = 5.6256e-01, PNorm = 43.5358, GNorm = 2.9469, lr_0 = 4.8393e-04
Loss = 5.8289e-01, PNorm = 43.5584, GNorm = 4.6590, lr_0 = 4.6693e-04
Validation rmse = 0.834972
Epoch 11
Loss = 4.4754e-01, PNorm = 43.5852, GNorm = 8.7327, lr_0 = 4.4893e-04
Loss = 4.9615e-01, PNorm = 43.6004, GNorm = 5.8386, lr_0 = 4.3316e-04
Validation rmse = 0.847228
Epoch 12
Loss = 4.8893e-01, PNorm = 43.6146, GNorm = 9.4418, lr_0 = 4.1645e-04
Loss = 4.3865e-01, PNorm = 43.6305, GNorm = 5.0701, lr_0 = 4.0183e-04
Loss = 4.8123e-01, PNorm = 43.6465, GNorm = 7.7060, lr_0 = 3.8771e-04
Validation rmse = 0.807461
Epoch 13
Loss = 4.3435e-01, PNorm = 43.6670, GNorm = 4.1846, lr_0 = 3.7276e-04
Loss = 4.6266e-01, PNorm = 43.6820, GNorm = 12.9176, lr_0 = 3.5967e-04
Validation rmse = 0.865348
Epoch 14
Loss = 4.0520e-01, PNorm = 43.6999, GNorm = 3.5669, lr_0 = 3.4580e-04
Loss = 4.6597e-01, PNorm = 43.7105, GNorm = 10.5010, lr_0 = 3.3365e-04
Validation rmse = 0.794618
Epoch 15
Loss = 2.5698e-01, PNorm = 43.7240, GNorm = 3.0669, lr_0 = 3.2193e-04
Loss = 4.6854e-01, PNorm = 43.7355, GNorm = 4.0862, lr_0 = 3.1062e-04
Loss = 4.2392e-01, PNorm = 43.7495, GNorm = 15.4703, lr_0 = 2.9971e-04
Validation rmse = 0.784561
Epoch 16
Loss = 3.2654e-01, PNorm = 43.7659, GNorm = 3.2035, lr_0 = 2.8816e-04
Loss = 4.4365e-01, PNorm = 43.7738, GNorm = 5.4777, lr_0 = 2.7803e-04
Validation rmse = 0.806232
Epoch 17
Loss = 3.6645e-01, PNorm = 43.7855, GNorm = 5.6999, lr_0 = 2.6731e-04
Loss = 4.1100e-01, PNorm = 43.8002, GNorm = 10.6586, lr_0 = 2.5792e-04
Validation rmse = 0.798169
Epoch 18
Loss = 3.6687e-01, PNorm = 43.8086, GNorm = 2.5872, lr_0 = 2.4798e-04
Loss = 3.4621e-01, PNorm = 43.8170, GNorm = 3.9017, lr_0 = 2.3927e-04
Loss = 4.0379e-01, PNorm = 43.8259, GNorm = 3.8853, lr_0 = 2.3086e-04
Loss = 8.7913e-01, PNorm = 43.8263, GNorm = 12.7863, lr_0 = 2.3004e-04
Validation rmse = 0.823247
Epoch 19
Loss = 3.4161e-01, PNorm = 43.8338, GNorm = 3.5780, lr_0 = 2.2196e-04
Loss = 3.3276e-01, PNorm = 43.8425, GNorm = 4.1015, lr_0 = 2.1416e-04
Validation rmse = 0.784028
Epoch 20
Loss = 3.7118e-01, PNorm = 43.8511, GNorm = 3.0270, lr_0 = 2.0664e-04
Loss = 3.3001e-01, PNorm = 43.8598, GNorm = 6.2585, lr_0 = 1.9938e-04
Validation rmse = 0.798559
Epoch 21
Loss = 2.5629e-01, PNorm = 43.8696, GNorm = 3.5216, lr_0 = 1.9169e-04
Loss = 3.7704e-01, PNorm = 43.8762, GNorm = 3.7309, lr_0 = 1.8496e-04
Loss = 3.1922e-01, PNorm = 43.8834, GNorm = 3.4564, lr_0 = 1.7846e-04
Loss = 3.3605e-01, PNorm = 43.8844, GNorm = 18.8606, lr_0 = 1.7783e-04
Validation rmse = 0.792316
Epoch 22
Loss = 3.7842e-01, PNorm = 43.8932, GNorm = 3.6331, lr_0 = 1.7158e-04
Loss = 2.8958e-01, PNorm = 43.8994, GNorm = 3.4330, lr_0 = 1.6556e-04
Validation rmse = 0.788112
Epoch 23
Loss = 2.6415e-01, PNorm = 43.9058, GNorm = 4.5810, lr_0 = 1.5917e-04
Loss = 3.5158e-01, PNorm = 43.9128, GNorm = 9.3243, lr_0 = 1.5358e-04
Validation rmse = 0.774685
Epoch 24
Loss = 2.5910e-01, PNorm = 43.9174, GNorm = 5.6804, lr_0 = 1.4766e-04
Loss = 3.0067e-01, PNorm = 43.9239, GNorm = 5.2308, lr_0 = 1.4247e-04
Loss = 3.5527e-01, PNorm = 43.9316, GNorm = 7.7778, lr_0 = 1.3747e-04
Validation rmse = 0.836183
Epoch 25
Loss = 3.0306e-01, PNorm = 43.9379, GNorm = 7.6500, lr_0 = 1.3264e-04
Loss = 3.3355e-01, PNorm = 43.9430, GNorm = 5.5316, lr_0 = 1.2798e-04
Validation rmse = 0.776891
Epoch 26
Loss = 2.3541e-01, PNorm = 43.9475, GNorm = 4.4844, lr_0 = 1.2304e-04
Loss = 3.1260e-01, PNorm = 43.9524, GNorm = 3.9242, lr_0 = 1.1872e-04
Validation rmse = 0.781867
Epoch 27
Loss = 2.8527e-01, PNorm = 43.9588, GNorm = 11.2646, lr_0 = 1.1414e-04
Loss = 3.1106e-01, PNorm = 43.9637, GNorm = 11.4484, lr_0 = 1.1014e-04
Validation rmse = 0.768585
Epoch 28
Loss = 2.5358e-01, PNorm = 43.9675, GNorm = 9.9528, lr_0 = 1.0589e-04
Loss = 2.5879e-01, PNorm = 43.9719, GNorm = 4.2369, lr_0 = 1.0217e-04
Loss = 3.6045e-01, PNorm = 43.9757, GNorm = 6.8849, lr_0 = 1.0000e-04
Validation rmse = 0.769950
Epoch 29
Loss = 2.5156e-01, PNorm = 43.9795, GNorm = 6.4444, lr_0 = 1.0000e-04
Loss = 3.1086e-01, PNorm = 43.9834, GNorm = 4.6157, lr_0 = 1.0000e-04
Validation rmse = 0.777040
Model 0 best validation rmse = 0.768585 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.652512
Ensemble test rmse = 0.652512
1-fold cross validation
	Seed 0 ==> test rmse = 0.652512
Overall test rmse = 0.652512 +/- 0.000000
Elapsed time = 0:01:56
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8735e+00, PNorm = 42.7410, GNorm = 1.3123, lr_0 = 3.0625e-04
Loss = 1.4407e+00, PNorm = 42.7402, GNorm = 0.8947, lr_0 = 4.9375e-04
Validation rmse = 1.504712
Epoch 1
Loss = 1.3393e+00, PNorm = 42.7461, GNorm = 0.7228, lr_0 = 6.8125e-04
Loss = 1.2856e+00, PNorm = 42.7668, GNorm = 1.1479, lr_0 = 8.6875e-04
Validation rmse = 1.351239
Epoch 2
Loss = 1.0876e+00, PNorm = 42.8012, GNorm = 1.4492, lr_0 = 9.8977e-04
Loss = 1.1205e+00, PNorm = 42.8546, GNorm = 1.4542, lr_0 = 9.5643e-04
Loss = 1.0236e+00, PNorm = 42.9205, GNorm = 1.5281, lr_0 = 9.2422e-04
Validation rmse = 1.156367
Epoch 3
Loss = 8.7890e-01, PNorm = 42.9964, GNorm = 1.6459, lr_0 = 8.9309e-04
Loss = 9.2371e-01, PNorm = 43.0546, GNorm = 19.2842, lr_0 = 8.6300e-04
Validation rmse = 1.017775
Epoch 4
Loss = 8.8902e-01, PNorm = 43.0984, GNorm = 4.7113, lr_0 = 8.3393e-04
Loss = 8.1808e-01, PNorm = 43.1546, GNorm = 3.7936, lr_0 = 8.0584e-04
Loss = 7.4995e-01, PNorm = 43.2005, GNorm = 5.5645, lr_0 = 7.7870e-04
Validation rmse = 0.993242
Epoch 5
Loss = 7.0194e-01, PNorm = 43.2482, GNorm = 2.4879, lr_0 = 7.5247e-04
Loss = 6.5574e-01, PNorm = 43.2893, GNorm = 6.3966, lr_0 = 7.2712e-04
Validation rmse = 0.924144
Epoch 6
Loss = 6.2485e-01, PNorm = 43.3201, GNorm = 3.3721, lr_0 = 7.0263e-04
Loss = 6.3428e-01, PNorm = 43.3573, GNorm = 14.5294, lr_0 = 6.7896e-04
Validation rmse = 0.893743
Epoch 7
Loss = 5.6459e-01, PNorm = 43.3815, GNorm = 3.1179, lr_0 = 6.5609e-04
Loss = 5.5952e-01, PNorm = 43.4146, GNorm = 8.6195, lr_0 = 6.3399e-04
Loss = 5.5225e-01, PNorm = 43.4409, GNorm = 3.7935, lr_0 = 6.1264e-04
Validation rmse = 0.864414
Epoch 8
Loss = 4.7763e-01, PNorm = 43.4696, GNorm = 4.0194, lr_0 = 5.9200e-04
Loss = 5.2732e-01, PNorm = 43.4915, GNorm = 12.7746, lr_0 = 5.7206e-04
Validation rmse = 0.911736
Epoch 9
Loss = 5.8668e-01, PNorm = 43.5169, GNorm = 11.5144, lr_0 = 5.5279e-04
Loss = 4.9745e-01, PNorm = 43.5435, GNorm = 6.4964, lr_0 = 5.3417e-04
Loss = 4.8715e-01, PNorm = 43.5611, GNorm = 4.9277, lr_0 = 5.1618e-04
Validation rmse = 0.846596
Epoch 10
Loss = 4.3406e-01, PNorm = 43.5800, GNorm = 2.7310, lr_0 = 4.9879e-04
Loss = 5.0418e-01, PNorm = 43.5999, GNorm = 4.8359, lr_0 = 4.8199e-04
Validation rmse = 0.858175
Epoch 11
Loss = 4.1823e-01, PNorm = 43.6190, GNorm = 17.4770, lr_0 = 4.6575e-04
Loss = 4.7191e-01, PNorm = 43.6368, GNorm = 9.7668, lr_0 = 4.5006e-04
Validation rmse = 0.845685
Epoch 12
Loss = 4.2749e-01, PNorm = 43.6542, GNorm = 8.0622, lr_0 = 4.3490e-04
Loss = 4.4499e-01, PNorm = 43.6698, GNorm = 5.0789, lr_0 = 4.2025e-04
Loss = 4.6252e-01, PNorm = 43.6866, GNorm = 2.9575, lr_0 = 4.0610e-04
Validation rmse = 0.904800
Epoch 13
Loss = 4.5772e-01, PNorm = 43.7005, GNorm = 8.1259, lr_0 = 3.9242e-04
Loss = 4.0818e-01, PNorm = 43.7164, GNorm = 4.5631, lr_0 = 3.7920e-04
Validation rmse = 0.836085
Epoch 14
Loss = 3.3226e-01, PNorm = 43.7313, GNorm = 5.1108, lr_0 = 3.6643e-04
Loss = 3.9580e-01, PNorm = 43.7494, GNorm = 3.8527, lr_0 = 3.5408e-04
Loss = 4.1171e-01, PNorm = 43.7594, GNorm = 6.7241, lr_0 = 3.4216e-04
Validation rmse = 0.823843
Epoch 15
Loss = 4.0494e-01, PNorm = 43.7695, GNorm = 7.9837, lr_0 = 3.3063e-04
Loss = 3.5754e-01, PNorm = 43.7853, GNorm = 8.2208, lr_0 = 3.1950e-04
Validation rmse = 0.851369
Epoch 16
Loss = 3.4766e-01, PNorm = 43.7941, GNorm = 5.2141, lr_0 = 3.0873e-04
Loss = 3.5264e-01, PNorm = 43.8054, GNorm = 3.6915, lr_0 = 2.9833e-04
Validation rmse = 0.822052
Epoch 17
Loss = 4.2468e-01, PNorm = 43.8128, GNorm = 13.9355, lr_0 = 2.8828e-04
Loss = 4.4472e-01, PNorm = 43.8205, GNorm = 5.9199, lr_0 = 2.7857e-04
Loss = 3.2292e-01, PNorm = 43.8344, GNorm = 2.3727, lr_0 = 2.6919e-04
Validation rmse = 0.815387
Epoch 18
Loss = 2.7739e-01, PNorm = 43.8462, GNorm = 7.4537, lr_0 = 2.6012e-04
Loss = 3.2216e-01, PNorm = 43.8560, GNorm = 6.3959, lr_0 = 2.5136e-04
Validation rmse = 0.840431
Epoch 19
Loss = 3.4057e-01, PNorm = 43.8632, GNorm = 3.7560, lr_0 = 2.4289e-04
Loss = 3.4143e-01, PNorm = 43.8720, GNorm = 7.5309, lr_0 = 2.3471e-04
Loss = 3.2262e-01, PNorm = 43.8807, GNorm = 14.3333, lr_0 = 2.2681e-04
Validation rmse = 0.809478
Epoch 20
Loss = 3.0959e-01, PNorm = 43.8900, GNorm = 3.1411, lr_0 = 2.1917e-04
Loss = 3.1818e-01, PNorm = 43.8985, GNorm = 10.1893, lr_0 = 2.1178e-04
Validation rmse = 0.808365
Epoch 21
Loss = 3.1656e-01, PNorm = 43.9048, GNorm = 6.8263, lr_0 = 2.0465e-04
Loss = 2.9191e-01, PNorm = 43.9134, GNorm = 11.9524, lr_0 = 1.9776e-04
Validation rmse = 0.787307
Epoch 22
Loss = 2.8048e-01, PNorm = 43.9217, GNorm = 3.3241, lr_0 = 1.9110e-04
Loss = 3.1544e-01, PNorm = 43.9302, GNorm = 4.0972, lr_0 = 1.8466e-04
Loss = 3.2500e-01, PNorm = 43.9360, GNorm = 12.3208, lr_0 = 1.7844e-04
Validation rmse = 0.803157
Epoch 23
Loss = 2.5475e-01, PNorm = 43.9440, GNorm = 7.4217, lr_0 = 1.7243e-04
Loss = 3.1096e-01, PNorm = 43.9521, GNorm = 13.0710, lr_0 = 1.6662e-04
Validation rmse = 0.800627
Epoch 24
Loss = 1.8025e-01, PNorm = 43.9579, GNorm = 11.6364, lr_0 = 1.6101e-04
Loss = 3.5485e-01, PNorm = 43.9633, GNorm = 5.6791, lr_0 = 1.5558e-04
Loss = 2.6205e-01, PNorm = 43.9696, GNorm = 3.5010, lr_0 = 1.5034e-04
Validation rmse = 0.807222
Epoch 25
Loss = 2.5847e-01, PNorm = 43.9771, GNorm = 9.6364, lr_0 = 1.4528e-04
Loss = 3.3767e-01, PNorm = 43.9831, GNorm = 2.9532, lr_0 = 1.4039e-04
Validation rmse = 0.801389
Epoch 26
Loss = 2.8592e-01, PNorm = 43.9877, GNorm = 5.0729, lr_0 = 1.3566e-04
Loss = 2.6436e-01, PNorm = 43.9934, GNorm = 3.1778, lr_0 = 1.3109e-04
Validation rmse = 0.799108
Epoch 27
Loss = 2.3035e-01, PNorm = 43.9984, GNorm = 7.0349, lr_0 = 1.2667e-04
Loss = 2.5321e-01, PNorm = 44.0038, GNorm = 4.7876, lr_0 = 1.2240e-04
Loss = 2.4178e-01, PNorm = 44.0091, GNorm = 4.1053, lr_0 = 1.1828e-04
Validation rmse = 0.793670
Epoch 28
Loss = 3.1455e-01, PNorm = 44.0132, GNorm = 4.4206, lr_0 = 1.1430e-04
Loss = 2.3482e-01, PNorm = 44.0178, GNorm = 5.4398, lr_0 = 1.1045e-04
Validation rmse = 0.784550
Epoch 29
Loss = 2.9642e-01, PNorm = 44.0217, GNorm = 8.0353, lr_0 = 1.0673e-04
Loss = 2.6133e-01, PNorm = 44.0270, GNorm = 6.2835, lr_0 = 1.0313e-04
Loss = 2.3803e-01, PNorm = 44.0311, GNorm = 9.0773, lr_0 = 1.0000e-04
Validation rmse = 0.789696
Model 0 best validation rmse = 0.784550 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.636031
Ensemble test rmse = 0.636031
1-fold cross validation
	Seed 0 ==> test rmse = 0.636031
Overall test rmse = 0.636031 +/- 0.000000
Elapsed time = 0:01:58
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7494e+00, PNorm = 42.7406, GNorm = 1.4808, lr_0 = 4.0937e-04
Validation rmse = 1.364198
Epoch 1
Loss = 1.4085e+00, PNorm = 42.7394, GNorm = 1.6365, lr_0 = 6.9063e-04
Loss = 1.4040e+00, PNorm = 42.7496, GNorm = 0.7636, lr_0 = 9.7187e-04
Validation rmse = 1.303994
Epoch 2
Loss = 1.3376e+00, PNorm = 42.7680, GNorm = 2.0722, lr_0 = 9.5480e-04
Validation rmse = 1.226037
Epoch 3
Loss = 1.2553e+00, PNorm = 42.7965, GNorm = 0.6791, lr_0 = 9.0696e-04
Loss = 1.2705e+00, PNorm = 42.8353, GNorm = 1.1747, lr_0 = 8.6152e-04
Validation rmse = 1.237228
Epoch 4
Loss = 1.1974e+00, PNorm = 42.8760, GNorm = 1.5397, lr_0 = 8.1836e-04
Loss = 1.1798e+00, PNorm = 42.9317, GNorm = 1.9020, lr_0 = 7.7737e-04
Validation rmse = 1.087873
Epoch 5
Loss = 1.0649e+00, PNorm = 42.9948, GNorm = 2.3207, lr_0 = 7.3842e-04
Validation rmse = 1.122950
Epoch 6
Loss = 1.0800e+00, PNorm = 43.0517, GNorm = 1.9226, lr_0 = 7.0143e-04
Loss = 1.0223e+00, PNorm = 43.1099, GNorm = 1.5332, lr_0 = 6.6629e-04
Validation rmse = 0.966601
Epoch 7
Loss = 9.6890e-01, PNorm = 43.1571, GNorm = 2.0218, lr_0 = 6.3291e-04
Validation rmse = 0.932265
Epoch 8
Loss = 9.0040e-01, PNorm = 43.2027, GNorm = 1.6503, lr_0 = 6.0120e-04
Loss = 9.0668e-01, PNorm = 43.2449, GNorm = 5.4062, lr_0 = 5.7108e-04
Validation rmse = 0.948163
Epoch 9
Loss = 8.1298e-01, PNorm = 43.2859, GNorm = 2.0526, lr_0 = 5.4247e-04
Loss = 8.1163e-01, PNorm = 43.3244, GNorm = 2.2039, lr_0 = 5.1529e-04
Validation rmse = 0.876847
Epoch 10
Loss = 7.3151e-01, PNorm = 43.3705, GNorm = 3.6240, lr_0 = 4.8948e-04
Validation rmse = 0.872098
Epoch 11
Loss = 6.8144e-01, PNorm = 43.4036, GNorm = 3.2065, lr_0 = 4.6495e-04
Loss = 7.1977e-01, PNorm = 43.4368, GNorm = 5.9081, lr_0 = 4.4166e-04
Validation rmse = 0.887407
Epoch 12
Loss = 6.4621e-01, PNorm = 43.4613, GNorm = 9.5357, lr_0 = 4.1953e-04
Validation rmse = 0.852912
Epoch 13
Loss = 6.3450e-01, PNorm = 43.4846, GNorm = 3.0729, lr_0 = 3.9852e-04
Loss = 6.4642e-01, PNorm = 43.5103, GNorm = 6.1306, lr_0 = 3.7855e-04
Validation rmse = 0.866834
Epoch 14
Loss = 6.2635e-01, PNorm = 43.5356, GNorm = 2.8034, lr_0 = 3.5959e-04
Loss = 6.2887e-01, PNorm = 43.5527, GNorm = 5.2558, lr_0 = 3.4157e-04
Validation rmse = 0.855848
Epoch 15
Loss = 5.7717e-01, PNorm = 43.5756, GNorm = 8.7943, lr_0 = 3.2446e-04
Validation rmse = 0.836619
Epoch 16
Loss = 5.3806e-01, PNorm = 43.5948, GNorm = 1.8433, lr_0 = 3.0820e-04
Loss = 5.7794e-01, PNorm = 43.6110, GNorm = 2.8056, lr_0 = 2.9276e-04
Validation rmse = 0.858136
Epoch 17
Loss = 4.5589e-01, PNorm = 43.6298, GNorm = 10.2575, lr_0 = 2.7810e-04
Validation rmse = 0.846629
Epoch 18
Loss = 5.6105e-01, PNorm = 43.6432, GNorm = 7.4637, lr_0 = 2.6416e-04
Loss = 5.6315e-01, PNorm = 43.6554, GNorm = 8.0463, lr_0 = 2.5093e-04
Validation rmse = 0.871136
Epoch 19
Loss = 5.4796e-01, PNorm = 43.6708, GNorm = 4.8225, lr_0 = 2.3836e-04
Loss = 5.0744e-01, PNorm = 43.6845, GNorm = 2.9771, lr_0 = 2.2642e-04
Validation rmse = 0.861319
Epoch 20
Loss = 4.7528e-01, PNorm = 43.6956, GNorm = 2.5254, lr_0 = 2.1507e-04
Validation rmse = 0.832404
Epoch 21
Loss = 4.9768e-01, PNorm = 43.7066, GNorm = 15.6791, lr_0 = 2.0430e-04
Loss = 5.5716e-01, PNorm = 43.7174, GNorm = 14.2910, lr_0 = 1.9406e-04
Validation rmse = 0.837613
Epoch 22
Loss = 5.1916e-01, PNorm = 43.7260, GNorm = 10.3299, lr_0 = 1.8434e-04
Validation rmse = 0.829437
Epoch 23
Loss = 4.8341e-01, PNorm = 43.7347, GNorm = 11.1736, lr_0 = 1.7511e-04
Loss = 5.0404e-01, PNorm = 43.7437, GNorm = 5.3519, lr_0 = 1.6633e-04
Validation rmse = 0.863652
Epoch 24
Loss = 4.3238e-01, PNorm = 43.7531, GNorm = 5.2081, lr_0 = 1.5800e-04
Loss = 4.7630e-01, PNorm = 43.7621, GNorm = 5.7591, lr_0 = 1.5009e-04
Validation rmse = 0.836153
Epoch 25
Loss = 4.8508e-01, PNorm = 43.7683, GNorm = 3.8795, lr_0 = 1.4257e-04
Validation rmse = 0.828619
Epoch 26
Loss = 4.3091e-01, PNorm = 43.7745, GNorm = 11.4975, lr_0 = 1.3542e-04
Loss = 4.6094e-01, PNorm = 43.7811, GNorm = 6.0391, lr_0 = 1.2864e-04
Validation rmse = 0.842076
Epoch 27
Loss = 4.4553e-01, PNorm = 43.7882, GNorm = 5.5225, lr_0 = 1.2220e-04
Validation rmse = 0.824444
Epoch 28
Loss = 5.9872e-01, PNorm = 43.7947, GNorm = 6.3701, lr_0 = 1.1607e-04
Loss = 4.0308e-01, PNorm = 43.8010, GNorm = 7.4889, lr_0 = 1.1026e-04
Validation rmse = 0.847646
Epoch 29
Loss = 3.6588e-01, PNorm = 43.8060, GNorm = 3.3036, lr_0 = 1.0473e-04
Loss = 4.3892e-01, PNorm = 43.8112, GNorm = 2.7272, lr_0 = 1.0000e-04
Validation rmse = 0.828322
Model 0 best validation rmse = 0.824444 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.701411
Ensemble test rmse = 0.701411
1-fold cross validation
	Seed 0 ==> test rmse = 0.701411
Overall test rmse = 0.701411 +/- 0.000000
Elapsed time = 0:01:20
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7783e+00, PNorm = 42.7402, GNorm = 2.0295, lr_0 = 4.0937e-04
Validation rmse = 1.409991
Epoch 1
Loss = 1.4594e+00, PNorm = 42.7417, GNorm = 0.7093, lr_0 = 7.1875e-04
Loss = 1.3642e+00, PNorm = 42.7546, GNorm = 1.0419, lr_0 = 1.0000e-03
Validation rmse = 1.282215
Epoch 2
Loss = 1.2843e+00, PNorm = 42.7832, GNorm = 1.2704, lr_0 = 9.4990e-04
Loss = 1.2563e+00, PNorm = 42.8233, GNorm = 1.8942, lr_0 = 9.0231e-04
Validation rmse = 1.180403
Epoch 3
Loss = 1.1993e+00, PNorm = 42.8715, GNorm = 4.9151, lr_0 = 8.5711e-04
Validation rmse = 1.123160
Epoch 4
Loss = 9.9413e-01, PNorm = 42.9235, GNorm = 2.4301, lr_0 = 8.1417e-04
Loss = 1.1132e+00, PNorm = 42.9752, GNorm = 4.3911, lr_0 = 7.7338e-04
Validation rmse = 1.008849
Epoch 5
Loss = 9.8037e-01, PNorm = 43.0292, GNorm = 4.6870, lr_0 = 7.3463e-04
Loss = 9.6508e-01, PNorm = 43.0794, GNorm = 3.5408, lr_0 = 6.9783e-04
Loss = 9.4038e-01, PNorm = 43.0851, GNorm = 1.5037, lr_0 = 6.9425e-04
Validation rmse = 0.956468
Epoch 6
Loss = 8.7416e-01, PNorm = 43.1393, GNorm = 10.2676, lr_0 = 6.5947e-04
Validation rmse = 0.890545
Epoch 7
Loss = 8.4746e-01, PNorm = 43.1916, GNorm = 3.0723, lr_0 = 6.2643e-04
Loss = 7.7891e-01, PNorm = 43.2359, GNorm = 7.2097, lr_0 = 5.9505e-04
Validation rmse = 0.859353
Epoch 8
Loss = 7.3786e-01, PNorm = 43.2739, GNorm = 3.0889, lr_0 = 5.6524e-04
Loss = 7.3582e-01, PNorm = 43.3155, GNorm = 4.6383, lr_0 = 5.3692e-04
Validation rmse = 0.847877
Epoch 9
Loss = 6.6890e-01, PNorm = 43.3551, GNorm = 3.7274, lr_0 = 5.1002e-04
Validation rmse = 0.833777
Epoch 10
Loss = 8.0158e-01, PNorm = 43.3865, GNorm = 12.1033, lr_0 = 4.8447e-04
Loss = 6.3278e-01, PNorm = 43.4158, GNorm = 4.4018, lr_0 = 4.6020e-04
Validation rmse = 0.834359
Epoch 11
Loss = 6.9876e-01, PNorm = 43.4529, GNorm = 12.0350, lr_0 = 4.3490e-04
Loss = 6.2688e-01, PNorm = 43.4821, GNorm = 5.0166, lr_0 = 4.1312e-04
Validation rmse = 0.798979
Epoch 12
Loss = 5.8257e-01, PNorm = 43.5057, GNorm = 27.6807, lr_0 = 3.9242e-04
Validation rmse = 0.803540
Epoch 13
Loss = 6.4595e-01, PNorm = 43.5222, GNorm = 13.0892, lr_0 = 3.7276e-04
Loss = 6.2475e-01, PNorm = 43.5383, GNorm = 6.5221, lr_0 = 3.5408e-04
Validation rmse = 0.796352
Epoch 14
Loss = 5.4126e-01, PNorm = 43.5569, GNorm = 8.4716, lr_0 = 3.3635e-04
Loss = 6.1253e-01, PNorm = 43.5743, GNorm = 8.3863, lr_0 = 3.1950e-04
Validation rmse = 0.851712
Epoch 15
Loss = 6.1791e-01, PNorm = 43.5888, GNorm = 6.5095, lr_0 = 3.0349e-04
Validation rmse = 0.787002
Epoch 16
Loss = 5.2380e-01, PNorm = 43.6039, GNorm = 4.4516, lr_0 = 2.8681e-04
Loss = 5.6683e-01, PNorm = 43.6181, GNorm = 5.0175, lr_0 = 2.7244e-04
Validation rmse = 0.772064
Epoch 17
Loss = 4.9607e-01, PNorm = 43.6329, GNorm = 5.7140, lr_0 = 2.5879e-04
Loss = 5.0087e-01, PNorm = 43.6461, GNorm = 13.2279, lr_0 = 2.4582e-04
Validation rmse = 0.776744
Epoch 18
Loss = 4.9896e-01, PNorm = 43.6602, GNorm = 5.4709, lr_0 = 2.3351e-04
Validation rmse = 0.771594
Epoch 19
Loss = 5.5691e-01, PNorm = 43.6690, GNorm = 7.4403, lr_0 = 2.2181e-04
Loss = 4.7244e-01, PNorm = 43.6795, GNorm = 4.8606, lr_0 = 2.1070e-04
Validation rmse = 0.783277
Epoch 20
Loss = 4.5469e-01, PNorm = 43.6891, GNorm = 2.9688, lr_0 = 2.0014e-04
Loss = 4.9929e-01, PNorm = 43.6992, GNorm = 5.4119, lr_0 = 1.9012e-04
Validation rmse = 0.773932
Epoch 21
Loss = 4.3218e-01, PNorm = 43.7101, GNorm = 3.1850, lr_0 = 1.7967e-04
Validation rmse = 0.761485
Epoch 22
Loss = 5.0244e-01, PNorm = 43.7184, GNorm = 3.8382, lr_0 = 1.7066e-04
Loss = 4.6654e-01, PNorm = 43.7249, GNorm = 3.3699, lr_0 = 1.6211e-04
Validation rmse = 0.764575
Epoch 23
Loss = 4.6089e-01, PNorm = 43.7322, GNorm = 2.9897, lr_0 = 1.5399e-04
Loss = 4.3113e-01, PNorm = 43.7395, GNorm = 16.1995, lr_0 = 1.4628e-04
Validation rmse = 0.756062
Epoch 24
Loss = 4.0807e-01, PNorm = 43.7459, GNorm = 9.7376, lr_0 = 1.3895e-04
Loss = 4.2156e-01, PNorm = 43.7526, GNorm = 6.3488, lr_0 = 1.3199e-04
Validation rmse = 0.752497
Epoch 25
Loss = 4.3824e-01, PNorm = 43.7584, GNorm = 12.8007, lr_0 = 1.2538e-04
Validation rmse = 0.772936
Epoch 26
Loss = 3.5150e-01, PNorm = 43.7643, GNorm = 3.4864, lr_0 = 1.1848e-04
Loss = 4.5294e-01, PNorm = 43.7702, GNorm = 3.8569, lr_0 = 1.1255e-04
Validation rmse = 0.756284
Epoch 27
Loss = 3.2516e-01, PNorm = 43.7757, GNorm = 4.4802, lr_0 = 1.0691e-04
Loss = 4.5434e-01, PNorm = 43.7804, GNorm = 10.0382, lr_0 = 1.0155e-04
Validation rmse = 0.763557
Epoch 28
Loss = 4.1871e-01, PNorm = 43.7861, GNorm = 6.3564, lr_0 = 1.0000e-04
Validation rmse = 0.754771
Epoch 29
Loss = 3.5369e-01, PNorm = 43.7900, GNorm = 10.3637, lr_0 = 1.0000e-04
Loss = 4.1164e-01, PNorm = 43.7945, GNorm = 2.6612, lr_0 = 1.0000e-04
Validation rmse = 0.756918
Model 0 best validation rmse = 0.752497 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.798404
Ensemble test rmse = 0.798404
1-fold cross validation
	Seed 0 ==> test rmse = 0.798404
Overall test rmse = 0.798404 +/- 0.000000
Elapsed time = 0:01:23
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6987e+00, PNorm = 42.7401, GNorm = 1.6022, lr_0 = 3.9118e-04
Validation rmse = 1.464374
Epoch 1
Loss = 1.4467e+00, PNorm = 42.7411, GNorm = 0.7897, lr_0 = 6.8235e-04
Loss = 1.3428e+00, PNorm = 42.7542, GNorm = 1.6589, lr_0 = 9.4706e-04
Validation rmse = 1.262909
Epoch 2
Loss = 1.2777e+00, PNorm = 42.7797, GNorm = 1.8506, lr_0 = 9.6204e-04
Loss = 1.2246e+00, PNorm = 42.8179, GNorm = 1.0929, lr_0 = 9.1661e-04
Validation rmse = 1.207061
Epoch 3
Loss = 1.1424e+00, PNorm = 42.8749, GNorm = 3.0431, lr_0 = 8.6911e-04
Loss = 1.0188e+00, PNorm = 42.9349, GNorm = 1.8963, lr_0 = 8.2807e-04
Validation rmse = 0.995825
Epoch 4
Loss = 9.7340e-01, PNorm = 43.0001, GNorm = 11.1582, lr_0 = 7.8897e-04
Validation rmse = 0.868449
Epoch 5
Loss = 8.7865e-01, PNorm = 43.0582, GNorm = 4.0000, lr_0 = 7.5171e-04
Loss = 8.6635e-01, PNorm = 43.1126, GNorm = 1.6142, lr_0 = 7.1621e-04
Validation rmse = 0.817413
Epoch 6
Loss = 8.8017e-01, PNorm = 43.1643, GNorm = 3.3155, lr_0 = 6.7910e-04
Loss = 8.4806e-01, PNorm = 43.2060, GNorm = 3.1460, lr_0 = 6.4703e-04
Validation rmse = 0.794840
Epoch 7
Loss = 7.8716e-01, PNorm = 43.2543, GNorm = 1.5039, lr_0 = 6.1648e-04
Loss = 7.5481e-01, PNorm = 43.2898, GNorm = 2.7117, lr_0 = 5.8736e-04
Loss = 7.0203e-01, PNorm = 43.2927, GNorm = 2.9440, lr_0 = 5.8453e-04
Validation rmse = 0.812756
Epoch 8
Loss = 6.6619e-01, PNorm = 43.3279, GNorm = 2.1329, lr_0 = 5.5693e-04
Validation rmse = 0.735111
Epoch 9
Loss = 6.1704e-01, PNorm = 43.3587, GNorm = 3.3237, lr_0 = 5.3063e-04
Loss = 6.3877e-01, PNorm = 43.3923, GNorm = 3.9562, lr_0 = 5.0557e-04
Validation rmse = 0.712044
Epoch 10
Loss = 5.7885e-01, PNorm = 43.4172, GNorm = 4.5442, lr_0 = 4.8170e-04
Loss = 5.7106e-01, PNorm = 43.4456, GNorm = 3.5780, lr_0 = 4.5895e-04
Validation rmse = 0.703957
Epoch 11
Loss = 5.7442e-01, PNorm = 43.4741, GNorm = 8.6260, lr_0 = 4.3517e-04
Loss = 5.0764e-01, PNorm = 43.4990, GNorm = 6.6563, lr_0 = 4.1462e-04
Validation rmse = 0.714299
Epoch 12
Loss = 5.4302e-01, PNorm = 43.5225, GNorm = 5.1899, lr_0 = 3.9504e-04
Validation rmse = 0.682537
Epoch 13
Loss = 4.1924e-01, PNorm = 43.5502, GNorm = 2.6387, lr_0 = 3.7457e-04
Loss = 5.4703e-01, PNorm = 43.5698, GNorm = 15.2816, lr_0 = 3.5688e-04
Validation rmse = 0.692406
Epoch 14
Loss = 5.0915e-01, PNorm = 43.5851, GNorm = 4.5678, lr_0 = 3.4003e-04
Loss = 4.7279e-01, PNorm = 43.6064, GNorm = 9.9624, lr_0 = 3.2397e-04
Validation rmse = 0.674350
Epoch 15
Loss = 4.9262e-01, PNorm = 43.6215, GNorm = 7.8002, lr_0 = 3.0867e-04
Loss = 5.1418e-01, PNorm = 43.6363, GNorm = 15.7404, lr_0 = 2.9409e-04
Validation rmse = 0.729002
Epoch 16
Loss = 4.6247e-01, PNorm = 43.6493, GNorm = 4.0295, lr_0 = 2.7885e-04
Validation rmse = 0.672005
Epoch 17
Loss = 4.7906e-01, PNorm = 43.6612, GNorm = 3.4406, lr_0 = 2.6569e-04
Loss = 4.3138e-01, PNorm = 43.6760, GNorm = 6.1961, lr_0 = 2.5314e-04
Validation rmse = 0.671364
Epoch 18
Loss = 3.8297e-01, PNorm = 43.6882, GNorm = 13.2122, lr_0 = 2.4002e-04
Loss = 4.5994e-01, PNorm = 43.6981, GNorm = 10.5662, lr_0 = 2.2869e-04
Validation rmse = 0.671495
Epoch 19
Loss = 4.0557e-01, PNorm = 43.7097, GNorm = 8.2642, lr_0 = 2.1789e-04
Loss = 3.8773e-01, PNorm = 43.7201, GNorm = 3.1191, lr_0 = 2.0760e-04
Validation rmse = 0.653294
Epoch 20
Loss = 3.7809e-01, PNorm = 43.7291, GNorm = 8.4993, lr_0 = 1.9780e-04
Validation rmse = 0.669782
Epoch 21
Loss = 3.0109e-01, PNorm = 43.7411, GNorm = 3.7821, lr_0 = 1.8755e-04
Loss = 3.7167e-01, PNorm = 43.7503, GNorm = 16.6165, lr_0 = 1.7869e-04
Validation rmse = 0.668957
Epoch 22
Loss = 4.1885e-01, PNorm = 43.7582, GNorm = 9.4886, lr_0 = 1.7025e-04
Loss = 3.7149e-01, PNorm = 43.7675, GNorm = 3.4867, lr_0 = 1.6221e-04
Validation rmse = 0.657309
Epoch 23
Loss = 3.2050e-01, PNorm = 43.7770, GNorm = 4.9151, lr_0 = 1.5381e-04
Loss = 4.0396e-01, PNorm = 43.7844, GNorm = 8.1874, lr_0 = 1.4654e-04
Validation rmse = 0.656601
Epoch 24
Loss = 3.4821e-01, PNorm = 43.7908, GNorm = 9.4450, lr_0 = 1.3962e-04
Loss = 3.8584e-01, PNorm = 43.7973, GNorm = 8.9580, lr_0 = 1.3303e-04
Validation rmse = 0.677406
Epoch 25
Loss = 3.3469e-01, PNorm = 43.8034, GNorm = 6.0191, lr_0 = 1.2675e-04
Validation rmse = 0.653169
Epoch 26
Loss = 3.2863e-01, PNorm = 43.8091, GNorm = 4.3076, lr_0 = 1.2018e-04
Loss = 3.0762e-01, PNorm = 43.8144, GNorm = 7.3084, lr_0 = 1.1450e-04
Validation rmse = 0.653976
Epoch 27
Loss = 3.1430e-01, PNorm = 43.8213, GNorm = 3.4680, lr_0 = 1.0910e-04
Loss = 3.3437e-01, PNorm = 43.8267, GNorm = 18.3615, lr_0 = 1.0395e-04
Validation rmse = 0.653789
Epoch 28
Loss = 2.9788e-01, PNorm = 43.8316, GNorm = 4.6195, lr_0 = 1.0000e-04
Loss = 3.1866e-01, PNorm = 43.8361, GNorm = 7.2797, lr_0 = 1.0000e-04
Validation rmse = 0.658530
Epoch 29
Loss = 3.0120e-01, PNorm = 43.8410, GNorm = 5.4437, lr_0 = 1.0000e-04
Validation rmse = 0.662007
Model 0 best validation rmse = 0.653169 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.696453
Ensemble test rmse = 0.696453
1-fold cross validation
	Seed 0 ==> test rmse = 0.696453
Overall test rmse = 0.696453 +/- 0.000000
Elapsed time = 0:01:27
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7250e+00, PNorm = 42.7399, GNorm = 1.8835, lr_0 = 3.7500e-04
Validation rmse = 1.293053
Epoch 1
Loss = 1.4393e+00, PNorm = 42.7398, GNorm = 0.7371, lr_0 = 6.5000e-04
Loss = 1.3526e+00, PNorm = 42.7530, GNorm = 1.5547, lr_0 = 9.0000e-04
Validation rmse = 1.333436
Epoch 2
Loss = 1.2199e+00, PNorm = 42.7896, GNorm = 4.2199, lr_0 = 9.6853e-04
Loss = 1.2619e+00, PNorm = 42.8275, GNorm = 1.9783, lr_0 = 9.2527e-04
Validation rmse = 1.068419
Epoch 3
Loss = 1.0859e+00, PNorm = 42.8823, GNorm = 1.5841, lr_0 = 8.8395e-04
Loss = 1.0587e+00, PNorm = 42.9417, GNorm = 1.3645, lr_0 = 8.4448e-04
Validation rmse = 0.944083
Epoch 4
Loss = 9.8429e-01, PNorm = 43.0120, GNorm = 6.2957, lr_0 = 8.0309e-04
Loss = 8.7738e-01, PNorm = 43.0803, GNorm = 4.3955, lr_0 = 7.6722e-04
Validation rmse = 0.927620
Epoch 5
Loss = 8.2593e-01, PNorm = 43.1334, GNorm = 4.6429, lr_0 = 7.3296e-04
Loss = 8.0175e-01, PNorm = 43.1841, GNorm = 3.4907, lr_0 = 7.0023e-04
Loss = 8.4668e-01, PNorm = 43.1882, GNorm = 3.2428, lr_0 = 6.9703e-04
Validation rmse = 0.833109
Epoch 6
Loss = 6.9803e-01, PNorm = 43.2367, GNorm = 6.6403, lr_0 = 6.6591e-04
Validation rmse = 1.076376
Epoch 7
Loss = 7.8166e-01, PNorm = 43.2803, GNorm = 4.1596, lr_0 = 6.3327e-04
Loss = 6.7294e-01, PNorm = 43.3259, GNorm = 3.9005, lr_0 = 6.0499e-04
Validation rmse = 0.823889
Epoch 8
Loss = 6.0951e-01, PNorm = 43.3676, GNorm = 2.5476, lr_0 = 5.7797e-04
Loss = 5.8314e-01, PNorm = 43.3965, GNorm = 3.9779, lr_0 = 5.5216e-04
Validation rmse = 0.798788
Epoch 9
Loss = 5.3669e-01, PNorm = 43.4276, GNorm = 1.6455, lr_0 = 5.2510e-04
Loss = 5.1711e-01, PNorm = 43.4481, GNorm = 2.5896, lr_0 = 5.0165e-04
Validation rmse = 0.806557
Epoch 10
Loss = 5.0749e-01, PNorm = 43.4778, GNorm = 2.6042, lr_0 = 4.7924e-04
Loss = 5.7442e-01, PNorm = 43.5027, GNorm = 8.6431, lr_0 = 4.5784e-04
Validation rmse = 0.747788
Epoch 11
Loss = 4.9129e-01, PNorm = 43.5284, GNorm = 17.2619, lr_0 = 4.3540e-04
Loss = 4.7789e-01, PNorm = 43.5516, GNorm = 2.5781, lr_0 = 4.1596e-04
Loss = 3.9531e-01, PNorm = 43.5537, GNorm = 5.0895, lr_0 = 4.1406e-04
Validation rmse = 0.853636
Epoch 12
Loss = 4.7761e-01, PNorm = 43.5691, GNorm = 5.9308, lr_0 = 3.9557e-04
Validation rmse = 0.752317
Epoch 13
Loss = 6.7148e-01, PNorm = 43.5896, GNorm = 11.2704, lr_0 = 3.7790e-04
Loss = 4.6623e-01, PNorm = 43.6058, GNorm = 7.9616, lr_0 = 3.6103e-04
Validation rmse = 0.773139
Epoch 14
Loss = 4.2770e-01, PNorm = 43.6230, GNorm = 10.3835, lr_0 = 3.4333e-04
Loss = 4.4277e-01, PNorm = 43.6391, GNorm = 4.9329, lr_0 = 3.2800e-04
Validation rmse = 0.767482
Epoch 15
Loss = 4.2143e-01, PNorm = 43.6565, GNorm = 4.5019, lr_0 = 3.1335e-04
Loss = 4.0299e-01, PNorm = 43.6711, GNorm = 7.9264, lr_0 = 2.9936e-04
Validation rmse = 0.743714
Epoch 16
Loss = 4.1955e-01, PNorm = 43.6869, GNorm = 4.2866, lr_0 = 2.8469e-04
Loss = 3.7912e-01, PNorm = 43.6990, GNorm = 8.1856, lr_0 = 2.7197e-04
Validation rmse = 0.733139
Epoch 17
Loss = 3.8869e-01, PNorm = 43.7110, GNorm = 10.4220, lr_0 = 2.5864e-04
Loss = 3.6381e-01, PNorm = 43.7236, GNorm = 9.4064, lr_0 = 2.4709e-04
Validation rmse = 0.741389
Epoch 18
Loss = 4.2255e-01, PNorm = 43.7363, GNorm = 4.2466, lr_0 = 2.3606e-04
Validation rmse = 0.730656
Epoch 19
Loss = 1.8163e-01, PNorm = 43.7459, GNorm = 3.3546, lr_0 = 2.2449e-04
Loss = 3.6710e-01, PNorm = 43.7567, GNorm = 7.7809, lr_0 = 2.1446e-04
Validation rmse = 0.719583
Epoch 20
Loss = 2.9988e-01, PNorm = 43.7660, GNorm = 8.8319, lr_0 = 2.0488e-04
Loss = 3.4995e-01, PNorm = 43.7750, GNorm = 5.0141, lr_0 = 1.9573e-04
Validation rmse = 0.717173
Epoch 21
Loss = 2.8192e-01, PNorm = 43.7833, GNorm = 3.0669, lr_0 = 1.8614e-04
Loss = 3.3106e-01, PNorm = 43.7916, GNorm = 3.8249, lr_0 = 1.7783e-04
Validation rmse = 0.706653
Epoch 22
Loss = 3.6479e-01, PNorm = 43.8000, GNorm = 6.1933, lr_0 = 1.6911e-04
Loss = 3.3787e-01, PNorm = 43.8062, GNorm = 3.1672, lr_0 = 1.6156e-04
Validation rmse = 0.715484
Epoch 23
Loss = 2.9795e-01, PNorm = 43.8150, GNorm = 3.0950, lr_0 = 1.5434e-04
Loss = 3.1871e-01, PNorm = 43.8227, GNorm = 3.9403, lr_0 = 1.4745e-04
Validation rmse = 0.747734
Epoch 24
Loss = 2.2588e-01, PNorm = 43.8293, GNorm = 7.4498, lr_0 = 1.4022e-04
Loss = 3.6634e-01, PNorm = 43.8353, GNorm = 14.1574, lr_0 = 1.3396e-04
Validation rmse = 0.704179
Epoch 25
Loss = 3.0279e-01, PNorm = 43.8402, GNorm = 3.9620, lr_0 = 1.2798e-04
Validation rmse = 0.710382
Epoch 26
Loss = 3.0153e-01, PNorm = 43.8474, GNorm = 3.8010, lr_0 = 1.2171e-04
Loss = 2.8883e-01, PNorm = 43.8532, GNorm = 4.7869, lr_0 = 1.1627e-04
Validation rmse = 0.709610
Epoch 27
Loss = 3.5240e-01, PNorm = 43.8589, GNorm = 16.3472, lr_0 = 1.1057e-04
Loss = 2.7404e-01, PNorm = 43.8629, GNorm = 11.8921, lr_0 = 1.0564e-04
Validation rmse = 0.711631
Epoch 28
Loss = 2.9669e-01, PNorm = 43.8672, GNorm = 6.5581, lr_0 = 1.0092e-04
Loss = 2.8443e-01, PNorm = 43.8730, GNorm = 2.7204, lr_0 = 1.0000e-04
Validation rmse = 0.706353
Epoch 29
Loss = 2.5186e-01, PNorm = 43.8771, GNorm = 5.3635, lr_0 = 1.0000e-04
Loss = 2.9564e-01, PNorm = 43.8822, GNorm = 9.6061, lr_0 = 1.0000e-04
Validation rmse = 0.720752
Model 0 best validation rmse = 0.704179 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.684688
Ensemble test rmse = 0.684688
1-fold cross validation
	Seed 0 ==> test rmse = 0.684688
Overall test rmse = 0.684688 +/- 0.000000
Elapsed time = 0:01:31
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7152e+00, PNorm = 42.7401, GNorm = 1.6360, lr_0 = 3.6053e-04
Validation rmse = 1.530802
Epoch 1
Loss = 1.4593e+00, PNorm = 42.7397, GNorm = 0.7576, lr_0 = 6.2105e-04
Loss = 1.3114e+00, PNorm = 42.7514, GNorm = 1.2264, lr_0 = 8.5789e-04
Validation rmse = 1.420406
Epoch 2
Loss = 1.1893e+00, PNorm = 42.7801, GNorm = 1.8657, lr_0 = 9.7859e-04
Loss = 1.2050e+00, PNorm = 42.8208, GNorm = 2.1323, lr_0 = 9.3714e-04
Validation rmse = 1.247133
Epoch 3
Loss = 1.0750e+00, PNorm = 42.8793, GNorm = 3.7750, lr_0 = 8.9357e-04
Loss = 1.0450e+00, PNorm = 42.9334, GNorm = 1.9986, lr_0 = 8.5572e-04
Validation rmse = 1.052975
Epoch 4
Loss = 8.6296e-01, PNorm = 42.9944, GNorm = 3.0275, lr_0 = 8.1593e-04
Loss = 9.1428e-01, PNorm = 43.0431, GNorm = 4.0105, lr_0 = 7.8137e-04
Validation rmse = 0.938448
Epoch 5
Loss = 8.0802e-01, PNorm = 43.0948, GNorm = 2.2982, lr_0 = 7.4827e-04
Loss = 7.4756e-01, PNorm = 43.1446, GNorm = 6.8624, lr_0 = 7.1658e-04
Validation rmse = 0.897843
Epoch 6
Loss = 7.8417e-01, PNorm = 43.1872, GNorm = 4.5918, lr_0 = 6.8326e-04
Loss = 6.9511e-01, PNorm = 43.2356, GNorm = 6.7875, lr_0 = 6.5432e-04
Validation rmse = 0.994164
Epoch 7
Loss = 5.8994e-01, PNorm = 43.2774, GNorm = 11.9191, lr_0 = 6.2390e-04
Loss = 7.2187e-01, PNorm = 43.3083, GNorm = 1.8074, lr_0 = 5.9747e-04
Validation rmse = 0.836863
Epoch 8
Loss = 5.6758e-01, PNorm = 43.3531, GNorm = 3.4624, lr_0 = 5.6969e-04
Loss = 6.0691e-01, PNorm = 43.3774, GNorm = 6.4572, lr_0 = 5.4556e-04
Validation rmse = 0.812808
Epoch 9
Loss = 4.9449e-01, PNorm = 43.4111, GNorm = 3.2372, lr_0 = 5.2019e-04
Loss = 5.6069e-01, PNorm = 43.4426, GNorm = 2.6649, lr_0 = 4.9816e-04
Validation rmse = 0.760473
Epoch 10
Loss = 5.7310e-01, PNorm = 43.4687, GNorm = 5.5702, lr_0 = 4.7706e-04
Loss = 5.0588e-01, PNorm = 43.4924, GNorm = 11.7458, lr_0 = 4.5685e-04
Validation rmse = 0.754916
Epoch 11
Loss = 4.8047e-01, PNorm = 43.5160, GNorm = 15.6519, lr_0 = 4.3561e-04
Loss = 5.0235e-01, PNorm = 43.5363, GNorm = 5.9686, lr_0 = 4.1716e-04
Loss = 5.0858e-01, PNorm = 43.5380, GNorm = 4.6392, lr_0 = 4.1536e-04
Validation rmse = 0.781213
Epoch 12
Loss = 4.1026e-01, PNorm = 43.5565, GNorm = 3.6154, lr_0 = 3.9776e-04
Validation rmse = 0.794234
Epoch 13
Loss = 3.7977e-01, PNorm = 43.5811, GNorm = 7.9776, lr_0 = 3.7927e-04
Loss = 4.8117e-01, PNorm = 43.5974, GNorm = 4.9259, lr_0 = 3.6320e-04
Validation rmse = 0.729924
Epoch 14
Loss = 4.3232e-01, PNorm = 43.6171, GNorm = 10.7579, lr_0 = 3.4632e-04
Loss = 4.8888e-01, PNorm = 43.6331, GNorm = 8.4973, lr_0 = 3.3165e-04
Validation rmse = 0.790939
Epoch 15
Loss = 4.4027e-01, PNorm = 43.6467, GNorm = 16.0052, lr_0 = 3.1760e-04
Loss = 5.1445e-01, PNorm = 43.6583, GNorm = 12.4677, lr_0 = 3.0415e-04
Validation rmse = 0.788742
Epoch 16
Loss = 3.8138e-01, PNorm = 43.6770, GNorm = 3.4015, lr_0 = 2.9001e-04
Loss = 3.8862e-01, PNorm = 43.6909, GNorm = 7.7148, lr_0 = 2.7772e-04
Validation rmse = 0.763731
Epoch 17
Loss = 3.6855e-01, PNorm = 43.7040, GNorm = 3.8249, lr_0 = 2.6481e-04
Loss = 4.0558e-01, PNorm = 43.7140, GNorm = 8.1134, lr_0 = 2.5359e-04
Validation rmse = 0.758352
Epoch 18
Loss = 3.7620e-01, PNorm = 43.7231, GNorm = 8.0188, lr_0 = 2.4180e-04
Loss = 3.5172e-01, PNorm = 43.7348, GNorm = 7.4297, lr_0 = 2.3156e-04
Validation rmse = 0.752216
Epoch 19
Loss = 3.0677e-01, PNorm = 43.7451, GNorm = 8.8295, lr_0 = 2.2079e-04
Loss = 3.3697e-01, PNorm = 43.7539, GNorm = 7.6745, lr_0 = 2.1144e-04
Validation rmse = 0.782801
Epoch 20
Loss = 3.6507e-01, PNorm = 43.7590, GNorm = 21.4719, lr_0 = 2.0248e-04
Loss = 3.8859e-01, PNorm = 43.7657, GNorm = 9.9158, lr_0 = 1.9391e-04
Validation rmse = 0.733831
Epoch 21
Loss = 2.9776e-01, PNorm = 43.7766, GNorm = 3.8323, lr_0 = 1.8489e-04
Loss = 3.6672e-01, PNorm = 43.7853, GNorm = 3.2506, lr_0 = 1.7706e-04
Validation rmse = 0.706949
Epoch 22
Loss = 3.1260e-01, PNorm = 43.7935, GNorm = 8.1472, lr_0 = 1.6883e-04
Loss = 3.2568e-01, PNorm = 43.8012, GNorm = 9.2137, lr_0 = 1.6168e-04
Validation rmse = 0.722800
Epoch 23
Loss = 3.3616e-01, PNorm = 43.8074, GNorm = 14.1870, lr_0 = 1.5416e-04
Loss = 3.5950e-01, PNorm = 43.8135, GNorm = 3.6022, lr_0 = 1.4763e-04
Loss = 1.2038e-01, PNorm = 43.8143, GNorm = 5.2916, lr_0 = 1.4699e-04
Validation rmse = 0.708411
Epoch 24
Loss = 3.2238e-01, PNorm = 43.8219, GNorm = 9.5074, lr_0 = 1.4077e-04
Loss = 2.8121e-01, PNorm = 43.8293, GNorm = 7.0310, lr_0 = 1.3480e-04
Validation rmse = 0.713003
Epoch 25
Loss = 2.5578e-01, PNorm = 43.8346, GNorm = 8.9817, lr_0 = 1.2909e-04
Validation rmse = 0.724630
Epoch 26
Loss = 4.5632e-01, PNorm = 43.8383, GNorm = 9.1506, lr_0 = 1.2309e-04
Loss = 2.8032e-01, PNorm = 43.8424, GNorm = 12.6054, lr_0 = 1.1788e-04
Validation rmse = 0.740392
Epoch 27
Loss = 3.2787e-01, PNorm = 43.8477, GNorm = 9.5816, lr_0 = 1.1240e-04
Loss = 2.6634e-01, PNorm = 43.8530, GNorm = 8.4119, lr_0 = 1.0764e-04
Validation rmse = 0.697876
Epoch 28
Loss = 2.3220e-01, PNorm = 43.8580, GNorm = 4.4253, lr_0 = 1.0263e-04
Loss = 2.6203e-01, PNorm = 43.8620, GNorm = 16.5433, lr_0 = 1.0000e-04
Validation rmse = 0.712257
Epoch 29
Loss = 2.1925e-01, PNorm = 43.8666, GNorm = 2.8410, lr_0 = 1.0000e-04
Loss = 2.8054e-01, PNorm = 43.8711, GNorm = 4.9791, lr_0 = 1.0000e-04
Validation rmse = 0.708242
Model 0 best validation rmse = 0.697876 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.666490
Ensemble test rmse = 0.666490
1-fold cross validation
	Seed 0 ==> test rmse = 0.666490
Overall test rmse = 0.666490 +/- 0.000000
Elapsed time = 0:01:35
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6679e+00, PNorm = 42.7369, GNorm = 1.3985, lr_0 = 3.4750e-04
Loss = 1.4303e+00, PNorm = 42.7359, GNorm = 1.6386, lr_0 = 5.7250e-04
Validation rmse = 1.460952
Epoch 1
Loss = 1.3649e+00, PNorm = 42.7447, GNorm = 1.1783, lr_0 = 7.9750e-04
Loss = 1.2736e+00, PNorm = 42.7679, GNorm = 1.1551, lr_0 = 9.9590e-04
Validation rmse = 1.356712
Epoch 2
Loss = 1.2068e+00, PNorm = 42.8070, GNorm = 0.6621, lr_0 = 9.5578e-04
Loss = 1.0904e+00, PNorm = 42.8591, GNorm = 3.9474, lr_0 = 9.1728e-04
Validation rmse = 1.085335
Epoch 3
Loss = 1.0151e+00, PNorm = 42.9231, GNorm = 3.7431, lr_0 = 8.8032e-04
Loss = 9.5171e-01, PNorm = 42.9842, GNorm = 5.0996, lr_0 = 8.4486e-04
Validation rmse = 0.939135
Epoch 4
Loss = 8.6376e-01, PNorm = 43.0458, GNorm = 2.0311, lr_0 = 8.1083e-04
Loss = 8.0722e-01, PNorm = 43.1168, GNorm = 3.4995, lr_0 = 7.7816e-04
Validation rmse = 0.840525
Epoch 5
Loss = 7.1814e-01, PNorm = 43.1810, GNorm = 14.8394, lr_0 = 7.4682e-04
Loss = 7.6300e-01, PNorm = 43.2196, GNorm = 10.1406, lr_0 = 7.1673e-04
Validation rmse = 0.778865
Epoch 6
Loss = 7.3383e-01, PNorm = 43.2635, GNorm = 6.4845, lr_0 = 6.8786e-04
Loss = 6.3006e-01, PNorm = 43.3040, GNorm = 4.0108, lr_0 = 6.6015e-04
Validation rmse = 0.740362
Epoch 7
Loss = 5.6889e-01, PNorm = 43.3407, GNorm = 6.0362, lr_0 = 6.3356e-04
Loss = 5.9999e-01, PNorm = 43.3841, GNorm = 3.0911, lr_0 = 6.0803e-04
Validation rmse = 0.728129
Epoch 8
Loss = 5.6402e-01, PNorm = 43.4129, GNorm = 3.9225, lr_0 = 5.8354e-04
Loss = 5.6679e-01, PNorm = 43.4489, GNorm = 2.3895, lr_0 = 5.6003e-04
Validation rmse = 0.723798
Epoch 9
Loss = 4.7302e-01, PNorm = 43.4896, GNorm = 4.4428, lr_0 = 5.3747e-04
Loss = 5.9768e-01, PNorm = 43.5124, GNorm = 11.9818, lr_0 = 5.1582e-04
Validation rmse = 0.757895
Epoch 10
Loss = 5.3628e-01, PNorm = 43.5388, GNorm = 2.7772, lr_0 = 4.9504e-04
Loss = 5.4020e-01, PNorm = 43.5652, GNorm = 10.3404, lr_0 = 4.7510e-04
Validation rmse = 0.761278
Epoch 11
Loss = 4.7995e-01, PNorm = 43.5896, GNorm = 9.5625, lr_0 = 4.5596e-04
Loss = 5.1540e-01, PNorm = 43.6108, GNorm = 13.5716, lr_0 = 4.3759e-04
Validation rmse = 0.763426
Epoch 12
Loss = 4.7711e-01, PNorm = 43.6317, GNorm = 12.2090, lr_0 = 4.1997e-04
Loss = 4.4873e-01, PNorm = 43.6564, GNorm = 5.4632, lr_0 = 4.0305e-04
Validation rmse = 0.705606
Epoch 13
Loss = 3.8416e-01, PNorm = 43.6725, GNorm = 10.0862, lr_0 = 3.8681e-04
Loss = 4.0595e-01, PNorm = 43.6899, GNorm = 14.3006, lr_0 = 3.7123e-04
Validation rmse = 0.683498
Epoch 14
Loss = 3.9417e-01, PNorm = 43.7047, GNorm = 8.1067, lr_0 = 3.5628e-04
Loss = 4.2083e-01, PNorm = 43.7224, GNorm = 3.7658, lr_0 = 3.4192e-04
Validation rmse = 0.715824
Epoch 15
Loss = 3.3609e-01, PNorm = 43.7448, GNorm = 2.7353, lr_0 = 3.2815e-04
Loss = 3.8478e-01, PNorm = 43.7584, GNorm = 3.5660, lr_0 = 3.1493e-04
Validation rmse = 0.687124
Epoch 16
Loss = 3.5919e-01, PNorm = 43.7697, GNorm = 9.4858, lr_0 = 3.0224e-04
Loss = 3.2362e-01, PNorm = 43.7826, GNorm = 5.9921, lr_0 = 2.9007e-04
Validation rmse = 0.692251
Epoch 17
Loss = 3.5696e-01, PNorm = 43.7959, GNorm = 15.9775, lr_0 = 2.7838e-04
Loss = 3.2087e-01, PNorm = 43.8082, GNorm = 7.9456, lr_0 = 2.6717e-04
Validation rmse = 0.683952
Epoch 18
Loss = 2.7918e-01, PNorm = 43.8229, GNorm = 9.9444, lr_0 = 2.5641e-04
Loss = 3.5163e-01, PNorm = 43.8356, GNorm = 6.4929, lr_0 = 2.4608e-04
Validation rmse = 0.694182
Epoch 19
Loss = 3.5562e-01, PNorm = 43.8445, GNorm = 3.8191, lr_0 = 2.3616e-04
Loss = 3.0288e-01, PNorm = 43.8547, GNorm = 18.9559, lr_0 = 2.2665e-04
Validation rmse = 0.693914
Epoch 20
Loss = 2.9729e-01, PNorm = 43.8665, GNorm = 2.2367, lr_0 = 2.1752e-04
Loss = 3.7093e-01, PNorm = 43.8749, GNorm = 3.1041, lr_0 = 2.0876e-04
Validation rmse = 0.720438
Epoch 21
Loss = 3.8459e-01, PNorm = 43.8838, GNorm = 6.1959, lr_0 = 2.0035e-04
Loss = 3.3096e-01, PNorm = 43.8941, GNorm = 7.8957, lr_0 = 1.9228e-04
Validation rmse = 0.701105
Epoch 22
Loss = 2.8144e-01, PNorm = 43.9037, GNorm = 4.5761, lr_0 = 1.8453e-04
Loss = 2.9895e-01, PNorm = 43.9108, GNorm = 4.7664, lr_0 = 1.7710e-04
Validation rmse = 0.686571
Epoch 23
Loss = 2.5622e-01, PNorm = 43.9176, GNorm = 3.4436, lr_0 = 1.6996e-04
Loss = 2.6538e-01, PNorm = 43.9265, GNorm = 3.5995, lr_0 = 1.6312e-04
Validation rmse = 0.679572
Epoch 24
Loss = 2.3702e-01, PNorm = 43.9347, GNorm = 13.6831, lr_0 = 1.5655e-04
Loss = 2.5612e-01, PNorm = 43.9409, GNorm = 5.9586, lr_0 = 1.5024e-04
Validation rmse = 0.673234
Epoch 25
Loss = 2.4223e-01, PNorm = 43.9475, GNorm = 4.7488, lr_0 = 1.4419e-04
Loss = 2.3669e-01, PNorm = 43.9535, GNorm = 3.1068, lr_0 = 1.3838e-04
Validation rmse = 0.685704
Epoch 26
Loss = 2.2194e-01, PNorm = 43.9613, GNorm = 5.2627, lr_0 = 1.3280e-04
Loss = 2.7435e-01, PNorm = 43.9653, GNorm = 11.2831, lr_0 = 1.2746e-04
Validation rmse = 0.688086
Epoch 27
Loss = 2.1141e-01, PNorm = 43.9706, GNorm = 3.2511, lr_0 = 1.2232e-04
Loss = 2.5854e-01, PNorm = 43.9768, GNorm = 5.9419, lr_0 = 1.1739e-04
Validation rmse = 0.691551
Epoch 28
Loss = 2.1396e-01, PNorm = 43.9824, GNorm = 5.2680, lr_0 = 1.1266e-04
Loss = 2.4860e-01, PNorm = 43.9868, GNorm = 4.6393, lr_0 = 1.0813e-04
Validation rmse = 0.676942
Epoch 29
Loss = 2.2140e-01, PNorm = 43.9903, GNorm = 11.5546, lr_0 = 1.0377e-04
Loss = 2.2862e-01, PNorm = 43.9950, GNorm = 4.7177, lr_0 = 1.0000e-04
Validation rmse = 0.683419
Model 0 best validation rmse = 0.673234 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.702915
Ensemble test rmse = 0.702915
1-fold cross validation
	Seed 0 ==> test rmse = 0.702915
Overall test rmse = 0.702915 +/- 0.000000
Elapsed time = 0:01:38
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7884e+00, PNorm = 42.7385, GNorm = 2.1753, lr_0 = 3.4750e-04
Loss = 1.4093e+00, PNorm = 42.7363, GNorm = 1.2483, lr_0 = 5.7250e-04
Loss = 1.4076e+00, PNorm = 42.7367, GNorm = 1.0760, lr_0 = 5.9500e-04
Validation rmse = 1.597723
Epoch 1
Loss = 1.3497e+00, PNorm = 42.7468, GNorm = 1.2602, lr_0 = 8.2000e-04
Loss = 1.2376e+00, PNorm = 42.7719, GNorm = 1.3876, lr_0 = 9.9181e-04
Validation rmse = 1.434142
Epoch 2
Loss = 1.1716e+00, PNorm = 42.8097, GNorm = 1.9012, lr_0 = 9.5186e-04
Loss = 1.1146e+00, PNorm = 42.8579, GNorm = 3.9416, lr_0 = 9.1351e-04
Validation rmse = 1.176728
Epoch 3
Loss = 1.0187e+00, PNorm = 42.9121, GNorm = 2.9474, lr_0 = 8.7671e-04
Loss = 9.8669e-01, PNorm = 42.9723, GNorm = 3.1483, lr_0 = 8.4140e-04
Validation rmse = 1.070382
Epoch 4
Loss = 9.0838e-01, PNorm = 43.0381, GNorm = 5.5961, lr_0 = 8.0750e-04
Loss = 9.1120e-01, PNorm = 43.0869, GNorm = 2.4291, lr_0 = 7.7497e-04
Validation rmse = 0.910768
Epoch 5
Loss = 8.7305e-01, PNorm = 43.1320, GNorm = 5.6897, lr_0 = 7.4375e-04
Loss = 7.5248e-01, PNorm = 43.1842, GNorm = 6.7010, lr_0 = 7.1379e-04
Validation rmse = 0.877868
Epoch 6
Loss = 7.3205e-01, PNorm = 43.2317, GNorm = 1.9102, lr_0 = 6.8223e-04
Loss = 6.6640e-01, PNorm = 43.2840, GNorm = 3.0859, lr_0 = 6.5474e-04
Validation rmse = 0.718365
Epoch 7
Loss = 7.2825e-01, PNorm = 43.3174, GNorm = 10.0823, lr_0 = 6.2837e-04
Loss = 6.3690e-01, PNorm = 43.3584, GNorm = 6.2202, lr_0 = 6.0306e-04
Validation rmse = 0.808054
Epoch 8
Loss = 5.8584e-01, PNorm = 43.3955, GNorm = 2.7326, lr_0 = 5.7876e-04
Loss = 6.7613e-01, PNorm = 43.4238, GNorm = 8.2537, lr_0 = 5.5545e-04
Validation rmse = 0.718960
Epoch 9
Loss = 5.9393e-01, PNorm = 43.4538, GNorm = 1.7278, lr_0 = 5.3307e-04
Loss = 5.1117e-01, PNorm = 43.4882, GNorm = 6.4299, lr_0 = 5.1160e-04
Validation rmse = 0.659099
Epoch 10
Loss = 4.6144e-01, PNorm = 43.5114, GNorm = 7.4197, lr_0 = 4.9099e-04
Loss = 4.7334e-01, PNorm = 43.5337, GNorm = 3.3611, lr_0 = 4.7121e-04
Validation rmse = 0.682301
Epoch 11
Loss = 3.3565e-01, PNorm = 43.5563, GNorm = 2.4947, lr_0 = 4.5037e-04
Loss = 4.5124e-01, PNorm = 43.5833, GNorm = 8.0430, lr_0 = 4.3223e-04
Validation rmse = 0.668751
Epoch 12
Loss = 6.0443e-01, PNorm = 43.5974, GNorm = 5.4285, lr_0 = 4.1482e-04
Loss = 3.9471e-01, PNorm = 43.6172, GNorm = 5.6852, lr_0 = 3.9811e-04
Loss = 4.6025e-01, PNorm = 43.6382, GNorm = 4.4721, lr_0 = 3.8207e-04
Validation rmse = 0.631104
Epoch 13
Loss = 3.6817e-01, PNorm = 43.6545, GNorm = 6.7078, lr_0 = 3.6668e-04
Loss = 5.2343e-01, PNorm = 43.6656, GNorm = 3.8116, lr_0 = 3.5191e-04
Validation rmse = 0.767012
Epoch 14
Loss = 5.0450e-01, PNorm = 43.6780, GNorm = 4.1909, lr_0 = 3.3773e-04
Loss = 4.3065e-01, PNorm = 43.6973, GNorm = 8.6920, lr_0 = 3.2413e-04
Validation rmse = 0.652858
Epoch 15
Loss = 4.1881e-01, PNorm = 43.7128, GNorm = 15.6382, lr_0 = 3.1107e-04
Loss = 3.8108e-01, PNorm = 43.7254, GNorm = 6.4704, lr_0 = 2.9854e-04
Validation rmse = 0.648099
Epoch 16
Loss = 3.3594e-01, PNorm = 43.7394, GNorm = 5.4209, lr_0 = 2.8534e-04
Loss = 3.4413e-01, PNorm = 43.7520, GNorm = 5.4422, lr_0 = 2.7384e-04
Validation rmse = 0.638762
Epoch 17
Loss = 3.3631e-01, PNorm = 43.7629, GNorm = 8.5964, lr_0 = 2.6281e-04
Loss = 3.7281e-01, PNorm = 43.7741, GNorm = 10.4892, lr_0 = 2.5222e-04
Validation rmse = 0.644490
Epoch 18
Loss = 4.0687e-01, PNorm = 43.7824, GNorm = 3.4698, lr_0 = 2.4206e-04
Loss = 3.7533e-01, PNorm = 43.7918, GNorm = 3.4461, lr_0 = 2.3231e-04
Validation rmse = 0.648270
Epoch 19
Loss = 3.0679e-01, PNorm = 43.8037, GNorm = 3.5595, lr_0 = 2.2295e-04
Loss = 3.1779e-01, PNorm = 43.8140, GNorm = 13.6446, lr_0 = 2.1397e-04
Validation rmse = 0.626158
Epoch 20
Loss = 2.5680e-01, PNorm = 43.8218, GNorm = 6.9197, lr_0 = 2.0535e-04
Loss = 2.9445e-01, PNorm = 43.8307, GNorm = 14.9325, lr_0 = 1.9708e-04
Validation rmse = 0.639123
Epoch 21
Loss = 2.8905e-01, PNorm = 43.8383, GNorm = 3.1730, lr_0 = 1.8836e-04
Loss = 2.9078e-01, PNorm = 43.8463, GNorm = 5.1579, lr_0 = 1.8078e-04
Validation rmse = 0.632393
Epoch 22
Loss = 2.9753e-01, PNorm = 43.8550, GNorm = 18.5740, lr_0 = 1.7349e-04
Loss = 3.1400e-01, PNorm = 43.8624, GNorm = 3.9990, lr_0 = 1.6651e-04
Validation rmse = 0.636220
Epoch 23
Loss = 2.7212e-01, PNorm = 43.8673, GNorm = 8.2691, lr_0 = 1.5980e-04
Loss = 2.5609e-01, PNorm = 43.8754, GNorm = 7.9510, lr_0 = 1.5336e-04
Validation rmse = 0.626968
Epoch 24
Loss = 4.0297e-01, PNorm = 43.8816, GNorm = 13.5747, lr_0 = 1.4718e-04
Loss = 2.7721e-01, PNorm = 43.8860, GNorm = 4.3324, lr_0 = 1.4125e-04
Loss = 2.5735e-01, PNorm = 43.8912, GNorm = 6.5328, lr_0 = 1.3556e-04
Validation rmse = 0.632698
Epoch 25
Loss = 2.1793e-01, PNorm = 43.8962, GNorm = 8.4478, lr_0 = 1.3010e-04
Loss = 3.1091e-01, PNorm = 43.9025, GNorm = 4.0611, lr_0 = 1.2486e-04
Loss = 3.6285e-01, PNorm = 43.9030, GNorm = 6.4500, lr_0 = 1.2435e-04
Validation rmse = 0.626307
Epoch 26
Loss = 2.3333e-01, PNorm = 43.9087, GNorm = 9.6353, lr_0 = 1.1934e-04
Loss = 2.9707e-01, PNorm = 43.9145, GNorm = 18.7839, lr_0 = 1.1453e-04
Validation rmse = 0.621303
Epoch 27
Loss = 2.6476e-01, PNorm = 43.9193, GNorm = 13.1470, lr_0 = 1.0992e-04
Loss = 2.6023e-01, PNorm = 43.9232, GNorm = 4.4676, lr_0 = 1.0549e-04
Validation rmse = 0.630150
Epoch 28
Loss = 2.0850e-01, PNorm = 43.9280, GNorm = 4.3171, lr_0 = 1.0124e-04
Loss = 2.6600e-01, PNorm = 43.9324, GNorm = 4.1974, lr_0 = 1.0000e-04
Validation rmse = 0.621874
Epoch 29
Loss = 2.2706e-01, PNorm = 43.9356, GNorm = 5.6936, lr_0 = 1.0000e-04
Loss = 2.6031e-01, PNorm = 43.9406, GNorm = 5.9660, lr_0 = 1.0000e-04
Validation rmse = 0.632931
Model 0 best validation rmse = 0.621303 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.697053
Ensemble test rmse = 0.697053
1-fold cross validation
	Seed 0 ==> test rmse = 0.697053
Overall test rmse = 0.697053 +/- 0.000000
Elapsed time = 0:01:46
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8431e+00, PNorm = 42.7385, GNorm = 1.4896, lr_0 = 3.3571e-04
Loss = 1.4064e+00, PNorm = 42.7346, GNorm = 1.5160, lr_0 = 5.5000e-04
Validation rmse = 1.638655
Epoch 1
Loss = 1.3316e+00, PNorm = 42.7436, GNorm = 0.5389, lr_0 = 7.8571e-04
Loss = 1.2952e+00, PNorm = 42.7663, GNorm = 1.0267, lr_0 = 1.0000e-03
Validation rmse = 1.453364
Epoch 2
Loss = 1.1462e+00, PNorm = 42.8066, GNorm = 2.1824, lr_0 = 9.6160e-04
Loss = 1.1451e+00, PNorm = 42.8547, GNorm = 1.0370, lr_0 = 9.2467e-04
Validation rmse = 1.230862
Epoch 3
Loss = 9.8553e-01, PNorm = 42.9149, GNorm = 2.6203, lr_0 = 8.8568e-04
Loss = 9.7114e-01, PNorm = 42.9737, GNorm = 3.4117, lr_0 = 8.5167e-04
Validation rmse = 1.028178
Epoch 4
Loss = 8.5244e-01, PNorm = 43.0320, GNorm = 4.2327, lr_0 = 8.1896e-04
Loss = 8.1205e-01, PNorm = 43.0815, GNorm = 2.2296, lr_0 = 7.8751e-04
Validation rmse = 0.949800
Epoch 5
Loss = 8.1074e-01, PNorm = 43.1310, GNorm = 6.6537, lr_0 = 7.5727e-04
Loss = 8.1351e-01, PNorm = 43.1717, GNorm = 5.6079, lr_0 = 7.2819e-04
Validation rmse = 0.857432
Epoch 6
Loss = 9.1224e-01, PNorm = 43.2163, GNorm = 8.0755, lr_0 = 6.9749e-04
Loss = 6.6614e-01, PNorm = 43.2604, GNorm = 8.0181, lr_0 = 6.7070e-04
Loss = 5.5002e-01, PNorm = 43.2984, GNorm = 11.1989, lr_0 = 6.4495e-04
Validation rmse = 0.795199
Epoch 7
Loss = 6.0767e-01, PNorm = 43.3241, GNorm = 11.2316, lr_0 = 6.2018e-04
Loss = 6.3286e-01, PNorm = 43.3568, GNorm = 7.7505, lr_0 = 5.9636e-04
Validation rmse = 0.758220
Epoch 8
Loss = 4.8144e-01, PNorm = 43.3888, GNorm = 7.1931, lr_0 = 5.7122e-04
Loss = 5.3910e-01, PNorm = 43.4161, GNorm = 8.0273, lr_0 = 5.4928e-04
Validation rmse = 0.746690
Epoch 9
Loss = 5.4368e-01, PNorm = 43.4345, GNorm = 7.3401, lr_0 = 5.2819e-04
Loss = 4.9805e-01, PNorm = 43.4614, GNorm = 4.4756, lr_0 = 5.0790e-04
Validation rmse = 0.841309
Epoch 10
Loss = 5.8937e-01, PNorm = 43.4756, GNorm = 13.7082, lr_0 = 4.8840e-04
Loss = 5.2563e-01, PNorm = 43.4948, GNorm = 4.4006, lr_0 = 4.6964e-04
Validation rmse = 0.739940
Epoch 11
Loss = 3.2177e-01, PNorm = 43.5196, GNorm = 3.2422, lr_0 = 4.4984e-04
Loss = 4.2933e-01, PNorm = 43.5406, GNorm = 3.2725, lr_0 = 4.3257e-04
Validation rmse = 0.703238
Epoch 12
Loss = 5.9244e-01, PNorm = 43.5568, GNorm = 6.2288, lr_0 = 4.1596e-04
Loss = 4.2135e-01, PNorm = 43.5753, GNorm = 4.1577, lr_0 = 3.9998e-04
Loss = 3.8792e-01, PNorm = 43.5912, GNorm = 5.7798, lr_0 = 3.8462e-04
Loss = 4.9437e-01, PNorm = 43.5923, GNorm = 4.7288, lr_0 = 3.8312e-04
Validation rmse = 0.670113
Epoch 13
Loss = 4.1237e-01, PNorm = 43.6063, GNorm = 16.7449, lr_0 = 3.6841e-04
Loss = 3.9506e-01, PNorm = 43.6224, GNorm = 6.1981, lr_0 = 3.5426e-04
Validation rmse = 0.688532
Epoch 14
Loss = 3.7784e-01, PNorm = 43.6362, GNorm = 9.2993, lr_0 = 3.4065e-04
Loss = 3.8849e-01, PNorm = 43.6493, GNorm = 5.8356, lr_0 = 3.2757e-04
Validation rmse = 0.670825
Epoch 15
Loss = 3.9784e-01, PNorm = 43.6605, GNorm = 12.3541, lr_0 = 3.1499e-04
Loss = 3.9989e-01, PNorm = 43.6659, GNorm = 7.0788, lr_0 = 3.0290e-04
Validation rmse = 0.678279
Epoch 16
Loss = 3.9269e-01, PNorm = 43.6793, GNorm = 8.2124, lr_0 = 2.9012e-04
Loss = 3.7336e-01, PNorm = 43.6924, GNorm = 10.3472, lr_0 = 2.7898e-04
Validation rmse = 0.692351
Epoch 17
Loss = 2.6976e-01, PNorm = 43.7030, GNorm = 7.4376, lr_0 = 2.6827e-04
Loss = 4.0884e-01, PNorm = 43.7137, GNorm = 10.5622, lr_0 = 2.5797e-04
Validation rmse = 0.670010
Epoch 18
Loss = 3.7680e-01, PNorm = 43.7258, GNorm = 7.2580, lr_0 = 2.4709e-04
Loss = 2.6622e-01, PNorm = 43.7355, GNorm = 9.8963, lr_0 = 2.3760e-04
Loss = 4.5114e-01, PNorm = 43.7413, GNorm = 7.7348, lr_0 = 2.2848e-04
Validation rmse = 0.710260
Epoch 19
Loss = 3.9494e-01, PNorm = 43.7490, GNorm = 2.5615, lr_0 = 2.1970e-04
Loss = 3.0148e-01, PNorm = 43.7600, GNorm = 4.7156, lr_0 = 2.1127e-04
Validation rmse = 0.685850
Epoch 20
Loss = 2.8649e-01, PNorm = 43.7693, GNorm = 15.5794, lr_0 = 2.0315e-04
Loss = 3.0055e-01, PNorm = 43.7756, GNorm = 3.9841, lr_0 = 1.9535e-04
Validation rmse = 0.659410
Epoch 21
Loss = 2.5451e-01, PNorm = 43.7826, GNorm = 9.8976, lr_0 = 1.8712e-04
Loss = 2.9054e-01, PNorm = 43.7894, GNorm = 2.8752, lr_0 = 1.7993e-04
Validation rmse = 0.652036
Epoch 22
Loss = 2.5973e-01, PNorm = 43.7955, GNorm = 4.8556, lr_0 = 1.7302e-04
Loss = 2.8790e-01, PNorm = 43.8018, GNorm = 4.6503, lr_0 = 1.6638e-04
Validation rmse = 0.667228
Epoch 23
Loss = 2.6572e-01, PNorm = 43.8088, GNorm = 21.0593, lr_0 = 1.5936e-04
Loss = 2.9218e-01, PNorm = 43.8157, GNorm = 6.7035, lr_0 = 1.5324e-04
Validation rmse = 0.671626
Epoch 24
Loss = 3.7482e-01, PNorm = 43.8198, GNorm = 8.1968, lr_0 = 1.4736e-04
Loss = 2.4509e-01, PNorm = 43.8249, GNorm = 4.1901, lr_0 = 1.4170e-04
Loss = 2.5706e-01, PNorm = 43.8298, GNorm = 4.2107, lr_0 = 1.3626e-04
Validation rmse = 0.667362
Epoch 25
Loss = 2.3639e-01, PNorm = 43.8349, GNorm = 4.3478, lr_0 = 1.3102e-04
Loss = 2.7203e-01, PNorm = 43.8384, GNorm = 5.0982, lr_0 = 1.2599e-04
Validation rmse = 0.660334
Epoch 26
Loss = 2.8971e-01, PNorm = 43.8428, GNorm = 6.2541, lr_0 = 1.2068e-04
Loss = 1.9721e-01, PNorm = 43.8482, GNorm = 8.7983, lr_0 = 1.1604e-04
Validation rmse = 0.658660
Epoch 27
Loss = 1.9417e-01, PNorm = 43.8535, GNorm = 4.7715, lr_0 = 1.1159e-04
Loss = 2.9415e-01, PNorm = 43.8568, GNorm = 5.7463, lr_0 = 1.0730e-04
Validation rmse = 0.656025
Epoch 28
Loss = 2.9118e-01, PNorm = 43.8602, GNorm = 8.1858, lr_0 = 1.0278e-04
Loss = 2.1134e-01, PNorm = 43.8643, GNorm = 5.8986, lr_0 = 1.0000e-04
Validation rmse = 0.658570
Epoch 29
Loss = 2.5719e-01, PNorm = 43.8683, GNorm = 2.8138, lr_0 = 1.0000e-04
Loss = 2.5805e-01, PNorm = 43.8721, GNorm = 6.0516, lr_0 = 1.0000e-04
Validation rmse = 0.651801
Model 0 best validation rmse = 0.651801 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.679315
Ensemble test rmse = 0.679315
1-fold cross validation
	Seed 0 ==> test rmse = 0.679315
Overall test rmse = 0.679315 +/- 0.000000
Elapsed time = 0:01:49
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8072e+00, PNorm = 42.7391, GNorm = 2.6187, lr_0 = 3.2500e-04
Loss = 1.4340e+00, PNorm = 42.7375, GNorm = 1.0948, lr_0 = 5.2955e-04
Validation rmse = 1.594104
Epoch 1
Loss = 1.3378e+00, PNorm = 42.7449, GNorm = 1.2825, lr_0 = 7.5455e-04
Loss = 1.2571e+00, PNorm = 42.7670, GNorm = 1.9071, lr_0 = 9.5909e-04
Validation rmse = 1.428102
Epoch 2
Loss = 1.2347e+00, PNorm = 42.8102, GNorm = 4.4891, lr_0 = 9.6692e-04
Loss = 1.0942e+00, PNorm = 42.8558, GNorm = 1.1628, lr_0 = 9.3144e-04
Validation rmse = 1.148919
Epoch 3
Loss = 9.8250e-01, PNorm = 42.9176, GNorm = 1.4630, lr_0 = 8.9727e-04
Loss = 9.2854e-01, PNorm = 42.9908, GNorm = 3.1168, lr_0 = 8.6435e-04
Validation rmse = 1.017009
Epoch 4
Loss = 1.1166e+00, PNorm = 43.0568, GNorm = 11.4205, lr_0 = 8.2953e-04
Loss = 7.5411e-01, PNorm = 43.1134, GNorm = 9.1437, lr_0 = 7.9909e-04
Loss = 7.8398e-01, PNorm = 43.1622, GNorm = 1.4688, lr_0 = 7.6977e-04
Validation rmse = 0.939944
Epoch 5
Loss = 7.1779e-01, PNorm = 43.2077, GNorm = 7.1608, lr_0 = 7.4153e-04
Loss = 7.2001e-01, PNorm = 43.2487, GNorm = 11.2259, lr_0 = 7.1433e-04
Validation rmse = 0.848102
Epoch 6
Loss = 6.9628e-01, PNorm = 43.2842, GNorm = 1.5613, lr_0 = 6.8555e-04
Loss = 5.6336e-01, PNorm = 43.3290, GNorm = 5.0241, lr_0 = 6.6040e-04
Validation rmse = 0.768476
Epoch 7
Loss = 5.4215e-01, PNorm = 43.3623, GNorm = 5.5691, lr_0 = 6.3379e-04
Loss = 5.3529e-01, PNorm = 43.3952, GNorm = 10.9402, lr_0 = 6.1054e-04
Validation rmse = 0.771483
Epoch 8
Loss = 5.3251e-01, PNorm = 43.4200, GNorm = 9.8779, lr_0 = 5.8814e-04
Loss = 5.4449e-01, PNorm = 43.4481, GNorm = 7.1844, lr_0 = 5.6656e-04
Loss = 5.5822e-01, PNorm = 43.4712, GNorm = 6.1299, lr_0 = 5.4577e-04
Validation rmse = 0.766742
Epoch 9
Loss = 4.2840e-01, PNorm = 43.5020, GNorm = 4.3120, lr_0 = 5.2379e-04
Loss = 5.6705e-01, PNorm = 43.5209, GNorm = 8.0630, lr_0 = 5.0457e-04
Validation rmse = 0.784714
Epoch 10
Loss = 5.0084e-01, PNorm = 43.5423, GNorm = 5.4847, lr_0 = 4.8606e-04
Loss = 4.5385e-01, PNorm = 43.5651, GNorm = 11.5988, lr_0 = 4.6822e-04
Validation rmse = 0.730734
Epoch 11
Loss = 5.2261e-01, PNorm = 43.5798, GNorm = 3.3473, lr_0 = 4.4936e-04
Loss = 4.4746e-01, PNorm = 43.5973, GNorm = 15.6157, lr_0 = 4.3288e-04
Validation rmse = 0.725245
Epoch 12
Loss = 4.6078e-01, PNorm = 43.6172, GNorm = 16.4643, lr_0 = 4.1544e-04
Loss = 4.8740e-01, PNorm = 43.6258, GNorm = 5.0393, lr_0 = 4.0020e-04
Loss = 5.0963e-01, PNorm = 43.6402, GNorm = 10.9416, lr_0 = 3.8551e-04
Validation rmse = 0.758332
Epoch 13
Loss = 4.7921e-01, PNorm = 43.6538, GNorm = 11.3405, lr_0 = 3.7137e-04
Loss = 4.5650e-01, PNorm = 43.6679, GNorm = 15.9131, lr_0 = 3.5774e-04
Validation rmse = 0.736005
Epoch 14
Loss = 4.3992e-01, PNorm = 43.6851, GNorm = 9.0648, lr_0 = 3.4333e-04
Loss = 3.7624e-01, PNorm = 43.6981, GNorm = 3.0220, lr_0 = 3.3074e-04
Validation rmse = 0.691995
Epoch 15
Loss = 4.0084e-01, PNorm = 43.7115, GNorm = 10.4301, lr_0 = 3.1860e-04
Loss = 4.1041e-01, PNorm = 43.7222, GNorm = 5.2297, lr_0 = 3.0691e-04
Validation rmse = 0.728104
Epoch 16
Loss = 3.2564e-01, PNorm = 43.7333, GNorm = 3.0692, lr_0 = 2.9455e-04
Loss = 4.0177e-01, PNorm = 43.7442, GNorm = 4.4575, lr_0 = 2.8374e-04
Loss = 3.6115e-01, PNorm = 43.7561, GNorm = 4.9182, lr_0 = 2.7333e-04
Loss = 5.7436e-01, PNorm = 43.7570, GNorm = 6.4516, lr_0 = 2.7231e-04
Validation rmse = 0.724983
Epoch 17
Loss = 3.1990e-01, PNorm = 43.7663, GNorm = 8.8695, lr_0 = 2.6232e-04
Loss = 3.4527e-01, PNorm = 43.7755, GNorm = 5.1127, lr_0 = 2.5270e-04
Validation rmse = 0.702040
Epoch 18
Loss = 2.9750e-01, PNorm = 43.7830, GNorm = 2.4944, lr_0 = 2.4342e-04
Loss = 2.7660e-01, PNorm = 43.7940, GNorm = 5.0057, lr_0 = 2.3449e-04
Validation rmse = 0.690543
Epoch 19
Loss = 3.4640e-01, PNorm = 43.8036, GNorm = 7.4086, lr_0 = 2.2505e-04
Loss = 3.0594e-01, PNorm = 43.8088, GNorm = 5.0847, lr_0 = 2.1679e-04
Validation rmse = 0.701587
Epoch 20
Loss = 3.8642e-01, PNorm = 43.8190, GNorm = 3.1552, lr_0 = 2.0884e-04
Loss = 2.9230e-01, PNorm = 43.8276, GNorm = 5.2262, lr_0 = 2.0117e-04
Loss = 2.6847e-01, PNorm = 43.8340, GNorm = 6.1151, lr_0 = 1.9379e-04
Loss = 4.6706e-01, PNorm = 43.8346, GNorm = 5.3872, lr_0 = 1.9307e-04
Validation rmse = 0.692538
Epoch 21
Loss = 2.8352e-01, PNorm = 43.8406, GNorm = 6.1913, lr_0 = 1.8599e-04
Loss = 2.9216e-01, PNorm = 43.8484, GNorm = 3.6678, lr_0 = 1.7916e-04
Validation rmse = 0.683993
Epoch 22
Loss = 2.7907e-01, PNorm = 43.8540, GNorm = 15.7843, lr_0 = 1.7195e-04
Loss = 2.9358e-01, PNorm = 43.8596, GNorm = 20.9899, lr_0 = 1.6564e-04
Validation rmse = 0.693468
Epoch 23
Loss = 2.1705e-01, PNorm = 43.8672, GNorm = 5.5941, lr_0 = 1.5956e-04
Loss = 2.7172e-01, PNorm = 43.8745, GNorm = 11.1027, lr_0 = 1.5371e-04
Validation rmse = 0.684115
Epoch 24
Loss = 1.2963e-01, PNorm = 43.8806, GNorm = 3.7479, lr_0 = 1.4751e-04
Loss = 2.8555e-01, PNorm = 43.8860, GNorm = 4.3050, lr_0 = 1.4210e-04
Loss = 2.6140e-01, PNorm = 43.8902, GNorm = 9.8133, lr_0 = 1.3689e-04
Validation rmse = 0.690006
Epoch 25
Loss = 2.4977e-01, PNorm = 43.8955, GNorm = 3.7461, lr_0 = 1.3187e-04
Loss = 2.6066e-01, PNorm = 43.9000, GNorm = 5.4628, lr_0 = 1.2703e-04
Validation rmse = 0.689299
Epoch 26
Loss = 2.3119e-01, PNorm = 43.9057, GNorm = 10.7159, lr_0 = 1.2191e-04
Loss = 2.2923e-01, PNorm = 43.9110, GNorm = 3.5026, lr_0 = 1.1744e-04
Validation rmse = 0.694775
Epoch 27
Loss = 2.4544e-01, PNorm = 43.9142, GNorm = 7.1429, lr_0 = 1.1271e-04
Loss = 2.2675e-01, PNorm = 43.9186, GNorm = 10.5649, lr_0 = 1.0857e-04
Validation rmse = 0.688009
Epoch 28
Loss = 2.3439e-01, PNorm = 43.9211, GNorm = 3.2238, lr_0 = 1.0459e-04
Loss = 2.0356e-01, PNorm = 43.9253, GNorm = 7.3236, lr_0 = 1.0075e-04
Validation rmse = 0.685732
Epoch 29
Loss = 3.3610e-02, PNorm = 43.9302, GNorm = 2.9755, lr_0 = 1.0000e-04
Loss = 2.3313e-01, PNorm = 43.9340, GNorm = 13.4605, lr_0 = 1.0000e-04
Loss = 2.6769e-01, PNorm = 43.9377, GNorm = 3.7068, lr_0 = 1.0000e-04
Validation rmse = 0.678833
Model 0 best validation rmse = 0.678833 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.691217
Ensemble test rmse = 0.691217
1-fold cross validation
	Seed 0 ==> test rmse = 0.691217
Overall test rmse = 0.691217 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8228e+00, PNorm = 42.7383, GNorm = 1.7327, lr_0 = 3.1522e-04
Loss = 1.4058e+00, PNorm = 42.7357, GNorm = 1.4265, lr_0 = 5.1087e-04
Validation rmse = 1.548138
Epoch 1
Loss = 1.3182e+00, PNorm = 42.7410, GNorm = 1.1019, lr_0 = 7.2609e-04
Loss = 1.2381e+00, PNorm = 42.7612, GNorm = 1.0639, lr_0 = 9.2174e-04
Validation rmse = 1.323007
Epoch 2
Loss = 1.1569e+00, PNorm = 42.8018, GNorm = 1.1047, lr_0 = 9.7528e-04
Loss = 1.1009e+00, PNorm = 42.8527, GNorm = 1.9434, lr_0 = 9.4103e-04
Validation rmse = 1.093027
Epoch 3
Loss = 1.0177e+00, PNorm = 42.9099, GNorm = 1.4166, lr_0 = 9.0474e-04
Loss = 9.1847e-01, PNorm = 42.9721, GNorm = 1.5273, lr_0 = 8.7296e-04
Loss = 8.5439e-01, PNorm = 43.0305, GNorm = 7.8195, lr_0 = 8.4230e-04
Validation rmse = 0.999511
Epoch 4
Loss = 7.9752e-01, PNorm = 43.0843, GNorm = 7.5522, lr_0 = 8.0981e-04
Loss = 7.7585e-01, PNorm = 43.1368, GNorm = 6.2147, lr_0 = 7.8137e-04
Validation rmse = 1.024827
Epoch 5
Loss = 9.5903e-01, PNorm = 43.1771, GNorm = 12.8229, lr_0 = 7.5393e-04
Loss = 7.2804e-01, PNorm = 43.2144, GNorm = 5.0022, lr_0 = 7.2745e-04
Validation rmse = 0.830515
Epoch 6
Loss = 5.0447e-01, PNorm = 43.2553, GNorm = 2.4808, lr_0 = 6.9939e-04
Loss = 6.2288e-01, PNorm = 43.2903, GNorm = 1.9328, lr_0 = 6.7483e-04
Loss = 6.3355e-01, PNorm = 43.3261, GNorm = 8.6716, lr_0 = 6.5113e-04
Validation rmse = 0.740374
Epoch 7
Loss = 6.1533e-01, PNorm = 43.3601, GNorm = 1.9892, lr_0 = 6.2601e-04
Loss = 5.1930e-01, PNorm = 43.3943, GNorm = 6.6503, lr_0 = 6.0403e-04
Validation rmse = 0.730006
Epoch 8
Loss = 4.8034e-01, PNorm = 43.4228, GNorm = 6.5918, lr_0 = 5.8073e-04
Loss = 5.4094e-01, PNorm = 43.4478, GNorm = 11.2658, lr_0 = 5.6033e-04
Validation rmse = 0.713369
Epoch 9
Loss = 4.8504e-01, PNorm = 43.4687, GNorm = 7.9142, lr_0 = 5.3872e-04
Loss = 4.9907e-01, PNorm = 43.4918, GNorm = 4.3442, lr_0 = 5.1980e-04
Loss = 4.8562e-01, PNorm = 43.5085, GNorm = 10.0340, lr_0 = 5.0155e-04
Validation rmse = 0.705927
Epoch 10
Loss = 4.6660e-01, PNorm = 43.5269, GNorm = 4.9384, lr_0 = 4.8393e-04
Loss = 4.8311e-01, PNorm = 43.5444, GNorm = 12.9399, lr_0 = 4.6693e-04
Validation rmse = 0.696413
Epoch 11
Loss = 4.6524e-01, PNorm = 43.5580, GNorm = 4.8080, lr_0 = 4.4893e-04
Loss = 4.8171e-01, PNorm = 43.5769, GNorm = 3.1867, lr_0 = 4.3316e-04
Validation rmse = 0.736480
Epoch 12
Loss = 4.2613e-01, PNorm = 43.5932, GNorm = 3.4599, lr_0 = 4.1645e-04
Loss = 3.6333e-01, PNorm = 43.6145, GNorm = 8.9839, lr_0 = 4.0183e-04
Loss = 4.3623e-01, PNorm = 43.6326, GNorm = 17.0958, lr_0 = 3.8771e-04
Validation rmse = 0.749161
Epoch 13
Loss = 3.3503e-01, PNorm = 43.6472, GNorm = 8.1168, lr_0 = 3.7276e-04
Loss = 4.0228e-01, PNorm = 43.6636, GNorm = 3.1989, lr_0 = 3.5967e-04
Validation rmse = 0.741509
Epoch 14
Loss = 2.6137e-01, PNorm = 43.6755, GNorm = 3.5103, lr_0 = 3.4580e-04
Loss = 4.1639e-01, PNorm = 43.6869, GNorm = 2.3073, lr_0 = 3.3365e-04
Validation rmse = 0.662511
Epoch 15
Loss = 4.1467e-01, PNorm = 43.7002, GNorm = 2.5033, lr_0 = 3.2193e-04
Loss = 3.5478e-01, PNorm = 43.7134, GNorm = 4.6501, lr_0 = 3.1062e-04
Loss = 2.9272e-01, PNorm = 43.7253, GNorm = 4.8418, lr_0 = 2.9971e-04
Validation rmse = 0.680046
Epoch 16
Loss = 4.1013e-01, PNorm = 43.7348, GNorm = 3.1288, lr_0 = 2.8816e-04
Loss = 3.3897e-01, PNorm = 43.7464, GNorm = 6.5438, lr_0 = 2.7803e-04
Validation rmse = 0.680598
Epoch 17
Loss = 2.9995e-01, PNorm = 43.7593, GNorm = 11.6288, lr_0 = 2.6731e-04
Loss = 3.2504e-01, PNorm = 43.7688, GNorm = 5.7238, lr_0 = 2.5792e-04
Validation rmse = 0.714551
Epoch 18
Loss = 5.6980e-01, PNorm = 43.7742, GNorm = 13.2193, lr_0 = 2.4798e-04
Loss = 3.6276e-01, PNorm = 43.7838, GNorm = 9.3894, lr_0 = 2.3927e-04
Loss = 3.0908e-01, PNorm = 43.7965, GNorm = 11.1613, lr_0 = 2.3086e-04
Loss = 1.0073e+00, PNorm = 43.7976, GNorm = 25.5247, lr_0 = 2.3004e-04
Validation rmse = 0.698446
Epoch 19
Loss = 3.6237e-01, PNorm = 43.8056, GNorm = 9.0070, lr_0 = 2.2196e-04
Loss = 3.4320e-01, PNorm = 43.8139, GNorm = 12.9456, lr_0 = 2.1416e-04
Validation rmse = 0.669772
Epoch 20
Loss = 3.4582e-01, PNorm = 43.8221, GNorm = 10.3124, lr_0 = 2.0664e-04
Loss = 3.1804e-01, PNorm = 43.8296, GNorm = 3.7825, lr_0 = 1.9938e-04
Validation rmse = 0.660532
Epoch 21
Loss = 1.9399e-01, PNorm = 43.8374, GNorm = 9.1910, lr_0 = 1.9169e-04
Loss = 3.2496e-01, PNorm = 43.8435, GNorm = 4.8541, lr_0 = 1.8496e-04
Loss = 3.3623e-01, PNorm = 43.8494, GNorm = 5.1095, lr_0 = 1.7846e-04
Loss = 2.3197e-01, PNorm = 43.8500, GNorm = 5.6862, lr_0 = 1.7783e-04
Validation rmse = 0.673455
Epoch 22
Loss = 3.0749e-01, PNorm = 43.8575, GNorm = 3.4146, lr_0 = 1.7158e-04
Loss = 2.5439e-01, PNorm = 43.8635, GNorm = 8.2498, lr_0 = 1.6556e-04
Validation rmse = 0.672199
Epoch 23
Loss = 2.8910e-01, PNorm = 43.8679, GNorm = 5.5936, lr_0 = 1.5917e-04
Loss = 3.0742e-01, PNorm = 43.8721, GNorm = 3.4083, lr_0 = 1.5358e-04
Validation rmse = 0.665899
Epoch 24
Loss = 2.2712e-01, PNorm = 43.8785, GNorm = 9.6570, lr_0 = 1.4766e-04
Loss = 3.3106e-01, PNorm = 43.8821, GNorm = 3.9351, lr_0 = 1.4247e-04
Loss = 2.1355e-01, PNorm = 43.8876, GNorm = 5.7509, lr_0 = 1.3747e-04
Validation rmse = 0.662885
Epoch 25
Loss = 2.5148e-01, PNorm = 43.8945, GNorm = 7.6132, lr_0 = 1.3264e-04
Loss = 2.4395e-01, PNorm = 43.8997, GNorm = 6.3927, lr_0 = 1.2798e-04
Validation rmse = 0.651677
Epoch 26
Loss = 2.5653e-01, PNorm = 43.9050, GNorm = 6.1404, lr_0 = 1.2304e-04
Loss = 2.2605e-01, PNorm = 43.9092, GNorm = 3.4208, lr_0 = 1.1872e-04
Validation rmse = 0.667538
Epoch 27
Loss = 1.8348e-01, PNorm = 43.9135, GNorm = 6.1951, lr_0 = 1.1414e-04
Loss = 2.3529e-01, PNorm = 43.9166, GNorm = 3.1557, lr_0 = 1.1014e-04
Validation rmse = 0.654023
Epoch 28
Loss = 1.6099e-01, PNorm = 43.9202, GNorm = 3.6761, lr_0 = 1.0589e-04
Loss = 2.5720e-01, PNorm = 43.9241, GNorm = 3.2911, lr_0 = 1.0217e-04
Loss = 2.1421e-01, PNorm = 43.9278, GNorm = 5.9417, lr_0 = 1.0000e-04
Validation rmse = 0.653661
Epoch 29
Loss = 2.0629e-01, PNorm = 43.9315, GNorm = 5.5404, lr_0 = 1.0000e-04
Loss = 2.3573e-01, PNorm = 43.9352, GNorm = 3.3612, lr_0 = 1.0000e-04
Validation rmse = 0.655476
Model 0 best validation rmse = 0.651677 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.665470
Ensemble test rmse = 0.665470
1-fold cross validation
	Seed 0 ==> test rmse = 0.665470
Overall test rmse = 0.665470 +/- 0.000000
Elapsed time = 0:01:57
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7966e+00, PNorm = 42.7386, GNorm = 3.1132, lr_0 = 3.0625e-04
Loss = 1.3866e+00, PNorm = 42.7355, GNorm = 2.4330, lr_0 = 4.9375e-04
Validation rmse = 1.507285
Epoch 1
Loss = 1.2942e+00, PNorm = 42.7418, GNorm = 0.7934, lr_0 = 6.8125e-04
Loss = 1.2660e+00, PNorm = 42.7610, GNorm = 0.9793, lr_0 = 8.6875e-04
Validation rmse = 1.294802
Epoch 2
Loss = 1.2492e+00, PNorm = 42.7951, GNorm = 3.3691, lr_0 = 9.8977e-04
Loss = 1.1777e+00, PNorm = 42.8392, GNorm = 2.0468, lr_0 = 9.5643e-04
Loss = 1.0493e+00, PNorm = 42.8926, GNorm = 2.8722, lr_0 = 9.2422e-04
Validation rmse = 1.228188
Epoch 3
Loss = 1.0013e+00, PNorm = 42.9497, GNorm = 1.4801, lr_0 = 8.9309e-04
Loss = 8.8415e-01, PNorm = 43.0174, GNorm = 1.5402, lr_0 = 8.6300e-04
Validation rmse = 0.920439
Epoch 4
Loss = 7.4818e-01, PNorm = 43.0922, GNorm = 2.9241, lr_0 = 8.3393e-04
Loss = 7.8904e-01, PNorm = 43.1561, GNorm = 10.2425, lr_0 = 8.0584e-04
Loss = 8.2993e-01, PNorm = 43.1979, GNorm = 4.5450, lr_0 = 7.7870e-04
Validation rmse = 0.993088
Epoch 5
Loss = 7.1712e-01, PNorm = 43.2469, GNorm = 1.6389, lr_0 = 7.5247e-04
Loss = 6.2329e-01, PNorm = 43.3013, GNorm = 7.1215, lr_0 = 7.2712e-04
Validation rmse = 0.729038
Epoch 6
Loss = 6.0669e-01, PNorm = 43.3388, GNorm = 4.3606, lr_0 = 7.0263e-04
Loss = 5.8684e-01, PNorm = 43.3757, GNorm = 2.6749, lr_0 = 6.7896e-04
Validation rmse = 0.724914
Epoch 7
Loss = 6.0146e-01, PNorm = 43.4150, GNorm = 5.3539, lr_0 = 6.5609e-04
Loss = 5.7449e-01, PNorm = 43.4478, GNorm = 7.0954, lr_0 = 6.3399e-04
Loss = 5.9527e-01, PNorm = 43.4738, GNorm = 8.0405, lr_0 = 6.1264e-04
Validation rmse = 0.773347
Epoch 8
Loss = 4.3446e-01, PNorm = 43.5124, GNorm = 4.1408, lr_0 = 5.9200e-04
Loss = 5.0575e-01, PNorm = 43.5467, GNorm = 5.2217, lr_0 = 5.7206e-04
Validation rmse = 0.676769
Epoch 9
Loss = 3.9304e-01, PNorm = 43.5654, GNorm = 2.7112, lr_0 = 5.5279e-04
Loss = 4.3240e-01, PNorm = 43.5915, GNorm = 6.5467, lr_0 = 5.3417e-04
Loss = 4.7521e-01, PNorm = 43.6096, GNorm = 4.8330, lr_0 = 5.1618e-04
Validation rmse = 0.681569
Epoch 10
Loss = 4.0436e-01, PNorm = 43.6349, GNorm = 4.2709, lr_0 = 4.9879e-04
Loss = 5.2732e-01, PNorm = 43.6476, GNorm = 2.9566, lr_0 = 4.8199e-04
Validation rmse = 0.678775
Epoch 11
Loss = 3.8907e-01, PNorm = 43.6679, GNorm = 4.3088, lr_0 = 4.6575e-04
Loss = 4.4943e-01, PNorm = 43.6929, GNorm = 12.1512, lr_0 = 4.5006e-04
Validation rmse = 0.672341
Epoch 12
Loss = 3.4913e-01, PNorm = 43.7039, GNorm = 5.2371, lr_0 = 4.3490e-04
Loss = 3.8647e-01, PNorm = 43.7197, GNorm = 10.6023, lr_0 = 4.2025e-04
Loss = 3.9828e-01, PNorm = 43.7345, GNorm = 2.2904, lr_0 = 4.0610e-04
Validation rmse = 0.657945
Epoch 13
Loss = 3.1099e-01, PNorm = 43.7519, GNorm = 5.4815, lr_0 = 3.9242e-04
Loss = 4.2250e-01, PNorm = 43.7648, GNorm = 14.3167, lr_0 = 3.7920e-04
Validation rmse = 0.694405
Epoch 14
Loss = 3.9925e-01, PNorm = 43.7735, GNorm = 2.2817, lr_0 = 3.6643e-04
Loss = 3.3456e-01, PNorm = 43.7898, GNorm = 8.5115, lr_0 = 3.5408e-04
Loss = 3.5060e-01, PNorm = 43.8008, GNorm = 6.3957, lr_0 = 3.4216e-04
Validation rmse = 0.680558
Epoch 15
Loss = 3.0604e-01, PNorm = 43.8145, GNorm = 15.0226, lr_0 = 3.3063e-04
Loss = 3.3158e-01, PNorm = 43.8274, GNorm = 2.3386, lr_0 = 3.1950e-04
Validation rmse = 0.671395
Epoch 16
Loss = 3.3687e-01, PNorm = 43.8384, GNorm = 2.6647, lr_0 = 3.0873e-04
Loss = 2.8410e-01, PNorm = 43.8537, GNorm = 4.4195, lr_0 = 2.9833e-04
Validation rmse = 0.679780
Epoch 17
Loss = 4.0453e-01, PNorm = 43.8635, GNorm = 11.9534, lr_0 = 2.8828e-04
Loss = 3.0788e-01, PNorm = 43.8742, GNorm = 6.1006, lr_0 = 2.7857e-04
Loss = 3.3278e-01, PNorm = 43.8848, GNorm = 8.9287, lr_0 = 2.6919e-04
Validation rmse = 0.669780
Epoch 18
Loss = 2.0355e-01, PNorm = 43.8966, GNorm = 3.6223, lr_0 = 2.6012e-04
Loss = 2.9001e-01, PNorm = 43.9046, GNorm = 7.4742, lr_0 = 2.5136e-04
Validation rmse = 0.661058
Epoch 19
Loss = 2.5783e-01, PNorm = 43.9139, GNorm = 3.6336, lr_0 = 2.4289e-04
Loss = 2.8842e-01, PNorm = 43.9232, GNorm = 3.4160, lr_0 = 2.3471e-04
Loss = 2.5816e-01, PNorm = 43.9312, GNorm = 4.3581, lr_0 = 2.2681e-04
Validation rmse = 0.640552
Epoch 20
Loss = 2.7561e-01, PNorm = 43.9386, GNorm = 9.2558, lr_0 = 2.1917e-04
Loss = 3.2652e-01, PNorm = 43.9444, GNorm = 3.1370, lr_0 = 2.1178e-04
Validation rmse = 0.645418
Epoch 21
Loss = 1.9245e-01, PNorm = 43.9545, GNorm = 2.9244, lr_0 = 2.0465e-04
Loss = 2.9264e-01, PNorm = 43.9650, GNorm = 8.3692, lr_0 = 1.9776e-04
Validation rmse = 0.635628
Epoch 22
Loss = 2.1895e-01, PNorm = 43.9710, GNorm = 11.0323, lr_0 = 1.9110e-04
Loss = 2.9285e-01, PNorm = 43.9759, GNorm = 4.3950, lr_0 = 1.8466e-04
Loss = 2.3046e-01, PNorm = 43.9828, GNorm = 4.9237, lr_0 = 1.7844e-04
Validation rmse = 0.649015
Epoch 23
Loss = 2.1357e-01, PNorm = 43.9911, GNorm = 3.9213, lr_0 = 1.7243e-04
Loss = 2.6322e-01, PNorm = 43.9973, GNorm = 12.1186, lr_0 = 1.6662e-04
Validation rmse = 0.626377
Epoch 24
Loss = 1.7044e-01, PNorm = 44.0031, GNorm = 3.6238, lr_0 = 1.6101e-04
Loss = 2.5567e-01, PNorm = 44.0105, GNorm = 11.9972, lr_0 = 1.5558e-04
Loss = 2.3371e-01, PNorm = 44.0150, GNorm = 3.5312, lr_0 = 1.5034e-04
Validation rmse = 0.630092
Epoch 25
Loss = 2.0034e-01, PNorm = 44.0199, GNorm = 8.1691, lr_0 = 1.4528e-04
Loss = 2.5347e-01, PNorm = 44.0254, GNorm = 5.5936, lr_0 = 1.4039e-04
Validation rmse = 0.637506
Epoch 26
Loss = 2.3337e-01, PNorm = 44.0303, GNorm = 4.6912, lr_0 = 1.3566e-04
Loss = 1.7611e-01, PNorm = 44.0360, GNorm = 3.3336, lr_0 = 1.3109e-04
Validation rmse = 0.637510
Epoch 27
Loss = 1.2526e-01, PNorm = 44.0407, GNorm = 3.6922, lr_0 = 1.2667e-04
Loss = 2.0622e-01, PNorm = 44.0457, GNorm = 4.2551, lr_0 = 1.2240e-04
Loss = 2.0033e-01, PNorm = 44.0501, GNorm = 4.6749, lr_0 = 1.1828e-04
Validation rmse = 0.636226
Epoch 28
Loss = 2.1809e-01, PNorm = 44.0537, GNorm = 12.5697, lr_0 = 1.1430e-04
Loss = 1.8000e-01, PNorm = 44.0576, GNorm = 7.7472, lr_0 = 1.1045e-04
Validation rmse = 0.638574
Epoch 29
Loss = 1.5714e-01, PNorm = 44.0626, GNorm = 6.5936, lr_0 = 1.0673e-04
Loss = 2.3818e-01, PNorm = 44.0666, GNorm = 3.2749, lr_0 = 1.0313e-04
Loss = 1.6740e-01, PNorm = 44.0704, GNorm = 9.8981, lr_0 = 1.0000e-04
Validation rmse = 0.633112
Model 0 best validation rmse = 0.626377 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.680117
Ensemble test rmse = 0.680117
1-fold cross validation
	Seed 0 ==> test rmse = 0.680117
Overall test rmse = 0.680117 +/- 0.000000
Elapsed time = 0:02:01
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7811e+00, PNorm = 42.7400, GNorm = 2.9501, lr_0 = 4.0937e-04
Validation rmse = 1.235823
Epoch 1
Loss = 1.4605e+00, PNorm = 42.7366, GNorm = 1.0246, lr_0 = 6.9063e-04
Loss = 1.4065e+00, PNorm = 42.7430, GNorm = 0.9627, lr_0 = 9.7187e-04
Validation rmse = 1.147602
Epoch 2
Loss = 1.3719e+00, PNorm = 42.7581, GNorm = 1.5831, lr_0 = 9.5480e-04
Validation rmse = 1.064459
Epoch 3
Loss = 1.2340e+00, PNorm = 42.7798, GNorm = 1.2749, lr_0 = 9.0696e-04
Loss = 1.2896e+00, PNorm = 42.8100, GNorm = 0.9341, lr_0 = 8.6152e-04
Validation rmse = 0.998129
Epoch 4
Loss = 1.2317e+00, PNorm = 42.8485, GNorm = 3.3530, lr_0 = 8.1836e-04
Loss = 1.2130e+00, PNorm = 42.8954, GNorm = 0.9946, lr_0 = 7.7737e-04
Validation rmse = 0.956953
Epoch 5
Loss = 1.1752e+00, PNorm = 42.9526, GNorm = 2.1761, lr_0 = 7.3842e-04
Validation rmse = 0.913473
Epoch 6
Loss = 1.1041e+00, PNorm = 43.0150, GNorm = 8.9352, lr_0 = 7.0143e-04
Loss = 1.0677e+00, PNorm = 43.0670, GNorm = 5.9429, lr_0 = 6.6629e-04
Validation rmse = 0.849180
Epoch 7
Loss = 1.0084e+00, PNorm = 43.1196, GNorm = 10.3527, lr_0 = 6.3291e-04
Validation rmse = 0.831559
Epoch 8
Loss = 8.9069e-01, PNorm = 43.1696, GNorm = 4.7448, lr_0 = 6.0120e-04
Loss = 9.1651e-01, PNorm = 43.2133, GNorm = 3.3598, lr_0 = 5.7108e-04
Validation rmse = 0.785737
Epoch 9
Loss = 7.9234e-01, PNorm = 43.2574, GNorm = 2.3066, lr_0 = 5.4247e-04
Loss = 8.4096e-01, PNorm = 43.2969, GNorm = 7.8238, lr_0 = 5.1529e-04
Validation rmse = 0.745170
Epoch 10
Loss = 7.0984e-01, PNorm = 43.3354, GNorm = 11.1623, lr_0 = 4.8948e-04
Validation rmse = 0.760675
Epoch 11
Loss = 8.4888e-01, PNorm = 43.3554, GNorm = 2.5387, lr_0 = 4.6495e-04
Loss = 7.9279e-01, PNorm = 43.3849, GNorm = 12.9007, lr_0 = 4.4166e-04
Validation rmse = 0.824103
Epoch 12
Loss = 7.4551e-01, PNorm = 43.4145, GNorm = 7.4593, lr_0 = 4.1953e-04
Validation rmse = 0.704536
Epoch 13
Loss = 7.2627e-01, PNorm = 43.4421, GNorm = 11.2903, lr_0 = 3.9852e-04
Loss = 7.1494e-01, PNorm = 43.4696, GNorm = 3.8946, lr_0 = 3.7855e-04
Validation rmse = 0.808030
Epoch 14
Loss = 8.6533e-01, PNorm = 43.4871, GNorm = 11.3040, lr_0 = 3.5959e-04
Loss = 7.5062e-01, PNorm = 43.5030, GNorm = 5.0052, lr_0 = 3.4157e-04
Validation rmse = 0.738459
Epoch 15
Loss = 6.6653e-01, PNorm = 43.5234, GNorm = 6.2070, lr_0 = 3.2446e-04
Validation rmse = 0.733322
Epoch 16
Loss = 6.5241e-01, PNorm = 43.5411, GNorm = 3.3696, lr_0 = 3.0820e-04
Loss = 6.2773e-01, PNorm = 43.5588, GNorm = 11.2557, lr_0 = 2.9276e-04
Validation rmse = 0.712319
Epoch 17
Loss = 6.1463e-01, PNorm = 43.5761, GNorm = 7.8831, lr_0 = 2.7810e-04
Validation rmse = 0.701618
Epoch 18
Loss = 5.9220e-01, PNorm = 43.5901, GNorm = 7.8871, lr_0 = 2.6416e-04
Loss = 6.0266e-01, PNorm = 43.6033, GNorm = 5.5422, lr_0 = 2.5093e-04
Validation rmse = 0.704675
Epoch 19
Loss = 5.7907e-01, PNorm = 43.6155, GNorm = 3.3493, lr_0 = 2.3836e-04
Loss = 5.6085e-01, PNorm = 43.6287, GNorm = 6.6165, lr_0 = 2.2642e-04
Validation rmse = 0.692764
Epoch 20
Loss = 5.3099e-01, PNorm = 43.6421, GNorm = 3.8618, lr_0 = 2.1507e-04
Validation rmse = 0.687617
Epoch 21
Loss = 4.5822e-01, PNorm = 43.6547, GNorm = 2.4376, lr_0 = 2.0430e-04
Loss = 5.5906e-01, PNorm = 43.6661, GNorm = 12.7994, lr_0 = 1.9406e-04
Validation rmse = 0.690030
Epoch 22
Loss = 5.3867e-01, PNorm = 43.6776, GNorm = 14.0968, lr_0 = 1.8434e-04
Validation rmse = 0.679042
Epoch 23
Loss = 4.3199e-01, PNorm = 43.6873, GNorm = 3.4026, lr_0 = 1.7511e-04
Loss = 5.0586e-01, PNorm = 43.6962, GNorm = 5.0471, lr_0 = 1.6633e-04
Validation rmse = 0.680995
Epoch 24
Loss = 5.1689e-01, PNorm = 43.7039, GNorm = 6.8677, lr_0 = 1.5800e-04
Loss = 5.0185e-01, PNorm = 43.7121, GNorm = 3.5528, lr_0 = 1.5009e-04
Validation rmse = 0.688508
Epoch 25
Loss = 4.6095e-01, PNorm = 43.7198, GNorm = 11.6379, lr_0 = 1.4257e-04
Validation rmse = 0.683668
Epoch 26
Loss = 4.6619e-01, PNorm = 43.7270, GNorm = 9.0139, lr_0 = 1.3542e-04
Loss = 4.9475e-01, PNorm = 43.7341, GNorm = 15.1581, lr_0 = 1.2864e-04
Validation rmse = 0.679858
Epoch 27
Loss = 4.8423e-01, PNorm = 43.7409, GNorm = 15.6422, lr_0 = 1.2220e-04
Validation rmse = 0.693340
Epoch 28
Loss = 4.8528e-01, PNorm = 43.7471, GNorm = 8.8365, lr_0 = 1.1607e-04
Loss = 4.3778e-01, PNorm = 43.7523, GNorm = 4.2582, lr_0 = 1.1026e-04
Validation rmse = 0.696939
Epoch 29
Loss = 5.1120e-01, PNorm = 43.7579, GNorm = 10.5681, lr_0 = 1.0473e-04
Loss = 4.6462e-01, PNorm = 43.7624, GNorm = 3.2798, lr_0 = 1.0000e-04
Validation rmse = 0.676663
Model 0 best validation rmse = 0.676663 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.812948
Ensemble test rmse = 0.812948
1-fold cross validation
	Seed 0 ==> test rmse = 0.812948
Overall test rmse = 0.812948 +/- 0.000000
Elapsed time = 0:01:22
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,050 | train size = 840 | val size = 105 | test size = 105
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8457e+00, PNorm = 42.7402, GNorm = 1.4668, lr_0 = 4.0937e-04
Validation rmse = 1.370318
Epoch 1
Loss = 1.4576e+00, PNorm = 42.7397, GNorm = 0.6849, lr_0 = 7.1875e-04
Loss = 1.3978e+00, PNorm = 42.7511, GNorm = 0.9582, lr_0 = 1.0000e-03
Validation rmse = 1.292124
Epoch 2
Loss = 1.3294e+00, PNorm = 42.7729, GNorm = 1.8299, lr_0 = 9.4990e-04
Loss = 1.2945e+00, PNorm = 42.8015, GNorm = 2.7056, lr_0 = 9.0231e-04
Validation rmse = 1.202748
Epoch 3
Loss = 1.2899e+00, PNorm = 42.8328, GNorm = 1.9994, lr_0 = 8.5711e-04
Validation rmse = 1.137064
Epoch 4
Loss = 1.2096e+00, PNorm = 42.8754, GNorm = 2.7620, lr_0 = 8.1417e-04
Loss = 1.1349e+00, PNorm = 42.9227, GNorm = 1.5184, lr_0 = 7.7338e-04
Validation rmse = 1.136174
Epoch 5
Loss = 1.0453e+00, PNorm = 42.9795, GNorm = 3.2370, lr_0 = 7.3463e-04
Loss = 1.0482e+00, PNorm = 43.0329, GNorm = 2.3679, lr_0 = 6.9783e-04
Loss = 1.1967e+00, PNorm = 43.0373, GNorm = 8.8551, lr_0 = 6.9425e-04
Validation rmse = 1.081142
Epoch 6
Loss = 9.9107e-01, PNorm = 43.0881, GNorm = 2.6260, lr_0 = 6.5947e-04
Validation rmse = 1.023540
Epoch 7
Loss = 9.6126e-01, PNorm = 43.1338, GNorm = 6.7489, lr_0 = 6.2643e-04
Loss = 9.0708e-01, PNorm = 43.1785, GNorm = 5.7894, lr_0 = 5.9505e-04
Validation rmse = 0.928001
Epoch 8
Loss = 8.4372e-01, PNorm = 43.2185, GNorm = 3.0391, lr_0 = 5.6524e-04
Loss = 9.2922e-01, PNorm = 43.2511, GNorm = 7.0972, lr_0 = 5.3692e-04
Validation rmse = 0.911396
Epoch 9
Loss = 8.4871e-01, PNorm = 43.2818, GNorm = 3.7567, lr_0 = 5.1002e-04
Validation rmse = 0.837357
Epoch 10
Loss = 7.8529e-01, PNorm = 43.3212, GNorm = 1.5342, lr_0 = 4.8447e-04
Loss = 7.8499e-01, PNorm = 43.3540, GNorm = 2.4758, lr_0 = 4.6020e-04
Validation rmse = 0.847415
Epoch 11
Loss = 6.4740e-01, PNorm = 43.3852, GNorm = 4.3714, lr_0 = 4.3490e-04
Loss = 7.6066e-01, PNorm = 43.4100, GNorm = 8.9386, lr_0 = 4.1312e-04
Validation rmse = 0.808864
Epoch 12
Loss = 7.4162e-01, PNorm = 43.4374, GNorm = 6.8790, lr_0 = 3.9242e-04
Validation rmse = 0.792981
Epoch 13
Loss = 7.0772e-01, PNorm = 43.4616, GNorm = 3.7863, lr_0 = 3.7276e-04
Loss = 5.9817e-01, PNorm = 43.4879, GNorm = 2.1623, lr_0 = 3.5408e-04
Validation rmse = 0.777455
Epoch 14
Loss = 6.7483e-01, PNorm = 43.5094, GNorm = 3.2283, lr_0 = 3.3635e-04
Loss = 6.3562e-01, PNorm = 43.5329, GNorm = 2.3476, lr_0 = 3.1950e-04
Validation rmse = 0.775853
Epoch 15
Loss = 6.0843e-01, PNorm = 43.5559, GNorm = 13.4186, lr_0 = 3.0349e-04
Validation rmse = 0.747880
Epoch 16
Loss = 6.0305e-01, PNorm = 43.5790, GNorm = 5.5492, lr_0 = 2.8681e-04
Loss = 6.6399e-01, PNorm = 43.5959, GNorm = 4.3545, lr_0 = 2.7244e-04
Validation rmse = 0.762309
Epoch 17
Loss = 5.9632e-01, PNorm = 43.6137, GNorm = 11.9022, lr_0 = 2.5879e-04
Loss = 6.0124e-01, PNorm = 43.6335, GNorm = 10.3432, lr_0 = 2.4582e-04
Validation rmse = 0.738406
Epoch 18
Loss = 5.8379e-01, PNorm = 43.6488, GNorm = 5.8931, lr_0 = 2.3351e-04
Validation rmse = 0.736876
Epoch 19
Loss = 7.0563e-01, PNorm = 43.6616, GNorm = 5.5845, lr_0 = 2.2181e-04
Loss = 5.6873e-01, PNorm = 43.6746, GNorm = 3.0572, lr_0 = 2.1070e-04
Validation rmse = 0.770270
Epoch 20
Loss = 4.4321e-01, PNorm = 43.6871, GNorm = 3.1174, lr_0 = 2.0014e-04
Loss = 5.6125e-01, PNorm = 43.6990, GNorm = 8.4009, lr_0 = 1.9012e-04
Validation rmse = 0.745240
Epoch 21
Loss = 4.6628e-01, PNorm = 43.7088, GNorm = 4.3260, lr_0 = 1.7967e-04
Validation rmse = 0.711522
Epoch 22
Loss = 4.7306e-01, PNorm = 43.7195, GNorm = 6.5154, lr_0 = 1.7066e-04
Loss = 4.8608e-01, PNorm = 43.7296, GNorm = 9.7204, lr_0 = 1.6211e-04
Validation rmse = 0.732541
Epoch 23
Loss = 6.4041e-01, PNorm = 43.7374, GNorm = 17.1058, lr_0 = 1.5399e-04
Loss = 5.0303e-01, PNorm = 43.7463, GNorm = 12.6071, lr_0 = 1.4628e-04
Validation rmse = 0.719766
Epoch 24
Loss = 4.9514e-01, PNorm = 43.7533, GNorm = 6.6953, lr_0 = 1.3895e-04
Loss = 4.8794e-01, PNorm = 43.7614, GNorm = 8.4845, lr_0 = 1.3199e-04
Validation rmse = 0.708227
Epoch 25
Loss = 4.3762e-01, PNorm = 43.7696, GNorm = 5.4819, lr_0 = 1.2538e-04
Validation rmse = 0.720174
Epoch 26
Loss = 4.9058e-01, PNorm = 43.7758, GNorm = 7.6670, lr_0 = 1.1848e-04
Loss = 4.8023e-01, PNorm = 43.7818, GNorm = 6.5936, lr_0 = 1.1255e-04
Validation rmse = 0.712912
Epoch 27
Loss = 4.9016e-01, PNorm = 43.7880, GNorm = 8.0456, lr_0 = 1.0691e-04
Loss = 4.0959e-01, PNorm = 43.7943, GNorm = 10.7101, lr_0 = 1.0155e-04
Validation rmse = 0.699180
Epoch 28
Loss = 4.4234e-01, PNorm = 43.8005, GNorm = 4.6561, lr_0 = 1.0000e-04
Validation rmse = 0.699824
Epoch 29
Loss = 4.1635e-01, PNorm = 43.8062, GNorm = 4.6172, lr_0 = 1.0000e-04
Loss = 4.2223e-01, PNorm = 43.8118, GNorm = 5.5776, lr_0 = 1.0000e-04
Validation rmse = 0.697935
Model 0 best validation rmse = 0.697935 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.820679
Ensemble test rmse = 0.820679
1-fold cross validation
	Seed 0 ==> test rmse = 0.820679
Overall test rmse = 0.820679 +/- 0.000000
Elapsed time = 0:01:25
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8624e+00, PNorm = 42.7391, GNorm = 1.7072, lr_0 = 3.9118e-04
Validation rmse = 1.389324
Epoch 1
Loss = 1.4921e+00, PNorm = 42.7388, GNorm = 1.1962, lr_0 = 6.8235e-04
Loss = 1.3626e+00, PNorm = 42.7495, GNorm = 0.7032, lr_0 = 9.4706e-04
Validation rmse = 1.328342
Epoch 2
Loss = 1.3334e+00, PNorm = 42.7739, GNorm = 1.1778, lr_0 = 9.6204e-04
Loss = 1.3020e+00, PNorm = 42.8030, GNorm = 1.1040, lr_0 = 9.1661e-04
Validation rmse = 1.203058
Epoch 3
Loss = 1.2162e+00, PNorm = 42.8451, GNorm = 1.9854, lr_0 = 8.6911e-04
Loss = 1.2147e+00, PNorm = 42.8938, GNorm = 1.6338, lr_0 = 8.2807e-04
Validation rmse = 1.120427
Epoch 4
Loss = 1.1067e+00, PNorm = 42.9509, GNorm = 0.9195, lr_0 = 7.8897e-04
Validation rmse = 1.034867
Epoch 5
Loss = 9.6940e-01, PNorm = 43.0030, GNorm = 2.0314, lr_0 = 7.5171e-04
Loss = 9.8230e-01, PNorm = 43.0604, GNorm = 7.7859, lr_0 = 7.1621e-04
Validation rmse = 0.994531
Epoch 6
Loss = 9.1714e-01, PNorm = 43.1058, GNorm = 4.4183, lr_0 = 6.7910e-04
Loss = 8.9757e-01, PNorm = 43.1583, GNorm = 1.9252, lr_0 = 6.4703e-04
Validation rmse = 0.953439
Epoch 7
Loss = 8.0842e-01, PNorm = 43.1982, GNorm = 7.9349, lr_0 = 6.1648e-04
Loss = 8.1084e-01, PNorm = 43.2339, GNorm = 8.0581, lr_0 = 5.8736e-04
Loss = 1.1319e+00, PNorm = 43.2372, GNorm = 12.8403, lr_0 = 5.8453e-04
Validation rmse = 0.926006
Epoch 8
Loss = 8.0015e-01, PNorm = 43.2759, GNorm = 2.2980, lr_0 = 5.5693e-04
Validation rmse = 1.214705
Epoch 9
Loss = 9.1278e-01, PNorm = 43.3144, GNorm = 12.5731, lr_0 = 5.3063e-04
Loss = 8.9443e-01, PNorm = 43.3385, GNorm = 5.2501, lr_0 = 5.0557e-04
Validation rmse = 0.972838
Epoch 10
Loss = 7.8393e-01, PNorm = 43.3654, GNorm = 5.3736, lr_0 = 4.8170e-04
Loss = 6.8864e-01, PNorm = 43.3982, GNorm = 2.0686, lr_0 = 4.5895e-04
Validation rmse = 0.870492
Epoch 11
Loss = 7.2106e-01, PNorm = 43.4316, GNorm = 3.9267, lr_0 = 4.3517e-04
Loss = 6.7048e-01, PNorm = 43.4588, GNorm = 10.6019, lr_0 = 4.1462e-04
Validation rmse = 0.870014
Epoch 12
Loss = 6.1904e-01, PNorm = 43.4819, GNorm = 4.7478, lr_0 = 3.9504e-04
Validation rmse = 0.876827
Epoch 13
Loss = 5.7606e-01, PNorm = 43.5087, GNorm = 2.6949, lr_0 = 3.7457e-04
Loss = 6.0645e-01, PNorm = 43.5398, GNorm = 3.4794, lr_0 = 3.5688e-04
Validation rmse = 0.897646
Epoch 14
Loss = 7.0386e-01, PNorm = 43.5550, GNorm = 4.7021, lr_0 = 3.4003e-04
Loss = 5.8668e-01, PNorm = 43.5751, GNorm = 3.7810, lr_0 = 3.2397e-04
Validation rmse = 0.853591
Epoch 15
Loss = 4.8111e-01, PNorm = 43.5958, GNorm = 2.2991, lr_0 = 3.0867e-04
Loss = 5.9101e-01, PNorm = 43.6130, GNorm = 1.9015, lr_0 = 2.9409e-04
Validation rmse = 0.882829
Epoch 16
Loss = 5.2941e-01, PNorm = 43.6332, GNorm = 9.1860, lr_0 = 2.7885e-04
Validation rmse = 0.859862
Epoch 17
Loss = 4.2638e-01, PNorm = 43.6507, GNorm = 4.2558, lr_0 = 2.6569e-04
Loss = 5.1528e-01, PNorm = 43.6661, GNorm = 7.9459, lr_0 = 2.5314e-04
Validation rmse = 0.800533
Epoch 18
Loss = 5.2299e-01, PNorm = 43.6830, GNorm = 4.3717, lr_0 = 2.4002e-04
Loss = 5.1306e-01, PNorm = 43.6984, GNorm = 2.3450, lr_0 = 2.2869e-04
Validation rmse = 0.818853
Epoch 19
Loss = 4.8628e-01, PNorm = 43.7110, GNorm = 9.1491, lr_0 = 2.1789e-04
Loss = 4.6270e-01, PNorm = 43.7235, GNorm = 8.6420, lr_0 = 2.0760e-04
Validation rmse = 0.797973
Epoch 20
Loss = 4.7991e-01, PNorm = 43.7353, GNorm = 14.7077, lr_0 = 1.9780e-04
Validation rmse = 0.851699
Epoch 21
Loss = 6.6048e-01, PNorm = 43.7477, GNorm = 7.6050, lr_0 = 1.8755e-04
Loss = 4.3019e-01, PNorm = 43.7594, GNorm = 3.4443, lr_0 = 1.7869e-04
Validation rmse = 0.786115
Epoch 22
Loss = 4.3045e-01, PNorm = 43.7706, GNorm = 2.9207, lr_0 = 1.7025e-04
Loss = 4.7329e-01, PNorm = 43.7812, GNorm = 8.6557, lr_0 = 1.6221e-04
Validation rmse = 0.810278
Epoch 23
Loss = 4.2530e-01, PNorm = 43.7893, GNorm = 6.0522, lr_0 = 1.5381e-04
Loss = 4.4591e-01, PNorm = 43.7967, GNorm = 4.5878, lr_0 = 1.4654e-04
Validation rmse = 0.801818
Epoch 24
Loss = 4.6289e-01, PNorm = 43.8055, GNorm = 4.7871, lr_0 = 1.3962e-04
Loss = 3.6211e-01, PNorm = 43.8148, GNorm = 9.9854, lr_0 = 1.3303e-04
Validation rmse = 0.799026
Epoch 25
Loss = 4.6881e-01, PNorm = 43.8201, GNorm = 3.3788, lr_0 = 1.2675e-04
Validation rmse = 0.801340
Epoch 26
Loss = 3.4473e-01, PNorm = 43.8282, GNorm = 3.8982, lr_0 = 1.2018e-04
Loss = 4.3005e-01, PNorm = 43.8358, GNorm = 8.6173, lr_0 = 1.1450e-04
Validation rmse = 0.833202
Epoch 27
Loss = 3.8641e-01, PNorm = 43.8409, GNorm = 4.2518, lr_0 = 1.0910e-04
Loss = 4.0644e-01, PNorm = 43.8467, GNorm = 8.0697, lr_0 = 1.0395e-04
Validation rmse = 0.789944
Epoch 28
Loss = 3.9434e-01, PNorm = 43.8517, GNorm = 6.1791, lr_0 = 1.0000e-04
Loss = 3.7133e-01, PNorm = 43.8572, GNorm = 6.3315, lr_0 = 1.0000e-04
Validation rmse = 0.773450
Epoch 29
Loss = 3.7250e-01, PNorm = 43.8631, GNorm = 4.9053, lr_0 = 1.0000e-04
Validation rmse = 0.795615
Model 0 best validation rmse = 0.773450 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.583221
Ensemble test rmse = 0.583221
1-fold cross validation
	Seed 0 ==> test rmse = 0.583221
Overall test rmse = 0.583221 +/- 0.000000
Elapsed time = 0:01:30
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,150 | train size = 920 | val size = 115 | test size = 115
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7277e+00, PNorm = 42.7397, GNorm = 1.4876, lr_0 = 3.7500e-04
Validation rmse = 1.346935
Epoch 1
Loss = 1.4352e+00, PNorm = 42.7365, GNorm = 0.8892, lr_0 = 6.5000e-04
Loss = 1.3873e+00, PNorm = 42.7457, GNorm = 1.1186, lr_0 = 9.0000e-04
Validation rmse = 1.177191
Epoch 2
Loss = 1.3674e+00, PNorm = 42.7724, GNorm = 4.0041, lr_0 = 9.6853e-04
Loss = 1.1971e+00, PNorm = 42.8080, GNorm = 3.2065, lr_0 = 9.2527e-04
Validation rmse = 1.102034
Epoch 3
Loss = 1.1049e+00, PNorm = 42.8565, GNorm = 2.6934, lr_0 = 8.8395e-04
Loss = 1.0673e+00, PNorm = 42.9148, GNorm = 4.7059, lr_0 = 8.4448e-04
Validation rmse = 1.012474
Epoch 4
Loss = 9.1727e-01, PNorm = 42.9730, GNorm = 7.1813, lr_0 = 8.0309e-04
Loss = 9.9316e-01, PNorm = 43.0179, GNorm = 1.5963, lr_0 = 7.6722e-04
Validation rmse = 0.913580
Epoch 5
Loss = 9.1505e-01, PNorm = 43.0657, GNorm = 4.2950, lr_0 = 7.3296e-04
Loss = 8.9808e-01, PNorm = 43.0960, GNorm = 2.8695, lr_0 = 7.0023e-04
Loss = 9.7937e-01, PNorm = 43.0996, GNorm = 7.8861, lr_0 = 6.9703e-04
Validation rmse = 0.924454
Epoch 6
Loss = 7.7588e-01, PNorm = 43.1418, GNorm = 1.7510, lr_0 = 6.6591e-04
Validation rmse = 0.843994
Epoch 7
Loss = 7.5880e-01, PNorm = 43.1888, GNorm = 11.3560, lr_0 = 6.3327e-04
Loss = 7.6104e-01, PNorm = 43.2245, GNorm = 5.3347, lr_0 = 6.0499e-04
Validation rmse = 0.796703
Epoch 8
Loss = 6.6814e-01, PNorm = 43.2609, GNorm = 3.3587, lr_0 = 5.7797e-04
Loss = 6.8770e-01, PNorm = 43.2925, GNorm = 5.5912, lr_0 = 5.5216e-04
Validation rmse = 0.783257
Epoch 9
Loss = 6.4434e-01, PNorm = 43.3289, GNorm = 6.9858, lr_0 = 5.2510e-04
Loss = 6.6422e-01, PNorm = 43.3511, GNorm = 10.9563, lr_0 = 5.0165e-04
Validation rmse = 0.773861
Epoch 10
Loss = 6.3366e-01, PNorm = 43.3769, GNorm = 2.0094, lr_0 = 4.7924e-04
Loss = 5.9335e-01, PNorm = 43.4082, GNorm = 4.6551, lr_0 = 4.5784e-04
Validation rmse = 0.835947
Epoch 11
Loss = 6.1551e-01, PNorm = 43.4334, GNorm = 12.8591, lr_0 = 4.3540e-04
Loss = 5.8869e-01, PNorm = 43.4527, GNorm = 2.3402, lr_0 = 4.1596e-04
Loss = 5.4168e-01, PNorm = 43.4547, GNorm = 16.2818, lr_0 = 4.1406e-04
Validation rmse = 0.763681
Epoch 12
Loss = 5.6630e-01, PNorm = 43.4751, GNorm = 6.3858, lr_0 = 3.9557e-04
Validation rmse = 0.753024
Epoch 13
Loss = 5.0228e-01, PNorm = 43.4925, GNorm = 5.3307, lr_0 = 3.7790e-04
Loss = 5.6372e-01, PNorm = 43.5081, GNorm = 8.9013, lr_0 = 3.6103e-04
Validation rmse = 0.738853
Epoch 14
Loss = 4.5408e-01, PNorm = 43.5271, GNorm = 3.2833, lr_0 = 3.4333e-04
Loss = 5.5400e-01, PNorm = 43.5429, GNorm = 7.4000, lr_0 = 3.2800e-04
Validation rmse = 0.739165
Epoch 15
Loss = 5.1930e-01, PNorm = 43.5620, GNorm = 7.4712, lr_0 = 3.1335e-04
Loss = 5.0356e-01, PNorm = 43.5748, GNorm = 6.6006, lr_0 = 2.9936e-04
Validation rmse = 0.761601
Epoch 16
Loss = 4.2350e-01, PNorm = 43.5888, GNorm = 3.9219, lr_0 = 2.8469e-04
Loss = 5.0244e-01, PNorm = 43.6020, GNorm = 3.6022, lr_0 = 2.7197e-04
Validation rmse = 0.737316
Epoch 17
Loss = 4.3994e-01, PNorm = 43.6150, GNorm = 4.0930, lr_0 = 2.5864e-04
Loss = 4.3923e-01, PNorm = 43.6272, GNorm = 4.9558, lr_0 = 2.4709e-04
Validation rmse = 0.726488
Epoch 18
Loss = 4.1579e-01, PNorm = 43.6401, GNorm = 6.4579, lr_0 = 2.3606e-04
Validation rmse = 0.740041
Epoch 19
Loss = 2.8911e-01, PNorm = 43.6522, GNorm = 12.3705, lr_0 = 2.2449e-04
Loss = 3.9211e-01, PNorm = 43.6632, GNorm = 9.0577, lr_0 = 2.1446e-04
Validation rmse = 0.721530
Epoch 20
Loss = 4.5873e-01, PNorm = 43.6728, GNorm = 4.2415, lr_0 = 2.0488e-04
Loss = 3.7737e-01, PNorm = 43.6841, GNorm = 4.5506, lr_0 = 1.9573e-04
Validation rmse = 0.721700
Epoch 21
Loss = 4.0566e-01, PNorm = 43.6958, GNorm = 6.8500, lr_0 = 1.8614e-04
Loss = 4.0949e-01, PNorm = 43.7048, GNorm = 4.9278, lr_0 = 1.7783e-04
Validation rmse = 0.755498
Epoch 22
Loss = 4.3031e-01, PNorm = 43.7109, GNorm = 18.6004, lr_0 = 1.6911e-04
Loss = 3.8615e-01, PNorm = 43.7173, GNorm = 9.6528, lr_0 = 1.6156e-04
Validation rmse = 0.733021
Epoch 23
Loss = 4.3586e-01, PNorm = 43.7260, GNorm = 14.5340, lr_0 = 1.5434e-04
Loss = 3.6011e-01, PNorm = 43.7342, GNorm = 10.5484, lr_0 = 1.4745e-04
Validation rmse = 0.716225
Epoch 24
Loss = 3.6031e-01, PNorm = 43.7414, GNorm = 10.0502, lr_0 = 1.4022e-04
Loss = 3.6240e-01, PNorm = 43.7472, GNorm = 7.3754, lr_0 = 1.3396e-04
Validation rmse = 0.724320
Epoch 25
Loss = 3.3798e-01, PNorm = 43.7545, GNorm = 4.6758, lr_0 = 1.2798e-04
Validation rmse = 0.717409
Epoch 26
Loss = 3.3790e-01, PNorm = 43.7609, GNorm = 4.3088, lr_0 = 1.2171e-04
Loss = 2.9615e-01, PNorm = 43.7665, GNorm = 4.4120, lr_0 = 1.1627e-04
Validation rmse = 0.720639
Epoch 27
Loss = 3.3843e-01, PNorm = 43.7703, GNorm = 6.6599, lr_0 = 1.1057e-04
Loss = 3.3799e-01, PNorm = 43.7758, GNorm = 6.0202, lr_0 = 1.0564e-04
Validation rmse = 0.712851
Epoch 28
Loss = 3.4086e-01, PNorm = 43.7811, GNorm = 11.4371, lr_0 = 1.0092e-04
Loss = 2.9156e-01, PNorm = 43.7853, GNorm = 6.9678, lr_0 = 1.0000e-04
Validation rmse = 0.710738
Epoch 29
Loss = 3.7861e-01, PNorm = 43.7897, GNorm = 3.7840, lr_0 = 1.0000e-04
Loss = 3.2512e-01, PNorm = 43.7939, GNorm = 20.0804, lr_0 = 1.0000e-04
Validation rmse = 0.714127
Model 0 best validation rmse = 0.710738 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.629691
Ensemble test rmse = 0.629691
1-fold cross validation
	Seed 0 ==> test rmse = 0.629691
Overall test rmse = 0.629691 +/- 0.000000
Elapsed time = 0:01:34
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7259e+00, PNorm = 42.7374, GNorm = 0.9606, lr_0 = 3.6053e-04
Validation rmse = 1.421851
Epoch 1
Loss = 1.4197e+00, PNorm = 42.7354, GNorm = 2.6265, lr_0 = 6.2105e-04
Loss = 1.3561e+00, PNorm = 42.7448, GNorm = 0.7579, lr_0 = 8.5789e-04
Validation rmse = 1.266939
Epoch 2
Loss = 1.2871e+00, PNorm = 42.7726, GNorm = 6.0146, lr_0 = 9.7859e-04
Loss = 1.2197e+00, PNorm = 42.8092, GNorm = 0.8986, lr_0 = 9.3714e-04
Validation rmse = 1.106918
Epoch 3
Loss = 1.0443e+00, PNorm = 42.8681, GNorm = 3.4419, lr_0 = 8.9357e-04
Loss = 1.0798e+00, PNorm = 42.9257, GNorm = 10.1419, lr_0 = 8.5572e-04
Validation rmse = 0.956374
Epoch 4
Loss = 9.2360e-01, PNorm = 42.9806, GNorm = 1.4200, lr_0 = 8.1593e-04
Loss = 9.2171e-01, PNorm = 43.0364, GNorm = 5.9564, lr_0 = 7.8137e-04
Validation rmse = 0.940460
Epoch 5
Loss = 8.7985e-01, PNorm = 43.0906, GNorm = 7.4513, lr_0 = 7.4827e-04
Loss = 8.2273e-01, PNorm = 43.1299, GNorm = 2.1587, lr_0 = 7.1658e-04
Validation rmse = 0.873808
Epoch 6
Loss = 8.5364e-01, PNorm = 43.1742, GNorm = 4.1101, lr_0 = 6.8326e-04
Loss = 7.2633e-01, PNorm = 43.2162, GNorm = 5.2873, lr_0 = 6.5432e-04
Validation rmse = 0.802353
Epoch 7
Loss = 8.3753e-01, PNorm = 43.2554, GNorm = 4.6496, lr_0 = 6.2390e-04
Loss = 8.2404e-01, PNorm = 43.2926, GNorm = 12.0182, lr_0 = 5.9747e-04
Validation rmse = 0.742424
Epoch 8
Loss = 7.4231e-01, PNorm = 43.3266, GNorm = 3.2761, lr_0 = 5.6969e-04
Loss = 6.6573e-01, PNorm = 43.3602, GNorm = 12.1175, lr_0 = 5.4556e-04
Validation rmse = 0.697206
Epoch 9
Loss = 6.3921e-01, PNorm = 43.3814, GNorm = 5.1188, lr_0 = 5.2019e-04
Loss = 6.7997e-01, PNorm = 43.4010, GNorm = 12.9441, lr_0 = 4.9816e-04
Validation rmse = 0.668675
Epoch 10
Loss = 6.1720e-01, PNorm = 43.4317, GNorm = 2.6864, lr_0 = 4.7706e-04
Loss = 6.1963e-01, PNorm = 43.4557, GNorm = 4.2887, lr_0 = 4.5685e-04
Validation rmse = 0.662110
Epoch 11
Loss = 6.0553e-01, PNorm = 43.4851, GNorm = 5.6017, lr_0 = 4.3561e-04
Loss = 5.6043e-01, PNorm = 43.5025, GNorm = 3.3379, lr_0 = 4.1716e-04
Loss = 8.1745e-01, PNorm = 43.5037, GNorm = 13.1038, lr_0 = 4.1536e-04
Validation rmse = 0.697294
Epoch 12
Loss = 5.8562e-01, PNorm = 43.5195, GNorm = 8.0263, lr_0 = 3.9776e-04
Validation rmse = 0.650463
Epoch 13
Loss = 8.6489e-01, PNorm = 43.5366, GNorm = 13.6474, lr_0 = 3.7927e-04
Loss = 5.1192e-01, PNorm = 43.5572, GNorm = 3.6343, lr_0 = 3.6320e-04
Validation rmse = 0.678193
Epoch 14
Loss = 6.1850e-01, PNorm = 43.5738, GNorm = 22.3515, lr_0 = 3.4632e-04
Loss = 5.8932e-01, PNorm = 43.5889, GNorm = 6.9651, lr_0 = 3.3165e-04
Validation rmse = 0.670825
Epoch 15
Loss = 4.2586e-01, PNorm = 43.6044, GNorm = 3.9726, lr_0 = 3.1760e-04
Loss = 5.5081e-01, PNorm = 43.6192, GNorm = 13.1610, lr_0 = 3.0415e-04
Validation rmse = 0.659427
Epoch 16
Loss = 4.8749e-01, PNorm = 43.6328, GNorm = 10.3091, lr_0 = 2.9001e-04
Loss = 5.3099e-01, PNorm = 43.6449, GNorm = 9.5904, lr_0 = 2.7772e-04
Validation rmse = 0.646892
Epoch 17
Loss = 4.5669e-01, PNorm = 43.6597, GNorm = 7.5042, lr_0 = 2.6481e-04
Loss = 4.6607e-01, PNorm = 43.6706, GNorm = 3.6198, lr_0 = 2.5359e-04
Validation rmse = 0.648569
Epoch 18
Loss = 3.8865e-01, PNorm = 43.6830, GNorm = 4.3147, lr_0 = 2.4180e-04
Loss = 5.2983e-01, PNorm = 43.6929, GNorm = 10.6088, lr_0 = 2.3156e-04
Validation rmse = 0.683201
Epoch 19
Loss = 4.7950e-01, PNorm = 43.7036, GNorm = 2.1414, lr_0 = 2.2079e-04
Loss = 4.4222e-01, PNorm = 43.7132, GNorm = 10.1364, lr_0 = 2.1144e-04
Validation rmse = 0.655040
Epoch 20
Loss = 4.6959e-01, PNorm = 43.7241, GNorm = 18.3045, lr_0 = 2.0248e-04
Loss = 4.2310e-01, PNorm = 43.7335, GNorm = 4.4990, lr_0 = 1.9391e-04
Validation rmse = 0.654474
Epoch 21
Loss = 3.9431e-01, PNorm = 43.7391, GNorm = 13.8607, lr_0 = 1.8489e-04
Loss = 4.6197e-01, PNorm = 43.7470, GNorm = 3.2511, lr_0 = 1.7706e-04
Validation rmse = 0.641704
Epoch 22
Loss = 4.4471e-01, PNorm = 43.7572, GNorm = 3.5192, lr_0 = 1.6883e-04
Loss = 3.9449e-01, PNorm = 43.7656, GNorm = 8.9390, lr_0 = 1.6168e-04
Validation rmse = 0.651243
Epoch 23
Loss = 3.9033e-01, PNorm = 43.7750, GNorm = 8.5806, lr_0 = 1.5416e-04
Loss = 4.0924e-01, PNorm = 43.7817, GNorm = 3.1398, lr_0 = 1.4763e-04
Loss = 5.2378e-01, PNorm = 43.7821, GNorm = 20.1776, lr_0 = 1.4699e-04
Validation rmse = 0.642406
Epoch 24
Loss = 3.9739e-01, PNorm = 43.7874, GNorm = 5.9282, lr_0 = 1.4077e-04
Loss = 3.6074e-01, PNorm = 43.7934, GNorm = 12.3648, lr_0 = 1.3480e-04
Validation rmse = 0.688491
Epoch 25
Loss = 4.2004e-01, PNorm = 43.7992, GNorm = 4.8823, lr_0 = 1.2909e-04
Validation rmse = 0.648986
Epoch 26
Loss = 1.7139e-01, PNorm = 43.8044, GNorm = 2.9151, lr_0 = 1.2309e-04
Loss = 3.8652e-01, PNorm = 43.8099, GNorm = 8.2733, lr_0 = 1.1788e-04
Validation rmse = 0.650645
Epoch 27
Loss = 2.9732e-01, PNorm = 43.8147, GNorm = 5.6019, lr_0 = 1.1240e-04
Loss = 3.7204e-01, PNorm = 43.8199, GNorm = 5.1547, lr_0 = 1.0764e-04
Validation rmse = 0.667245
Epoch 28
Loss = 3.8498e-01, PNorm = 43.8253, GNorm = 13.2311, lr_0 = 1.0263e-04
Loss = 3.7216e-01, PNorm = 43.8300, GNorm = 5.2552, lr_0 = 1.0000e-04
Validation rmse = 0.644739
Epoch 29
Loss = 3.3156e-01, PNorm = 43.8342, GNorm = 11.2306, lr_0 = 1.0000e-04
Loss = 3.8501e-01, PNorm = 43.8386, GNorm = 5.9920, lr_0 = 1.0000e-04
Validation rmse = 0.642308
Model 0 best validation rmse = 0.641704 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.622895
Ensemble test rmse = 0.622895
1-fold cross validation
	Seed 0 ==> test rmse = 0.622895
Overall test rmse = 0.622895 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,250 | train size = 1,000 | val size = 125 | test size = 125
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7486e+00, PNorm = 42.7377, GNorm = 1.2272, lr_0 = 3.4750e-04
Loss = 1.4449e+00, PNorm = 42.7362, GNorm = 1.2792, lr_0 = 5.7250e-04
Validation rmse = 1.554851
Epoch 1
Loss = 1.3897e+00, PNorm = 42.7442, GNorm = 0.8028, lr_0 = 7.9750e-04
Loss = 1.2649e+00, PNorm = 42.7691, GNorm = 1.1231, lr_0 = 9.9590e-04
Validation rmse = 1.282186
Epoch 2
Loss = 1.2225e+00, PNorm = 42.8094, GNorm = 2.5899, lr_0 = 9.5578e-04
Loss = 1.1121e+00, PNorm = 42.8572, GNorm = 1.7531, lr_0 = 9.1728e-04
Validation rmse = 1.142360
Epoch 3
Loss = 1.0158e+00, PNorm = 42.9196, GNorm = 3.2958, lr_0 = 8.8032e-04
Loss = 1.0022e+00, PNorm = 42.9698, GNorm = 1.5696, lr_0 = 8.4486e-04
Validation rmse = 1.017881
Epoch 4
Loss = 9.1467e-01, PNorm = 43.0175, GNorm = 2.4535, lr_0 = 8.1083e-04
Loss = 9.7930e-01, PNorm = 43.0627, GNorm = 6.2409, lr_0 = 7.7816e-04
Validation rmse = 1.089048
Epoch 5
Loss = 9.9642e-01, PNorm = 43.1070, GNorm = 2.9731, lr_0 = 7.4682e-04
Loss = 9.0188e-01, PNorm = 43.1548, GNorm = 3.0378, lr_0 = 7.1673e-04
Validation rmse = 0.944956
Epoch 6
Loss = 8.2683e-01, PNorm = 43.1989, GNorm = 3.0023, lr_0 = 6.8786e-04
Loss = 7.6675e-01, PNorm = 43.2289, GNorm = 2.6679, lr_0 = 6.6015e-04
Validation rmse = 0.878121
Epoch 7
Loss = 7.0968e-01, PNorm = 43.2580, GNorm = 2.1291, lr_0 = 6.3356e-04
Loss = 7.0239e-01, PNorm = 43.2961, GNorm = 2.8540, lr_0 = 6.0803e-04
Validation rmse = 0.880810
Epoch 8
Loss = 6.5478e-01, PNorm = 43.3326, GNorm = 3.0180, lr_0 = 5.8354e-04
Loss = 7.4581e-01, PNorm = 43.3614, GNorm = 8.7367, lr_0 = 5.6003e-04
Validation rmse = 0.879858
Epoch 9
Loss = 6.5294e-01, PNorm = 43.3992, GNorm = 5.2003, lr_0 = 5.3747e-04
Loss = 6.1899e-01, PNorm = 43.4325, GNorm = 3.4993, lr_0 = 5.1582e-04
Validation rmse = 0.819785
Epoch 10
Loss = 5.3481e-01, PNorm = 43.4615, GNorm = 3.7250, lr_0 = 4.9504e-04
Loss = 6.6032e-01, PNorm = 43.4863, GNorm = 4.4185, lr_0 = 4.7510e-04
Validation rmse = 0.805977
Epoch 11
Loss = 5.8740e-01, PNorm = 43.5146, GNorm = 4.7609, lr_0 = 4.5596e-04
Loss = 5.5284e-01, PNorm = 43.5373, GNorm = 5.5230, lr_0 = 4.3759e-04
Validation rmse = 0.815138
Epoch 12
Loss = 5.0107e-01, PNorm = 43.5630, GNorm = 3.2759, lr_0 = 4.1997e-04
Loss = 6.0838e-01, PNorm = 43.5867, GNorm = 5.6590, lr_0 = 4.0305e-04
Validation rmse = 0.858322
Epoch 13
Loss = 5.0277e-01, PNorm = 43.6065, GNorm = 4.8499, lr_0 = 3.8681e-04
Loss = 5.1398e-01, PNorm = 43.6293, GNorm = 6.7325, lr_0 = 3.7123e-04
Validation rmse = 0.745200
Epoch 14
Loss = 4.8484e-01, PNorm = 43.6526, GNorm = 7.7963, lr_0 = 3.5628e-04
Loss = 5.5688e-01, PNorm = 43.6658, GNorm = 12.8907, lr_0 = 3.4192e-04
Validation rmse = 0.813881
Epoch 15
Loss = 5.2274e-01, PNorm = 43.6844, GNorm = 2.4344, lr_0 = 3.2815e-04
Loss = 5.3133e-01, PNorm = 43.7046, GNorm = 6.9722, lr_0 = 3.1493e-04
Validation rmse = 0.778336
Epoch 16
Loss = 4.3401e-01, PNorm = 43.7235, GNorm = 3.4602, lr_0 = 3.0224e-04
Loss = 4.7512e-01, PNorm = 43.7363, GNorm = 5.4467, lr_0 = 2.9007e-04
Validation rmse = 0.771437
Epoch 17
Loss = 3.7386e-01, PNorm = 43.7541, GNorm = 6.5241, lr_0 = 2.7838e-04
Loss = 4.7235e-01, PNorm = 43.7675, GNorm = 5.4245, lr_0 = 2.6717e-04
Validation rmse = 0.773833
Epoch 18
Loss = 4.3842e-01, PNorm = 43.7805, GNorm = 12.0056, lr_0 = 2.5641e-04
Loss = 4.9162e-01, PNorm = 43.7948, GNorm = 7.2723, lr_0 = 2.4608e-04
Validation rmse = 0.777671
Epoch 19
Loss = 4.4513e-01, PNorm = 43.8076, GNorm = 7.4737, lr_0 = 2.3616e-04
Loss = 3.9013e-01, PNorm = 43.8212, GNorm = 4.7429, lr_0 = 2.2665e-04
Validation rmse = 0.773270
Epoch 20
Loss = 3.4910e-01, PNorm = 43.8325, GNorm = 10.4351, lr_0 = 2.1752e-04
Loss = 4.4789e-01, PNorm = 43.8423, GNorm = 5.5454, lr_0 = 2.0876e-04
Validation rmse = 0.749343
Epoch 21
Loss = 3.8137e-01, PNorm = 43.8530, GNorm = 4.4191, lr_0 = 2.0035e-04
Loss = 3.7416e-01, PNorm = 43.8642, GNorm = 5.3821, lr_0 = 1.9228e-04
Validation rmse = 0.757158
Epoch 22
Loss = 3.7281e-01, PNorm = 43.8739, GNorm = 19.7563, lr_0 = 1.8453e-04
Loss = 3.9160e-01, PNorm = 43.8830, GNorm = 6.9586, lr_0 = 1.7710e-04
Validation rmse = 0.739320
Epoch 23
Loss = 3.9280e-01, PNorm = 43.8938, GNorm = 8.1922, lr_0 = 1.6996e-04
Loss = 3.9431e-01, PNorm = 43.9022, GNorm = 3.3905, lr_0 = 1.6312e-04
Validation rmse = 0.741943
Epoch 24
Loss = 3.6170e-01, PNorm = 43.9106, GNorm = 5.7026, lr_0 = 1.5655e-04
Loss = 3.2655e-01, PNorm = 43.9185, GNorm = 11.6814, lr_0 = 1.5024e-04
Validation rmse = 0.751788
Epoch 25
Loss = 3.3233e-01, PNorm = 43.9268, GNorm = 2.6970, lr_0 = 1.4419e-04
Loss = 3.6871e-01, PNorm = 43.9328, GNorm = 6.4619, lr_0 = 1.3838e-04
Validation rmse = 0.767899
Epoch 26
Loss = 3.3278e-01, PNorm = 43.9386, GNorm = 4.8253, lr_0 = 1.3280e-04
Loss = 3.4504e-01, PNorm = 43.9459, GNorm = 4.6726, lr_0 = 1.2746e-04
Validation rmse = 0.749072
Epoch 27
Loss = 3.4144e-01, PNorm = 43.9527, GNorm = 3.9055, lr_0 = 1.2232e-04
Loss = 3.2853e-01, PNorm = 43.9590, GNorm = 9.9054, lr_0 = 1.1739e-04
Validation rmse = 0.757180
Epoch 28
Loss = 3.7507e-01, PNorm = 43.9626, GNorm = 7.3935, lr_0 = 1.1266e-04
Loss = 3.1675e-01, PNorm = 43.9681, GNorm = 6.0475, lr_0 = 1.0813e-04
Validation rmse = 0.739540
Epoch 29
Loss = 3.2578e-01, PNorm = 43.9741, GNorm = 5.2187, lr_0 = 1.0377e-04
Loss = 3.2006e-01, PNorm = 43.9792, GNorm = 8.1989, lr_0 = 1.0000e-04
Validation rmse = 0.742060
Model 0 best validation rmse = 0.739320 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.624409
Ensemble test rmse = 0.624409
1-fold cross validation
	Seed 0 ==> test rmse = 0.624409
Overall test rmse = 0.624409 +/- 0.000000
Elapsed time = 0:01:41
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7383e+00, PNorm = 42.7386, GNorm = 2.6524, lr_0 = 3.4750e-04
Loss = 1.4389e+00, PNorm = 42.7354, GNorm = 1.7560, lr_0 = 5.7250e-04
Loss = 1.4388e+00, PNorm = 42.7355, GNorm = 2.0588, lr_0 = 5.9500e-04
Validation rmse = 1.434317
Epoch 1
Loss = 1.3625e+00, PNorm = 42.7449, GNorm = 2.7562, lr_0 = 8.2000e-04
Loss = 1.2550e+00, PNorm = 42.7673, GNorm = 2.2906, lr_0 = 9.9181e-04
Validation rmse = 1.217095
Epoch 2
Loss = 1.1838e+00, PNorm = 42.8131, GNorm = 1.5986, lr_0 = 9.5186e-04
Loss = 1.0977e+00, PNorm = 42.8674, GNorm = 2.9839, lr_0 = 9.1351e-04
Validation rmse = 1.005598
Epoch 3
Loss = 1.0668e+00, PNorm = 42.9267, GNorm = 8.1689, lr_0 = 8.7671e-04
Loss = 1.0219e+00, PNorm = 42.9737, GNorm = 3.2100, lr_0 = 8.4140e-04
Validation rmse = 0.962645
Epoch 4
Loss = 8.9881e-01, PNorm = 43.0233, GNorm = 7.4046, lr_0 = 8.0750e-04
Loss = 8.6796e-01, PNorm = 43.0733, GNorm = 5.9491, lr_0 = 7.7497e-04
Validation rmse = 0.901608
Epoch 5
Loss = 7.6664e-01, PNorm = 43.1161, GNorm = 6.0180, lr_0 = 7.4375e-04
Loss = 8.1444e-01, PNorm = 43.1539, GNorm = 6.1752, lr_0 = 7.1379e-04
Validation rmse = 0.826392
Epoch 6
Loss = 7.6955e-01, PNorm = 43.1998, GNorm = 1.7671, lr_0 = 6.8223e-04
Loss = 6.4824e-01, PNorm = 43.2513, GNorm = 3.2768, lr_0 = 6.5474e-04
Validation rmse = 0.764888
Epoch 7
Loss = 6.9999e-01, PNorm = 43.2806, GNorm = 8.9041, lr_0 = 6.2837e-04
Loss = 6.3339e-01, PNorm = 43.3182, GNorm = 4.1556, lr_0 = 6.0306e-04
Validation rmse = 0.787046
Epoch 8
Loss = 6.4295e-01, PNorm = 43.3538, GNorm = 7.0097, lr_0 = 5.7876e-04
Loss = 6.0325e-01, PNorm = 43.3868, GNorm = 2.3609, lr_0 = 5.5545e-04
Validation rmse = 0.742110
Epoch 9
Loss = 6.2869e-01, PNorm = 43.4127, GNorm = 4.1749, lr_0 = 5.3307e-04
Loss = 5.9828e-01, PNorm = 43.4387, GNorm = 3.9882, lr_0 = 5.1160e-04
Validation rmse = 0.719806
Epoch 10
Loss = 5.2613e-01, PNorm = 43.4625, GNorm = 2.9013, lr_0 = 4.9099e-04
Loss = 5.7163e-01, PNorm = 43.4857, GNorm = 8.8497, lr_0 = 4.7121e-04
Validation rmse = 0.696272
Epoch 11
Loss = 3.9413e-01, PNorm = 43.5123, GNorm = 2.4253, lr_0 = 4.5037e-04
Loss = 4.8201e-01, PNorm = 43.5363, GNorm = 5.7874, lr_0 = 4.3223e-04
Validation rmse = 0.687587
Epoch 12
Loss = 4.7393e-01, PNorm = 43.5551, GNorm = 3.0438, lr_0 = 4.1482e-04
Loss = 5.0441e-01, PNorm = 43.5753, GNorm = 13.7672, lr_0 = 3.9811e-04
Loss = 5.8383e-01, PNorm = 43.5918, GNorm = 4.6406, lr_0 = 3.8207e-04
Validation rmse = 0.738825
Epoch 13
Loss = 5.4951e-01, PNorm = 43.6091, GNorm = 10.7274, lr_0 = 3.6668e-04
Loss = 4.9101e-01, PNorm = 43.6275, GNorm = 4.5426, lr_0 = 3.5191e-04
Validation rmse = 0.756384
Epoch 14
Loss = 4.7374e-01, PNorm = 43.6406, GNorm = 8.0797, lr_0 = 3.3773e-04
Loss = 5.1324e-01, PNorm = 43.6519, GNorm = 10.1559, lr_0 = 3.2413e-04
Validation rmse = 0.678217
Epoch 15
Loss = 4.7279e-01, PNorm = 43.6667, GNorm = 3.6174, lr_0 = 3.1107e-04
Loss = 4.0998e-01, PNorm = 43.6813, GNorm = 4.1938, lr_0 = 2.9854e-04
Validation rmse = 0.682741
Epoch 16
Loss = 3.3298e-01, PNorm = 43.6948, GNorm = 4.0678, lr_0 = 2.8534e-04
Loss = 4.8565e-01, PNorm = 43.7083, GNorm = 2.3444, lr_0 = 2.7384e-04
Validation rmse = 0.706366
Epoch 17
Loss = 3.9127e-01, PNorm = 43.7204, GNorm = 2.9667, lr_0 = 2.6281e-04
Loss = 4.1071e-01, PNorm = 43.7351, GNorm = 11.1321, lr_0 = 2.5222e-04
Validation rmse = 0.683251
Epoch 18
Loss = 3.3739e-01, PNorm = 43.7431, GNorm = 2.2929, lr_0 = 2.4206e-04
Loss = 4.3610e-01, PNorm = 43.7558, GNorm = 6.7013, lr_0 = 2.3231e-04
Validation rmse = 0.707380
Epoch 19
Loss = 3.7239e-01, PNorm = 43.7638, GNorm = 15.7287, lr_0 = 2.2295e-04
Loss = 3.8896e-01, PNorm = 43.7738, GNorm = 10.2879, lr_0 = 2.1397e-04
Validation rmse = 0.670966
Epoch 20
Loss = 3.3298e-01, PNorm = 43.7830, GNorm = 3.6533, lr_0 = 2.0535e-04
Loss = 3.9201e-01, PNorm = 43.7924, GNorm = 16.1569, lr_0 = 1.9708e-04
Validation rmse = 0.675209
Epoch 21
Loss = 4.3379e-01, PNorm = 43.7996, GNorm = 11.4636, lr_0 = 1.8836e-04
Loss = 4.2866e-01, PNorm = 43.8058, GNorm = 11.6569, lr_0 = 1.8078e-04
Validation rmse = 0.669512
Epoch 22
Loss = 3.7765e-01, PNorm = 43.8141, GNorm = 7.1222, lr_0 = 1.7349e-04
Loss = 3.8337e-01, PNorm = 43.8233, GNorm = 3.0347, lr_0 = 1.6651e-04
Validation rmse = 0.670421
Epoch 23
Loss = 3.7048e-01, PNorm = 43.8316, GNorm = 2.6300, lr_0 = 1.5980e-04
Loss = 3.3439e-01, PNorm = 43.8375, GNorm = 3.8320, lr_0 = 1.5336e-04
Validation rmse = 0.669296
Epoch 24
Loss = 4.6849e-01, PNorm = 43.8438, GNorm = 5.6806, lr_0 = 1.4718e-04
Loss = 3.5217e-01, PNorm = 43.8522, GNorm = 3.3360, lr_0 = 1.4125e-04
Loss = 2.8490e-01, PNorm = 43.8573, GNorm = 12.1529, lr_0 = 1.3556e-04
Validation rmse = 0.662549
Epoch 25
Loss = 3.8812e-01, PNorm = 43.8623, GNorm = 7.9898, lr_0 = 1.3010e-04
Loss = 2.6735e-01, PNorm = 43.8687, GNorm = 7.1147, lr_0 = 1.2486e-04
Loss = 3.0156e-01, PNorm = 43.8692, GNorm = 11.2326, lr_0 = 1.2435e-04
Validation rmse = 0.747364
Epoch 26
Loss = 3.7535e-01, PNorm = 43.8743, GNorm = 5.3244, lr_0 = 1.1934e-04
Loss = 3.1864e-01, PNorm = 43.8792, GNorm = 6.6859, lr_0 = 1.1453e-04
Validation rmse = 0.678634
Epoch 27
Loss = 4.1431e-01, PNorm = 43.8828, GNorm = 9.8094, lr_0 = 1.0992e-04
Loss = 2.9635e-01, PNorm = 43.8872, GNorm = 3.3708, lr_0 = 1.0549e-04
Validation rmse = 0.678516
Epoch 28
Loss = 3.9118e-01, PNorm = 43.8921, GNorm = 5.5550, lr_0 = 1.0124e-04
Loss = 2.3416e-01, PNorm = 43.8968, GNorm = 6.2568, lr_0 = 1.0000e-04
Validation rmse = 0.661796
Epoch 29
Loss = 2.3741e-01, PNorm = 43.9015, GNorm = 14.2581, lr_0 = 1.0000e-04
Loss = 3.2907e-01, PNorm = 43.9058, GNorm = 4.2154, lr_0 = 1.0000e-04
Validation rmse = 0.659276
Model 0 best validation rmse = 0.659276 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.595760
Ensemble test rmse = 0.595760
1-fold cross validation
	Seed 0 ==> test rmse = 0.595760
Overall test rmse = 0.595760 +/- 0.000000
Elapsed time = 0:01:45
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,350 | train size = 1,080 | val size = 135 | test size = 135
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7881e+00, PNorm = 42.7384, GNorm = 1.4083, lr_0 = 3.3571e-04
Loss = 1.4276e+00, PNorm = 42.7356, GNorm = 1.3933, lr_0 = 5.5000e-04
Validation rmse = 1.502227
Epoch 1
Loss = 1.3433e+00, PNorm = 42.7450, GNorm = 1.6530, lr_0 = 7.8571e-04
Loss = 1.2634e+00, PNorm = 42.7682, GNorm = 2.6848, lr_0 = 1.0000e-03
Validation rmse = 1.265786
Epoch 2
Loss = 1.1672e+00, PNorm = 42.8087, GNorm = 3.4550, lr_0 = 9.6160e-04
Loss = 1.1112e+00, PNorm = 42.8637, GNorm = 1.0138, lr_0 = 9.2467e-04
Validation rmse = 1.072971
Epoch 3
Loss = 9.6760e-01, PNorm = 42.9252, GNorm = 1.6458, lr_0 = 8.8568e-04
Loss = 9.2472e-01, PNorm = 42.9797, GNorm = 3.9015, lr_0 = 8.5167e-04
Validation rmse = 1.044484
Epoch 4
Loss = 1.0074e+00, PNorm = 43.0274, GNorm = 9.9522, lr_0 = 8.1896e-04
Loss = 9.1319e-01, PNorm = 43.0764, GNorm = 1.7535, lr_0 = 7.8751e-04
Validation rmse = 0.948903
Epoch 5
Loss = 9.8438e-01, PNorm = 43.1245, GNorm = 5.5737, lr_0 = 7.5727e-04
Loss = 7.5735e-01, PNorm = 43.1724, GNorm = 2.0068, lr_0 = 7.2819e-04
Validation rmse = 0.885261
Epoch 6
Loss = 5.8988e-01, PNorm = 43.2117, GNorm = 2.6729, lr_0 = 6.9749e-04
Loss = 7.2104e-01, PNorm = 43.2516, GNorm = 6.3389, lr_0 = 6.7070e-04
Loss = 7.2578e-01, PNorm = 43.2906, GNorm = 5.9151, lr_0 = 6.4495e-04
Validation rmse = 0.786568
Epoch 7
Loss = 6.3026e-01, PNorm = 43.3291, GNorm = 4.4047, lr_0 = 6.2018e-04
Loss = 6.4801e-01, PNorm = 43.3653, GNorm = 3.5190, lr_0 = 5.9636e-04
Validation rmse = 0.853405
Epoch 8
Loss = 6.3519e-01, PNorm = 43.3936, GNorm = 5.5891, lr_0 = 5.7122e-04
Loss = 6.0879e-01, PNorm = 43.4224, GNorm = 10.3558, lr_0 = 5.4928e-04
Validation rmse = 0.811960
Epoch 9
Loss = 5.7867e-01, PNorm = 43.4586, GNorm = 18.5883, lr_0 = 5.2819e-04
Loss = 5.6803e-01, PNorm = 43.4842, GNorm = 9.0853, lr_0 = 5.0790e-04
Validation rmse = 0.771698
Epoch 10
Loss = 4.5899e-01, PNorm = 43.5071, GNorm = 2.8448, lr_0 = 4.8840e-04
Loss = 5.4219e-01, PNorm = 43.5357, GNorm = 4.1119, lr_0 = 4.6964e-04
Validation rmse = 0.762364
Epoch 11
Loss = 3.9364e-01, PNorm = 43.5613, GNorm = 3.0314, lr_0 = 4.4984e-04
Loss = 5.0822e-01, PNorm = 43.5846, GNorm = 7.1227, lr_0 = 4.3257e-04
Validation rmse = 0.770056
Epoch 12
Loss = 4.1756e-01, PNorm = 43.6029, GNorm = 6.0160, lr_0 = 4.1596e-04
Loss = 4.9180e-01, PNorm = 43.6219, GNorm = 12.9549, lr_0 = 3.9998e-04
Loss = 5.7139e-01, PNorm = 43.6406, GNorm = 12.3910, lr_0 = 3.8462e-04
Loss = 5.6892e-01, PNorm = 43.6422, GNorm = 5.9700, lr_0 = 3.8312e-04
Validation rmse = 0.769317
Epoch 13
Loss = 4.4544e-01, PNorm = 43.6610, GNorm = 3.2633, lr_0 = 3.6841e-04
Loss = 4.6920e-01, PNorm = 43.6817, GNorm = 17.5959, lr_0 = 3.5426e-04
Validation rmse = 0.728145
Epoch 14
Loss = 3.9078e-01, PNorm = 43.6947, GNorm = 4.8689, lr_0 = 3.4065e-04
Loss = 5.3249e-01, PNorm = 43.7064, GNorm = 2.8111, lr_0 = 3.2757e-04
Validation rmse = 0.726122
Epoch 15
Loss = 4.2277e-01, PNorm = 43.7216, GNorm = 8.7150, lr_0 = 3.1499e-04
Loss = 4.1500e-01, PNorm = 43.7397, GNorm = 6.4725, lr_0 = 3.0290e-04
Validation rmse = 0.743945
Epoch 16
Loss = 3.5193e-01, PNorm = 43.7550, GNorm = 2.6378, lr_0 = 2.9012e-04
Loss = 4.3626e-01, PNorm = 43.7705, GNorm = 10.6792, lr_0 = 2.7898e-04
Validation rmse = 0.727687
Epoch 17
Loss = 3.4321e-01, PNorm = 43.7814, GNorm = 2.5521, lr_0 = 2.6827e-04
Loss = 3.3123e-01, PNorm = 43.7960, GNorm = 4.3938, lr_0 = 2.5797e-04
Validation rmse = 0.710364
Epoch 18
Loss = 3.9396e-01, PNorm = 43.8048, GNorm = 6.9713, lr_0 = 2.4709e-04
Loss = 3.9961e-01, PNorm = 43.8143, GNorm = 3.0485, lr_0 = 2.3760e-04
Loss = 4.0099e-01, PNorm = 43.8264, GNorm = 6.0105, lr_0 = 2.2848e-04
Validation rmse = 0.734580
Epoch 19
Loss = 3.8900e-01, PNorm = 43.8355, GNorm = 8.0220, lr_0 = 2.1970e-04
Loss = 3.4835e-01, PNorm = 43.8458, GNorm = 6.1982, lr_0 = 2.1127e-04
Validation rmse = 0.717790
Epoch 20
Loss = 3.2280e-01, PNorm = 43.8567, GNorm = 8.1153, lr_0 = 2.0315e-04
Loss = 3.1450e-01, PNorm = 43.8676, GNorm = 7.2489, lr_0 = 1.9535e-04
Validation rmse = 0.706942
Epoch 21
Loss = 3.0092e-01, PNorm = 43.8766, GNorm = 9.9750, lr_0 = 1.8712e-04
Loss = 3.4445e-01, PNorm = 43.8826, GNorm = 3.5622, lr_0 = 1.7993e-04
Validation rmse = 0.750640
Epoch 22
Loss = 2.6567e-01, PNorm = 43.8925, GNorm = 12.8413, lr_0 = 1.7302e-04
Loss = 3.7689e-01, PNorm = 43.8987, GNorm = 10.9866, lr_0 = 1.6638e-04
Validation rmse = 0.728393
Epoch 23
Loss = 3.3627e-01, PNorm = 43.9047, GNorm = 5.0819, lr_0 = 1.5936e-04
Loss = 3.0373e-01, PNorm = 43.9127, GNorm = 10.0517, lr_0 = 1.5324e-04
Validation rmse = 0.702192
Epoch 24
Loss = 2.1725e-01, PNorm = 43.9185, GNorm = 3.9290, lr_0 = 1.4736e-04
Loss = 3.2408e-01, PNorm = 43.9254, GNorm = 4.0248, lr_0 = 1.4170e-04
Loss = 2.9752e-01, PNorm = 43.9324, GNorm = 6.6210, lr_0 = 1.3626e-04
Validation rmse = 0.714856
Epoch 25
Loss = 3.1419e-01, PNorm = 43.9398, GNorm = 10.6575, lr_0 = 1.3102e-04
Loss = 2.8873e-01, PNorm = 43.9440, GNorm = 9.2507, lr_0 = 1.2599e-04
Validation rmse = 0.701650
Epoch 26
Loss = 2.6357e-01, PNorm = 43.9495, GNorm = 4.4466, lr_0 = 1.2068e-04
Loss = 2.8857e-01, PNorm = 43.9552, GNorm = 9.7908, lr_0 = 1.1604e-04
Validation rmse = 0.724358
Epoch 27
Loss = 2.2704e-01, PNorm = 43.9599, GNorm = 3.7374, lr_0 = 1.1159e-04
Loss = 3.2169e-01, PNorm = 43.9649, GNorm = 3.4940, lr_0 = 1.0730e-04
Validation rmse = 0.711253
Epoch 28
Loss = 2.3161e-01, PNorm = 43.9701, GNorm = 10.3778, lr_0 = 1.0278e-04
Loss = 3.4350e-01, PNorm = 43.9748, GNorm = 12.4350, lr_0 = 1.0000e-04
Validation rmse = 0.704703
Epoch 29
Loss = 2.6239e-01, PNorm = 43.9774, GNorm = 6.0834, lr_0 = 1.0000e-04
Loss = 2.9154e-01, PNorm = 43.9815, GNorm = 5.0548, lr_0 = 1.0000e-04
Validation rmse = 0.701227
Model 0 best validation rmse = 0.701227 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.577363
Ensemble test rmse = 0.577363
1-fold cross validation
	Seed 0 ==> test rmse = 0.577363
Overall test rmse = 0.577363 +/- 0.000000
Elapsed time = 0:01:49
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8278e+00, PNorm = 42.7371, GNorm = 1.6891, lr_0 = 3.2500e-04
Loss = 1.4415e+00, PNorm = 42.7334, GNorm = 1.2390, lr_0 = 5.2955e-04
Validation rmse = 1.599686
Epoch 1
Loss = 1.4043e+00, PNorm = 42.7392, GNorm = 0.8295, lr_0 = 7.5455e-04
Loss = 1.2633e+00, PNorm = 42.7597, GNorm = 1.3289, lr_0 = 9.5909e-04
Validation rmse = 1.292718
Epoch 2
Loss = 1.1763e+00, PNorm = 42.8004, GNorm = 0.8452, lr_0 = 9.6692e-04
Loss = 1.0995e+00, PNorm = 42.8576, GNorm = 1.5994, lr_0 = 9.3144e-04
Validation rmse = 1.198287
Epoch 3
Loss = 9.6046e-01, PNorm = 42.9180, GNorm = 2.9533, lr_0 = 8.9727e-04
Loss = 9.9161e-01, PNorm = 42.9717, GNorm = 4.6118, lr_0 = 8.6435e-04
Validation rmse = 1.020228
Epoch 4
Loss = 9.0656e-01, PNorm = 43.0303, GNorm = 1.7969, lr_0 = 8.2953e-04
Loss = 8.8546e-01, PNorm = 43.0837, GNorm = 8.0587, lr_0 = 7.9909e-04
Loss = 8.6678e-01, PNorm = 43.1309, GNorm = 1.5692, lr_0 = 7.6977e-04
Validation rmse = 0.993201
Epoch 5
Loss = 8.1938e-01, PNorm = 43.1702, GNorm = 4.4729, lr_0 = 7.4153e-04
Loss = 7.7861e-01, PNorm = 43.2221, GNorm = 3.6959, lr_0 = 7.1433e-04
Validation rmse = 0.782317
Epoch 6
Loss = 7.7335e-01, PNorm = 43.2706, GNorm = 7.4397, lr_0 = 6.8555e-04
Loss = 7.1962e-01, PNorm = 43.3181, GNorm = 3.3718, lr_0 = 6.6040e-04
Validation rmse = 0.775611
Epoch 7
Loss = 6.9276e-01, PNorm = 43.3556, GNorm = 2.5853, lr_0 = 6.3379e-04
Loss = 6.1433e-01, PNorm = 43.3968, GNorm = 3.1381, lr_0 = 6.1054e-04
Validation rmse = 0.724472
Epoch 8
Loss = 6.9028e-01, PNorm = 43.4271, GNorm = 2.0972, lr_0 = 5.8814e-04
Loss = 5.6467e-01, PNorm = 43.4633, GNorm = 4.8119, lr_0 = 5.6656e-04
Loss = 6.5037e-01, PNorm = 43.4890, GNorm = 6.8747, lr_0 = 5.4577e-04
Validation rmse = 0.702617
Epoch 9
Loss = 5.7958e-01, PNorm = 43.5252, GNorm = 8.7768, lr_0 = 5.2379e-04
Loss = 5.5220e-01, PNorm = 43.5514, GNorm = 5.3866, lr_0 = 5.0457e-04
Validation rmse = 0.690890
Epoch 10
Loss = 5.6515e-01, PNorm = 43.5723, GNorm = 21.0829, lr_0 = 4.8606e-04
Loss = 5.2953e-01, PNorm = 43.5997, GNorm = 4.6979, lr_0 = 4.6822e-04
Validation rmse = 0.705267
Epoch 11
Loss = 4.7604e-01, PNorm = 43.6294, GNorm = 3.8384, lr_0 = 4.4936e-04
Loss = 5.1712e-01, PNorm = 43.6484, GNorm = 12.8272, lr_0 = 4.3288e-04
Validation rmse = 0.756226
Epoch 12
Loss = 4.7117e-01, PNorm = 43.6660, GNorm = 2.6777, lr_0 = 4.1544e-04
Loss = 4.4253e-01, PNorm = 43.6860, GNorm = 2.7738, lr_0 = 4.0020e-04
Loss = 4.8812e-01, PNorm = 43.7044, GNorm = 3.7206, lr_0 = 3.8551e-04
Validation rmse = 0.680848
Epoch 13
Loss = 4.6921e-01, PNorm = 43.7208, GNorm = 8.3314, lr_0 = 3.7137e-04
Loss = 4.4928e-01, PNorm = 43.7343, GNorm = 3.2790, lr_0 = 3.5774e-04
Validation rmse = 0.746128
Epoch 14
Loss = 4.9216e-01, PNorm = 43.7504, GNorm = 2.5519, lr_0 = 3.4333e-04
Loss = 4.0907e-01, PNorm = 43.7652, GNorm = 10.6082, lr_0 = 3.3074e-04
Validation rmse = 0.712034
Epoch 15
Loss = 4.3479e-01, PNorm = 43.7773, GNorm = 6.5617, lr_0 = 3.1860e-04
Loss = 4.6823e-01, PNorm = 43.7918, GNorm = 5.0033, lr_0 = 3.0691e-04
Validation rmse = 0.660840
Epoch 16
Loss = 4.2764e-01, PNorm = 43.8062, GNorm = 4.7012, lr_0 = 2.9455e-04
Loss = 3.4831e-01, PNorm = 43.8216, GNorm = 9.0007, lr_0 = 2.8374e-04
Loss = 4.1757e-01, PNorm = 43.8306, GNorm = 11.2801, lr_0 = 2.7333e-04
Loss = 4.9415e-01, PNorm = 43.8311, GNorm = 8.9859, lr_0 = 2.7231e-04
Validation rmse = 0.656455
Epoch 17
Loss = 3.8039e-01, PNorm = 43.8416, GNorm = 3.6044, lr_0 = 2.6232e-04
Loss = 3.7880e-01, PNorm = 43.8554, GNorm = 9.8173, lr_0 = 2.5270e-04
Validation rmse = 0.641618
Epoch 18
Loss = 3.5848e-01, PNorm = 43.8622, GNorm = 2.5304, lr_0 = 2.4342e-04
Loss = 3.9842e-01, PNorm = 43.8734, GNorm = 8.0841, lr_0 = 2.3449e-04
Validation rmse = 0.673114
Epoch 19
Loss = 2.8280e-01, PNorm = 43.8858, GNorm = 3.1717, lr_0 = 2.2505e-04
Loss = 3.5587e-01, PNorm = 43.8973, GNorm = 4.9303, lr_0 = 2.1679e-04
Validation rmse = 0.654120
Epoch 20
Loss = 1.9162e-01, PNorm = 43.9023, GNorm = 8.7210, lr_0 = 2.0884e-04
Loss = 3.1412e-01, PNorm = 43.9139, GNorm = 3.5933, lr_0 = 2.0117e-04
Loss = 4.4836e-01, PNorm = 43.9216, GNorm = 11.3126, lr_0 = 1.9379e-04
Loss = 2.1842e-01, PNorm = 43.9220, GNorm = 11.7133, lr_0 = 1.9307e-04
Validation rmse = 0.642554
Epoch 21
Loss = 3.2912e-01, PNorm = 43.9294, GNorm = 4.3047, lr_0 = 1.8599e-04
Loss = 3.5062e-01, PNorm = 43.9391, GNorm = 4.7641, lr_0 = 1.7916e-04
Validation rmse = 0.655930
Epoch 22
Loss = 3.1320e-01, PNorm = 43.9489, GNorm = 5.2649, lr_0 = 1.7195e-04
Loss = 3.3050e-01, PNorm = 43.9563, GNorm = 3.9975, lr_0 = 1.6564e-04
Validation rmse = 0.660103
Epoch 23
Loss = 4.0762e-01, PNorm = 43.9603, GNorm = 19.3476, lr_0 = 1.5956e-04
Loss = 3.2911e-01, PNorm = 43.9654, GNorm = 6.0718, lr_0 = 1.5371e-04
Validation rmse = 0.659779
Epoch 24
Loss = 3.0239e-01, PNorm = 43.9713, GNorm = 10.7963, lr_0 = 1.4751e-04
Loss = 3.2496e-01, PNorm = 43.9778, GNorm = 3.7887, lr_0 = 1.4210e-04
Loss = 2.9386e-01, PNorm = 43.9844, GNorm = 4.2360, lr_0 = 1.3689e-04
Validation rmse = 0.641489
Epoch 25
Loss = 3.5240e-01, PNorm = 43.9908, GNorm = 4.6325, lr_0 = 1.3187e-04
Loss = 2.7960e-01, PNorm = 43.9962, GNorm = 4.0191, lr_0 = 1.2703e-04
Validation rmse = 0.653368
Epoch 26
Loss = 2.6654e-01, PNorm = 44.0027, GNorm = 5.7757, lr_0 = 1.2191e-04
Loss = 3.6032e-01, PNorm = 44.0075, GNorm = 5.0372, lr_0 = 1.1744e-04
Validation rmse = 0.644987
Epoch 27
Loss = 3.1897e-01, PNorm = 44.0104, GNorm = 10.8465, lr_0 = 1.1271e-04
Loss = 3.4544e-01, PNorm = 44.0143, GNorm = 3.5223, lr_0 = 1.0857e-04
Validation rmse = 0.644755
Epoch 28
Loss = 2.0831e-01, PNorm = 44.0193, GNorm = 11.4995, lr_0 = 1.0459e-04
Loss = 2.9806e-01, PNorm = 44.0236, GNorm = 9.2060, lr_0 = 1.0075e-04
Validation rmse = 0.661606
Epoch 29
Loss = 3.4307e-01, PNorm = 44.0287, GNorm = 4.6317, lr_0 = 1.0000e-04
Loss = 3.4623e-01, PNorm = 44.0331, GNorm = 5.8800, lr_0 = 1.0000e-04
Loss = 2.4055e-01, PNorm = 44.0369, GNorm = 5.0995, lr_0 = 1.0000e-04
Validation rmse = 0.637079
Model 0 best validation rmse = 0.637079 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.634853
Ensemble test rmse = 0.634853
1-fold cross validation
	Seed 0 ==> test rmse = 0.634853
Overall test rmse = 0.634853 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,450 | train size = 1,160 | val size = 145 | test size = 145
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8297e+00, PNorm = 42.7385, GNorm = 3.3435, lr_0 = 3.1522e-04
Loss = 1.4187e+00, PNorm = 42.7350, GNorm = 1.7549, lr_0 = 5.1087e-04
Validation rmse = 1.502711
Epoch 1
Loss = 1.3545e+00, PNorm = 42.7404, GNorm = 0.7602, lr_0 = 7.2609e-04
Loss = 1.2866e+00, PNorm = 42.7578, GNorm = 0.9517, lr_0 = 9.2174e-04
Validation rmse = 1.246781
Epoch 2
Loss = 1.1395e+00, PNorm = 42.7958, GNorm = 2.7031, lr_0 = 9.7528e-04
Loss = 1.0695e+00, PNorm = 42.8489, GNorm = 1.3928, lr_0 = 9.4103e-04
Validation rmse = 1.097328
Epoch 3
Loss = 1.0605e+00, PNorm = 42.9056, GNorm = 3.2120, lr_0 = 9.0474e-04
Loss = 9.9057e-01, PNorm = 42.9639, GNorm = 1.3398, lr_0 = 8.7296e-04
Loss = 9.2108e-01, PNorm = 43.0231, GNorm = 19.6671, lr_0 = 8.4230e-04
Validation rmse = 0.922681
Epoch 4
Loss = 9.1078e-01, PNorm = 43.0645, GNorm = 2.0893, lr_0 = 8.0981e-04
Loss = 8.5782e-01, PNorm = 43.1130, GNorm = 5.2884, lr_0 = 7.8137e-04
Validation rmse = 0.898743
Epoch 5
Loss = 7.6511e-01, PNorm = 43.1591, GNorm = 5.0746, lr_0 = 7.5393e-04
Loss = 7.7003e-01, PNorm = 43.2012, GNorm = 8.4599, lr_0 = 7.2745e-04
Validation rmse = 0.874058
Epoch 6
Loss = 6.6923e-01, PNorm = 43.2393, GNorm = 7.1372, lr_0 = 6.9939e-04
Loss = 6.8170e-01, PNorm = 43.2927, GNorm = 5.4326, lr_0 = 6.7483e-04
Loss = 6.2867e-01, PNorm = 43.3270, GNorm = 3.0914, lr_0 = 6.5113e-04
Validation rmse = 0.802484
Epoch 7
Loss = 7.0709e-01, PNorm = 43.3601, GNorm = 14.1410, lr_0 = 6.2601e-04
Loss = 7.0327e-01, PNorm = 43.3895, GNorm = 1.9400, lr_0 = 6.0403e-04
Validation rmse = 0.793390
Epoch 8
Loss = 6.1877e-01, PNorm = 43.4243, GNorm = 6.3028, lr_0 = 5.8073e-04
Loss = 5.2760e-01, PNorm = 43.4577, GNorm = 8.1791, lr_0 = 5.6033e-04
Validation rmse = 0.825629
Epoch 9
Loss = 4.9997e-01, PNorm = 43.4872, GNorm = 3.1759, lr_0 = 5.3872e-04
Loss = 5.6970e-01, PNorm = 43.5148, GNorm = 3.7982, lr_0 = 5.1980e-04
Loss = 5.6501e-01, PNorm = 43.5430, GNorm = 8.7024, lr_0 = 5.0155e-04
Validation rmse = 0.773120
Epoch 10
Loss = 5.4395e-01, PNorm = 43.5673, GNorm = 9.6237, lr_0 = 4.8393e-04
Loss = 6.0005e-01, PNorm = 43.5883, GNorm = 2.5872, lr_0 = 4.6693e-04
Validation rmse = 0.776020
Epoch 11
Loss = 5.0939e-01, PNorm = 43.6090, GNorm = 6.5768, lr_0 = 4.4893e-04
Loss = 4.6033e-01, PNorm = 43.6327, GNorm = 2.6853, lr_0 = 4.3316e-04
Validation rmse = 0.901609
Epoch 12
Loss = 8.0932e-01, PNorm = 43.6503, GNorm = 18.0262, lr_0 = 4.1645e-04
Loss = 5.1812e-01, PNorm = 43.6696, GNorm = 2.3751, lr_0 = 4.0183e-04
Loss = 4.5085e-01, PNorm = 43.6886, GNorm = 4.9834, lr_0 = 3.8771e-04
Validation rmse = 0.783253
Epoch 13
Loss = 4.7981e-01, PNorm = 43.7015, GNorm = 3.2422, lr_0 = 3.7276e-04
Loss = 4.7051e-01, PNorm = 43.7182, GNorm = 3.5048, lr_0 = 3.5967e-04
Validation rmse = 0.724587
Epoch 14
Loss = 4.1160e-01, PNorm = 43.7334, GNorm = 3.8917, lr_0 = 3.4580e-04
Loss = 4.2014e-01, PNorm = 43.7454, GNorm = 7.2399, lr_0 = 3.3365e-04
Validation rmse = 0.736712
Epoch 15
Loss = 4.1024e-01, PNorm = 43.7569, GNorm = 16.5149, lr_0 = 3.2193e-04
Loss = 4.3144e-01, PNorm = 43.7708, GNorm = 7.1446, lr_0 = 3.1062e-04
Loss = 4.4694e-01, PNorm = 43.7841, GNorm = 9.3530, lr_0 = 2.9971e-04
Validation rmse = 0.750932
Epoch 16
Loss = 4.0825e-01, PNorm = 43.7992, GNorm = 3.8868, lr_0 = 2.8816e-04
Loss = 4.0707e-01, PNorm = 43.8130, GNorm = 3.9768, lr_0 = 2.7803e-04
Validation rmse = 0.757340
Epoch 17
Loss = 4.6630e-01, PNorm = 43.8232, GNorm = 10.4174, lr_0 = 2.6731e-04
Loss = 3.9909e-01, PNorm = 43.8332, GNorm = 6.2870, lr_0 = 2.5792e-04
Validation rmse = 0.737538
Epoch 18
Loss = 4.5036e-01, PNorm = 43.8466, GNorm = 10.2425, lr_0 = 2.4798e-04
Loss = 3.1955e-01, PNorm = 43.8557, GNorm = 3.4541, lr_0 = 2.3927e-04
Loss = 4.3685e-01, PNorm = 43.8653, GNorm = 2.5039, lr_0 = 2.3086e-04
Loss = 2.6131e-01, PNorm = 43.8665, GNorm = 6.6748, lr_0 = 2.3004e-04
Validation rmse = 0.746176
Epoch 19
Loss = 4.0064e-01, PNorm = 43.8761, GNorm = 10.4103, lr_0 = 2.2196e-04
Loss = 3.6587e-01, PNorm = 43.8854, GNorm = 4.0719, lr_0 = 2.1416e-04
Validation rmse = 0.721457
Epoch 20
Loss = 3.0407e-01, PNorm = 43.8940, GNorm = 6.5705, lr_0 = 2.0664e-04
Loss = 3.1769e-01, PNorm = 43.9026, GNorm = 3.9636, lr_0 = 1.9938e-04
Validation rmse = 0.714168
Epoch 21
Loss = 3.3925e-01, PNorm = 43.9102, GNorm = 7.9533, lr_0 = 1.9169e-04
Loss = 3.0960e-01, PNorm = 43.9198, GNorm = 11.9376, lr_0 = 1.8496e-04
Loss = 3.7653e-01, PNorm = 43.9250, GNorm = 6.9873, lr_0 = 1.7846e-04
Loss = 2.6778e-01, PNorm = 43.9255, GNorm = 7.7659, lr_0 = 1.7783e-04
Validation rmse = 0.717780
Epoch 22
Loss = 3.1702e-01, PNorm = 43.9327, GNorm = 3.1668, lr_0 = 1.7158e-04
Loss = 3.5085e-01, PNorm = 43.9410, GNorm = 9.9918, lr_0 = 1.6556e-04
Validation rmse = 0.699929
Epoch 23
Loss = 3.6038e-01, PNorm = 43.9471, GNorm = 15.4380, lr_0 = 1.5917e-04
Loss = 3.4652e-01, PNorm = 43.9510, GNorm = 5.0343, lr_0 = 1.5358e-04
Validation rmse = 0.710628
Epoch 24
Loss = 3.9512e-01, PNorm = 43.9579, GNorm = 9.8621, lr_0 = 1.4766e-04
Loss = 3.2455e-01, PNorm = 43.9656, GNorm = 8.4409, lr_0 = 1.4247e-04
Loss = 3.1678e-01, PNorm = 43.9712, GNorm = 21.5331, lr_0 = 1.3747e-04
Validation rmse = 0.707101
Epoch 25
Loss = 3.2632e-01, PNorm = 43.9771, GNorm = 6.7909, lr_0 = 1.3264e-04
Loss = 2.9934e-01, PNorm = 43.9813, GNorm = 7.7718, lr_0 = 1.2798e-04
Validation rmse = 0.701481
Epoch 26
Loss = 2.6575e-01, PNorm = 43.9874, GNorm = 2.7055, lr_0 = 1.2304e-04
Loss = 3.0004e-01, PNorm = 43.9939, GNorm = 3.2096, lr_0 = 1.1872e-04
Validation rmse = 0.700763
Epoch 27
Loss = 2.3981e-01, PNorm = 43.9978, GNorm = 3.0012, lr_0 = 1.1414e-04
Loss = 3.1123e-01, PNorm = 44.0024, GNorm = 11.1936, lr_0 = 1.1014e-04
Validation rmse = 0.710275
Epoch 28
Loss = 5.5685e-01, PNorm = 44.0069, GNorm = 10.1513, lr_0 = 1.0589e-04
Loss = 2.9094e-01, PNorm = 44.0119, GNorm = 3.1956, lr_0 = 1.0217e-04
Loss = 3.0132e-01, PNorm = 44.0159, GNorm = 5.8104, lr_0 = 1.0000e-04
Validation rmse = 0.714061
Epoch 29
Loss = 3.0082e-01, PNorm = 44.0208, GNorm = 4.3006, lr_0 = 1.0000e-04
Loss = 3.1079e-01, PNorm = 44.0253, GNorm = 11.3402, lr_0 = 1.0000e-04
Validation rmse = 0.696128
Model 0 best validation rmse = 0.696128 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.582339
Ensemble test rmse = 0.582339
1-fold cross validation
	Seed 0 ==> test rmse = 0.582339
Overall test rmse = 0.582339 +/- 0.000000
Elapsed time = 0:01:57
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.8166e+00, PNorm = 42.7376, GNorm = 1.7908, lr_0 = 3.0625e-04
Loss = 1.4314e+00, PNorm = 42.7324, GNorm = 1.0684, lr_0 = 4.9375e-04
Validation rmse = 1.573149
Epoch 1
Loss = 1.3702e+00, PNorm = 42.7372, GNorm = 1.0850, lr_0 = 6.8125e-04
Loss = 1.3074e+00, PNorm = 42.7544, GNorm = 1.6744, lr_0 = 8.6875e-04
Validation rmse = 1.371825
Epoch 2
Loss = 1.2216e+00, PNorm = 42.7891, GNorm = 1.8160, lr_0 = 9.8977e-04
Loss = 1.0980e+00, PNorm = 42.8463, GNorm = 2.0264, lr_0 = 9.5643e-04
Loss = 1.0435e+00, PNorm = 42.9089, GNorm = 4.1917, lr_0 = 9.2422e-04
Validation rmse = 1.115901
Epoch 3
Loss = 9.4800e-01, PNorm = 42.9719, GNorm = 4.0426, lr_0 = 8.9309e-04
Loss = 9.0240e-01, PNorm = 43.0229, GNorm = 2.6414, lr_0 = 8.6300e-04
Validation rmse = 1.152794
Epoch 4
Loss = 9.6086e-01, PNorm = 43.0637, GNorm = 7.6267, lr_0 = 8.3393e-04
Loss = 8.4964e-01, PNorm = 43.1067, GNorm = 4.0251, lr_0 = 8.0584e-04
Loss = 7.9792e-01, PNorm = 43.1666, GNorm = 3.2269, lr_0 = 7.7870e-04
Validation rmse = 0.896384
Epoch 5
Loss = 8.3015e-01, PNorm = 43.2113, GNorm = 4.3677, lr_0 = 7.5247e-04
Loss = 6.7326e-01, PNorm = 43.2483, GNorm = 8.5363, lr_0 = 7.2712e-04
Validation rmse = 0.821582
Epoch 6
Loss = 7.0841e-01, PNorm = 43.2793, GNorm = 3.1527, lr_0 = 7.0263e-04
Loss = 7.2850e-01, PNorm = 43.3184, GNorm = 3.1682, lr_0 = 6.7896e-04
Validation rmse = 0.785310
Epoch 7
Loss = 5.9616e-01, PNorm = 43.3521, GNorm = 3.8954, lr_0 = 6.5609e-04
Loss = 6.4860e-01, PNorm = 43.3880, GNorm = 5.7774, lr_0 = 6.3399e-04
Loss = 6.5406e-01, PNorm = 43.4203, GNorm = 15.5452, lr_0 = 6.1264e-04
Validation rmse = 0.867075
Epoch 8
Loss = 6.8936e-01, PNorm = 43.4473, GNorm = 3.3954, lr_0 = 5.9200e-04
Loss = 6.4777e-01, PNorm = 43.4811, GNorm = 14.2243, lr_0 = 5.7206e-04
Validation rmse = 0.747785
Epoch 9
Loss = 4.7875e-01, PNorm = 43.5133, GNorm = 5.8877, lr_0 = 5.5279e-04
Loss = 5.4071e-01, PNorm = 43.5415, GNorm = 10.4465, lr_0 = 5.3417e-04
Loss = 5.9798e-01, PNorm = 43.5629, GNorm = 16.5283, lr_0 = 5.1618e-04
Validation rmse = 0.725743
Epoch 10
Loss = 5.8505e-01, PNorm = 43.5831, GNorm = 9.1198, lr_0 = 4.9879e-04
Loss = 5.7923e-01, PNorm = 43.6091, GNorm = 5.9169, lr_0 = 4.8199e-04
Validation rmse = 0.708688
Epoch 11
Loss = 5.1821e-01, PNorm = 43.6393, GNorm = 5.5789, lr_0 = 4.6575e-04
Loss = 4.8897e-01, PNorm = 43.6625, GNorm = 4.8729, lr_0 = 4.5006e-04
Validation rmse = 0.709828
Epoch 12
Loss = 5.2520e-01, PNorm = 43.6837, GNorm = 14.5009, lr_0 = 4.3490e-04
Loss = 5.4949e-01, PNorm = 43.7016, GNorm = 2.2234, lr_0 = 4.2025e-04
Loss = 4.4570e-01, PNorm = 43.7227, GNorm = 7.2601, lr_0 = 4.0610e-04
Validation rmse = 0.727233
Epoch 13
Loss = 3.8823e-01, PNorm = 43.7454, GNorm = 4.7029, lr_0 = 3.9242e-04
Loss = 4.7143e-01, PNorm = 43.7641, GNorm = 15.8453, lr_0 = 3.7920e-04
Validation rmse = 0.747104
Epoch 14
Loss = 4.9619e-01, PNorm = 43.7802, GNorm = 9.3905, lr_0 = 3.6643e-04
Loss = 3.7836e-01, PNorm = 43.7948, GNorm = 13.4557, lr_0 = 3.5408e-04
Loss = 5.2095e-01, PNorm = 43.8114, GNorm = 3.0063, lr_0 = 3.4216e-04
Validation rmse = 0.733274
Epoch 15
Loss = 4.2208e-01, PNorm = 43.8302, GNorm = 5.5191, lr_0 = 3.3063e-04
Loss = 3.7304e-01, PNorm = 43.8463, GNorm = 4.2861, lr_0 = 3.1950e-04
Validation rmse = 0.711091
Epoch 16
Loss = 3.7480e-01, PNorm = 43.8556, GNorm = 4.0037, lr_0 = 3.0873e-04
Loss = 3.7599e-01, PNorm = 43.8706, GNorm = 12.4316, lr_0 = 2.9833e-04
Validation rmse = 0.697093
Epoch 17
Loss = 3.5039e-01, PNorm = 43.8858, GNorm = 2.2844, lr_0 = 2.8828e-04
Loss = 3.7592e-01, PNorm = 43.8990, GNorm = 8.2143, lr_0 = 2.7857e-04
Loss = 3.6143e-01, PNorm = 43.9110, GNorm = 8.5082, lr_0 = 2.6919e-04
Validation rmse = 0.701205
Epoch 18
Loss = 4.1001e-01, PNorm = 43.9216, GNorm = 16.5041, lr_0 = 2.6012e-04
Loss = 4.2916e-01, PNorm = 43.9290, GNorm = 4.2338, lr_0 = 2.5136e-04
Validation rmse = 0.691060
Epoch 19
Loss = 3.2566e-01, PNorm = 43.9435, GNorm = 2.9991, lr_0 = 2.4289e-04
Loss = 3.3598e-01, PNorm = 43.9568, GNorm = 13.7393, lr_0 = 2.3471e-04
Loss = 3.6762e-01, PNorm = 43.9663, GNorm = 7.7333, lr_0 = 2.2681e-04
Validation rmse = 0.711820
Epoch 20
Loss = 3.5781e-01, PNorm = 43.9755, GNorm = 10.2404, lr_0 = 2.1917e-04
Loss = 3.6110e-01, PNorm = 43.9862, GNorm = 10.1718, lr_0 = 2.1178e-04
Validation rmse = 0.713599
Epoch 21
Loss = 3.5650e-01, PNorm = 43.9942, GNorm = 12.4775, lr_0 = 2.0465e-04
Loss = 3.8984e-01, PNorm = 44.0026, GNorm = 11.2076, lr_0 = 1.9776e-04
Validation rmse = 0.707431
Epoch 22
Loss = 3.3746e-01, PNorm = 44.0123, GNorm = 10.5508, lr_0 = 1.9110e-04
Loss = 3.1845e-01, PNorm = 44.0219, GNorm = 5.9253, lr_0 = 1.8466e-04
Loss = 4.0210e-01, PNorm = 44.0302, GNorm = 9.3111, lr_0 = 1.7844e-04
Validation rmse = 0.769832
Epoch 23
Loss = 3.5156e-01, PNorm = 44.0366, GNorm = 13.4217, lr_0 = 1.7243e-04
Loss = 2.9896e-01, PNorm = 44.0463, GNorm = 5.9024, lr_0 = 1.6662e-04
Validation rmse = 0.682924
Epoch 24
Loss = 3.3807e-01, PNorm = 44.0545, GNorm = 4.0384, lr_0 = 1.6101e-04
Loss = 2.8262e-01, PNorm = 44.0609, GNorm = 6.5676, lr_0 = 1.5558e-04
Loss = 3.0577e-01, PNorm = 44.0679, GNorm = 10.3566, lr_0 = 1.5034e-04
Validation rmse = 0.695278
Epoch 25
Loss = 2.6821e-01, PNorm = 44.0743, GNorm = 6.6475, lr_0 = 1.4528e-04
Loss = 3.1595e-01, PNorm = 44.0812, GNorm = 9.6129, lr_0 = 1.4039e-04
Validation rmse = 0.686549
Epoch 26
Loss = 3.0767e-01, PNorm = 44.0864, GNorm = 4.0175, lr_0 = 1.3566e-04
Loss = 2.4973e-01, PNorm = 44.0922, GNorm = 5.3857, lr_0 = 1.3109e-04
Validation rmse = 0.703698
Epoch 27
Loss = 3.3016e-01, PNorm = 44.0985, GNorm = 2.1642, lr_0 = 1.2667e-04
Loss = 2.8082e-01, PNorm = 44.1047, GNorm = 3.5873, lr_0 = 1.2240e-04
Loss = 2.6512e-01, PNorm = 44.1091, GNorm = 3.7387, lr_0 = 1.1828e-04
Validation rmse = 0.686034
Epoch 28
Loss = 2.2165e-01, PNorm = 44.1152, GNorm = 5.7046, lr_0 = 1.1430e-04
Loss = 3.2471e-01, PNorm = 44.1192, GNorm = 8.2426, lr_0 = 1.1045e-04
Validation rmse = 0.684485
Epoch 29
Loss = 2.8421e-01, PNorm = 44.1241, GNorm = 13.5019, lr_0 = 1.0673e-04
Loss = 2.8843e-01, PNorm = 44.1288, GNorm = 6.8613, lr_0 = 1.0313e-04
Loss = 2.5804e-01, PNorm = 44.1332, GNorm = 5.2992, lr_0 = 1.0000e-04
Validation rmse = 0.693539
Model 0 best validation rmse = 0.682924 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.607542
Ensemble test rmse = 0.607542
1-fold cross validation
	Seed 0 ==> test rmse = 0.607542
Overall test rmse = 0.607542 +/- 0.000000
Elapsed time = 0:02:01
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.424708
Epoch 1
Loss = 1.4054e+00, PNorm = 42.7451, GNorm = 0.8717, lr_0 = 7.1875e-04
Validation rmse = 1.313273
Epoch 2
Loss = 1.3811e+00, PNorm = 42.7703, GNorm = 0.8602, lr_0 = 9.4990e-04
Validation rmse = 1.292422
Epoch 3
Loss = 1.3214e+00, PNorm = 42.8047, GNorm = 0.9288, lr_0 = 8.5711e-04
Validation rmse = 1.265145
Epoch 4
Loss = 1.2917e+00, PNorm = 42.8415, GNorm = 2.2705, lr_0 = 7.7338e-04
Validation rmse = 1.264247
Epoch 5
Validation rmse = 1.198321
Epoch 6
Loss = 1.1809e+00, PNorm = 42.8819, GNorm = 0.9027, lr_0 = 6.9783e-04
Validation rmse = 1.163275
Epoch 7
Loss = 1.1694e+00, PNorm = 42.9311, GNorm = 1.7175, lr_0 = 6.2966e-04
Validation rmse = 1.140684
Epoch 8
Loss = 1.1079e+00, PNorm = 42.9929, GNorm = 2.6701, lr_0 = 5.6815e-04
Validation rmse = 1.071093
Epoch 9
Loss = 1.0330e+00, PNorm = 43.0542, GNorm = 0.8268, lr_0 = 5.1265e-04
Validation rmse = 1.041726
Epoch 10
Validation rmse = 1.027498
Epoch 11
Loss = 9.2783e-01, PNorm = 43.1114, GNorm = 8.2206, lr_0 = 4.6257e-04
Validation rmse = 1.003140
Epoch 12
Loss = 9.0059e-01, PNorm = 43.1566, GNorm = 4.6608, lr_0 = 4.1738e-04
Validation rmse = 0.996043
Epoch 13
Loss = 8.7904e-01, PNorm = 43.1932, GNorm = 11.8985, lr_0 = 3.7661e-04
Validation rmse = 0.953624
Epoch 14
Loss = 8.6444e-01, PNorm = 43.2213, GNorm = 10.6629, lr_0 = 3.3982e-04
Validation rmse = 1.006388
Epoch 15
Validation rmse = 0.928745
Epoch 16
Loss = 8.0103e-01, PNorm = 43.2460, GNorm = 3.1282, lr_0 = 3.0662e-04
Validation rmse = 0.943352
Epoch 17
Loss = 7.9274e-01, PNorm = 43.2682, GNorm = 4.0974, lr_0 = 2.7667e-04
Validation rmse = 0.953406
Epoch 18
Loss = 8.4357e-01, PNorm = 43.2888, GNorm = 19.4975, lr_0 = 2.4964e-04
Validation rmse = 0.893844
Epoch 19
Loss = 7.6873e-01, PNorm = 43.3048, GNorm = 2.5189, lr_0 = 2.2526e-04
Validation rmse = 0.895581
Epoch 20
Validation rmse = 0.889196
Epoch 21
Loss = 7.7826e-01, PNorm = 43.3193, GNorm = 3.3952, lr_0 = 2.0325e-04
Validation rmse = 0.881335
Epoch 22
Loss = 7.6705e-01, PNorm = 43.3323, GNorm = 3.7830, lr_0 = 1.8340e-04
Validation rmse = 0.876444
Epoch 23
Loss = 6.9899e-01, PNorm = 43.3448, GNorm = 6.8004, lr_0 = 1.6548e-04
Validation rmse = 0.865698
Epoch 24
Loss = 6.8936e-01, PNorm = 43.3579, GNorm = 2.7946, lr_0 = 1.4932e-04
Validation rmse = 0.860824
Epoch 25
Validation rmse = 0.857961
Epoch 26
Loss = 6.9627e-01, PNorm = 43.3682, GNorm = 2.6420, lr_0 = 1.3473e-04
Validation rmse = 0.852164
Epoch 27
Loss = 7.4303e-01, PNorm = 43.3779, GNorm = 8.1783, lr_0 = 1.2157e-04
Validation rmse = 0.846255
Epoch 28
Loss = 6.8841e-01, PNorm = 43.3860, GNorm = 5.7167, lr_0 = 1.0969e-04
Validation rmse = 0.856717
Epoch 29
Loss = 6.6975e-01, PNorm = 43.3933, GNorm = 5.2603, lr_0 = 1.0000e-04
Validation rmse = 0.866869
Model 0 best validation rmse = 0.846255 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.744118
Ensemble test rmse = 0.744118
1-fold cross validation
	Seed 0 ==> test rmse = 0.744118
Overall test rmse = 0.744118 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.383718
Epoch 1
Loss = 1.4795e+00, PNorm = 42.7421, GNorm = 0.6230, lr_0 = 7.7500e-04
Validation rmse = 1.314524
Epoch 2
Loss = 1.4041e+00, PNorm = 42.7670, GNorm = 0.9595, lr_0 = 9.4019e-04
Validation rmse = 1.281152
Epoch 3
Loss = 1.3209e+00, PNorm = 42.8000, GNorm = 2.4966, lr_0 = 8.4834e-04
Validation rmse = 1.225417
Epoch 4
Loss = 1.2595e+00, PNorm = 42.8333, GNorm = 0.4974, lr_0 = 7.6547e-04
Validation rmse = 1.159026
Epoch 5
Loss = 1.2121e+00, PNorm = 42.8723, GNorm = 0.6697, lr_0 = 6.9069e-04
Validation rmse = 1.099073
Epoch 6
Loss = 1.1594e+00, PNorm = 42.9200, GNorm = 2.2793, lr_0 = 6.1685e-04
Validation rmse = 1.199470
Epoch 7
Loss = 1.1074e+00, PNorm = 42.9650, GNorm = 5.8894, lr_0 = 5.5659e-04
Validation rmse = 1.104823
Epoch 8
Validation rmse = 0.974566
Epoch 9
Loss = 9.8998e-01, PNorm = 43.0079, GNorm = 3.5887, lr_0 = 5.0222e-04
Validation rmse = 0.932843
Epoch 10
Loss = 9.2161e-01, PNorm = 43.0495, GNorm = 1.4631, lr_0 = 4.5316e-04
Validation rmse = 0.928906
Epoch 11
Loss = 9.1868e-01, PNorm = 43.0949, GNorm = 5.3032, lr_0 = 4.0471e-04
Validation rmse = 0.913969
Epoch 12
Loss = 9.0022e-01, PNorm = 43.1275, GNorm = 1.0502, lr_0 = 3.6517e-04
Validation rmse = 1.012959
Epoch 13
Loss = 8.4475e-01, PNorm = 43.1542, GNorm = 8.3239, lr_0 = 3.2950e-04
Validation rmse = 0.939482
Epoch 14
Loss = 7.9946e-01, PNorm = 43.1796, GNorm = 6.0208, lr_0 = 2.9731e-04
Validation rmse = 0.878176
Epoch 15
Loss = 7.5306e-01, PNorm = 43.2029, GNorm = 2.0304, lr_0 = 2.6827e-04
Loss = 9.1560e-01, PNorm = 43.2050, GNorm = 4.9108, lr_0 = 2.6553e-04
Validation rmse = 0.892501
Epoch 16
Validation rmse = 0.891512
Epoch 17
Loss = 7.8787e-01, PNorm = 43.2251, GNorm = 1.6350, lr_0 = 2.3959e-04
Validation rmse = 0.826928
Epoch 18
Loss = 6.6274e-01, PNorm = 43.2427, GNorm = 6.3700, lr_0 = 2.1618e-04
Validation rmse = 0.801436
Epoch 19
Loss = 7.5054e-01, PNorm = 43.2577, GNorm = 6.9777, lr_0 = 1.9506e-04
Validation rmse = 0.828737
Epoch 20
Loss = 6.6379e-01, PNorm = 43.2711, GNorm = 5.0382, lr_0 = 1.7601e-04
Validation rmse = 0.849549
Epoch 21
Loss = 6.7621e-01, PNorm = 43.2837, GNorm = 9.1292, lr_0 = 1.5719e-04
Validation rmse = 0.852590
Epoch 22
Loss = 6.5050e-01, PNorm = 43.2943, GNorm = 8.9245, lr_0 = 1.4184e-04
Validation rmse = 0.829554
Epoch 23
Loss = 6.4415e-01, PNorm = 43.3036, GNorm = 3.1968, lr_0 = 1.2798e-04
Validation rmse = 0.813368
Epoch 24
Loss = 6.4642e-01, PNorm = 43.3116, GNorm = 2.7931, lr_0 = 1.1548e-04
Validation rmse = 0.823744
Epoch 25
Validation rmse = 0.817026
Epoch 26
Loss = 6.2884e-01, PNorm = 43.3198, GNorm = 9.2080, lr_0 = 1.0313e-04
Validation rmse = 0.819230
Epoch 27
Loss = 6.1177e-01, PNorm = 43.3265, GNorm = 3.4503, lr_0 = 1.0000e-04
Validation rmse = 0.797303
Epoch 28
Loss = 5.9608e-01, PNorm = 43.3331, GNorm = 2.5227, lr_0 = 1.0000e-04
Validation rmse = 0.765524
Epoch 29
Loss = 5.8042e-01, PNorm = 43.3394, GNorm = 20.0848, lr_0 = 1.0000e-04
Validation rmse = 0.764307
Model 0 best validation rmse = 0.764307 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.784637
Ensemble test rmse = 0.784637
1-fold cross validation
	Seed 0 ==> test rmse = 0.784637
Overall test rmse = 0.784637 +/- 0.000000
Elapsed time = 0:01:29
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.503812
Epoch 1
Loss = 1.3921e+00, PNorm = 42.7406, GNorm = 1.3331, lr_0 = 7.0000e-04
Validation rmse = 1.386988
Epoch 2
Loss = 1.3377e+00, PNorm = 42.7634, GNorm = 0.7373, lr_0 = 9.6411e-04
Validation rmse = 1.260793
Epoch 3
Loss = 1.2664e+00, PNorm = 42.8017, GNorm = 0.4524, lr_0 = 8.7192e-04
Validation rmse = 1.245196
Epoch 4
Loss = 1.1950e+00, PNorm = 42.8424, GNorm = 1.5311, lr_0 = 7.9578e-04
Validation rmse = 1.173357
Epoch 5
Loss = 1.1445e+00, PNorm = 42.8880, GNorm = 5.7867, lr_0 = 7.2629e-04
Validation rmse = 1.080175
Epoch 6
Loss = 1.0293e+00, PNorm = 42.9413, GNorm = 1.7217, lr_0 = 6.5684e-04
Validation rmse = 1.032190
Epoch 7
Loss = 9.6368e-01, PNorm = 42.9918, GNorm = 2.4546, lr_0 = 5.9948e-04
Validation rmse = 1.072326
Epoch 8
Loss = 9.1806e-01, PNorm = 43.0472, GNorm = 4.1945, lr_0 = 5.4216e-04
Validation rmse = 0.951534
Epoch 9
Loss = 8.0933e-01, PNorm = 43.0938, GNorm = 1.5979, lr_0 = 4.9482e-04
Validation rmse = 0.963225
Epoch 10
Loss = 8.0662e-01, PNorm = 43.1225, GNorm = 9.6039, lr_0 = 4.5161e-04
Validation rmse = 0.920599
Epoch 11
Loss = 7.7802e-01, PNorm = 43.1524, GNorm = 2.9996, lr_0 = 4.0842e-04
Validation rmse = 0.978574
Epoch 12
Loss = 7.6139e-01, PNorm = 43.1793, GNorm = 5.7040, lr_0 = 3.7276e-04
Validation rmse = 0.934186
Epoch 13
Loss = 7.2462e-01, PNorm = 43.2001, GNorm = 3.5330, lr_0 = 3.3711e-04
Validation rmse = 0.846533
Epoch 14
Loss = 6.9884e-01, PNorm = 43.2218, GNorm = 7.6995, lr_0 = 3.0768e-04
Validation rmse = 0.853792
Epoch 15
Loss = 6.8239e-01, PNorm = 43.2377, GNorm = 10.3393, lr_0 = 2.8081e-04
Validation rmse = 0.820930
Epoch 16
Loss = 6.9199e-01, PNorm = 43.2557, GNorm = 5.4908, lr_0 = 2.5396e-04
Validation rmse = 0.823293
Epoch 17
Loss = 6.2754e-01, PNorm = 43.2694, GNorm = 7.9505, lr_0 = 2.3178e-04
Validation rmse = 0.877941
Epoch 18
Loss = 6.5413e-01, PNorm = 43.2831, GNorm = 3.5202, lr_0 = 2.0962e-04
Validation rmse = 0.868543
Epoch 19
Loss = 6.1717e-01, PNorm = 43.2935, GNorm = 5.1268, lr_0 = 1.9131e-04
Validation rmse = 0.859271
Epoch 20
Loss = 6.0525e-01, PNorm = 43.3034, GNorm = 2.2118, lr_0 = 1.7461e-04
Validation rmse = 0.825870
Epoch 21
Loss = 6.1672e-01, PNorm = 43.3133, GNorm = 8.2240, lr_0 = 1.5791e-04
Validation rmse = 0.826735
Epoch 22
Loss = 5.9950e-01, PNorm = 43.3214, GNorm = 4.2282, lr_0 = 1.4412e-04
Loss = 5.0929e-01, PNorm = 43.3223, GNorm = 11.0124, lr_0 = 1.4281e-04
Validation rmse = 0.819598
Epoch 23
Loss = 5.7161e-01, PNorm = 43.3307, GNorm = 2.5047, lr_0 = 1.3034e-04
Validation rmse = 0.800062
Epoch 24
Loss = 5.7418e-01, PNorm = 43.3381, GNorm = 10.6033, lr_0 = 1.1896e-04
Validation rmse = 0.787623
Epoch 25
Validation rmse = 0.783797
Epoch 26
Loss = 5.8296e-01, PNorm = 43.3448, GNorm = 3.8648, lr_0 = 1.0758e-04
Validation rmse = 0.789304
Epoch 27
Loss = 6.0684e-01, PNorm = 43.3510, GNorm = 1.7762, lr_0 = 1.0000e-04
Validation rmse = 0.788812
Epoch 28
Loss = 6.5529e-01, PNorm = 43.3575, GNorm = 4.5388, lr_0 = 1.0000e-04
Validation rmse = 0.782720
Epoch 29
Loss = 5.1242e-01, PNorm = 43.3630, GNorm = 2.5251, lr_0 = 1.0000e-04
Validation rmse = 0.777955
Model 0 best validation rmse = 0.777955 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.801799
Ensemble test rmse = 0.801799
1-fold cross validation
	Seed 0 ==> test rmse = 0.801799
Overall test rmse = 0.801799 +/- 0.000000
Elapsed time = 0:01:37
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7545e+00, PNorm = 42.7407, GNorm = 1.3431, lr_0 = 5.9500e-04
Loss = 1.2685e+00, PNorm = 42.7410, GNorm = 1.4570, lr_0 = 6.4000e-04
Validation rmse = 1.524737
Epoch 1
Loss = 1.3758e+00, PNorm = 42.7601, GNorm = 0.7083, lr_0 = 9.8369e-04
Loss = 1.2539e+00, PNorm = 42.7633, GNorm = 0.9049, lr_0 = 9.7563e-04
Validation rmse = 1.461234
Epoch 2
Loss = 1.2699e+00, PNorm = 42.7993, GNorm = 0.8359, lr_0 = 8.9861e-04
Validation rmse = 1.358729
Epoch 3
Loss = 1.1906e+00, PNorm = 42.8420, GNorm = 1.0306, lr_0 = 8.2767e-04
Validation rmse = 1.272557
Epoch 4
Loss = 1.0857e+00, PNorm = 42.8992, GNorm = 1.1042, lr_0 = 7.5609e-04
Validation rmse = 1.205156
Epoch 5
Loss = 1.0012e+00, PNorm = 42.9562, GNorm = 2.4797, lr_0 = 6.9640e-04
Validation rmse = 1.076655
Epoch 6
Loss = 8.6326e-01, PNorm = 43.0208, GNorm = 4.3783, lr_0 = 6.3617e-04
Validation rmse = 1.016466
Epoch 7
Loss = 8.5837e-01, PNorm = 43.0704, GNorm = 6.1004, lr_0 = 5.8115e-04
Validation rmse = 0.980279
Epoch 8
Loss = 7.3185e-01, PNorm = 43.1110, GNorm = 6.6656, lr_0 = 5.3527e-04
Validation rmse = 0.957290
Epoch 9
Loss = 7.4127e-01, PNorm = 43.1445, GNorm = 6.0006, lr_0 = 4.8897e-04
Validation rmse = 0.955892
Epoch 10
Loss = 7.7108e-01, PNorm = 43.1725, GNorm = 16.3145, lr_0 = 4.5037e-04
Validation rmse = 1.034613
Epoch 11
Loss = 7.2307e-01, PNorm = 43.1960, GNorm = 11.5636, lr_0 = 4.1142e-04
Validation rmse = 0.947376
Epoch 12
Loss = 6.7833e-01, PNorm = 43.2200, GNorm = 7.6962, lr_0 = 3.7584e-04
Validation rmse = 0.921536
Epoch 13
Loss = 5.9612e-01, PNorm = 43.2380, GNorm = 3.6076, lr_0 = 3.4617e-04
Validation rmse = 0.917926
Epoch 14
Loss = 5.9308e-01, PNorm = 43.2553, GNorm = 8.2902, lr_0 = 3.1623e-04
Validation rmse = 0.919459
Epoch 15
Loss = 5.6057e-01, PNorm = 43.2718, GNorm = 7.8951, lr_0 = 2.9126e-04
Validation rmse = 0.893026
Epoch 16
Loss = 5.7506e-01, PNorm = 43.2887, GNorm = 4.2244, lr_0 = 2.6607e-04
Validation rmse = 0.900238
Epoch 17
Loss = 5.3060e-01, PNorm = 43.3029, GNorm = 5.4402, lr_0 = 2.4306e-04
Validation rmse = 0.917406
Epoch 18
Loss = 5.2394e-01, PNorm = 43.3148, GNorm = 11.1301, lr_0 = 2.2387e-04
Validation rmse = 0.908148
Epoch 19
Loss = 5.6330e-01, PNorm = 43.3283, GNorm = 6.8827, lr_0 = 2.0451e-04
Validation rmse = 0.914084
Epoch 20
Loss = 4.9408e-01, PNorm = 43.3391, GNorm = 10.1464, lr_0 = 1.8836e-04
Validation rmse = 0.891448
Epoch 21
Loss = 4.7758e-01, PNorm = 43.3507, GNorm = 3.4468, lr_0 = 1.7207e-04
Validation rmse = 0.904082
Epoch 22
Loss = 4.9813e-01, PNorm = 43.3600, GNorm = 2.0161, lr_0 = 1.5719e-04
Validation rmse = 0.889363
Epoch 23
Loss = 3.4747e-01, PNorm = 43.3682, GNorm = 2.2295, lr_0 = 1.4478e-04
Validation rmse = 0.884668
Epoch 24
Loss = 6.0973e-01, PNorm = 43.3757, GNorm = 7.5244, lr_0 = 1.3226e-04
Loss = 4.7155e-01, PNorm = 43.3817, GNorm = 10.0828, lr_0 = 1.2182e-04
Validation rmse = 0.888200
Epoch 25
Loss = 4.6644e-01, PNorm = 43.3882, GNorm = 16.3524, lr_0 = 1.1220e-04
Loss = 5.0529e-01, PNorm = 43.3886, GNorm = 3.7283, lr_0 = 1.1128e-04
Validation rmse = 0.879245
Epoch 26
Loss = 4.5774e-01, PNorm = 43.3940, GNorm = 17.7639, lr_0 = 1.0250e-04
Loss = 6.0503e-01, PNorm = 43.3944, GNorm = 5.8967, lr_0 = 1.0166e-04
Validation rmse = 0.882821
Epoch 27
Loss = 4.5507e-01, PNorm = 43.3994, GNorm = 4.4367, lr_0 = 1.0000e-04
Validation rmse = 0.872154
Epoch 28
Loss = 4.5198e-01, PNorm = 43.4044, GNorm = 13.4275, lr_0 = 1.0000e-04
Validation rmse = 0.877771
Epoch 29
Loss = 4.6495e-01, PNorm = 43.4097, GNorm = 5.5578, lr_0 = 1.0000e-04
Validation rmse = 0.878232
Model 0 best validation rmse = 0.872154 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.768256
Ensemble test rmse = 0.768256
1-fold cross validation
	Seed 0 ==> test rmse = 0.768256
Overall test rmse = 0.768256 +/- 0.000000
Elapsed time = 0:01:45
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7092e+00, PNorm = 42.7391, GNorm = 1.9928, lr_0 = 5.5000e-04
Validation rmse = 1.500497
Epoch 1
Loss = 1.3739e+00, PNorm = 42.7580, GNorm = 1.5964, lr_0 = 1.0000e-03
Validation rmse = 1.419912
Epoch 2
Loss = 1.2656e+00, PNorm = 42.7989, GNorm = 0.6907, lr_0 = 9.2106e-04
Validation rmse = 1.310427
Epoch 3
Loss = 1.1865e+00, PNorm = 42.8511, GNorm = 3.6567, lr_0 = 8.4834e-04
Validation rmse = 1.309905
Epoch 4
Loss = 1.1356e+00, PNorm = 42.9106, GNorm = 2.1560, lr_0 = 7.8137e-04
Validation rmse = 1.239380
Epoch 5
Loss = 9.7804e-01, PNorm = 42.9670, GNorm = 1.3136, lr_0 = 7.2509e-04
Validation rmse = 1.057826
Epoch 6
Loss = 9.7472e-01, PNorm = 43.0297, GNorm = 3.0309, lr_0 = 6.6784e-04
Validation rmse = 1.099590
Epoch 7
Loss = 9.2440e-01, PNorm = 43.0821, GNorm = 2.5179, lr_0 = 6.1512e-04
Validation rmse = 0.969991
Epoch 8
Loss = 7.1902e-01, PNorm = 43.1313, GNorm = 3.8609, lr_0 = 5.6656e-04
Loss = 7.7990e-01, PNorm = 43.1713, GNorm = 7.4473, lr_0 = 5.2575e-04
Loss = 7.3480e-01, PNorm = 43.1750, GNorm = 4.4681, lr_0 = 5.2183e-04
Validation rmse = 0.964520
Epoch 9
Loss = 7.5373e-01, PNorm = 43.2108, GNorm = 5.7220, lr_0 = 4.8424e-04
Validation rmse = 0.931626
Epoch 10
Loss = 6.8353e-01, PNorm = 43.2402, GNorm = 1.5719, lr_0 = 4.4936e-04
Validation rmse = 0.919515
Epoch 11
Loss = 6.1674e-01, PNorm = 43.2682, GNorm = 3.1415, lr_0 = 4.1389e-04
Validation rmse = 0.922728
Epoch 12
Loss = 6.3455e-01, PNorm = 43.2913, GNorm = 4.0218, lr_0 = 3.8121e-04
Validation rmse = 0.898674
Epoch 13
Loss = 6.1903e-01, PNorm = 43.3119, GNorm = 5.0157, lr_0 = 3.5112e-04
Validation rmse = 0.871916
Epoch 14
Loss = 5.9116e-01, PNorm = 43.3308, GNorm = 6.5126, lr_0 = 3.2340e-04
Validation rmse = 0.869211
Epoch 15
Loss = 5.6562e-01, PNorm = 43.3495, GNorm = 7.9138, lr_0 = 3.0010e-04
Validation rmse = 0.915428
Epoch 16
Loss = 5.2987e-01, PNorm = 43.3681, GNorm = 6.5767, lr_0 = 2.7641e-04
Loss = 5.6635e-01, PNorm = 43.3800, GNorm = 2.3288, lr_0 = 2.5650e-04
Loss = 4.0839e-01, PNorm = 43.3812, GNorm = 8.3863, lr_0 = 2.5459e-04
Validation rmse = 0.855170
Epoch 17
Loss = 5.5494e-01, PNorm = 43.3950, GNorm = 5.0779, lr_0 = 2.3625e-04
Validation rmse = 0.934260
Epoch 18
Loss = 5.2497e-01, PNorm = 43.4083, GNorm = 3.6573, lr_0 = 2.1760e-04
Validation rmse = 0.869704
Epoch 19
Loss = 5.3408e-01, PNorm = 43.4213, GNorm = 4.1760, lr_0 = 2.0042e-04
Validation rmse = 0.855204
Epoch 20
Loss = 5.1229e-01, PNorm = 43.4315, GNorm = 5.3003, lr_0 = 1.8599e-04
Validation rmse = 0.859284
Epoch 21
Loss = 4.2604e-01, PNorm = 43.4427, GNorm = 3.0054, lr_0 = 1.7130e-04
Validation rmse = 0.842513
Epoch 22
Loss = 4.3513e-01, PNorm = 43.4526, GNorm = 3.1061, lr_0 = 1.5778e-04
Validation rmse = 0.844679
Epoch 23
Loss = 4.7229e-01, PNorm = 43.4615, GNorm = 9.3174, lr_0 = 1.4532e-04
Validation rmse = 0.857387
Epoch 24
Loss = 4.7477e-01, PNorm = 43.4694, GNorm = 9.8879, lr_0 = 1.3385e-04
Loss = 4.9330e-01, PNorm = 43.4761, GNorm = 9.4400, lr_0 = 1.2421e-04
Validation rmse = 0.871889
Epoch 25
Loss = 4.7099e-01, PNorm = 43.4824, GNorm = 7.9428, lr_0 = 1.1526e-04
Validation rmse = 0.843773
Epoch 26
Loss = 4.5353e-01, PNorm = 43.4892, GNorm = 2.4416, lr_0 = 1.0616e-04
Validation rmse = 0.837892
Epoch 27
Loss = 4.4044e-01, PNorm = 43.4944, GNorm = 7.3395, lr_0 = 1.0000e-04
Validation rmse = 0.844635
Epoch 28
Loss = 4.2589e-01, PNorm = 43.5008, GNorm = 5.1556, lr_0 = 1.0000e-04
Validation rmse = 0.853101
Epoch 29
Loss = 3.8771e-01, PNorm = 43.5063, GNorm = 8.3809, lr_0 = 1.0000e-04
Validation rmse = 0.858938
Model 0 best validation rmse = 0.837892 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.726647
Ensemble test rmse = 0.726647
1-fold cross validation
	Seed 0 ==> test rmse = 0.726647
Overall test rmse = 0.726647 +/- 0.000000
Elapsed time = 0:01:52
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7269e+00, PNorm = 42.7402, GNorm = 2.0643, lr_0 = 5.1250e-04
Validation rmse = 1.547980
Epoch 1
Loss = 1.3848e+00, PNorm = 42.7503, GNorm = 1.0596, lr_0 = 8.8750e-04
Validation rmse = 1.468588
Epoch 2
Loss = 1.2913e+00, PNorm = 42.7809, GNorm = 1.3267, lr_0 = 9.5316e-04
Validation rmse = 1.354811
Epoch 3
Loss = 1.1978e+00, PNorm = 42.8231, GNorm = 1.5451, lr_0 = 8.9003e-04
Validation rmse = 1.269867
Epoch 4
Loss = 1.1580e+00, PNorm = 42.8740, GNorm = 3.3850, lr_0 = 8.3108e-04
Loss = 1.0619e+00, PNorm = 42.9342, GNorm = 1.7007, lr_0 = 7.7603e-04
Validation rmse = 1.209473
Epoch 5
Loss = 9.9196e-01, PNorm = 42.9919, GNorm = 3.3780, lr_0 = 7.2463e-04
Validation rmse = 1.092498
Epoch 6
Loss = 9.2215e-01, PNorm = 43.0543, GNorm = 4.7375, lr_0 = 6.7664e-04
Validation rmse = 1.041512
Epoch 7
Loss = 7.8374e-01, PNorm = 43.1034, GNorm = 5.1229, lr_0 = 6.3182e-04
Validation rmse = 1.048823
Epoch 8
Loss = 7.7120e-01, PNorm = 43.1436, GNorm = 9.9062, lr_0 = 5.8997e-04
Validation rmse = 0.996773
Epoch 9
Loss = 7.7340e-01, PNorm = 43.1830, GNorm = 7.7970, lr_0 = 5.5090e-04
Loss = 7.0423e-01, PNorm = 43.2191, GNorm = 5.7794, lr_0 = 5.1441e-04
Validation rmse = 0.919390
Epoch 10
Loss = 6.6197e-01, PNorm = 43.2520, GNorm = 3.9166, lr_0 = 4.8034e-04
Validation rmse = 0.922467
Epoch 11
Loss = 5.9659e-01, PNorm = 43.2794, GNorm = 5.0649, lr_0 = 4.4852e-04
Validation rmse = 0.942334
Epoch 12
Loss = 6.4755e-01, PNorm = 43.3049, GNorm = 15.3026, lr_0 = 4.1882e-04
Validation rmse = 0.927938
Epoch 13
Loss = 6.3162e-01, PNorm = 43.3267, GNorm = 5.1577, lr_0 = 3.9108e-04
Validation rmse = 0.900635
Epoch 14
Loss = 6.5006e-01, PNorm = 43.3466, GNorm = 16.0328, lr_0 = 3.6517e-04
Loss = 5.7315e-01, PNorm = 43.3673, GNorm = 5.0047, lr_0 = 3.4099e-04
Validation rmse = 0.880674
Epoch 15
Loss = 5.5651e-01, PNorm = 43.3871, GNorm = 3.8709, lr_0 = 3.1840e-04
Validation rmse = 0.860946
Epoch 16
Loss = 4.8360e-01, PNorm = 43.4026, GNorm = 3.6276, lr_0 = 2.9731e-04
Validation rmse = 0.925162
Epoch 17
Loss = 5.7047e-01, PNorm = 43.4156, GNorm = 9.8482, lr_0 = 2.7762e-04
Validation rmse = 0.854942
Epoch 18
Loss = 4.6190e-01, PNorm = 43.4313, GNorm = 2.2355, lr_0 = 2.5923e-04
Validation rmse = 0.881333
Epoch 19
Loss = 4.9892e-01, PNorm = 43.4452, GNorm = 2.1087, lr_0 = 2.4206e-04
Loss = 4.9610e-01, PNorm = 43.4570, GNorm = 7.5292, lr_0 = 2.2603e-04
Validation rmse = 0.852617
Epoch 20
Loss = 4.7021e-01, PNorm = 43.4674, GNorm = 4.1007, lr_0 = 2.1106e-04
Validation rmse = 0.850031
Epoch 21
Loss = 4.6349e-01, PNorm = 43.4777, GNorm = 8.7318, lr_0 = 1.9708e-04
Validation rmse = 0.850856
Epoch 22
Loss = 4.4556e-01, PNorm = 43.4874, GNorm = 2.7079, lr_0 = 1.8403e-04
Validation rmse = 0.844721
Epoch 23
Loss = 4.5360e-01, PNorm = 43.4949, GNorm = 11.9047, lr_0 = 1.7184e-04
Validation rmse = 0.841437
Epoch 24
Loss = 4.0040e-01, PNorm = 43.5030, GNorm = 6.5670, lr_0 = 1.6046e-04
Loss = 4.9827e-01, PNorm = 43.5104, GNorm = 4.7499, lr_0 = 1.4983e-04
Validation rmse = 0.857621
Epoch 25
Loss = 4.5379e-01, PNorm = 43.5174, GNorm = 3.5340, lr_0 = 1.3991e-04
Validation rmse = 0.849893
Epoch 26
Loss = 4.2116e-01, PNorm = 43.5249, GNorm = 5.5125, lr_0 = 1.3064e-04
Validation rmse = 0.838617
Epoch 27
Loss = 4.0233e-01, PNorm = 43.5308, GNorm = 2.3489, lr_0 = 1.2199e-04
Validation rmse = 0.860638
Epoch 28
Loss = 4.7003e-01, PNorm = 43.5372, GNorm = 3.9232, lr_0 = 1.1391e-04
Validation rmse = 0.844300
Epoch 29
Loss = 4.8101e-01, PNorm = 43.5416, GNorm = 2.8451, lr_0 = 1.0636e-04
Loss = 4.1847e-01, PNorm = 43.5473, GNorm = 5.4232, lr_0 = 1.0000e-04
Validation rmse = 0.838311
Model 0 best validation rmse = 0.838311 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.693092
Ensemble test rmse = 0.693092
1-fold cross validation
	Seed 0 ==> test rmse = 0.693092
Overall test rmse = 0.693092 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.420674
Epoch 1
Loss = 1.4060e+00, PNorm = 42.7411, GNorm = 0.7865, lr_0 = 7.1875e-04
Validation rmse = 1.336977
Epoch 2
Loss = 1.3950e+00, PNorm = 42.7562, GNorm = 0.8772, lr_0 = 9.4990e-04
Validation rmse = 1.315599
Epoch 3
Loss = 1.3525e+00, PNorm = 42.7816, GNorm = 1.4199, lr_0 = 8.5711e-04
Validation rmse = 1.342548
Epoch 4
Loss = 1.3384e+00, PNorm = 42.8065, GNorm = 1.7113, lr_0 = 7.7338e-04
Validation rmse = 1.253933
Epoch 5
Validation rmse = 1.218631
Epoch 6
Loss = 1.2615e+00, PNorm = 42.8382, GNorm = 0.9287, lr_0 = 6.9783e-04
Validation rmse = 1.213905
Epoch 7
Loss = 1.2079e+00, PNorm = 42.8772, GNorm = 0.9397, lr_0 = 6.2966e-04
Validation rmse = 1.149841
Epoch 8
Loss = 1.1517e+00, PNorm = 42.9234, GNorm = 3.1846, lr_0 = 5.6815e-04
Validation rmse = 1.116326
Epoch 9
Loss = 1.1313e+00, PNorm = 42.9739, GNorm = 2.7133, lr_0 = 5.1265e-04
Validation rmse = 1.084046
Epoch 10
Validation rmse = 1.021824
Epoch 11
Loss = 9.9985e-01, PNorm = 43.0245, GNorm = 3.8916, lr_0 = 4.6257e-04
Validation rmse = 1.001816
Epoch 12
Loss = 1.0051e+00, PNorm = 43.0695, GNorm = 6.8442, lr_0 = 4.1738e-04
Validation rmse = 1.003504
Epoch 13
Loss = 9.8071e-01, PNorm = 43.1045, GNorm = 2.4017, lr_0 = 3.7661e-04
Validation rmse = 0.972519
Epoch 14
Loss = 9.3658e-01, PNorm = 43.1400, GNorm = 8.4381, lr_0 = 3.3982e-04
Validation rmse = 0.977864
Epoch 15
Validation rmse = 0.938946
Epoch 16
Loss = 8.1726e-01, PNorm = 43.1726, GNorm = 3.3982, lr_0 = 3.0662e-04
Validation rmse = 0.936102
Epoch 17
Loss = 8.1467e-01, PNorm = 43.2002, GNorm = 10.5003, lr_0 = 2.7667e-04
Validation rmse = 0.911287
Epoch 18
Loss = 8.0732e-01, PNorm = 43.2260, GNorm = 1.1758, lr_0 = 2.4964e-04
Validation rmse = 0.903613
Epoch 19
Loss = 7.9240e-01, PNorm = 43.2496, GNorm = 2.2146, lr_0 = 2.2526e-04
Validation rmse = 0.908909
Epoch 20
Validation rmse = 0.890749
Epoch 21
Loss = 7.8701e-01, PNorm = 43.2709, GNorm = 3.5186, lr_0 = 2.0325e-04
Validation rmse = 0.879958
Epoch 22
Loss = 7.5229e-01, PNorm = 43.2904, GNorm = 1.6078, lr_0 = 1.8340e-04
Validation rmse = 0.882832
Epoch 23
Loss = 7.3662e-01, PNorm = 43.3071, GNorm = 2.1059, lr_0 = 1.6548e-04
Validation rmse = 0.885815
Epoch 24
Loss = 6.9778e-01, PNorm = 43.3227, GNorm = 3.3153, lr_0 = 1.4932e-04
Validation rmse = 0.886689
Epoch 25
Validation rmse = 0.877284
Epoch 26
Loss = 6.4950e-01, PNorm = 43.3356, GNorm = 10.3383, lr_0 = 1.3473e-04
Validation rmse = 0.868351
Epoch 27
Loss = 6.7084e-01, PNorm = 43.3482, GNorm = 5.4926, lr_0 = 1.2157e-04
Validation rmse = 0.863627
Epoch 28
Loss = 6.5535e-01, PNorm = 43.3587, GNorm = 2.5238, lr_0 = 1.0969e-04
Validation rmse = 0.866044
Epoch 29
Loss = 6.3528e-01, PNorm = 43.3679, GNorm = 1.8865, lr_0 = 1.0000e-04
Validation rmse = 0.864106
Model 0 best validation rmse = 0.863627 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.781841
Ensemble test rmse = 0.781841
1-fold cross validation
	Seed 0 ==> test rmse = 0.781841
Overall test rmse = 0.781841 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.438580
Epoch 1
Loss = 1.4420e+00, PNorm = 42.7417, GNorm = 1.4351, lr_0 = 7.7500e-04
Validation rmse = 1.387207
Epoch 2
Loss = 1.3996e+00, PNorm = 42.7640, GNorm = 0.7942, lr_0 = 9.4019e-04
Validation rmse = 1.301331
Epoch 3
Loss = 1.3239e+00, PNorm = 42.7926, GNorm = 0.5726, lr_0 = 8.4834e-04
Validation rmse = 1.207485
Epoch 4
Loss = 1.2450e+00, PNorm = 42.8257, GNorm = 1.1358, lr_0 = 7.6547e-04
Validation rmse = 1.132343
Epoch 5
Loss = 1.1966e+00, PNorm = 42.8667, GNorm = 1.0264, lr_0 = 6.9069e-04
Validation rmse = 1.110381
Epoch 6
Loss = 1.1419e+00, PNorm = 42.9162, GNorm = 4.1477, lr_0 = 6.1685e-04
Validation rmse = 1.007603
Epoch 7
Loss = 1.0691e+00, PNorm = 42.9643, GNorm = 3.3648, lr_0 = 5.5659e-04
Validation rmse = 0.947981
Epoch 8
Validation rmse = 0.907835
Epoch 9
Loss = 9.7959e-01, PNorm = 43.0119, GNorm = 5.5988, lr_0 = 5.0222e-04
Validation rmse = 0.884136
Epoch 10
Loss = 9.5956e-01, PNorm = 43.0569, GNorm = 9.8051, lr_0 = 4.5316e-04
Validation rmse = 0.849045
Epoch 11
Loss = 9.1670e-01, PNorm = 43.0974, GNorm = 2.4300, lr_0 = 4.0471e-04
Validation rmse = 0.895407
Epoch 12
Loss = 9.1138e-01, PNorm = 43.1276, GNorm = 11.9492, lr_0 = 3.6517e-04
Validation rmse = 0.853366
Epoch 13
Loss = 8.9490e-01, PNorm = 43.1554, GNorm = 8.0251, lr_0 = 3.2950e-04
Validation rmse = 0.811032
Epoch 14
Loss = 8.3027e-01, PNorm = 43.1790, GNorm = 7.4776, lr_0 = 2.9731e-04
Validation rmse = 0.800127
Epoch 15
Loss = 7.6135e-01, PNorm = 43.1990, GNorm = 7.0282, lr_0 = 2.6827e-04
Loss = 9.1160e-01, PNorm = 43.2009, GNorm = 5.3306, lr_0 = 2.6553e-04
Validation rmse = 0.797706
Epoch 16
Validation rmse = 0.816056
Epoch 17
Loss = 8.3750e-01, PNorm = 43.2209, GNorm = 12.3947, lr_0 = 2.3959e-04
Validation rmse = 0.789742
Epoch 18
Loss = 6.6253e-01, PNorm = 43.2402, GNorm = 3.0983, lr_0 = 2.1618e-04
Validation rmse = 0.775341
Epoch 19
Loss = 7.1793e-01, PNorm = 43.2567, GNorm = 6.9733, lr_0 = 1.9506e-04
Validation rmse = 0.767608
Epoch 20
Loss = 7.4103e-01, PNorm = 43.2712, GNorm = 10.8461, lr_0 = 1.7601e-04
Validation rmse = 0.761541
Epoch 21
Loss = 6.5889e-01, PNorm = 43.2860, GNorm = 1.8117, lr_0 = 1.5719e-04
Validation rmse = 0.760223
Epoch 22
Loss = 6.6943e-01, PNorm = 43.2981, GNorm = 8.9436, lr_0 = 1.4184e-04
Validation rmse = 0.756563
Epoch 23
Loss = 6.6201e-01, PNorm = 43.3088, GNorm = 2.4492, lr_0 = 1.2798e-04
Validation rmse = 0.744688
Epoch 24
Loss = 6.3942e-01, PNorm = 43.3177, GNorm = 7.7794, lr_0 = 1.1548e-04
Validation rmse = 0.748143
Epoch 25
Validation rmse = 0.747720
Epoch 26
Loss = 6.1811e-01, PNorm = 43.3268, GNorm = 2.1455, lr_0 = 1.0313e-04
Validation rmse = 0.740457
Epoch 27
Loss = 5.9708e-01, PNorm = 43.3348, GNorm = 11.3579, lr_0 = 1.0000e-04
Validation rmse = 0.735624
Epoch 28
Loss = 5.9458e-01, PNorm = 43.3423, GNorm = 2.3256, lr_0 = 1.0000e-04
Validation rmse = 0.736068
Epoch 29
Loss = 5.8972e-01, PNorm = 43.3497, GNorm = 13.0006, lr_0 = 1.0000e-04
Validation rmse = 0.734607
Model 0 best validation rmse = 0.734607 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.787943
Ensemble test rmse = 0.787943
1-fold cross validation
	Seed 0 ==> test rmse = 0.787943
Overall test rmse = 0.787943 +/- 0.000000
Elapsed time = 0:01:29
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.487228
Epoch 1
Loss = 1.3954e+00, PNorm = 42.7395, GNorm = 1.0771, lr_0 = 7.0000e-04
Validation rmse = 1.480981
Epoch 2
Loss = 1.3097e+00, PNorm = 42.7612, GNorm = 0.6447, lr_0 = 9.6411e-04
Validation rmse = 1.390288
Epoch 3
Loss = 1.2014e+00, PNorm = 42.8014, GNorm = 0.9492, lr_0 = 8.7192e-04
Validation rmse = 1.316172
Epoch 4
Loss = 1.1405e+00, PNorm = 42.8423, GNorm = 1.6290, lr_0 = 7.9578e-04
Validation rmse = 1.256707
Epoch 5
Loss = 1.1059e+00, PNorm = 42.8869, GNorm = 3.6140, lr_0 = 7.2629e-04
Validation rmse = 1.142554
Epoch 6
Loss = 1.0393e+00, PNorm = 42.9378, GNorm = 2.5172, lr_0 = 6.5684e-04
Validation rmse = 1.107791
Epoch 7
Loss = 8.6235e-01, PNorm = 42.9850, GNorm = 1.4008, lr_0 = 5.9948e-04
Validation rmse = 1.050082
Epoch 8
Loss = 9.3844e-01, PNorm = 43.0302, GNorm = 11.0379, lr_0 = 5.4216e-04
Validation rmse = 1.066410
Epoch 9
Loss = 8.1684e-01, PNorm = 43.0669, GNorm = 6.2009, lr_0 = 4.9482e-04
Validation rmse = 0.949362
Epoch 10
Loss = 7.9031e-01, PNorm = 43.1057, GNorm = 1.5224, lr_0 = 4.5161e-04
Validation rmse = 0.955473
Epoch 11
Loss = 7.2772e-01, PNorm = 43.1447, GNorm = 6.5162, lr_0 = 4.0842e-04
Validation rmse = 0.894519
Epoch 12
Loss = 6.8534e-01, PNorm = 43.1764, GNorm = 3.1773, lr_0 = 3.7276e-04
Validation rmse = 0.896711
Epoch 13
Loss = 7.0544e-01, PNorm = 43.2116, GNorm = 7.8136, lr_0 = 3.3711e-04
Validation rmse = 0.844665
Epoch 14
Loss = 6.6360e-01, PNorm = 43.2380, GNorm = 10.4955, lr_0 = 3.0768e-04
Validation rmse = 0.850398
Epoch 15
Loss = 6.3823e-01, PNorm = 43.2597, GNorm = 17.0101, lr_0 = 2.8081e-04
Validation rmse = 0.820413
Epoch 16
Loss = 6.1322e-01, PNorm = 43.2831, GNorm = 5.3074, lr_0 = 2.5396e-04
Validation rmse = 0.833737
Epoch 17
Loss = 5.8852e-01, PNorm = 43.3039, GNorm = 5.1108, lr_0 = 2.3178e-04
Validation rmse = 0.810266
Epoch 18
Loss = 5.5893e-01, PNorm = 43.3222, GNorm = 4.5247, lr_0 = 2.0962e-04
Validation rmse = 0.792424
Epoch 19
Loss = 5.4905e-01, PNorm = 43.3363, GNorm = 1.5092, lr_0 = 1.9131e-04
Validation rmse = 0.803913
Epoch 20
Loss = 5.2192e-01, PNorm = 43.3508, GNorm = 7.5110, lr_0 = 1.7461e-04
Validation rmse = 0.767638
Epoch 21
Loss = 5.4512e-01, PNorm = 43.3640, GNorm = 3.8568, lr_0 = 1.5791e-04
Validation rmse = 0.773963
Epoch 22
Loss = 5.1169e-01, PNorm = 43.3763, GNorm = 2.4180, lr_0 = 1.4412e-04
Loss = 5.2182e-01, PNorm = 43.3773, GNorm = 3.0971, lr_0 = 1.4281e-04
Validation rmse = 0.783047
Epoch 23
Loss = 5.0951e-01, PNorm = 43.3872, GNorm = 7.0055, lr_0 = 1.3034e-04
Validation rmse = 0.783135
Epoch 24
Loss = 4.9813e-01, PNorm = 43.3961, GNorm = 8.2840, lr_0 = 1.1896e-04
Validation rmse = 0.769166
Epoch 25
Validation rmse = 0.772026
Epoch 26
Loss = 5.6946e-01, PNorm = 43.4052, GNorm = 3.2840, lr_0 = 1.0758e-04
Validation rmse = 0.793316
Epoch 27
Loss = 4.7582e-01, PNorm = 43.4125, GNorm = 8.6265, lr_0 = 1.0000e-04
Validation rmse = 0.767637
Epoch 28
Loss = 4.5150e-01, PNorm = 43.4203, GNorm = 3.7023, lr_0 = 1.0000e-04
Validation rmse = 0.800075
Epoch 29
Loss = 4.1490e-01, PNorm = 43.4270, GNorm = 6.2621, lr_0 = 1.0000e-04
Validation rmse = 0.759688
Model 0 best validation rmse = 0.759688 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.730892
Ensemble test rmse = 0.730892
1-fold cross validation
	Seed 0 ==> test rmse = 0.730892
Overall test rmse = 0.730892 +/- 0.000000
Elapsed time = 0:01:38
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7081e+00, PNorm = 42.7386, GNorm = 0.9975, lr_0 = 5.9500e-04
Loss = 1.3966e+00, PNorm = 42.7388, GNorm = 1.1855, lr_0 = 6.4000e-04
Validation rmse = 1.562921
Epoch 1
Loss = 1.3756e+00, PNorm = 42.7578, GNorm = 0.6783, lr_0 = 9.8369e-04
Loss = 1.2261e+00, PNorm = 42.7611, GNorm = 1.0807, lr_0 = 9.7563e-04
Validation rmse = 1.549141
Epoch 2
Loss = 1.2900e+00, PNorm = 42.7916, GNorm = 3.8388, lr_0 = 8.9861e-04
Validation rmse = 1.384803
Epoch 3
Loss = 1.1922e+00, PNorm = 42.8289, GNorm = 2.0004, lr_0 = 8.2767e-04
Validation rmse = 1.282370
Epoch 4
Loss = 1.1224e+00, PNorm = 42.8771, GNorm = 1.8965, lr_0 = 7.5609e-04
Validation rmse = 1.197606
Epoch 5
Loss = 1.0187e+00, PNorm = 42.9283, GNorm = 1.5492, lr_0 = 6.9640e-04
Validation rmse = 1.095665
Epoch 6
Loss = 9.7727e-01, PNorm = 42.9804, GNorm = 1.1215, lr_0 = 6.3617e-04
Validation rmse = 0.999772
Epoch 7
Loss = 8.7401e-01, PNorm = 43.0314, GNorm = 2.2036, lr_0 = 5.8115e-04
Validation rmse = 0.998529
Epoch 8
Loss = 8.3639e-01, PNorm = 43.0776, GNorm = 7.4778, lr_0 = 5.3527e-04
Validation rmse = 0.906887
Epoch 9
Loss = 8.0026e-01, PNorm = 43.1215, GNorm = 2.6339, lr_0 = 4.8897e-04
Validation rmse = 1.010101
Epoch 10
Loss = 8.1623e-01, PNorm = 43.1562, GNorm = 2.6981, lr_0 = 4.5037e-04
Validation rmse = 0.921555
Epoch 11
Loss = 7.5058e-01, PNorm = 43.1866, GNorm = 9.5140, lr_0 = 4.1142e-04
Validation rmse = 0.824048
Epoch 12
Loss = 6.6892e-01, PNorm = 43.2162, GNorm = 9.3572, lr_0 = 3.7584e-04
Validation rmse = 0.797221
Epoch 13
Loss = 6.3981e-01, PNorm = 43.2439, GNorm = 1.8510, lr_0 = 3.4617e-04
Validation rmse = 0.791067
Epoch 14
Loss = 6.5996e-01, PNorm = 43.2700, GNorm = 7.9352, lr_0 = 3.1623e-04
Validation rmse = 0.782898
Epoch 15
Loss = 6.3315e-01, PNorm = 43.2911, GNorm = 2.2235, lr_0 = 2.9126e-04
Validation rmse = 0.772730
Epoch 16
Loss = 5.5493e-01, PNorm = 43.3145, GNorm = 6.0333, lr_0 = 2.6607e-04
Validation rmse = 0.767899
Epoch 17
Loss = 5.8632e-01, PNorm = 43.3347, GNorm = 4.0047, lr_0 = 2.4306e-04
Validation rmse = 0.747403
Epoch 18
Loss = 5.5417e-01, PNorm = 43.3505, GNorm = 3.8429, lr_0 = 2.2387e-04
Validation rmse = 0.740316
Epoch 19
Loss = 5.7645e-01, PNorm = 43.3668, GNorm = 3.6756, lr_0 = 2.0451e-04
Validation rmse = 0.721243
Epoch 20
Loss = 4.1834e-01, PNorm = 43.3816, GNorm = 8.1382, lr_0 = 1.8836e-04
Validation rmse = 0.734155
Epoch 21
Loss = 4.8867e-01, PNorm = 43.3956, GNorm = 6.2907, lr_0 = 1.7207e-04
Validation rmse = 0.720649
Epoch 22
Loss = 4.9150e-01, PNorm = 43.4080, GNorm = 7.5359, lr_0 = 1.5719e-04
Validation rmse = 0.717341
Epoch 23
Loss = 4.4510e-01, PNorm = 43.4172, GNorm = 8.5786, lr_0 = 1.4478e-04
Validation rmse = 0.706490
Epoch 24
Loss = 3.8971e-01, PNorm = 43.4268, GNorm = 2.4562, lr_0 = 1.3226e-04
Loss = 4.7111e-01, PNorm = 43.4339, GNorm = 11.3122, lr_0 = 1.2182e-04
Validation rmse = 0.712726
Epoch 25
Loss = 4.6091e-01, PNorm = 43.4413, GNorm = 4.1989, lr_0 = 1.1220e-04
Loss = 5.5877e-01, PNorm = 43.4420, GNorm = 4.1632, lr_0 = 1.1128e-04
Validation rmse = 0.705247
Epoch 26
Loss = 4.4383e-01, PNorm = 43.4485, GNorm = 6.5032, lr_0 = 1.0250e-04
Loss = 4.6834e-01, PNorm = 43.4492, GNorm = 3.4938, lr_0 = 1.0166e-04
Validation rmse = 0.706491
Epoch 27
Loss = 4.4475e-01, PNorm = 43.4557, GNorm = 5.2554, lr_0 = 1.0000e-04
Validation rmse = 0.701679
Epoch 28
Loss = 4.3866e-01, PNorm = 43.4628, GNorm = 6.3584, lr_0 = 1.0000e-04
Validation rmse = 0.704637
Epoch 29
Loss = 4.4106e-01, PNorm = 43.4684, GNorm = 8.0683, lr_0 = 1.0000e-04
Validation rmse = 0.697843
Model 0 best validation rmse = 0.697843 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.748890
Ensemble test rmse = 0.748890
1-fold cross validation
	Seed 0 ==> test rmse = 0.748890
Overall test rmse = 0.748890 +/- 0.000000
Elapsed time = 0:01:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7478e+00, PNorm = 42.7379, GNorm = 1.9024, lr_0 = 5.5000e-04
Validation rmse = 1.550763
Epoch 1
Loss = 1.3899e+00, PNorm = 42.7478, GNorm = 0.5932, lr_0 = 1.0000e-03
Validation rmse = 1.531733
Epoch 2
Loss = 1.2906e+00, PNorm = 42.7803, GNorm = 2.3271, lr_0 = 9.2106e-04
Validation rmse = 1.354809
Epoch 3
Loss = 1.2221e+00, PNorm = 42.8261, GNorm = 2.1139, lr_0 = 8.4834e-04
Validation rmse = 1.277955
Epoch 4
Loss = 1.0905e+00, PNorm = 42.8790, GNorm = 0.9069, lr_0 = 7.8137e-04
Validation rmse = 1.162197
Epoch 5
Loss = 9.9190e-01, PNorm = 42.9337, GNorm = 4.1364, lr_0 = 7.2509e-04
Validation rmse = 1.045522
Epoch 6
Loss = 9.5971e-01, PNorm = 42.9903, GNorm = 6.6743, lr_0 = 6.6784e-04
Validation rmse = 0.928077
Epoch 7
Loss = 8.2843e-01, PNorm = 43.0463, GNorm = 2.6983, lr_0 = 6.1512e-04
Validation rmse = 0.868961
Epoch 8
Loss = 7.0796e-01, PNorm = 43.0897, GNorm = 5.1198, lr_0 = 5.6656e-04
Loss = 7.3533e-01, PNorm = 43.1323, GNorm = 4.8043, lr_0 = 5.2575e-04
Loss = 7.3508e-01, PNorm = 43.1367, GNorm = 5.3134, lr_0 = 5.2183e-04
Validation rmse = 0.896186
Epoch 9
Loss = 7.4927e-01, PNorm = 43.1714, GNorm = 5.4122, lr_0 = 4.8424e-04
Validation rmse = 0.791279
Epoch 10
Loss = 6.7932e-01, PNorm = 43.2018, GNorm = 14.3835, lr_0 = 4.4936e-04
Validation rmse = 0.782584
Epoch 11
Loss = 6.3464e-01, PNorm = 43.2270, GNorm = 3.2884, lr_0 = 4.1389e-04
Validation rmse = 0.756909
Epoch 12
Loss = 6.0766e-01, PNorm = 43.2558, GNorm = 13.0487, lr_0 = 3.8121e-04
Validation rmse = 0.782567
Epoch 13
Loss = 5.9482e-01, PNorm = 43.2783, GNorm = 11.4160, lr_0 = 3.5112e-04
Validation rmse = 0.729721
Epoch 14
Loss = 5.8270e-01, PNorm = 43.2987, GNorm = 2.1200, lr_0 = 3.2340e-04
Validation rmse = 0.712358
Epoch 15
Loss = 5.4293e-01, PNorm = 43.3162, GNorm = 6.8330, lr_0 = 3.0010e-04
Validation rmse = 0.706984
Epoch 16
Loss = 3.7985e-01, PNorm = 43.3357, GNorm = 3.5466, lr_0 = 2.7641e-04
Loss = 5.6759e-01, PNorm = 43.3491, GNorm = 3.7176, lr_0 = 2.5650e-04
Loss = 6.9159e-01, PNorm = 43.3499, GNorm = 17.8399, lr_0 = 2.5459e-04
Validation rmse = 0.763808
Epoch 17
Loss = 5.1989e-01, PNorm = 43.3611, GNorm = 6.7608, lr_0 = 2.3625e-04
Validation rmse = 0.716762
Epoch 18
Loss = 4.8832e-01, PNorm = 43.3739, GNorm = 7.4116, lr_0 = 2.1760e-04
Validation rmse = 0.709772
Epoch 19
Loss = 4.8833e-01, PNorm = 43.3862, GNorm = 4.9504, lr_0 = 2.0042e-04
Validation rmse = 0.700679
Epoch 20
Loss = 4.9734e-01, PNorm = 43.3957, GNorm = 6.1486, lr_0 = 1.8599e-04
Validation rmse = 0.686006
Epoch 21
Loss = 4.5015e-01, PNorm = 43.4060, GNorm = 2.4715, lr_0 = 1.7130e-04
Validation rmse = 0.702272
Epoch 22
Loss = 4.5385e-01, PNorm = 43.4162, GNorm = 12.5699, lr_0 = 1.5778e-04
Validation rmse = 0.678642
Epoch 23
Loss = 4.4708e-01, PNorm = 43.4250, GNorm = 7.5245, lr_0 = 1.4532e-04
Validation rmse = 0.680788
Epoch 24
Loss = 3.9456e-01, PNorm = 43.4328, GNorm = 9.0968, lr_0 = 1.3385e-04
Loss = 4.9495e-01, PNorm = 43.4393, GNorm = 7.4362, lr_0 = 1.2421e-04
Validation rmse = 0.675979
Epoch 25
Loss = 4.3625e-01, PNorm = 43.4443, GNorm = 7.0085, lr_0 = 1.1526e-04
Validation rmse = 0.671586
Epoch 26
Loss = 4.2343e-01, PNorm = 43.4514, GNorm = 7.6726, lr_0 = 1.0616e-04
Validation rmse = 0.670930
Epoch 27
Loss = 4.0156e-01, PNorm = 43.4560, GNorm = 6.2471, lr_0 = 1.0000e-04
Validation rmse = 0.669879
Epoch 28
Loss = 4.0341e-01, PNorm = 43.4612, GNorm = 12.0287, lr_0 = 1.0000e-04
Validation rmse = 0.663236
Epoch 29
Loss = 4.0205e-01, PNorm = 43.4661, GNorm = 8.4425, lr_0 = 1.0000e-04
Validation rmse = 0.658505
Model 0 best validation rmse = 0.658505 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.695041
Ensemble test rmse = 0.695041
1-fold cross validation
	Seed 0 ==> test rmse = 0.695041
Overall test rmse = 0.695041 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6827e+00, PNorm = 42.7366, GNorm = 0.9836, lr_0 = 5.1250e-04
Validation rmse = 1.565946
Epoch 1
Loss = 1.3814e+00, PNorm = 42.7433, GNorm = 1.5591, lr_0 = 8.8750e-04
Validation rmse = 1.529537
Epoch 2
Loss = 1.2933e+00, PNorm = 42.7749, GNorm = 2.1313, lr_0 = 9.5316e-04
Validation rmse = 1.421473
Epoch 3
Loss = 1.1471e+00, PNorm = 42.8144, GNorm = 1.2303, lr_0 = 8.9003e-04
Validation rmse = 1.247239
Epoch 4
Loss = 1.0924e+00, PNorm = 42.8665, GNorm = 3.1981, lr_0 = 8.3108e-04
Loss = 1.0276e+00, PNorm = 42.9293, GNorm = 2.8888, lr_0 = 7.7603e-04
Validation rmse = 1.139605
Epoch 5
Loss = 9.1891e-01, PNorm = 42.9900, GNorm = 5.5734, lr_0 = 7.2463e-04
Validation rmse = 1.037059
Epoch 6
Loss = 8.8312e-01, PNorm = 43.0389, GNorm = 4.7979, lr_0 = 6.7664e-04
Validation rmse = 0.998770
Epoch 7
Loss = 8.0403e-01, PNorm = 43.0848, GNorm = 3.8741, lr_0 = 6.3182e-04
Validation rmse = 0.852204
Epoch 8
Loss = 6.7266e-01, PNorm = 43.1279, GNorm = 3.2037, lr_0 = 5.8997e-04
Validation rmse = 0.819655
Epoch 9
Loss = 6.2855e-01, PNorm = 43.1696, GNorm = 2.0132, lr_0 = 5.5090e-04
Loss = 6.8011e-01, PNorm = 43.2069, GNorm = 5.4335, lr_0 = 5.1441e-04
Validation rmse = 0.823300
Epoch 10
Loss = 6.6494e-01, PNorm = 43.2402, GNorm = 12.1626, lr_0 = 4.8034e-04
Validation rmse = 0.745921
Epoch 11
Loss = 5.6090e-01, PNorm = 43.2751, GNorm = 2.9266, lr_0 = 4.4852e-04
Validation rmse = 0.742543
Epoch 12
Loss = 5.4242e-01, PNorm = 43.3053, GNorm = 14.2343, lr_0 = 4.1882e-04
Validation rmse = 0.728494
Epoch 13
Loss = 4.8594e-01, PNorm = 43.3325, GNorm = 3.2019, lr_0 = 3.9108e-04
Validation rmse = 0.735454
Epoch 14
Loss = 4.8721e-01, PNorm = 43.3550, GNorm = 4.6632, lr_0 = 3.6517e-04
Loss = 5.6859e-01, PNorm = 43.3759, GNorm = 15.5714, lr_0 = 3.4099e-04
Validation rmse = 0.691346
Epoch 15
Loss = 5.2077e-01, PNorm = 43.3942, GNorm = 10.5818, lr_0 = 3.1840e-04
Validation rmse = 0.718006
Epoch 16
Loss = 5.0899e-01, PNorm = 43.4108, GNorm = 9.3656, lr_0 = 2.9731e-04
Validation rmse = 0.689718
Epoch 17
Loss = 4.7786e-01, PNorm = 43.4270, GNorm = 3.2410, lr_0 = 2.7762e-04
Validation rmse = 0.729740
Epoch 18
Loss = 4.1161e-01, PNorm = 43.4443, GNorm = 22.3057, lr_0 = 2.5923e-04
Validation rmse = 0.685818
Epoch 19
Loss = 4.6763e-01, PNorm = 43.4567, GNorm = 1.9618, lr_0 = 2.4206e-04
Loss = 4.8898e-01, PNorm = 43.4705, GNorm = 17.2383, lr_0 = 2.2603e-04
Validation rmse = 0.716146
Epoch 20
Loss = 4.6723e-01, PNorm = 43.4821, GNorm = 8.7234, lr_0 = 2.1106e-04
Validation rmse = 0.678622
Epoch 21
Loss = 4.3430e-01, PNorm = 43.4944, GNorm = 3.3399, lr_0 = 1.9708e-04
Validation rmse = 0.671985
Epoch 22
Loss = 4.3067e-01, PNorm = 43.5046, GNorm = 4.0703, lr_0 = 1.8403e-04
Validation rmse = 0.663708
Epoch 23
Loss = 3.5928e-01, PNorm = 43.5148, GNorm = 2.2710, lr_0 = 1.7184e-04
Validation rmse = 0.660221
Epoch 24
Loss = 3.0713e-01, PNorm = 43.5228, GNorm = 3.1992, lr_0 = 1.6046e-04
Loss = 4.1727e-01, PNorm = 43.5315, GNorm = 3.4277, lr_0 = 1.4983e-04
Validation rmse = 0.660643
Epoch 25
Loss = 3.7920e-01, PNorm = 43.5393, GNorm = 6.6744, lr_0 = 1.3991e-04
Validation rmse = 0.658932
Epoch 26
Loss = 4.0241e-01, PNorm = 43.5468, GNorm = 14.3166, lr_0 = 1.3064e-04
Validation rmse = 0.655162
Epoch 27
Loss = 3.6407e-01, PNorm = 43.5546, GNorm = 8.6402, lr_0 = 1.2199e-04
Validation rmse = 0.661281
Epoch 28
Loss = 4.0284e-01, PNorm = 43.5603, GNorm = 7.4776, lr_0 = 1.1391e-04
Validation rmse = 0.678575
Epoch 29
Loss = 3.8716e-01, PNorm = 43.5660, GNorm = 6.8796, lr_0 = 1.0636e-04
Loss = 3.7546e-01, PNorm = 43.5717, GNorm = 5.5282, lr_0 = 1.0000e-04
Validation rmse = 0.658930
Model 0 best validation rmse = 0.655162 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.694294
Ensemble test rmse = 0.694294
1-fold cross validation
	Seed 0 ==> test rmse = 0.694294
Overall test rmse = 0.694294 +/- 0.000000
Elapsed time = 0:02:00
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,000 | train size = 800 | val size = 100 | test size = 100
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.266544
Epoch 1
Loss = 1.4823e+00, PNorm = 42.7398, GNorm = 1.9387, lr_0 = 7.1875e-04
Validation rmse = 1.184314
Epoch 2
Loss = 1.4428e+00, PNorm = 42.7516, GNorm = 0.5626, lr_0 = 9.4990e-04
Validation rmse = 1.140204
Epoch 3
Loss = 1.3721e+00, PNorm = 42.7730, GNorm = 0.6197, lr_0 = 8.5711e-04
Validation rmse = 1.112655
Epoch 4
Loss = 1.3427e+00, PNorm = 42.7943, GNorm = 0.7444, lr_0 = 7.7338e-04
Validation rmse = 1.073908
Epoch 5
Validation rmse = 1.071916
Epoch 6
Loss = 1.3411e+00, PNorm = 42.8221, GNorm = 0.6397, lr_0 = 6.9783e-04
Validation rmse = 1.025405
Epoch 7
Loss = 1.2636e+00, PNorm = 42.8517, GNorm = 0.7415, lr_0 = 6.2966e-04
Validation rmse = 0.990057
Epoch 8
Loss = 1.2200e+00, PNorm = 42.8887, GNorm = 0.5044, lr_0 = 5.6815e-04
Validation rmse = 0.964323
Epoch 9
Loss = 1.1756e+00, PNorm = 42.9334, GNorm = 2.5597, lr_0 = 5.1265e-04
Validation rmse = 0.927255
Epoch 10
Validation rmse = 0.907749
Epoch 11
Loss = 1.1093e+00, PNorm = 42.9820, GNorm = 3.3889, lr_0 = 4.6257e-04
Validation rmse = 0.859690
Epoch 12
Loss = 1.0367e+00, PNorm = 43.0312, GNorm = 2.0502, lr_0 = 4.1738e-04
Validation rmse = 0.846331
Epoch 13
Loss = 1.0149e+00, PNorm = 43.0743, GNorm = 3.5692, lr_0 = 3.7661e-04
Validation rmse = 0.820274
Epoch 14
Loss = 9.7168e-01, PNorm = 43.1143, GNorm = 1.6096, lr_0 = 3.3982e-04
Validation rmse = 0.816254
Epoch 15
Validation rmse = 0.792888
Epoch 16
Loss = 8.9335e-01, PNorm = 43.1478, GNorm = 2.9873, lr_0 = 3.0662e-04
Validation rmse = 0.790451
Epoch 17
Loss = 8.4879e-01, PNorm = 43.1800, GNorm = 1.5344, lr_0 = 2.7667e-04
Validation rmse = 0.779789
Epoch 18
Loss = 8.4258e-01, PNorm = 43.2062, GNorm = 3.5015, lr_0 = 2.4964e-04
Validation rmse = 0.767088
Epoch 19
Loss = 8.1481e-01, PNorm = 43.2290, GNorm = 4.6766, lr_0 = 2.2526e-04
Validation rmse = 0.764429
Epoch 20
Validation rmse = 0.748191
Epoch 21
Loss = 7.5549e-01, PNorm = 43.2509, GNorm = 3.3893, lr_0 = 2.0325e-04
Validation rmse = 0.749176
Epoch 22
Loss = 7.9648e-01, PNorm = 43.2716, GNorm = 3.6476, lr_0 = 1.8340e-04
Validation rmse = 0.742215
Epoch 23
Loss = 7.6864e-01, PNorm = 43.2888, GNorm = 12.7981, lr_0 = 1.6548e-04
Validation rmse = 0.752717
Epoch 24
Loss = 7.4434e-01, PNorm = 43.3031, GNorm = 9.0975, lr_0 = 1.4932e-04
Validation rmse = 0.734747
Epoch 25
Validation rmse = 0.736850
Epoch 26
Loss = 6.9216e-01, PNorm = 43.3165, GNorm = 3.9239, lr_0 = 1.3473e-04
Validation rmse = 0.727782
Epoch 27
Loss = 7.0311e-01, PNorm = 43.3280, GNorm = 1.7361, lr_0 = 1.2157e-04
Validation rmse = 0.728014
Epoch 28
Loss = 6.8106e-01, PNorm = 43.3388, GNorm = 7.8826, lr_0 = 1.0969e-04
Validation rmse = 0.722573
Epoch 29
Loss = 6.9278e-01, PNorm = 43.3480, GNorm = 3.2150, lr_0 = 1.0000e-04
Validation rmse = 0.718687
Model 0 best validation rmse = 0.718687 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.887537
Ensemble test rmse = 0.887537
1-fold cross validation
	Seed 0 ==> test rmse = 0.887537
Overall test rmse = 0.887537 +/- 0.000000
Elapsed time = 0:01:21
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,100 | train size = 880 | val size = 110 | test size = 110
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.394359
Epoch 1
Loss = 1.4863e+00, PNorm = 42.7407, GNorm = 0.7324, lr_0 = 7.7500e-04
Validation rmse = 1.352137
Epoch 2
Loss = 1.4093e+00, PNorm = 42.7633, GNorm = 1.3689, lr_0 = 9.4019e-04
Validation rmse = 1.380438
Epoch 3
Loss = 1.2808e+00, PNorm = 42.7927, GNorm = 0.6624, lr_0 = 8.4834e-04
Validation rmse = 1.248228
Epoch 4
Loss = 1.2439e+00, PNorm = 42.8220, GNorm = 0.6603, lr_0 = 7.6547e-04
Validation rmse = 1.206336
Epoch 5
Loss = 1.1924e+00, PNorm = 42.8575, GNorm = 3.8619, lr_0 = 6.9069e-04
Validation rmse = 1.182276
Epoch 6
Loss = 1.1608e+00, PNorm = 42.8985, GNorm = 5.6685, lr_0 = 6.1685e-04
Validation rmse = 1.074442
Epoch 7
Loss = 1.0979e+00, PNorm = 42.9409, GNorm = 1.6470, lr_0 = 5.5659e-04
Validation rmse = 1.027799
Epoch 8
Validation rmse = 1.001364
Epoch 9
Loss = 8.7631e-01, PNorm = 42.9821, GNorm = 1.2541, lr_0 = 5.0222e-04
Validation rmse = 1.030359
Epoch 10
Loss = 9.8883e-01, PNorm = 43.0221, GNorm = 3.8451, lr_0 = 4.5316e-04
Validation rmse = 0.958007
Epoch 11
Loss = 1.0562e+00, PNorm = 43.0580, GNorm = 12.0628, lr_0 = 4.0471e-04
Validation rmse = 0.980096
Epoch 12
Loss = 8.7253e-01, PNorm = 43.0871, GNorm = 1.4019, lr_0 = 3.6517e-04
Validation rmse = 1.011081
Epoch 13
Loss = 9.2571e-01, PNorm = 43.1142, GNorm = 8.4543, lr_0 = 3.2950e-04
Validation rmse = 1.016174
Epoch 14
Loss = 9.0813e-01, PNorm = 43.1373, GNorm = 6.7709, lr_0 = 2.9731e-04
Validation rmse = 0.971714
Epoch 15
Loss = 8.6830e-01, PNorm = 43.1599, GNorm = 9.7349, lr_0 = 2.6827e-04
Loss = 8.8095e-01, PNorm = 43.1620, GNorm = 6.1735, lr_0 = 2.6553e-04
Validation rmse = 0.975270
Epoch 16
Validation rmse = 0.954518
Epoch 17
Loss = 7.2004e-01, PNorm = 43.1820, GNorm = 1.7675, lr_0 = 2.3959e-04
Validation rmse = 0.920193
Epoch 18
Loss = 8.2025e-01, PNorm = 43.1995, GNorm = 9.3665, lr_0 = 2.1618e-04
Validation rmse = 0.908349
Epoch 19
Loss = 7.8175e-01, PNorm = 43.2166, GNorm = 4.6319, lr_0 = 1.9506e-04
Validation rmse = 0.972591
Epoch 20
Loss = 7.8466e-01, PNorm = 43.2318, GNorm = 6.1694, lr_0 = 1.7601e-04
Validation rmse = 0.932316
Epoch 21
Loss = 7.5873e-01, PNorm = 43.2465, GNorm = 5.0362, lr_0 = 1.5719e-04
Validation rmse = 0.923088
Epoch 22
Loss = 7.6531e-01, PNorm = 43.2597, GNorm = 8.1824, lr_0 = 1.4184e-04
Validation rmse = 0.897092
Epoch 23
Loss = 7.3902e-01, PNorm = 43.2712, GNorm = 8.0020, lr_0 = 1.2798e-04
Validation rmse = 0.883547
Epoch 24
Loss = 7.1298e-01, PNorm = 43.2822, GNorm = 2.3884, lr_0 = 1.1548e-04
Validation rmse = 0.885718
Epoch 25
Validation rmse = 0.941329
Epoch 26
Loss = 6.8316e-01, PNorm = 43.2923, GNorm = 3.2725, lr_0 = 1.0313e-04
Validation rmse = 0.948608
Epoch 27
Loss = 7.0040e-01, PNorm = 43.3008, GNorm = 1.4400, lr_0 = 1.0000e-04
Validation rmse = 0.896876
Epoch 28
Loss = 6.7371e-01, PNorm = 43.3092, GNorm = 6.8562, lr_0 = 1.0000e-04
Validation rmse = 0.897880
Epoch 29
Loss = 6.5319e-01, PNorm = 43.3181, GNorm = 6.2607, lr_0 = 1.0000e-04
Validation rmse = 0.931218
Model 0 best validation rmse = 0.883547 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.686165
Ensemble test rmse = 0.686165
1-fold cross validation
	Seed 0 ==> test rmse = 0.686165
Overall test rmse = 0.686165 +/- 0.000000
Elapsed time = 0:01:30
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,200 | train size = 960 | val size = 120 | test size = 120
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Validation rmse = 1.375573
Epoch 1
Loss = 1.4018e+00, PNorm = 42.7384, GNorm = 1.9371, lr_0 = 7.0000e-04
Validation rmse = 1.263921
Epoch 2
Loss = 1.3302e+00, PNorm = 42.7580, GNorm = 0.9037, lr_0 = 9.6411e-04
Validation rmse = 1.171351
Epoch 3
Loss = 1.2629e+00, PNorm = 42.7924, GNorm = 1.3020, lr_0 = 8.7192e-04
Validation rmse = 1.095251
Epoch 4
Loss = 1.2200e+00, PNorm = 42.8297, GNorm = 0.7797, lr_0 = 7.9578e-04
Validation rmse = 0.998025
Epoch 5
Loss = 1.1422e+00, PNorm = 42.8739, GNorm = 1.8234, lr_0 = 7.2629e-04
Validation rmse = 0.986838
Epoch 6
Loss = 1.0694e+00, PNorm = 42.9233, GNorm = 1.6816, lr_0 = 6.5684e-04
Validation rmse = 0.884114
Epoch 7
Loss = 1.0131e+00, PNorm = 42.9638, GNorm = 4.7039, lr_0 = 5.9948e-04
Validation rmse = 0.839451
Epoch 8
Loss = 9.9724e-01, PNorm = 43.0104, GNorm = 5.8306, lr_0 = 5.4216e-04
Validation rmse = 0.833105
Epoch 9
Loss = 9.0099e-01, PNorm = 43.0489, GNorm = 2.0650, lr_0 = 4.9482e-04
Validation rmse = 0.770740
Epoch 10
Loss = 8.7929e-01, PNorm = 43.0865, GNorm = 3.2645, lr_0 = 4.5161e-04
Validation rmse = 0.761522
Epoch 11
Loss = 8.6172e-01, PNorm = 43.1253, GNorm = 9.1378, lr_0 = 4.0842e-04
Validation rmse = 0.733483
Epoch 12
Loss = 7.6487e-01, PNorm = 43.1537, GNorm = 5.6500, lr_0 = 3.7276e-04
Validation rmse = 0.743647
Epoch 13
Loss = 7.2077e-01, PNorm = 43.1850, GNorm = 1.1668, lr_0 = 3.3711e-04
Validation rmse = 0.706120
Epoch 14
Loss = 7.5378e-01, PNorm = 43.2097, GNorm = 5.9100, lr_0 = 3.0768e-04
Validation rmse = 0.718412
Epoch 15
Loss = 7.1277e-01, PNorm = 43.2336, GNorm = 6.9320, lr_0 = 2.8081e-04
Validation rmse = 0.712664
Epoch 16
Loss = 7.0909e-01, PNorm = 43.2570, GNorm = 1.2923, lr_0 = 2.5396e-04
Validation rmse = 0.695582
Epoch 17
Loss = 6.5206e-01, PNorm = 43.2759, GNorm = 4.7753, lr_0 = 2.3178e-04
Validation rmse = 0.684304
Epoch 18
Loss = 6.4905e-01, PNorm = 43.2942, GNorm = 8.5743, lr_0 = 2.0962e-04
Validation rmse = 0.676848
Epoch 19
Loss = 6.2607e-01, PNorm = 43.3118, GNorm = 3.1990, lr_0 = 1.9131e-04
Validation rmse = 0.681564
Epoch 20
Loss = 6.3491e-01, PNorm = 43.3256, GNorm = 13.3596, lr_0 = 1.7461e-04
Validation rmse = 0.731915
Epoch 21
Loss = 6.2855e-01, PNorm = 43.3379, GNorm = 12.2295, lr_0 = 1.5791e-04
Validation rmse = 0.673677
Epoch 22
Loss = 6.0026e-01, PNorm = 43.3491, GNorm = 2.6038, lr_0 = 1.4412e-04
Loss = 4.9805e-01, PNorm = 43.3503, GNorm = 9.0285, lr_0 = 1.4281e-04
Validation rmse = 0.668886
Epoch 23
Loss = 5.9050e-01, PNorm = 43.3616, GNorm = 2.1460, lr_0 = 1.3034e-04
Validation rmse = 0.670949
Epoch 24
Loss = 5.7523e-01, PNorm = 43.3709, GNorm = 6.2363, lr_0 = 1.1896e-04
Validation rmse = 0.678575
Epoch 25
Validation rmse = 0.663961
Epoch 26
Loss = 5.1023e-01, PNorm = 43.3802, GNorm = 4.2307, lr_0 = 1.0758e-04
Validation rmse = 0.670214
Epoch 27
Loss = 5.1150e-01, PNorm = 43.3884, GNorm = 2.4094, lr_0 = 1.0000e-04
Validation rmse = 0.667293
Epoch 28
Loss = 5.0885e-01, PNorm = 43.3966, GNorm = 3.2699, lr_0 = 1.0000e-04
Validation rmse = 0.661615
Epoch 29
Loss = 5.4997e-01, PNorm = 43.4042, GNorm = 8.4678, lr_0 = 1.0000e-04
Validation rmse = 0.677163
Model 0 best validation rmse = 0.661615 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.696472
Ensemble test rmse = 0.696472
1-fold cross validation
	Seed 0 ==> test rmse = 0.696472
Overall test rmse = 0.696472 +/- 0.000000
Elapsed time = 0:01:43
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,300 | train size = 1,040 | val size = 130 | test size = 130
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.6899e+00, PNorm = 42.7373, GNorm = 0.9370, lr_0 = 5.9500e-04
Loss = 1.3828e+00, PNorm = 42.7371, GNorm = 2.1521, lr_0 = 6.4000e-04
Validation rmse = 1.572885
Epoch 1
Loss = 1.3942e+00, PNorm = 42.7518, GNorm = 0.8858, lr_0 = 9.8369e-04
Loss = 1.3394e+00, PNorm = 42.7546, GNorm = 1.0336, lr_0 = 9.7563e-04
Validation rmse = 1.468129
Epoch 2
Loss = 1.2860e+00, PNorm = 42.7890, GNorm = 0.8058, lr_0 = 8.9861e-04
Validation rmse = 1.336482
Epoch 3
Loss = 1.2011e+00, PNorm = 42.8345, GNorm = 1.5739, lr_0 = 8.2767e-04
Validation rmse = 1.221344
Epoch 4
Loss = 1.1212e+00, PNorm = 42.8884, GNorm = 0.7685, lr_0 = 7.5609e-04
Validation rmse = 1.103577
Epoch 5
Loss = 1.0438e+00, PNorm = 42.9382, GNorm = 1.2221, lr_0 = 6.9640e-04
Validation rmse = 0.994705
Epoch 6
Loss = 9.5516e-01, PNorm = 42.9906, GNorm = 1.5183, lr_0 = 6.3617e-04
Validation rmse = 0.911383
Epoch 7
Loss = 8.7671e-01, PNorm = 43.0436, GNorm = 3.3476, lr_0 = 5.8115e-04
Validation rmse = 0.849583
Epoch 8
Loss = 8.1659e-01, PNorm = 43.0874, GNorm = 6.6567, lr_0 = 5.3527e-04
Validation rmse = 0.804684
Epoch 9
Loss = 7.4995e-01, PNorm = 43.1234, GNorm = 3.2253, lr_0 = 4.8897e-04
Validation rmse = 0.793048
Epoch 10
Loss = 7.2348e-01, PNorm = 43.1548, GNorm = 2.5736, lr_0 = 4.5037e-04
Validation rmse = 0.766287
Epoch 11
Loss = 7.1256e-01, PNorm = 43.1911, GNorm = 11.3487, lr_0 = 4.1142e-04
Validation rmse = 0.752350
Epoch 12
Loss = 6.6366e-01, PNorm = 43.2180, GNorm = 8.0811, lr_0 = 3.7584e-04
Validation rmse = 0.748501
Epoch 13
Loss = 6.2738e-01, PNorm = 43.2446, GNorm = 6.8485, lr_0 = 3.4617e-04
Validation rmse = 0.725806
Epoch 14
Loss = 6.0670e-01, PNorm = 43.2688, GNorm = 1.6904, lr_0 = 3.1623e-04
Validation rmse = 0.754699
Epoch 15
Loss = 6.5953e-01, PNorm = 43.2889, GNorm = 18.3294, lr_0 = 2.9126e-04
Validation rmse = 0.716916
Epoch 16
Loss = 5.6314e-01, PNorm = 43.3088, GNorm = 9.4384, lr_0 = 2.6607e-04
Validation rmse = 0.718864
Epoch 17
Loss = 6.3245e-01, PNorm = 43.3243, GNorm = 3.7629, lr_0 = 2.4306e-04
Validation rmse = 0.735704
Epoch 18
Loss = 5.9136e-01, PNorm = 43.3370, GNorm = 7.1285, lr_0 = 2.2387e-04
Validation rmse = 0.716443
Epoch 19
Loss = 5.7091e-01, PNorm = 43.3517, GNorm = 3.0668, lr_0 = 2.0451e-04
Validation rmse = 0.693884
Epoch 20
Loss = 4.8088e-01, PNorm = 43.3633, GNorm = 4.5473, lr_0 = 1.8836e-04
Validation rmse = 0.693860
Epoch 21
Loss = 5.7812e-01, PNorm = 43.3757, GNorm = 1.7343, lr_0 = 1.7207e-04
Validation rmse = 0.686371
Epoch 22
Loss = 5.0676e-01, PNorm = 43.3862, GNorm = 13.4066, lr_0 = 1.5719e-04
Validation rmse = 0.699409
Epoch 23
Loss = 5.6706e-01, PNorm = 43.3963, GNorm = 8.8699, lr_0 = 1.4478e-04
Validation rmse = 0.680611
Epoch 24
Loss = 5.6271e-01, PNorm = 43.4054, GNorm = 5.5773, lr_0 = 1.3226e-04
Loss = 4.8967e-01, PNorm = 43.4138, GNorm = 3.0503, lr_0 = 1.2182e-04
Validation rmse = 0.678185
Epoch 25
Loss = 5.1329e-01, PNorm = 43.4203, GNorm = 16.2119, lr_0 = 1.1220e-04
Loss = 4.4673e-01, PNorm = 43.4210, GNorm = 12.5045, lr_0 = 1.1128e-04
Validation rmse = 0.686395
Epoch 26
Loss = 4.9859e-01, PNorm = 43.4278, GNorm = 5.6055, lr_0 = 1.0250e-04
Loss = 4.1956e-01, PNorm = 43.4284, GNorm = 3.8060, lr_0 = 1.0166e-04
Validation rmse = 0.677538
Epoch 27
Loss = 4.7697e-01, PNorm = 43.4338, GNorm = 9.4932, lr_0 = 1.0000e-04
Validation rmse = 0.675930
Epoch 28
Loss = 4.8268e-01, PNorm = 43.4399, GNorm = 7.0524, lr_0 = 1.0000e-04
Validation rmse = 0.675131
Epoch 29
Loss = 4.7957e-01, PNorm = 43.4464, GNorm = 15.3827, lr_0 = 1.0000e-04
Validation rmse = 0.695531
Model 0 best validation rmse = 0.675131 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.680265
Ensemble test rmse = 0.680265
1-fold cross validation
	Seed 0 ==> test rmse = 0.680265
Overall test rmse = 0.680265 +/- 0.000000
Elapsed time = 0:01:45
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,400 | train size = 1,120 | val size = 140 | test size = 140
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7459e+00, PNorm = 42.7378, GNorm = 1.8467, lr_0 = 5.5000e-04
Validation rmse = 1.530536
Epoch 1
Loss = 1.3972e+00, PNorm = 42.7473, GNorm = 1.1725, lr_0 = 1.0000e-03
Validation rmse = 1.441039
Epoch 2
Loss = 1.2920e+00, PNorm = 42.7800, GNorm = 2.4255, lr_0 = 9.2106e-04
Validation rmse = 1.348174
Epoch 3
Loss = 1.2282e+00, PNorm = 42.8234, GNorm = 3.4715, lr_0 = 8.4834e-04
Validation rmse = 1.194853
Epoch 4
Loss = 1.1293e+00, PNorm = 42.8719, GNorm = 3.1727, lr_0 = 7.8137e-04
Validation rmse = 1.054647
Epoch 5
Loss = 9.8176e-01, PNorm = 42.9253, GNorm = 1.9568, lr_0 = 7.2509e-04
Validation rmse = 0.952548
Epoch 6
Loss = 1.0139e+00, PNorm = 42.9799, GNorm = 4.5009, lr_0 = 6.6784e-04
Validation rmse = 0.939734
Epoch 7
Loss = 8.9742e-01, PNorm = 43.0314, GNorm = 1.7616, lr_0 = 6.1512e-04
Validation rmse = 0.829864
Epoch 8
Loss = 8.1135e-01, PNorm = 43.0786, GNorm = 2.1321, lr_0 = 5.6656e-04
Loss = 7.8862e-01, PNorm = 43.1157, GNorm = 1.1795, lr_0 = 5.2575e-04
Loss = 7.2839e-01, PNorm = 43.1191, GNorm = 6.6210, lr_0 = 5.2183e-04
Validation rmse = 0.843502
Epoch 9
Loss = 7.6664e-01, PNorm = 43.1497, GNorm = 5.3871, lr_0 = 4.8424e-04
Validation rmse = 0.787418
Epoch 10
Loss = 7.4113e-01, PNorm = 43.1750, GNorm = 5.5742, lr_0 = 4.4936e-04
Validation rmse = 0.761163
Epoch 11
Loss = 7.1489e-01, PNorm = 43.2072, GNorm = 1.7309, lr_0 = 4.1389e-04
Validation rmse = 0.742497
Epoch 12
Loss = 6.6407e-01, PNorm = 43.2355, GNorm = 8.3086, lr_0 = 3.8121e-04
Validation rmse = 0.732378
Epoch 13
Loss = 6.8715e-01, PNorm = 43.2607, GNorm = 7.4004, lr_0 = 3.5112e-04
Validation rmse = 0.751583
Epoch 14
Loss = 6.6432e-01, PNorm = 43.2837, GNorm = 4.8099, lr_0 = 3.2340e-04
Validation rmse = 0.705065
Epoch 15
Loss = 6.8642e-01, PNorm = 43.3011, GNorm = 6.3928, lr_0 = 3.0010e-04
Validation rmse = 0.716476
Epoch 16
Loss = 5.5409e-01, PNorm = 43.3204, GNorm = 5.5376, lr_0 = 2.7641e-04
Loss = 5.7949e-01, PNorm = 43.3392, GNorm = 2.6732, lr_0 = 2.5650e-04
Loss = 6.0244e-01, PNorm = 43.3407, GNorm = 5.7568, lr_0 = 2.5459e-04
Validation rmse = 0.694841
Epoch 17
Loss = 5.7315e-01, PNorm = 43.3547, GNorm = 5.4209, lr_0 = 2.3625e-04
Validation rmse = 0.698233
Epoch 18
Loss = 5.6173e-01, PNorm = 43.3697, GNorm = 5.4496, lr_0 = 2.1760e-04
Validation rmse = 0.686741
Epoch 19
Loss = 4.9631e-01, PNorm = 43.3857, GNorm = 8.3501, lr_0 = 2.0042e-04
Validation rmse = 0.720684
Epoch 20
Loss = 4.7203e-01, PNorm = 43.3962, GNorm = 13.4854, lr_0 = 1.8599e-04
Validation rmse = 0.692520
Epoch 21
Loss = 5.6901e-01, PNorm = 43.4073, GNorm = 2.7709, lr_0 = 1.7130e-04
Validation rmse = 0.678756
Epoch 22
Loss = 4.8572e-01, PNorm = 43.4194, GNorm = 4.2603, lr_0 = 1.5778e-04
Validation rmse = 0.674863
Epoch 23
Loss = 4.8557e-01, PNorm = 43.4306, GNorm = 5.9662, lr_0 = 1.4532e-04
Validation rmse = 0.704520
Epoch 24
Loss = 5.5860e-01, PNorm = 43.4393, GNorm = 15.8379, lr_0 = 1.3385e-04
Loss = 5.0365e-01, PNorm = 43.4463, GNorm = 11.8047, lr_0 = 1.2421e-04
Validation rmse = 0.696225
Epoch 25
Loss = 4.7929e-01, PNorm = 43.4537, GNorm = 5.2789, lr_0 = 1.1526e-04
Validation rmse = 0.674869
Epoch 26
Loss = 4.7193e-01, PNorm = 43.4624, GNorm = 2.8242, lr_0 = 1.0616e-04
Validation rmse = 0.662950
Epoch 27
Loss = 4.5172e-01, PNorm = 43.4685, GNorm = 3.1401, lr_0 = 1.0000e-04
Validation rmse = 0.667749
Epoch 28
Loss = 4.4076e-01, PNorm = 43.4756, GNorm = 2.2138, lr_0 = 1.0000e-04
Validation rmse = 0.662781
Epoch 29
Loss = 4.4937e-01, PNorm = 43.4820, GNorm = 5.5838, lr_0 = 1.0000e-04
Validation rmse = 0.659515
Model 0 best validation rmse = 0.659515 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.661321
Ensemble test rmse = 0.661321
1-fold cross validation
	Seed 0 ==> test rmse = 0.661321
Overall test rmse = 0.661321 +/- 0.000000
Elapsed time = 0:01:53
Command line
python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-81534e88-5d85-475e-81a9-01c1a0c46592.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 100,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model',
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': ['/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt'],
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/mc_train_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'ignore_nan_metrics': False,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mve',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quantile_loss_alpha': 0.1,
 'quantiles': [],
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/fine_tuned_model',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['target'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 1,500 | train size = 1,200 | val size = 150 | test size = 150
Fitting scaler
Loading model 0 from /Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/pretrained_model/fold_0/model_0/model.pt
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
MoleculeModel(
  (softplus): Softplus(beta=1, threshold=20)
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=2, bias=True)
  )
)
Number of parameters = 355,502
Epoch 0
Loss = 1.7687e+00, PNorm = 42.7364, GNorm = 1.1340, lr_0 = 5.1250e-04
Validation rmse = 1.496992
Epoch 1
Loss = 1.4030e+00, PNorm = 42.7430, GNorm = 0.9009, lr_0 = 8.8750e-04
Validation rmse = 1.399644
Epoch 2
Loss = 1.2743e+00, PNorm = 42.7719, GNorm = 2.0413, lr_0 = 9.5316e-04
Validation rmse = 1.254037
Epoch 3
Loss = 1.2103e+00, PNorm = 42.8129, GNorm = 2.5583, lr_0 = 8.9003e-04
Validation rmse = 1.180779
Epoch 4
Loss = 1.0824e+00, PNorm = 42.8646, GNorm = 1.1056, lr_0 = 8.3108e-04
Loss = 1.0871e+00, PNorm = 42.9194, GNorm = 1.8836, lr_0 = 7.7603e-04
Validation rmse = 1.048704
Epoch 5
Loss = 9.8707e-01, PNorm = 42.9826, GNorm = 3.2277, lr_0 = 7.2463e-04
Validation rmse = 0.932240
Epoch 6
Loss = 8.9052e-01, PNorm = 43.0372, GNorm = 1.9732, lr_0 = 6.7664e-04
Validation rmse = 0.885007
Epoch 7
Loss = 8.2941e-01, PNorm = 43.0840, GNorm = 3.6741, lr_0 = 6.3182e-04
Validation rmse = 0.849556
Epoch 8
Loss = 8.4938e-01, PNorm = 43.1249, GNorm = 9.2657, lr_0 = 5.8997e-04
Validation rmse = 0.861018
Epoch 9
Loss = 7.5936e-01, PNorm = 43.1585, GNorm = 6.5261, lr_0 = 5.5090e-04
Loss = 7.6366e-01, PNorm = 43.1933, GNorm = 9.3540, lr_0 = 5.1441e-04
Validation rmse = 0.853646
Epoch 10
Loss = 7.1113e-01, PNorm = 43.2265, GNorm = 2.3643, lr_0 = 4.8034e-04
Validation rmse = 0.770146
Epoch 11
Loss = 6.6451e-01, PNorm = 43.2603, GNorm = 10.5271, lr_0 = 4.4852e-04
Validation rmse = 0.763251
Epoch 12
Loss = 6.9398e-01, PNorm = 43.2823, GNorm = 6.9410, lr_0 = 4.1882e-04
Validation rmse = 0.813917
Epoch 13
Loss = 6.3179e-01, PNorm = 43.3095, GNorm = 4.0887, lr_0 = 3.9108e-04
Validation rmse = 0.751968
Epoch 14
Loss = 6.4718e-01, PNorm = 43.3349, GNorm = 3.6181, lr_0 = 3.6517e-04
Loss = 5.8585e-01, PNorm = 43.3590, GNorm = 6.6976, lr_0 = 3.4099e-04
Validation rmse = 0.720755
Epoch 15
Loss = 5.7305e-01, PNorm = 43.3792, GNorm = 4.7102, lr_0 = 3.1840e-04
Validation rmse = 0.697996
Epoch 16
Loss = 5.4060e-01, PNorm = 43.4001, GNorm = 2.8809, lr_0 = 2.9731e-04
Validation rmse = 0.698040
Epoch 17
Loss = 5.1377e-01, PNorm = 43.4201, GNorm = 5.9845, lr_0 = 2.7762e-04
Validation rmse = 0.686994
Epoch 18
Loss = 5.3452e-01, PNorm = 43.4373, GNorm = 7.8400, lr_0 = 2.5923e-04
Validation rmse = 0.688711
Epoch 19
Loss = 4.7644e-01, PNorm = 43.4539, GNorm = 3.3164, lr_0 = 2.4206e-04
Loss = 5.3543e-01, PNorm = 43.4688, GNorm = 9.1165, lr_0 = 2.2603e-04
Validation rmse = 0.755528
Epoch 20
Loss = 5.4760e-01, PNorm = 43.4824, GNorm = 10.9848, lr_0 = 2.1106e-04
Validation rmse = 0.693454
Epoch 21
Loss = 4.8856e-01, PNorm = 43.4959, GNorm = 4.7322, lr_0 = 1.9708e-04
Validation rmse = 0.684618
Epoch 22
Loss = 4.8234e-01, PNorm = 43.5078, GNorm = 12.1457, lr_0 = 1.8403e-04
Validation rmse = 0.694771
Epoch 23
Loss = 5.4478e-01, PNorm = 43.5188, GNorm = 7.7178, lr_0 = 1.7184e-04
Validation rmse = 0.693048
Epoch 24
Loss = 4.5222e-01, PNorm = 43.5287, GNorm = 2.8584, lr_0 = 1.6046e-04
Loss = 4.5960e-01, PNorm = 43.5387, GNorm = 4.8301, lr_0 = 1.4983e-04
Validation rmse = 0.662742
Epoch 25
Loss = 4.5518e-01, PNorm = 43.5475, GNorm = 7.1293, lr_0 = 1.3991e-04
Validation rmse = 0.661188
Epoch 26
Loss = 4.2952e-01, PNorm = 43.5558, GNorm = 6.5395, lr_0 = 1.3064e-04
Validation rmse = 0.662279
Epoch 27
Loss = 4.6932e-01, PNorm = 43.5645, GNorm = 11.6265, lr_0 = 1.2199e-04
Validation rmse = 0.655130
Epoch 28
Loss = 4.1533e-01, PNorm = 43.5707, GNorm = 8.7103, lr_0 = 1.1391e-04
Validation rmse = 0.690236
Epoch 29
Loss = 4.4490e-01, PNorm = 43.5779, GNorm = 12.8321, lr_0 = 1.0636e-04
Loss = 4.3962e-01, PNorm = 43.5842, GNorm = 3.6677, lr_0 = 1.0000e-04
Validation rmse = 0.678287
Model 0 best validation rmse = 0.655130 on epoch 27
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test rmse = 0.658663
Ensemble test rmse = 0.658663
1-fold cross validation
	Seed 0 ==> test rmse = 0.658663
Overall test rmse = 0.658663 +/- 0.000000
Elapsed time = 0:02:01
