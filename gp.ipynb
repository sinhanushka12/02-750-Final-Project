{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will run various query seleciton methods and evaluate performance using a Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)N)Cl</td>\n",
       "      <td>5.608397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...</td>\n",
       "      <td>7.972925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...</td>\n",
       "      <td>6.731267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...</td>\n",
       "      <td>7.653882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...</td>\n",
       "      <td>6.562022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CF)Cl</td>\n",
       "      <td>7.232871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CO)Cl</td>\n",
       "      <td>7.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)Cl)Cl</td>\n",
       "      <td>7.756025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl</td>\n",
       "      <td>9.215634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>c1coc(n1)Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl</td>\n",
       "      <td>8.817224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9997 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles    target\n",
       "0               C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)N)Cl  5.608397\n",
       "1     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  7.972925\n",
       "2     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  6.731267\n",
       "3     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  7.653882\n",
       "4     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  6.562022\n",
       "...                                                 ...       ...\n",
       "9992     c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CF)Cl  7.232871\n",
       "9993     c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CO)Cl  7.230769\n",
       "9994     c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)Cl)Cl  7.756025\n",
       "9995      c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl  9.215634\n",
       "9996     c1coc(n1)Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl  8.817224\n",
       "\n",
       "[9997 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in data and subsetting columns\n",
    "data = pd.read_csv(\"TYK2_final.csv\")\n",
    "data = data.drop(['target', 'top_2p', 'top_5p'], axis=1)\n",
    "column_names = ['smiles', 'target']\n",
    "data.columns = column_names\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles    target  \\\n",
      "0            C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)N)Cl  5.608397   \n",
      "1  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  7.972925   \n",
      "2  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  6.731267   \n",
      "3  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  7.653882   \n",
      "4  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  6.562022   \n",
      "\n",
      "                                         fingerprint  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "#Converting to fingerprints\n",
    "def smiles_to_fingerprint(smiles, nBits=4096):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=4, nBits=nBits, useChirality=True)\n",
    "    return list(fp)\n",
    "\n",
    "data['fingerprint'] = data['smiles'].apply(smiles_to_fingerprint)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([val for val in data['fingerprint'].values])\n",
    "y = data['target'].values.reshape(-1,1)\n",
    "X, y = shuffle(X,y, random_state=1)\n",
    "\n",
    "size = int(len(X) * 0.1)\n",
    "start_X = X[:size]\n",
    "start_y = y[:size]\n",
    "\n",
    "remaining_X = X[size:]\n",
    "remaining_y = y[size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform random sampling, we will randomly select 80% of the instances from the dataset to train on, and evaluate with the remaining 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(batch_size):\n",
    "    seeds = [1]\n",
    "\n",
    "    rmse_vals = []\n",
    "    r2_vals = []\n",
    "    spear_vals = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        rmse_instance =[]\n",
    "        r2_instance = []\n",
    "        spear_instance = []\n",
    "\n",
    "         #Getting X and y values to start with\n",
    "        X = np.array([val for val in data['fingerprint'].values])\n",
    "        y = data['target'].values.reshape(-1,1)\n",
    "        X, y = shuffle(X,y, random_state=seed)\n",
    "\n",
    "        size = int(len(X) * 0.1)\n",
    "        start_X = X[:size]\n",
    "        start_y = y[:size]\n",
    "\n",
    "        remaining_X = X[size:]\n",
    "        remaining_y = y[size:]\n",
    "\n",
    "        while len(start_X) < round(((len(X) * 0.2) / 500 )) * 500:\n",
    "\n",
    "            if len(start_X) % 500 == 0:\n",
    "                #creating kernel\n",
    "                k = GPy.kern.Linear(start_X.shape[1])\n",
    "\n",
    "                #training and optimizing GP regression model\n",
    "                m = GPy.models.SparseGPRegression(start_X, start_y, k, num_inducing=50)\n",
    "                print(\"model trained\")\n",
    "                #m.optimize('bfgs', max_iters=10)\n",
    "                print(\"model optimized\")\n",
    "\n",
    "\n",
    "                #Predicting on final 20%\n",
    "                pred_means, pred_vars = m.predict(remaining_X)\n",
    "\n",
    "                #Getting rmse score\n",
    "                rmse_instance.append(np.sqrt(mean_squared_error(remaining_y, pred_means)))\n",
    "                r2_instance.append(r2_score(remaining_y, pred_means))\n",
    "                spear_instance.append(spearmanr(remaining_y, pred_means)[1])\n",
    "            \n",
    "\n",
    "            #adding the row of the selected index to the starting data\n",
    "            start_X = np.vstack((start_X, remaining_X[:batch_size]))\n",
    "            start_y = np.vstack((start_y, remaining_y[:batch_size]))\n",
    "\n",
    "            #removing the row of the selected index from the remaining data\n",
    "            #Testing on remaining 20%\n",
    "            remaining_X = remaining_X[batch_size:]\n",
    "            remaining_y = remaining_y[batch_size:]\n",
    "\n",
    "        rmse_vals.append(rmse_instance)\n",
    "        r2_vals.append(r2_instance)\n",
    "        spear_vals.append(spear_instance)\n",
    "\n",
    "        \n",
    "    return rmse_vals, r2_vals, spear_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1]\n",
    "rand_rmse_dict = {}\n",
    "rand_r2_dict = {}\n",
    "rand_spear_dict = {}\n",
    "\n",
    "final_rand_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    rand_rmse, rand_r2, rand_spear = random_sampling(batch)\n",
    "\n",
    "    rand_rmse_mean = np.mean(rand_rmse, axis=0)\n",
    "    rand_rmse_stdev = np.std(rand_rmse, axis=0)\n",
    "    print(\"mean:\", rand_rmse_mean)\n",
    "    print(\"standard deviation:\", rand_rmse_stdev)\n",
    "    rand_rmse_dict[batch] = (rand_rmse, rand_rmse_mean, rand_rmse_stdev)\n",
    "    final_rand_data[f\"{batch}_rmse_mean\"] = rand_rmse_mean\n",
    "    final_rand_data[f\"{batch}_rmse_stdev\"] = rand_rmse_stdev\n",
    "\n",
    "\n",
    "    rand_r2_mean = np.mean(rand_r2, axis=0)\n",
    "    rand_r2_stdev = np.std(rand_r2, axis=0)\n",
    "    print(\"mean:\", rand_r2_mean)\n",
    "    print(\"standard deviation:\", rand_r2_stdev)\n",
    "    rand_r2_dict[batch] = (rand_r2, rand_r2_mean, rand_r2_stdev)\n",
    "    final_rand_data[f\"{batch}_r2_mean\"] = rand_r2_mean\n",
    "    final_rand_data[f\"{batch}_r2_stdev\"] = rand_r2_stdev\n",
    "\n",
    "    rand_spear_mean = np.mean(rand_spear, axis=0)\n",
    "    rand_spear_stdev = np.std(rand_spear, axis=0)\n",
    "    print(\"mean:\", rand_spear_mean)\n",
    "    print(\"standard deviation:\", rand_spear_stdev)\n",
    "    rand_spear_dict[batch] = (rand_spear, rand_spear_mean, rand_spear_stdev)\n",
    "    final_rand_data[f\"{batch}_spear_mean\"] = rand_spear_mean\n",
    "    final_rand_data[f\"{batch}_spear_stdev\"] = rand_spear_stdev\n",
    "\n",
    "\n",
    "final_rand_data.to_csv(\"final_data_random.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainity Sampling\n",
    "## Mean, Variance, UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function runs sequential model-based optimization. This function works by training a sparse GP model on the start data, \n",
    "#and using a selection/activation function that performs UCB to select the data point to query.\n",
    "\n",
    "#Input: starting data and unlabeled remaining data\n",
    "#Output: Instance with the maximum GP mean upon prediction, as well as the actual value (if it is 9.0)\n",
    "\n",
    "def smbo(start_X, start_y, remaining_X):\n",
    "    \n",
    "    k = GPy.kern.Linear(start_X.shape[1])\n",
    "\n",
    "    m = GPy.models.SparseGPRegression(start_X, start_y, k, num_inducing=50)\n",
    "\n",
    "    #m.optimize('bfgs', max_iters=10)\n",
    "\n",
    "    print(\"predicting smbo model\")\n",
    "    mean, var = m.predict(remaining_X, full_cov=False)\n",
    "\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_sampling(flag, batch_size):\n",
    "    seeds = [1]\n",
    "\n",
    "    rmse_vals = []\n",
    "    r2_vals = []\n",
    "    spear_vals = []\n",
    "\n",
    "    for seed in seeds:\n",
    "\n",
    "        rmse_instance =[]\n",
    "        r2_instance = []\n",
    "        spear_instance = []\n",
    "        \n",
    "        #Getting X and y values to start with\n",
    "        X = np.array([val for val in data['fingerprint'].values])\n",
    "        y = data['target'].values.reshape(-1,1)\n",
    "        X, y = shuffle(X,y, random_state=seed)\n",
    "\n",
    "        size = int(len(X) * 0.1)\n",
    "        start_X = X[:size]\n",
    "        start_y = y[:size]\n",
    "\n",
    "        remaining_X = X[size:]\n",
    "        remaining_y = y[size:]\n",
    "\n",
    "        #set initial variables for calculating UCB\n",
    "        Dsize = len(X)\n",
    "        bo_lambda = 0.1 #ADJUST LATER\n",
    "        bo_iters = 1 #ADJUST LATER\n",
    "\n",
    "        #calculate beta constant from \n",
    "        beta = 2 * math.log(Dsize * math.pow(bo_iters,2) * math.pow(np.pi,2) / (6 * bo_lambda) )\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        #Until we sample another 70%...\n",
    "        while len(start_X) <= round(((len(X) * 0.2) / 500 )) * 500:\n",
    "\n",
    "            #run smbo and get the sparse GP parameters to select the next instance\n",
    "            mean, var = smbo(start_X, start_y, remaining_X)\n",
    "\n",
    "            #depending on the selection function, we calculate a specific alpha_full value\n",
    "            if flag == \"ucb\":\n",
    "                #get the UCB value at each x\n",
    "                alpha_full = mean + math.sqrt(beta) * var\n",
    "            elif flag == \"mean\":\n",
    "                alpha_full = mean\n",
    "            else:\n",
    "                alpha_full = var\n",
    "\n",
    "            #get the index for the row with the largest UCB\n",
    "            sorted = np.argsort(alpha_full)\n",
    "            inds = sorted[-batch_size:]\n",
    "            inds = np.sort(inds)[::-1]\n",
    "\n",
    "            for ind in inds:\n",
    "                #adding the row of the selected index to the starting data\n",
    "                start_X = np.vstack((start_X, remaining_X[ind,:]))\n",
    "                start_y = np.vstack((start_y, remaining_y[ind]))\n",
    "\n",
    "                #removing the row of the selected index from the remaining data\n",
    "                remaining_X = np.delete(remaining_X, ind, axis=0)\n",
    "                remaining_y = np.delete(remaining_y, ind)\n",
    "\n",
    "\n",
    "            if counter % 500 == 0:\n",
    "                #creating kernel\n",
    "                k = GPy.kern.Linear(start_X.shape[1])\n",
    "\n",
    "                #training and optimizing GP regression model\n",
    "                m = GPy.models.SparseGPRegression(start_X, start_y, k, num_inducing=50)\n",
    "                m.optimize('bfgs', max_iters=10)\n",
    "\n",
    "                #Predicting on final 20%\n",
    "                pred_means, pred_vars = m.predict(remaining_X)\n",
    "                print(\"plotting model predictions\")\n",
    "\n",
    "                #Getting rmse score\n",
    "                rmse_instance.append(np.sqrt(mean_squared_error(remaining_y, pred_means)))\n",
    "                r2_instance.append(r2_score(remaining_y, pred_means))\n",
    "                spear = spearmanr(remaining_y, pred_means)\n",
    "                spear_instance.append(spear.statistic)\n",
    "\n",
    "            counter += batch_size\n",
    "\n",
    "        rmse_vals.append(rmse_instance)\n",
    "        r2_vals.append(r2_instance)\n",
    "        spear_vals.append(spear_instance)\n",
    "            \n",
    "    #return r2 vals\n",
    "    return r2_vals\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1]\n",
    "flag = \"ucb\"\n",
    "ucb_rmse_dict = {}\n",
    "ucb_r2_dict = {}\n",
    "ucb_spear_dict = {}\n",
    "\n",
    "final_ucb_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    ucb_rmse, ucb_r2, ucb_spear = uncertainty_sampling(flag, batch)\n",
    "\n",
    "    ucb_rmse_mean = np.mean(ucb_rmse, axis=0)\n",
    "    ucb_rmse_stdev = np.std(ucb_rmse, axis=0)\n",
    "    print(\"mean:\", ucb_rmse_mean)\n",
    "    print(\"standard deviation:\", ucb_rmse_stdev)\n",
    "    ucb_rmse_dict[batch] = (ucb_rmse, ucb_rmse_mean, ucb_rmse_stdev)\n",
    "    final_ucb_data[f\"{batch}_rmse_mean\"] = ucb_rmse_mean\n",
    "    final_ucb_data[f\"{batch}_rmse_stdev\"] = ucb_rmse_stdev\n",
    "\n",
    "\n",
    "    ucb_r2_mean = np.mean(ucb_r2, axis=0)\n",
    "    ucb_r2_stdev = np.std(ucb_r2, axis=0)\n",
    "    print(\"mean:\", ucb_r2_mean)\n",
    "    print(\"standard deviation:\", ucb_r2_stdev)\n",
    "    ucb_r2_dict[batch] = (ucb_r2, ucb_r2_mean, ucb_r2_stdev)\n",
    "    final_ucb_data[f\"{batch}_r2_mean\"] = ucb_r2_mean\n",
    "    final_ucb_data[f\"{batch}_r2_stdev\"] = ucb_r2_stdev\n",
    "\n",
    "    ucb_spear_mean = np.mean(ucb_spear, axis=0)\n",
    "    ucb_spear_stdev = np.std(ucb_spear, axis=0)\n",
    "    print(\"mean:\", ucb_spear_mean)\n",
    "    print(\"standard deviation:\", ucb_spear_stdev)\n",
    "    ucb_spear_dict[batch] = (ucb_spear, ucb_spear_mean, ucb_spear_stdev)\n",
    "    final_ucb_data[f\"{batch}_spear_mean\"] = ucb_spear_mean\n",
    "    final_ucb_data[f\"{batch}_spear_stdev\"] = ucb_spear_stdev\n",
    "\n",
    "\n",
    "final_ucb_data.to_csv(\"final_data_ucb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting smbo model\n",
      "plotting model predictions\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n",
      "predicting smbo model\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1]\n",
    "flag = \"mean\"\n",
    "mean_rmse_dict = {}\n",
    "mean_r2_dict = {}\n",
    "mean_spear_dict = {}\n",
    "\n",
    "final_mean_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    mean_rmse, mean_r2, mean_spear = uncertainty_sampling(flag, batch)\n",
    "\n",
    "    mean_rmse_mean = np.mean(mean_rmse, axis=0)\n",
    "    mean_rmse_stdev = np.std(mean_rmse, axis=0)\n",
    "    print(\"mean:\", mean_rmse_mean)\n",
    "    print(\"standard deviation:\", mean_rmse_stdev)\n",
    "    mean_rmse_dict[batch] = (mean_rmse, mean_rmse_mean, mean_rmse_stdev)\n",
    "    final_mean_data[f\"{batch}_rmse_mean\"] = mean_rmse_mean\n",
    "    final_mean_data[f\"{batch}_rmse_stdev\"] = mean_rmse_stdev\n",
    "\n",
    "\n",
    "    mean_r2_mean = np.mean(mean_r2, axis=0)\n",
    "    mean_r2_stdev = np.std(mean_r2, axis=0)\n",
    "    print(\"mean:\", mean_r2_mean)\n",
    "    print(\"standard deviation:\", mean_r2_stdev)\n",
    "    mean_r2_dict[batch] = (mean_r2, mean_r2_mean, mean_r2_stdev)\n",
    "    final_mean_data[f\"{batch}_r2_mean\"] = mean_r2_mean\n",
    "    final_mean_data[f\"{batch}_r2_stdev\"] = mean_r2_stdev\n",
    "\n",
    "    mean_spear_mean = np.mean(mean_spear, axis=0)\n",
    "    mean_spear_stdev = np.std(mean_spear, axis=0)\n",
    "    print(\"mean:\", mean_spear_mean)\n",
    "    print(\"standard deviation:\", mean_spear_stdev)\n",
    "    mean_spear_dict[batch] = (mean_spear, mean_spear_mean, mean_spear_stdev)\n",
    "    final_mean_data[f\"{batch}_spear_mean\"] = mean_spear_mean\n",
    "    final_mean_data[f\"{batch}_spear_stdev\"] = mean_spear_stdev\n",
    "\n",
    "\n",
    "final_mean_data.to_csv(\"final_data_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1,25,50]\n",
    "flag = \"var\"\n",
    "var_rmse_dict = {}\n",
    "var_r2_dict = {}\n",
    "var_spear_dict = {}\n",
    "\n",
    "final_var_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    var_rmse, var_r2, var_spear = uncertainty_sampling(flag, batch)\n",
    "\n",
    "    var_rmse_mean = np.mean(var_rmse, axis=0)\n",
    "    var_rmse_stdev = np.std(var_rmse, axis=0)\n",
    "    print(\"mean:\", var_rmse_mean)\n",
    "    print(\"standard deviation:\", var_rmse_stdev)\n",
    "    var_rmse_dict[batch] = (var_rmse, var_rmse_mean, var_rmse_stdev)\n",
    "    final_var_data[f\"{batch}_rmse_mean\"] = var_rmse_mean\n",
    "    final_var_data[f\"{batch}_rmse_stdev\"] = var_rmse_stdev\n",
    "\n",
    "\n",
    "    var_r2_mean = np.mean(var_r2, axis=0)\n",
    "    var_r2_stdev = np.std(var_r2, axis=0)\n",
    "    print(\"mean:\", var_r2_mean)\n",
    "    print(\"standard deviation:\", var_r2_stdev)\n",
    "    var_r2_dict[batch] = (var_r2, var_r2_mean, var_r2_stdev)\n",
    "    final_var_data[f\"{batch}_r2_mean\"] = var_r2_mean\n",
    "    final_var_data[f\"{batch}_r2_stdev\"] = var_r2_stdev\n",
    "\n",
    "    var_spear_mean = np.mean(var_spear, axis=0)\n",
    "    var_spear_stdev = np.std(var_spear, axis=0)\n",
    "    print(\"mean:\", var_spear_mean)\n",
    "    print(\"standard deviation:\", var_spear_stdev)\n",
    "    var_spear_dict[batch] = (var_spear, var_spear_mean, var_spear_stdev)\n",
    "    final_var_data[f\"{batch}_spear_mean\"] = var_spear_mean\n",
    "    final_var_data[f\"{batch}_spear_stdev\"] = var_spear_stdev\n",
    "\n",
    "\n",
    "final_var_data.to_csv(\"final_data_var.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
