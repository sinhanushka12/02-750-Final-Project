{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will run various query seleciton methods and evaluate performance using a Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)N)Cl</td>\n",
       "      <td>5.608397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...</td>\n",
       "      <td>7.972925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...</td>\n",
       "      <td>6.731267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...</td>\n",
       "      <td>7.653882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...</td>\n",
       "      <td>6.562022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CF)Cl</td>\n",
       "      <td>7.232871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CO)Cl</td>\n",
       "      <td>7.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)Cl)Cl</td>\n",
       "      <td>7.756025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl</td>\n",
       "      <td>9.215634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>c1coc(n1)Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl</td>\n",
       "      <td>8.817224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9997 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles    target\n",
       "0               C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)N)Cl  5.608397\n",
       "1     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  7.972925\n",
       "2     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  6.731267\n",
       "3     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  7.653882\n",
       "4     C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  6.562022\n",
       "...                                                 ...       ...\n",
       "9992     c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CF)Cl  7.232871\n",
       "9993     c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)CO)Cl  7.230769\n",
       "9994     c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)Cl)Cl  7.756025\n",
       "9995      c1cncnc1Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl  9.215634\n",
       "9996     c1coc(n1)Nc2cc(c(cn2)F)NC(=O)c3c(cc(cc3Cl)N)Cl  8.817224\n",
       "\n",
       "[9997 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in data and subsetting columns\n",
    "data = pd.read_csv(\"TYK2_final.csv\")\n",
    "data = data.drop(['target', 'top_2p', 'top_5p'], axis=1)\n",
    "column_names = ['smiles', 'target']\n",
    "data.columns = column_names\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles    target  \\\n",
      "0            C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)N)Cl  5.608397   \n",
      "1  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  7.972925   \n",
      "2  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC(...  6.731267   \n",
      "3  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  7.653882   \n",
      "4  C=Cc1cc(c(c(c1)Cl)C(=O)Nc2cc(ncc2F)NC(=O)C3CC3...  6.562022   \n",
      "\n",
      "                                         fingerprint  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "#Converting to fingerprints\n",
    "def smiles_to_fingerprint(smiles, nBits=4096):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=4, nBits=nBits, useChirality=True)\n",
    "    return list(fp)\n",
    "\n",
    "data['fingerprint'] = data['smiles'].apply(smiles_to_fingerprint)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"TYK2_fingerprints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform random sampling, we will randomly select 80% of the instances from the dataset to train on, and evaluate with the remaining 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(batch_size):\n",
    "    seeds = [1, 2, 3]\n",
    "\n",
    "    rmse_vals = []\n",
    "    r2_vals = []\n",
    "  \n",
    "    for seed in seeds:\n",
    "        rmse_instance =[]\n",
    "        r2_instance = []\n",
    "      \n",
    "        #Getting X and y values to start with\n",
    "        X = np.array([val for val in data['fingerprint'].values])\n",
    "        y = data['target'].values.reshape(-1,1)\n",
    "        X, y = shuffle(X,y, random_state=seed)\n",
    "\n",
    "        size = 1000\n",
    "        start_X = X[:size]\n",
    "        start_y = y[:size]\n",
    "\n",
    "        remaining_X = X[size:]\n",
    "        remaining_y = y[size:]\n",
    "        \n",
    "        counter = 0\n",
    "        while len(start_X) <= 1500:\n",
    "\n",
    "            if counter % 50 == 0:\n",
    "                #creating kernel\n",
    "                k = GPy.kern.Linear(start_X.shape[1])\n",
    "\n",
    "                #training and optimizing GP regression model\n",
    "                m = GPy.models.GPRegression(start_X, start_y, k)\n",
    "               \n",
    "                #Predicting on final 20%\n",
    "                pred_means, pred_vars = m.predict(remaining_X)\n",
    "\n",
    "                #Getting rmse score\n",
    "                rmse_instance.append(np.sqrt(mean_squared_error(remaining_y, pred_means)))\n",
    "                r2_instance.append(r2_score(remaining_y, pred_means))\n",
    "        \n",
    "            #adding the row of the selected index to the starting data\n",
    "            start_X = np.vstack((start_X, remaining_X[:batch_size]))\n",
    "            start_y = np.vstack((start_y, remaining_y[:batch_size]))\n",
    "\n",
    "            #removing the row of the selected index from the remaining data\n",
    "            #Testing on remaining 20%\n",
    "            remaining_X = remaining_X[batch_size:]\n",
    "            remaining_y = remaining_y[batch_size:]\n",
    "            \n",
    "            counter += batch_size\n",
    "        rmse_vals.append(rmse_instance)\n",
    "        r2_vals.append(r2_instance)\n",
    "        \n",
    "    return rmse_vals, r2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.67851335 0.66577417 0.65735525 0.6493212  0.6450358  0.63415625\n",
      " 0.63239482 0.62910644 0.62606269 0.62264844 0.61823679]\n",
      "standard deviation: [0.0114247  0.00430973 0.00954599 0.00519653 0.0075443  0.0110923\n",
      " 0.01172547 0.01033904 0.009591   0.0087983  0.01165945]\n",
      "mean: [0.75157578 0.76091184 0.76655504 0.7721683  0.7750749  0.78249936\n",
      " 0.78368823 0.78605724 0.78809443 0.79036235 0.79326152]\n",
      "standard deviation: [0.00803293 0.00246722 0.0059438  0.00328136 0.00521593 0.00760325\n",
      " 0.00801922 0.00727714 0.00695845 0.00649148 0.00860995]\n",
      "mean: [0.67851335 0.66577417 0.65735525 0.6493212  0.6450358  0.63415625\n",
      " 0.63239482 0.62910644 0.62606269 0.62264844 0.61823679]\n",
      "standard deviation: [0.0114247  0.00430973 0.00954599 0.00519653 0.0075443  0.0110923\n",
      " 0.01172547 0.01033904 0.009591   0.0087983  0.01165945]\n",
      "mean: [0.75157578 0.76091184 0.76655504 0.7721683  0.7750749  0.78249936\n",
      " 0.78368823 0.78605724 0.78809443 0.79036235 0.79326152]\n",
      "standard deviation: [0.00803293 0.00246722 0.0059438  0.00328136 0.00521593 0.00760325\n",
      " 0.00801922 0.00727714 0.00695845 0.00649148 0.00860995]\n",
      "mean: [0.67851335 0.66577417 0.65735525 0.6493212  0.6450358  0.63415625\n",
      " 0.63239482 0.62910644 0.62606269 0.62264844 0.61823679]\n",
      "standard deviation: [0.0114247  0.00430973 0.00954599 0.00519653 0.0075443  0.0110923\n",
      " 0.01172547 0.01033904 0.009591   0.0087983  0.01165945]\n",
      "mean: [0.75157578 0.76091184 0.76655504 0.7721683  0.7750749  0.78249936\n",
      " 0.78368823 0.78605724 0.78809443 0.79036235 0.79326152]\n",
      "standard deviation: [0.00803293 0.00246722 0.0059438  0.00328136 0.00521593 0.00760325\n",
      " 0.00801922 0.00727714 0.00695845 0.00649148 0.00860995]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1, 25, 50]\n",
    "rand_rmse_dict = {}\n",
    "rand_r2_dict = {}\n",
    "\n",
    "\n",
    "final_rand_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    rand_rmse, rand_r2 = random_sampling(batch)\n",
    "\n",
    "    rand_rmse_mean = np.mean(rand_rmse, axis=0)\n",
    "    rand_rmse_stdev = np.std(rand_rmse, axis=0)\n",
    "    print(\"mean:\", rand_rmse_mean)\n",
    "    print(\"standard deviation:\", rand_rmse_stdev)\n",
    "    rand_rmse_dict[batch] = (rand_rmse, rand_rmse_mean, rand_rmse_stdev)\n",
    "    final_rand_data[f\"{batch}_rmse_mean\"] = rand_rmse_mean\n",
    "    final_rand_data[f\"{batch}_rmse_stdev\"] = rand_rmse_stdev\n",
    "\n",
    "\n",
    "    rand_r2_mean = np.mean(rand_r2, axis=0)\n",
    "    rand_r2_stdev = np.std(rand_r2, axis=0)\n",
    "    print(\"mean:\", rand_r2_mean)\n",
    "    print(\"standard deviation:\", rand_r2_stdev)\n",
    "    rand_r2_dict[batch] = (rand_r2, rand_r2_mean, rand_r2_stdev)\n",
    "    final_rand_data[f\"{batch}_r2_mean\"] = rand_r2_mean\n",
    "    final_rand_data[f\"{batch}_r2_stdev\"] = rand_r2_stdev\n",
    "\n",
    "\n",
    "final_rand_data.to_csv(\"final_data_random.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainity Sampling\n",
    "## Mean, Variance, UCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function runs sequential model-based optimization. This function works by training a sparse GP model on the start data, \n",
    "#and using a selection/activation function that performs UCB to select the data point to query.\n",
    "\n",
    "#Input: starting data and unlabeled remaining data\n",
    "#Output: Instance with the maximum GP mean upon prediction, as well as the actual value (if it is 9.0)\n",
    "\n",
    "def smbo(start_X, start_y, remaining_X):\n",
    "    \n",
    "    k = GPy.kern.Linear(start_X.shape[1])\n",
    "\n",
    "    m = GPy.models.GPRegression(start_X, start_y, k)\n",
    "\n",
    "    mean, var = m.predict(remaining_X, full_cov=False)\n",
    "\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_sampling(flag, batch_size):\n",
    "    seeds = [1]\n",
    "\n",
    "    rmse_vals = []\n",
    "    r2_vals = []\n",
    "  \n",
    "    for seed in seeds:\n",
    "\n",
    "        fp = pd.DataFrame(columns=list(range(4096)))\n",
    "        \n",
    "\n",
    "        rmse_instance =[]\n",
    "        r2_instance = []\n",
    "      \n",
    "        #Getting X and y values to start with\n",
    "        X = np.array([val for val in data['fingerprint'].values])\n",
    "        y = data['target'].values.reshape(-1,1)\n",
    "        X, y = shuffle(X,y, random_state=seed)\n",
    "\n",
    "\n",
    "        size = 1000\n",
    "        start_X = X[:size]\n",
    "        start_y = y[:size]\n",
    "\n",
    "        remaining_X = X[size:]\n",
    "        remaining_y = y[size:]\n",
    "\n",
    "        #set initial variables for calculating UCB\n",
    "        Dsize = len(X)\n",
    "        bo_lambda = 0.1 #ADJUST LATER\n",
    "        bo_iters = 1 #ADJUST LATER\n",
    "\n",
    "        #calculate beta constant from \n",
    "        beta = 2 * math.log(Dsize * math.pow(bo_iters,2) * math.pow(np.pi,2) / (6 * bo_lambda) )\n",
    "        print(beta)\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        #Until we sample another 70%...\n",
    "        while len(start_X) <= 1500: #round(((len(X) * 0.2) / 500 )) * 500:\n",
    "\n",
    "            #run smbo and get the sparse GP parameters to select the next instance\n",
    "            mean, var = smbo(start_X, start_y, remaining_X)\n",
    "\n",
    "            #depending on the selection function, we calculate a specific alpha_full value\n",
    "            if flag == \"ucb\":\n",
    "                #get the UCB value at each x\n",
    "                alpha_full = mean + math.sqrt(beta) * var\n",
    "                alpha_full = [item for sublist in alpha_full for item in sublist]\n",
    "            elif flag == \"mean\":\n",
    "                alpha_full = mean\n",
    "                alpha_full = [item for sublist in alpha_full for item in sublist]\n",
    "            else:\n",
    "                # alpha_full = var # list of lists \n",
    "                alpha_full = [item for sublist in var for item in sublist]\n",
    "    \n",
    "            #get the index for the row with the largest UCB\n",
    "            sorted = np.argsort(alpha_full)\n",
    "            inds = sorted[-batch_size:]\n",
    "            inds = np.sort(inds)[::-1]\n",
    "\n",
    "            for ind in inds:\n",
    "                #adding the row of the selected index to the starting data\n",
    "                start_X = np.vstack((start_X, remaining_X[ind,:]))\n",
    "                start_y = np.vstack((start_y, remaining_y[ind]))\n",
    "\n",
    "                #cur_fp = remaining_X[ind,:].tolist()\n",
    "                fp = pd.concat([fp, pd.DataFrame(remaining_X[ind,:].reshape(-1,1))])\n",
    "\n",
    "                #removing the row of the selected index from the remaining data\n",
    "                remaining_X = np.delete(remaining_X, ind, axis=0)\n",
    "                remaining_y = np.delete(remaining_y, ind)\n",
    "\n",
    "\n",
    "            if counter % 50 == 0:\n",
    "                #creating kernel\n",
    "                k = GPy.kern.Linear(start_X.shape[1])\n",
    "\n",
    "                #training and optimizing GP regression model\n",
    "                m = GPy.models.GPRegression(start_X, start_y, k)\n",
    "\n",
    "                #Predicting on final 20%\n",
    "                pred_means, pred_vars = m.predict(remaining_X)\n",
    "                # print(\"plotting model predictions\")\n",
    "\n",
    "                #Getting rmse score\n",
    "                rmse_instance.append(np.sqrt(mean_squared_error(remaining_y, pred_means)))\n",
    "                r2_instance.append(r2_score(remaining_y, pred_means))\n",
    "\n",
    "            counter += batch_size\n",
    "\n",
    "        rmse_vals.append(rmse_instance)\n",
    "        r2_vals.append(r2_instance)\n",
    "        \n",
    "    return rmse_vals, r2_vals, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.020651444863944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m final_ucb_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batch_sizes:\n\u001b[0;32m----> 9\u001b[0m     ucb_rmse, ucb_r2, fp \u001b[38;5;241m=\u001b[39m \u001b[43muncertainty_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     ucb_rmse_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ucb_rmse, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m     ucb_rmse_stdev \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(ucb_rmse, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 68\u001b[0m, in \u001b[0;36muncertainty_sampling\u001b[0;34m(flag, batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m start_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((start_y, remaining_y[ind]))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#cur_fp = remaining_X[ind,:].tolist()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#removing the row of the selected index from the remaining data\u001b[39;00m\n\u001b[1;32m     71\u001b[0m remaining_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(remaining_X, ind, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/internals/concat.py:189\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    187\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/internals/concat.py:466\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[0;32m--> 466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    467\u001b[0m     ju\u001b[38;5;241m.\u001b[39mget_reindexed_values(empty_dtype\u001b[38;5;241m=\u001b[39mempty_dtype, upcasted_na\u001b[38;5;241m=\u001b[39mupcasted_na)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    469\u001b[0m ]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m         t\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[1;32m    481\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/internals/concat.py:467\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    463\u001b[0m has_none_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(unit\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    464\u001b[0m upcasted_na \u001b[38;5;241m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n\u001b[1;32m    466\u001b[0m to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 467\u001b[0m     \u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reindexed_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupcasted_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupcasted_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    469\u001b[0m ]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case not needed if all EAs used HybridBlocks\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"__getitem__\" of \"ExtensionArray\" matches\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# argument type \"Tuple[int, slice]\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     to_concat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    477\u001b[0m         t\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_1d_only_ea_dtype(t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m t[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m to_concat\n\u001b[1;32m    481\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/internals/concat.py:440\u001b[0m, in \u001b[0;36mJoinUnit.get_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m upcasted_na\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_valid_na_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mempty_dtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;66;03m# note: always holds when self.block.dtype.kind == \"V\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m         blk_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m blk_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;66;03m# we want to avoid filling with np.nan if we are\u001b[39;00m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# using None; we already know that we are all\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# nulls\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/internals/concat.py:371\u001b[0m, in \u001b[0;36mJoinUnit._is_valid_na_for\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_valid_na_for_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/internals/concat.py:371\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    370\u001b[0m     values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mis_valid_na_for_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    373\u001b[0m na_value \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m NaT \u001b[38;5;129;01mand\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# e.g. we are dt64 and other is td64\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# fill_values match but we should not cast blk.values to dtype\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# TODO: this will need updating if we ever have non-nano dt64/td64\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/comp_med/lib/python3.9/site-packages/pandas/core/dtypes/missing.py:741\u001b[0m, in \u001b[0;36mis_valid_na_for_dtype\u001b[0;34m(obj, dtype)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_na_for_dtype\u001b[39m(obj, dtype: DtypeObj) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    729\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m    isna check that excludes incompatible dtypes\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isna(obj):\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_sizes = [50]\n",
    "flag = \"ucb\"\n",
    "ucb_rmse_dict = {}\n",
    "ucb_r2_dict = {}\n",
    "final_ucb_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    ucb_rmse, ucb_r2, fp = uncertainty_sampling(flag, batch)\n",
    "\n",
    "    ucb_rmse_mean = np.mean(ucb_rmse, axis=0)\n",
    "    ucb_rmse_stdev = np.std(ucb_rmse, axis=0)\n",
    "    print(\"mean:\", ucb_rmse_mean)\n",
    "    print(\"standard deviation:\", ucb_rmse_stdev)\n",
    "    ucb_rmse_dict[batch] = (ucb_rmse, ucb_rmse_mean, ucb_rmse_stdev)\n",
    "    \n",
    "    final_ucb_data[f\"{batch}_rmse_mean\"] = ucb_rmse_mean\n",
    "    final_ucb_data[f\"{batch}_rmse_stdev\"] = ucb_rmse_stdev\n",
    "\n",
    "    ucb_r2_mean = np.mean(ucb_r2, axis=0)\n",
    "    ucb_r2_stdev = np.std(ucb_r2, axis=0)\n",
    "    print(\"mean:\", ucb_r2_mean)\n",
    "    print(\"standard deviation:\", ucb_r2_stdev)\n",
    "    ucb_r2_dict[batch] = (ucb_r2, ucb_r2_mean, ucb_r2_stdev)\n",
    "    final_ucb_data[f\"{batch}_r2_mean\"] = ucb_r2_mean\n",
    "    final_ucb_data[f\"{batch}_r2_stdev\"] = ucb_r2_stdev\n",
    "\n",
    "    fp.to_csv(\"fingerprints_ucb.csv\")\n",
    "\n",
    "#final_ucb_data.to_csv(\"final_data_ucb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.020651444863944\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "mean: [0.67845357 0.67447308 0.66812086 0.66800833 0.66710053 0.66689913\n",
      " 0.6656566  0.66424068 0.66093307 0.65968608 0.65882304]\n",
      "standard deviation: [0.01155563 0.01219732 0.01256901 0.01216398 0.01096211 0.01160074\n",
      " 0.00943003 0.0088856  0.00976811 0.01036883 0.00980504]\n",
      "mean: [0.75135272 0.74647127 0.74599032 0.74094491 0.7370467  0.73239053\n",
      " 0.72923834 0.72639511 0.72512922 0.72234419 0.71943569]\n",
      "standard deviation: [0.0081153  0.00856536 0.00921265 0.009102   0.00806927 0.00849449\n",
      " 0.00689882 0.00646998 0.00760497 0.00824478 0.00793708]\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "mean: [0.67742975 0.67188746 0.66969058 0.66756113 0.66560561 0.66533538\n",
      " 0.66546206 0.66270378 0.66100294 0.65999263 0.65879524]\n",
      "standard deviation: [0.01287797 0.01225493 0.01239483 0.01240643 0.01188406 0.01071635\n",
      " 0.01018414 0.00979287 0.01026874 0.00973006 0.00948009]\n",
      "mean: [0.74816757 0.74597296 0.74267438 0.73915535 0.73612955 0.73169894\n",
      " 0.72747448 0.72575607 0.72325865 0.72017836 0.71765067]\n",
      "standard deviation: [0.00932034 0.00879711 0.00921988 0.00935432 0.00861328 0.00778193\n",
      " 0.00747467 0.00722379 0.00825507 0.00777929 0.00755438]\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "mean: [0.67522698 0.66888795 0.66828209 0.66591557 0.66461274 0.66428664\n",
      " 0.66599546 0.66230929 0.66163835 0.65924249 0.65689466]\n",
      "standard deviation: [0.01412362 0.01345414 0.01139232 0.01210681 0.01213653 0.01055747\n",
      " 0.0085938  0.01011374 0.00955632 0.00906204 0.00873943]\n",
      "mean: [0.74661209 0.74570421 0.74129196 0.7382248  0.73458528 0.7305413\n",
      " 0.72499193 0.72440653 0.72095491 0.71923404 0.71759318]\n",
      "standard deviation: [0.01018278 0.0097871  0.00814757 0.00859255 0.0088398  0.00768433\n",
      " 0.00600806 0.00764051 0.00750846 0.00728663 0.00704906]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1, 25, 50]\n",
    "flag = \"mean\"\n",
    "mean_rmse_dict = {}\n",
    "mean_r2_dict = {}\n",
    "\n",
    "final_mean_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    mean_rmse, mean_r2= uncertainty_sampling(flag, batch)\n",
    "\n",
    "    mean_rmse_mean = np.mean(mean_rmse, axis=0)\n",
    "    mean_rmse_stdev = np.std(mean_rmse, axis=0)\n",
    "    print(\"mean:\", mean_rmse_mean)\n",
    "    print(\"standard deviation:\", mean_rmse_stdev)\n",
    "    mean_rmse_dict[batch] = (mean_rmse, mean_rmse_mean, mean_rmse_stdev)\n",
    "    final_mean_data[f\"{batch}_rmse_mean\"] = mean_rmse_mean\n",
    "    final_mean_data[f\"{batch}_rmse_stdev\"] = mean_rmse_stdev\n",
    "\n",
    "\n",
    "    mean_r2_mean = np.mean(mean_r2, axis=0)\n",
    "    mean_r2_stdev = np.std(mean_r2, axis=0)\n",
    "    print(\"mean:\", mean_r2_mean)\n",
    "    print(\"standard deviation:\", mean_r2_stdev)\n",
    "    mean_r2_dict[batch] = (mean_r2, mean_r2_mean, mean_r2_stdev)\n",
    "    final_mean_data[f\"{batch}_r2_mean\"] = mean_r2_mean\n",
    "    final_mean_data[f\"{batch}_r2_stdev\"] = mean_r2_stdev\n",
    "\n",
    "\n",
    "final_mean_data.to_csv(\"final_data_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.020651444863944\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "mean: [0.67819991 0.6596941  0.64504371 0.63949791 0.63199611 0.62300157\n",
      " 0.61664977 0.60738197 0.60327419 0.59863299 0.5946769 ]\n",
      "standard deviation: [0.01164893 0.00730648 0.00946949 0.00944724 0.01016513 0.00913082\n",
      " 0.00925947 0.0112312  0.01093421 0.00484561 0.00470246]\n",
      "mean: [0.75180788 0.76343433 0.77249823 0.7754492  0.77999436 0.78589229\n",
      " 0.78999894 0.79583891 0.79826274 0.8007928  0.80298902]\n",
      "standard deviation: [0.00818068 0.00495074 0.00689047 0.0070961  0.00749665 0.00675914\n",
      " 0.00689691 0.0077425  0.00743957 0.0038242  0.00366888]\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "mean: [0.67043076 0.66289466 0.66160931 0.65919448 0.64734462 0.64251213\n",
      " 0.6368117  0.63406883 0.62517979 0.62050684 0.61389138]\n",
      "standard deviation: [0.00651003 0.00675645 0.00877218 0.00517342 0.0075031  0.0093519\n",
      " 0.01093841 0.00890461 0.00818736 0.00749722 0.00852374]\n",
      "mean: [0.75674087 0.76129138 0.7608251  0.76183175 0.76911825 0.7719461\n",
      " 0.77472387 0.77588045 0.78149471 0.78416792 0.78841333]\n",
      "standard deviation: [0.00417708 0.0043002  0.00631425 0.00325797 0.00565072 0.00684351\n",
      " 0.00744122 0.00603868 0.0055686  0.00500913 0.00572554]\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "24.020651444863944\n",
      "mean: [0.67036407 0.6643701  0.65727985 0.65619099 0.6458607  0.64126758\n",
      " 0.63580139 0.63053756 0.627202   0.6193789  0.61665723]\n",
      "standard deviation: [0.00544068 0.00364246 0.00697409 0.00545298 0.00914631 0.01011616\n",
      " 0.01142095 0.01083809 0.01149267 0.01295409 0.01381159]\n",
      "mean: [0.75664416 0.76067642 0.76437047 0.76402957 0.7694273  0.77271253\n",
      " 0.77556378 0.77832243 0.78002152 0.78477768 0.78576082]\n",
      "standard deviation: [0.00327848 0.00239546 0.00424894 0.00345827 0.00652232 0.00740768\n",
      " 0.00752842 0.00755928 0.00855435 0.008548   0.00959746]\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1, 25, 50]\n",
    "flag = \"var\"\n",
    "var_rmse_dict = {}\n",
    "var_r2_dict = {}\n",
    "\n",
    "\n",
    "final_var_data = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    var_rmse, var_r2 = uncertainty_sampling(flag, batch)\n",
    "\n",
    "    var_rmse_mean = np.mean(var_rmse, axis=0)\n",
    "    var_rmse_stdev = np.std(var_rmse, axis=0)\n",
    "    print(\"mean:\", var_rmse_mean)\n",
    "    print(\"standard deviation:\", var_rmse_stdev)\n",
    "    var_rmse_dict[batch] = (var_rmse, var_rmse_mean, var_rmse_stdev)\n",
    "    final_var_data[f\"{batch}_rmse_mean\"] = var_rmse_mean\n",
    "    final_var_data[f\"{batch}_rmse_stdev\"] = var_rmse_stdev\n",
    "\n",
    "\n",
    "    var_r2_mean = np.mean(var_r2, axis=0)\n",
    "    var_r2_stdev = np.std(var_r2, axis=0)\n",
    "    print(\"mean:\", var_r2_mean)\n",
    "    print(\"standard deviation:\", var_r2_stdev)\n",
    "    var_r2_dict[batch] = (var_r2, var_r2_mean, var_r2_stdev)\n",
    "    final_var_data[f\"{batch}_r2_mean\"] = var_r2_mean\n",
    "    final_var_data[f\"{batch}_r2_stdev\"] = var_r2_stdev\n",
    "\n",
    "\n",
    "final_var_data.to_csv(\"final_data_var.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "70d57c135da11913b2ad31fa6150ab201732e694e7c1a956b2909783da6a3273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
