{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import chemprop\n",
    "from sklearn.utils import shuffle\n",
    "from chemprop.train.evaluate import evaluate_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TYK2_final.csv\", index_col=False)\n",
    "data = data.drop(['target', 'top_2p', 'top_5p'], axis=1)\n",
    "column_names = ['smiles', 'target']\n",
    "data.columns = column_names\n",
    "\n",
    "# Get 10% for training\n",
    "data = np.array(data)\n",
    "data= shuffle(data, random_state=1)\n",
    "size = int(len(data)*0.1)\n",
    "train, test = data[:size], data[size:]\n",
    "train_df = pd.DataFrame(train, columns=column_names)\n",
    "train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "test_df = pd.DataFrame(test, columns=column_names)\n",
    "test_df.to_csv(\"test_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command line\n",
      "python /Users/sinhanushka_/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/sinhanushka_/Library/Jupyter/runtime/kernel-737c4653-547e-4f1f-b17b-4a9f04f83bb4.json\n",
      "Args\n",
      "{'activation': 'ReLU',\n",
      " 'adding_bond_types': True,\n",
      " 'adding_h': False,\n",
      " 'aggregation': 'mean',\n",
      " 'aggregation_norm': 100,\n",
      " 'atom_constraints': [],\n",
      " 'atom_descriptor_scaling': True,\n",
      " 'atom_descriptors': None,\n",
      " 'atom_descriptors_path': None,\n",
      " 'atom_descriptors_size': 0,\n",
      " 'atom_features_size': 0,\n",
      " 'atom_messages': False,\n",
      " 'atom_targets': [],\n",
      " 'batch_size': 25,\n",
      " 'bias': False,\n",
      " 'bias_solvent': False,\n",
      " 'bond_constraints': [],\n",
      " 'bond_descriptor_scaling': True,\n",
      " 'bond_descriptors': None,\n",
      " 'bond_descriptors_path': None,\n",
      " 'bond_descriptors_size': 0,\n",
      " 'bond_features_size': 0,\n",
      " 'bond_targets': [],\n",
      " 'cache_cutoff': 10000,\n",
      " 'checkpoint_dir': None,\n",
      " 'checkpoint_frzn': None,\n",
      " 'checkpoint_path': None,\n",
      " 'checkpoint_paths': None,\n",
      " 'class_balance': False,\n",
      " 'config_path': None,\n",
      " 'constraints_path': None,\n",
      " 'crossval_index_dir': None,\n",
      " 'crossval_index_file': None,\n",
      " 'crossval_index_sets': None,\n",
      " 'cuda': False,\n",
      " 'data_path': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/train_dataset.csv',\n",
      " 'data_weights_path': None,\n",
      " 'dataset_type': 'regression',\n",
      " 'depth': 3,\n",
      " 'depth_solvent': 3,\n",
      " 'device': device(type='cpu'),\n",
      " 'dropout': 0.0,\n",
      " 'empty_cache': False,\n",
      " 'ensemble_size': 1,\n",
      " 'epochs': 30,\n",
      " 'evidential_regularization': 0,\n",
      " 'explicit_h': False,\n",
      " 'extra_metrics': [],\n",
      " 'features_generator': None,\n",
      " 'features_only': False,\n",
      " 'features_path': None,\n",
      " 'features_scaling': True,\n",
      " 'features_size': None,\n",
      " 'ffn_hidden_size': 300,\n",
      " 'ffn_num_layers': 2,\n",
      " 'final_lr': 0.0001,\n",
      " 'folds_file': None,\n",
      " 'freeze_first_only': False,\n",
      " 'frzn_ffn_layers': 0,\n",
      " 'gpu': None,\n",
      " 'grad_clip': None,\n",
      " 'hidden_size': 300,\n",
      " 'hidden_size_solvent': 300,\n",
      " 'ignore_columns': None,\n",
      " 'ignore_nan_metrics': False,\n",
      " 'init_lr': 0.0001,\n",
      " 'is_atom_bond_targets': False,\n",
      " 'keeping_atom_map': False,\n",
      " 'log_frequency': 10,\n",
      " 'loss_function': 'mse',\n",
      " 'max_data_size': None,\n",
      " 'max_lr': 0.001,\n",
      " 'metric': 'rmse',\n",
      " 'metrics': ['rmse'],\n",
      " 'minimize_score': True,\n",
      " 'mpn_shared': False,\n",
      " 'multiclass_num_classes': 3,\n",
      " 'no_adding_bond_types': False,\n",
      " 'no_atom_descriptor_scaling': False,\n",
      " 'no_bond_descriptor_scaling': False,\n",
      " 'no_cache_mol': False,\n",
      " 'no_cuda': False,\n",
      " 'no_features_scaling': False,\n",
      " 'no_shared_atom_bond_ffn': False,\n",
      " 'num_folds': 1,\n",
      " 'num_lrs': 1,\n",
      " 'num_tasks': 1,\n",
      " 'num_workers': 8,\n",
      " 'number_of_molecules': 1,\n",
      " 'overwrite_default_atom_features': False,\n",
      " 'overwrite_default_bond_features': False,\n",
      " 'phase_features_path': None,\n",
      " 'pytorch_seed': 0,\n",
      " 'quantile_loss_alpha': 0.1,\n",
      " 'quantiles': [],\n",
      " 'quiet': False,\n",
      " 'reaction': False,\n",
      " 'reaction_mode': 'reac_diff',\n",
      " 'reaction_solvent': False,\n",
      " 'resume_experiment': False,\n",
      " 'save_dir': '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/',\n",
      " 'save_preds': False,\n",
      " 'save_smiles_splits': False,\n",
      " 'seed': 0,\n",
      " 'separate_test_atom_descriptors_path': None,\n",
      " 'separate_test_bond_descriptors_path': None,\n",
      " 'separate_test_constraints_path': None,\n",
      " 'separate_test_features_path': None,\n",
      " 'separate_test_path': None,\n",
      " 'separate_test_phase_features_path': None,\n",
      " 'separate_val_atom_descriptors_path': None,\n",
      " 'separate_val_bond_descriptors_path': None,\n",
      " 'separate_val_constraints_path': None,\n",
      " 'separate_val_features_path': None,\n",
      " 'separate_val_path': None,\n",
      " 'separate_val_phase_features_path': None,\n",
      " 'shared_atom_bond_ffn': True,\n",
      " 'show_individual_scores': False,\n",
      " 'smiles_columns': ['smiles'],\n",
      " 'spectra_activation': 'exp',\n",
      " 'spectra_phase_mask_path': None,\n",
      " 'spectra_target_floor': 1e-08,\n",
      " 'split_key_molecule': 0,\n",
      " 'split_sizes': [0.8, 0.1, 0.1],\n",
      " 'split_type': 'random',\n",
      " 'target_columns': None,\n",
      " 'target_weights': None,\n",
      " 'task_names': ['target'],\n",
      " 'test': False,\n",
      " 'test_fold_index': None,\n",
      " 'train_data_size': None,\n",
      " 'undirected': False,\n",
      " 'use_input_features': False,\n",
      " 'val_fold_index': None,\n",
      " 'warmup_epochs': 2.0,\n",
      " 'weights_ffn_num_layers': 2}\n",
      "Setting molecule featurization parameters to default.\n",
      "Loading data\n",
      "999it [00:00, 225298.94it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 210104.28it/s]\n",
      "100%|██████████| 999/999 [00:00<00:00, 171796.22it/s]\n",
      "Number of tasks = 1\n",
      "Fold 0\n",
      "Splitting data with seed 0\n",
      "Total size = 999 | train size = 799 | val size = 100 | test size = 100\n",
      "Fitting scaler\n",
      "Building model 0\n",
      "MoleculeModel(\n",
      "  (encoder): MPN(\n",
      "    (encoder): ModuleList(\n",
      "      (0): MPNEncoder(\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (act_func): ReLU()\n",
      "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
      "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
      "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Dropout(p=0.0, inplace=False)\n",
      "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 355,201\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]Epoch 0\n",
      "Loss = 9.7418e-01, PNorm = 34.0102, GNorm = 4.2415, lr_0 = 2.5968e-04\n",
      "Loss = 1.0423e+00, PNorm = 34.0126, GNorm = 0.7972, lr_0 = 4.0484e-04\n",
      "Loss = 9.1704e-01, PNorm = 34.0218, GNorm = 0.7419, lr_0 = 5.5000e-04\n",
      "Validation rmse = 1.331804\n",
      "  3%|▎         | 1/30 [00:02<01:18,  2.72s/it]Epoch 1\n",
      "Loss = 9.0424e-01, PNorm = 34.0436, GNorm = 2.5574, lr_0 = 7.0968e-04\n",
      "Loss = 9.9068e-01, PNorm = 34.0671, GNorm = 2.1981, lr_0 = 8.5484e-04\n",
      "Loss = 1.0513e+00, PNorm = 34.0991, GNorm = 2.2742, lr_0 = 1.0000e-03\n",
      "Validation rmse = 1.385678\n",
      "  7%|▋         | 2/30 [00:05<01:15,  2.68s/it]Epoch 2\n",
      "Loss = 1.0004e+00, PNorm = 34.1427, GNorm = 2.7083, lr_0 = 9.7382e-04\n",
      "Loss = 9.1304e-01, PNorm = 34.1945, GNorm = 1.7462, lr_0 = 9.4833e-04\n",
      "Loss = 8.6423e-01, PNorm = 34.2424, GNorm = 1.6066, lr_0 = 9.2350e-04\n",
      "Validation rmse = 1.285578\n",
      " 10%|█         | 3/30 [00:08<01:11,  2.66s/it]Epoch 3\n",
      "Loss = 7.8818e-01, PNorm = 34.2975, GNorm = 2.1062, lr_0 = 8.9933e-04\n",
      "Loss = 8.2574e-01, PNorm = 34.3538, GNorm = 4.0563, lr_0 = 8.7578e-04\n",
      "Loss = 7.7007e-01, PNorm = 34.4000, GNorm = 5.0949, lr_0 = 8.5286e-04\n",
      "Validation rmse = 1.251397\n",
      " 13%|█▎        | 4/30 [00:10<01:08,  2.65s/it]Epoch 4\n",
      "Loss = 6.7013e-01, PNorm = 34.4571, GNorm = 1.3704, lr_0 = 8.3053e-04\n",
      "Loss = 7.2369e-01, PNorm = 34.5240, GNorm = 1.8779, lr_0 = 8.0879e-04\n",
      "Loss = 8.0906e-01, PNorm = 34.5903, GNorm = 1.2677, lr_0 = 7.8761e-04\n",
      "Validation rmse = 1.336654\n",
      " 17%|█▋        | 5/30 [00:13<01:05,  2.64s/it]Epoch 5\n",
      "Loss = 7.6628e-01, PNorm = 34.6561, GNorm = 8.3461, lr_0 = 7.6700e-04\n",
      "Loss = 6.9946e-01, PNorm = 34.7038, GNorm = 2.1907, lr_0 = 7.4692e-04\n",
      "Loss = 8.7478e-01, PNorm = 34.7660, GNorm = 2.7706, lr_0 = 7.2736e-04\n",
      "Loss = 6.8239e-01, PNorm = 34.8500, GNorm = 4.2714, lr_0 = 7.0832e-04\n",
      "Validation rmse = 1.192668\n",
      " 20%|██        | 6/30 [00:15<01:03,  2.64s/it]Epoch 6\n",
      "Loss = 5.9917e-01, PNorm = 34.9286, GNorm = 4.8925, lr_0 = 6.8978e-04\n",
      "Loss = 5.7835e-01, PNorm = 34.9876, GNorm = 3.1837, lr_0 = 6.7172e-04\n",
      "Loss = 6.1293e-01, PNorm = 35.0588, GNorm = 3.7441, lr_0 = 6.5414e-04\n",
      "Validation rmse = 1.067998\n",
      " 23%|██▎       | 7/30 [00:18<01:01,  2.65s/it]Epoch 7\n",
      "Loss = 4.9990e-01, PNorm = 35.1392, GNorm = 9.0198, lr_0 = 6.3701e-04\n",
      "Loss = 4.8801e-01, PNorm = 35.2226, GNorm = 2.0913, lr_0 = 6.2034e-04\n",
      "Loss = 6.4000e-01, PNorm = 35.2755, GNorm = 3.6846, lr_0 = 6.0410e-04\n",
      "Validation rmse = 1.038326\n",
      " 27%|██▋       | 8/30 [00:21<00:58,  2.66s/it]Epoch 8\n",
      "Loss = 5.1380e-01, PNorm = 35.3293, GNorm = 2.1098, lr_0 = 5.8828e-04\n",
      "Loss = 4.3674e-01, PNorm = 35.3857, GNorm = 1.6039, lr_0 = 5.7288e-04\n",
      "Loss = 4.9946e-01, PNorm = 35.4417, GNorm = 1.4583, lr_0 = 5.5788e-04\n",
      "Validation rmse = 1.019540\n",
      " 30%|███       | 9/30 [00:23<00:56,  2.67s/it]Epoch 9\n",
      "Loss = 3.0116e-01, PNorm = 35.4940, GNorm = 1.3336, lr_0 = 5.4328e-04\n",
      "Loss = 4.6865e-01, PNorm = 35.5364, GNorm = 1.4849, lr_0 = 5.2906e-04\n",
      "Loss = 4.1194e-01, PNorm = 35.5787, GNorm = 0.9104, lr_0 = 5.1521e-04\n",
      "Validation rmse = 1.076999\n",
      " 33%|███▎      | 10/30 [00:26<00:53,  2.69s/it]Epoch 10\n",
      "Loss = 3.3763e-01, PNorm = 35.6243, GNorm = 5.3869, lr_0 = 5.0172e-04\n",
      "Loss = 3.3230e-01, PNorm = 35.6667, GNorm = 1.5173, lr_0 = 4.8858e-04\n",
      "Loss = 3.9426e-01, PNorm = 35.7089, GNorm = 4.0849, lr_0 = 4.7579e-04\n",
      "Loss = 4.1999e-01, PNorm = 35.7331, GNorm = 3.3129, lr_0 = 4.6334e-04\n",
      "Validation rmse = 1.027254\n",
      " 37%|███▋      | 11/30 [00:29<00:50,  2.68s/it]Epoch 11\n",
      "Loss = 3.7559e-01, PNorm = 35.7587, GNorm = 5.5208, lr_0 = 4.5121e-04\n",
      "Loss = 3.6140e-01, PNorm = 35.7853, GNorm = 1.3597, lr_0 = 4.3940e-04\n",
      "Loss = 4.0925e-01, PNorm = 35.8218, GNorm = 3.6372, lr_0 = 4.2789e-04\n",
      "Validation rmse = 0.996803\n",
      " 40%|████      | 12/30 [00:32<00:48,  2.67s/it]Epoch 12\n",
      "Loss = 3.0523e-01, PNorm = 35.8522, GNorm = 1.1087, lr_0 = 4.1669e-04\n",
      "Loss = 3.7672e-01, PNorm = 35.8851, GNorm = 1.1284, lr_0 = 4.0578e-04\n",
      "Loss = 3.3086e-01, PNorm = 35.9118, GNorm = 1.9133, lr_0 = 3.9516e-04\n",
      "Validation rmse = 0.933006\n",
      " 43%|████▎     | 13/30 [00:34<00:45,  2.67s/it]Epoch 13\n",
      "Loss = 3.5078e-01, PNorm = 35.9280, GNorm = 1.4760, lr_0 = 3.8482e-04\n",
      "Loss = 2.7460e-01, PNorm = 35.9464, GNorm = 1.6560, lr_0 = 3.7474e-04\n",
      "Loss = 2.8610e-01, PNorm = 35.9702, GNorm = 2.6575, lr_0 = 3.6493e-04\n",
      "Validation rmse = 1.097148\n",
      " 47%|████▋     | 14/30 [00:37<00:42,  2.67s/it]Epoch 14\n",
      "Loss = 2.8460e-01, PNorm = 35.9879, GNorm = 1.3453, lr_0 = 3.5538e-04\n",
      "Loss = 2.8933e-01, PNorm = 36.0049, GNorm = 1.0422, lr_0 = 3.4608e-04\n",
      "Loss = 3.5456e-01, PNorm = 36.0274, GNorm = 2.1965, lr_0 = 3.3702e-04\n",
      "Validation rmse = 0.909193\n",
      " 50%|█████     | 15/30 [00:40<00:40,  2.67s/it]Epoch 15\n",
      "Loss = 2.1213e-01, PNorm = 36.0481, GNorm = 3.7342, lr_0 = 3.2819e-04\n",
      "Loss = 2.9522e-01, PNorm = 36.0637, GNorm = 0.9687, lr_0 = 3.1960e-04\n",
      "Loss = 2.6511e-01, PNorm = 36.0785, GNorm = 0.9959, lr_0 = 3.1123e-04\n",
      "Loss = 3.1090e-01, PNorm = 36.0933, GNorm = 3.5354, lr_0 = 3.0309e-04\n",
      "Validation rmse = 0.913930\n",
      " 53%|█████▎    | 16/30 [00:42<00:37,  2.66s/it]Epoch 16\n",
      "Loss = 2.7750e-01, PNorm = 36.1098, GNorm = 5.7057, lr_0 = 2.9515e-04\n",
      "Loss = 2.6774e-01, PNorm = 36.1248, GNorm = 4.4973, lr_0 = 2.8743e-04\n",
      "Loss = 3.0293e-01, PNorm = 36.1379, GNorm = 2.7240, lr_0 = 2.7990e-04\n",
      "Validation rmse = 0.904558\n",
      " 57%|█████▋    | 17/30 [00:45<00:34,  2.67s/it]Epoch 17\n",
      "Loss = 3.0854e-01, PNorm = 36.1490, GNorm = 4.0719, lr_0 = 2.7257e-04\n",
      "Loss = 2.6281e-01, PNorm = 36.1612, GNorm = 1.6116, lr_0 = 2.6544e-04\n",
      "Loss = 3.0573e-01, PNorm = 36.1744, GNorm = 2.5326, lr_0 = 2.5849e-04\n",
      "Validation rmse = 0.894388\n",
      " 60%|██████    | 18/30 [00:48<00:32,  2.68s/it]Epoch 18\n",
      "Loss = 2.3947e-01, PNorm = 36.1887, GNorm = 3.4737, lr_0 = 2.5172e-04\n",
      "Loss = 2.4217e-01, PNorm = 36.1991, GNorm = 3.6240, lr_0 = 2.4513e-04\n",
      "Loss = 2.8116e-01, PNorm = 36.2125, GNorm = 2.1743, lr_0 = 2.3872e-04\n",
      "Validation rmse = 0.910276\n",
      " 63%|██████▎   | 19/30 [00:50<00:29,  2.67s/it]Epoch 19\n",
      "Loss = 2.2969e-01, PNorm = 36.2199, GNorm = 2.5712, lr_0 = 2.3247e-04\n",
      "Loss = 2.4296e-01, PNorm = 36.2325, GNorm = 1.4380, lr_0 = 2.2638e-04\n",
      "Loss = 2.8259e-01, PNorm = 36.2441, GNorm = 3.8582, lr_0 = 2.2045e-04\n",
      "Validation rmse = 0.880858\n",
      " 67%|██████▋   | 20/30 [00:53<00:26,  2.67s/it]Epoch 20\n",
      "Loss = 1.8639e-01, PNorm = 36.2527, GNorm = 0.9286, lr_0 = 2.1468e-04\n",
      "Loss = 2.7314e-01, PNorm = 36.2643, GNorm = 2.2639, lr_0 = 2.0906e-04\n",
      "Loss = 2.5590e-01, PNorm = 36.2746, GNorm = 1.5546, lr_0 = 2.0359e-04\n",
      "Loss = 2.5851e-01, PNorm = 36.2822, GNorm = 3.5036, lr_0 = 1.9826e-04\n",
      "Validation rmse = 0.897225\n",
      " 70%|███████   | 21/30 [00:56<00:24,  2.72s/it]Epoch 21\n",
      "Loss = 2.1219e-01, PNorm = 36.2886, GNorm = 2.4379, lr_0 = 1.9307e-04\n",
      "Loss = 2.5951e-01, PNorm = 36.2955, GNorm = 1.8413, lr_0 = 1.8802e-04\n",
      "Loss = 2.4872e-01, PNorm = 36.3054, GNorm = 2.3057, lr_0 = 1.8309e-04\n",
      "Validation rmse = 0.864501\n",
      " 73%|███████▎  | 22/30 [00:58<00:21,  2.71s/it]Epoch 22\n",
      "Loss = 2.2059e-01, PNorm = 36.3138, GNorm = 3.5699, lr_0 = 1.7830e-04\n",
      "Loss = 2.3064e-01, PNorm = 36.3233, GNorm = 1.1483, lr_0 = 1.7363e-04\n",
      "Loss = 2.8782e-01, PNorm = 36.3276, GNorm = 2.7171, lr_0 = 1.6909e-04\n",
      "Validation rmse = 0.895253\n",
      " 77%|███████▋  | 23/30 [01:01<00:18,  2.69s/it]Epoch 23\n",
      "Loss = 2.8321e-01, PNorm = 36.3335, GNorm = 0.7589, lr_0 = 1.6466e-04\n",
      "Loss = 2.6805e-01, PNorm = 36.3404, GNorm = 5.2753, lr_0 = 1.6035e-04\n",
      "Loss = 2.1341e-01, PNorm = 36.3491, GNorm = 0.8576, lr_0 = 1.5615e-04\n",
      "Validation rmse = 0.869558\n",
      " 80%|████████  | 24/30 [01:04<00:16,  2.69s/it]Epoch 24\n",
      "Loss = 1.8946e-01, PNorm = 36.3554, GNorm = 1.5040, lr_0 = 1.5206e-04\n",
      "Loss = 2.2613e-01, PNorm = 36.3613, GNorm = 0.8326, lr_0 = 1.4808e-04\n",
      "Loss = 2.3844e-01, PNorm = 36.3685, GNorm = 1.6475, lr_0 = 1.4421e-04\n",
      "Validation rmse = 0.850918\n",
      " 83%|████████▎ | 25/30 [01:06<00:13,  2.69s/it]Epoch 25\n",
      "Loss = 1.3105e-01, PNorm = 36.3752, GNorm = 1.0198, lr_0 = 1.4043e-04\n",
      "Loss = 2.4568e-01, PNorm = 36.3800, GNorm = 1.6739, lr_0 = 1.3676e-04\n",
      "Loss = 2.2130e-01, PNorm = 36.3825, GNorm = 1.2668, lr_0 = 1.3318e-04\n",
      "Loss = 2.1714e-01, PNorm = 36.3880, GNorm = 2.2643, lr_0 = 1.2969e-04\n",
      "Loss = 3.0372e-01, PNorm = 36.3887, GNorm = 1.2243, lr_0 = 1.2935e-04\n",
      "Validation rmse = 0.859540\n",
      " 87%|████████▋ | 26/30 [01:09<00:10,  2.68s/it]Epoch 26\n",
      "Loss = 2.2137e-01, PNorm = 36.3951, GNorm = 1.3823, lr_0 = 1.2596e-04\n",
      "Loss = 2.3995e-01, PNorm = 36.4003, GNorm = 4.5272, lr_0 = 1.2266e-04\n",
      "Loss = 2.2001e-01, PNorm = 36.4044, GNorm = 2.1139, lr_0 = 1.1945e-04\n",
      "Validation rmse = 0.861988\n",
      " 90%|█████████ | 27/30 [01:12<00:08,  2.67s/it]Epoch 27\n",
      "Loss = 2.2360e-01, PNorm = 36.4089, GNorm = 1.1293, lr_0 = 1.1632e-04\n",
      "Loss = 2.5906e-01, PNorm = 36.4125, GNorm = 1.8932, lr_0 = 1.1328e-04\n",
      "Loss = 1.9033e-01, PNorm = 36.4167, GNorm = 1.1025, lr_0 = 1.1031e-04\n",
      "Validation rmse = 0.856083\n",
      " 93%|█████████▎| 28/30 [01:14<00:05,  2.67s/it]Epoch 28\n",
      "Loss = 2.0144e-01, PNorm = 36.4215, GNorm = 3.2660, lr_0 = 1.0743e-04\n",
      "Loss = 1.9704e-01, PNorm = 36.4257, GNorm = 2.0642, lr_0 = 1.0461e-04\n",
      "Loss = 2.5364e-01, PNorm = 36.4298, GNorm = 1.1313, lr_0 = 1.0187e-04\n",
      "Validation rmse = 0.887431\n",
      " 97%|█████████▋| 29/30 [01:17<00:02,  2.67s/it]Epoch 29\n",
      "Loss = 2.3404e-01, PNorm = 36.4344, GNorm = 2.5926, lr_0 = 1.0000e-04\n",
      "Loss = 2.1785e-01, PNorm = 36.4391, GNorm = 1.8008, lr_0 = 1.0000e-04\n",
      "Loss = 1.8145e-01, PNorm = 36.4435, GNorm = 2.0237, lr_0 = 1.0000e-04\n",
      "Validation rmse = 0.850985\n",
      "100%|██████████| 30/30 [01:20<00:00,  2.67s/it]\n",
      "Model 0 best validation rmse = 0.850918 on epoch 24\n",
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Model 0 test rmse = 0.692876                 \n",
      "Ensemble test rmse = 0.692876\n",
      "1-fold cross validation\n",
      "\tSeed 0 ==> test rmse = 0.692876\n",
      "Overall test rmse = 0.692876 +/- 0.000000\n",
      "Elapsed time = 0:01:21\n"
     ]
    }
   ],
   "source": [
    "def run_chemprop(batchsize):\n",
    "    train_arguments = [\n",
    "        '--data_path', '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/train_dataset.csv',\n",
    "        '--dataset_type', 'regression',\n",
    "        '--save_dir', '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/',\n",
    "        '--batch_size', str(batchsize), \n",
    "    ]\n",
    "\n",
    "    train_args = chemprop.args.TrainArgs().parse_args(train_arguments)\n",
    "    mean_score, std_score = chemprop.train.cross_validate(args=train_args, train_func=chemprop.train.run_training)\n",
    "\n",
    "    test_arguments = [\n",
    "    '--test_path', '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/test_dataset.csv',\n",
    "    '--preds_path', 'preds.csv',\n",
    "    '--checkpoint_dir', '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/', \n",
    "    ]   \n",
    "\n",
    "    test_args = chemprop.args.PredictArgs().parse_args(test_arguments)\n",
    "    preds = chemprop.train.make_predictions(args=test_args)\n",
    "\n",
    "    preds = pd.read_csv(\"preds.csv\")\n",
    "    y_preds = [[target] for target in preds[\"target\"].values]\n",
    "    test = pd.read_csv(\"test_dataset.csv\")\n",
    "    y_test = [[target] for target in test[\"target\"].values]\n",
    "    dataset_type = 'test'\n",
    "    num_tasks = len(y_preds[0])\n",
    "    results = evaluate_predictions(preds=y_preds, targets=y_test, num_tasks=num_tasks, metrics=['rmse', 'r2'], dataset_type=dataset_type)\n",
    "  \n",
    "    return results['rmse'], results['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training args\n",
      "Setting molecule featurization parameters to default.\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8998it [00:00, 375040.72it/s]\n",
      "100%|██████████| 8998/8998 [00:00<00:00, 248180.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating SMILES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size = 8,998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:10<00:00, 70.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to preds.csv\n",
      "Elapsed time = 0:01:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_arguments = [\n",
    "    '--test_path', '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/test_dataset.csv',\n",
    "    '--preds_path', 'preds.csv',\n",
    "    '--checkpoint_dir', '/Users/sinhanushka_/Documents/GitHub/02-750-Final-Project/', \n",
    "    '--batch_size', '25', \n",
    "]\n",
    "\n",
    "test_args = chemprop.args.PredictArgs().parse_args(test_arguments)\n",
    "preds = chemprop.train.make_predictions(args=test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': [0.760796544846458], 'r2': [0.6866690741579313]}\n"
     ]
    }
   ],
   "source": [
    "preds = pd.read_csv(\"preds.csv\")\n",
    "y_preds = [[target] for target in preds[\"target\"].values]\n",
    "test = pd.read_csv(\"test_dataset.csv\")\n",
    "y_test = [[target] for target in test[\"target\"].values]\n",
    "dataset_type = 'test'\n",
    "num_tasks = len(y_preds[0])\n",
    "results = evaluate_predictions(preds=y_preds, targets=y_test, num_tasks=num_tasks, metrics=['rmse', 'r2'], dataset_type=dataset_type)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for three different batches\n",
    "    # Run for three different seeds \n",
    "        # A while loop that runs until we have 20% \n",
    "            # train_args \n",
    "                # get the metrics \n",
    "            # pred args\n",
    "                # predictions and evaluation \n",
    "            # randomly select 10 samples \n",
    "            # remove them from the test\n",
    "            # update train_args \n",
    "            # update pred_args\n",
    "            # return \n",
    "def random_sampling_chemprop(batchsize):\n",
    "    seeds = [1, 2, 3]\n",
    "    \n",
    "    rmse_vals = []\n",
    "    r2_vals = []\n",
    "\n",
    "    data = pd.read_csv(\"TYK2_final.csv\", index_col=False)\n",
    "    data = data.drop(['target', 'top_2p', 'top_5p'], axis=1)\n",
    "    column_names = ['smiles', 'target']\n",
    "    data.columns = column_names\n",
    "\n",
    "    for seed in seeds:\n",
    "        rmse_instance = []\n",
    "        r2_instance = []\n",
    "        # Get the data \n",
    "        data = np.array(data)\n",
    "        shuffled_data = shuffle(data, random_state=seed)\n",
    "        size = int(len(shuffled_data)*0.1)\n",
    "        train, test = shuffled_data[:size], shuffled_data[size:]\n",
    "        train_df = pd.DataFrame(train, columns=column_names)\n",
    "        train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "        test_df = pd.DataFrame(test, columns=column_names)\n",
    "        test_df.to_csv(\"test_dataset.csv\", index=False)\n",
    "        \n",
    "        counter = 0\n",
    "        while len(train_df) <= round(((len(shuffled_data) * 0.2) / 500 )) * 500:\n",
    "            if counter % 10 == 0:\n",
    "                rmse, r2 = run_chemprop(batchsize) \n",
    "                rmse_instance.append(rmse)\n",
    "                r2_instance.append(r2)\n",
    "            train_df =  pd.concat([train_df, test_df.iloc[0]])  \n",
    "            test_df = test_df.drop(test_df.index[0]) \n",
    "            \n",
    "            # Update the csv\n",
    "            train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "            test_df.to_csv(\"test_dataset.csv\", index=False)\n",
    "\n",
    "            counter += batchsize\n",
    "\n",
    "        rmse_vals.append(rmse_instance)\n",
    "        r2_vals.append(r2_instance)\n",
    "\n",
    "    return rmse_vals, r2_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1]\n",
    "rand_rmse_dict = {}\n",
    "rand_r2_dict = {}\n",
    "\n",
    "final_rand_data_chemprop = pd.DataFrame()\n",
    "\n",
    "for batch in batch_sizes:\n",
    "\n",
    "    rand_rmse, rand_r2 = random_sampling_chemprop(batch)\n",
    "\n",
    "    rand_rmse_mean = np.mean(rand_rmse, axis=0)\n",
    "    rand_rmse_stdev = np.std(rand_rmse, axis=0)\n",
    "    print(\"mean:\", rand_rmse_mean)\n",
    "    print(\"standard deviation:\", rand_rmse_stdev)\n",
    "    rand_rmse_dict[batch] = (rand_rmse, rand_rmse_mean, rand_rmse_stdev)\n",
    "    final_rand_data_chemprop[f\"{batch}_rmse_mean\"] = rand_rmse_mean\n",
    "    final_rand_data_chemprop[f\"{batch}_rmse_stdev\"] = rand_rmse_stdev\n",
    "\n",
    "\n",
    "    rand_r2_mean = np.mean(rand_r2, axis=0)\n",
    "    rand_r2_stdev = np.std(rand_r2, axis=0)\n",
    "    print(\"mean:\", rand_r2_mean)\n",
    "    print(\"standard deviation:\", rand_r2_stdev)\n",
    "    rand_r2_dict[batch] = (rand_r2, rand_r2_mean, rand_r2_stdev)\n",
    "    final_rand_data_chemprop[f\"{batch}_r2_mean\"] = rand_r2_mean\n",
    "    final_rand_data_chemprop[f\"{batch}_r2_stdev\"] = rand_r2_stdev\n",
    "\n",
    "\n",
    "final_rand_data_chemprop.to_csv(\"final_data_random_chemprop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Run monte carlo dropout \n",
    "# Choose the sample with the highest dropout\n",
    "# Add it to training set \n",
    "# Remove it from the over all dataset "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('chemprop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "782c9f00c2f68b1c6d352eaff4906d850c3b7373af8ce254d2b87e9de0bd114a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
